{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-08-29T01:13:59.903432198Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【Rust日报】2021-08-28 开源操作系统夏令营最终报告会安排","link":"https://rustcc.cn/article?id=ef3dd4e8-a8e8-4fec-bc7e-75703e1117ff","description":"<h3>开源操作系统夏令营最终报告会安排</h3>\n<p>会议主题：开源操作系统夏令营最终报告会\n会议时间：2021/08/29 09:00-11:30 (GMT+08:00) 中国标准时间 - 北京\n点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/Mp7T1h5zeQOk?rs=25\n会议 ID：635 194 989</p>\n<p>下面是9位全程参与夏令营活动同学的报告顺序。每人报告时间最长15分钟。</p>\n<ol>\n<li>杨云枫 王涛 Rustsbi的哪吒开发版移植</li>\n<li>兰陈昕 zCore图形支持</li>\n<li>都秉甲 容器技术学习</li>\n<li>薛潇巍 RVM 的 RISC-V 支持</li>\n<li>陈乐 共享调度器</li>\n<li>吴非凡 基于用户态中断的异步系统调用设计与实现</li>\n<li>彭淳毅 陈志扬 基于rCore-Tutorial的性能分析软件实现</li>\n</ol>\n<h3>crates.live：可视化 Rust crates 依赖项</h3>\n<p>crates.live 是来自 crates.io 的 Rust crates 的依赖可视化工具。 它显示了 Rust crates（包）的依赖树。功能包括：</p>\n<ul>\n<li>依赖解析， crates.live 引擎通过匹配依赖版本来完成完整的依赖解析。</li>\n<li>交互式图表，带有标记的板条箱的可缩放交互式图表。</li>\n<li>图像导出， 将图形导出为 PNG。</li>\n<li>开放 API：（即将推出）GraphQL API。</li>\n</ul>\n<p>crates.live 使用了一堆技术框架，技术栈包括：</p>\n<ul>\n<li>Rust， crates.live 后端和爬虫是用 Rust 和开源 Rust 库开发的。</li>\n<li>GraphQl， WASM 驱动的 GraphQL 服务器。</li>\n<li>React/Bulma， 前端库。</li>\n<li>Terraform， 帮助启动和维护我们的基础设施。</li>\n<li>Cloudflare， Cloudflare 工作人员运行 WASM 后端。</li>\n</ul>\n<p>如果在使用此应用程序时有任何疑问、建议或问题； 可以通过 contact@crates.live 联系。 crates.live 由 Abid Omar 开发，可通过 contact@omarabid.com 联系。</p>\n<p><a href=\"https://crates.live/\" rel=\"noopener noreferrer\">链接</a>：https://crates.live/</p>\n<h3>Obake，版本化数据结构</h3>\n<p>Obake 是一个用于声明和维护版本化数据结构的过程宏。 “obake”这个名字取自日语“お化け（おばけ）”，这是日本民间传说中一类会变形的超自然生物。</p>\n<p>在开发应用程序时，配置格式和内部数据结构通常会在版本之间演变。 然而，保持这些版本之间的向后兼容性需要声明和维护遗留格式的数据结构和用于在它们之间迁移的代码。 Obake 的目标是让这个过程变得轻松。</p>\n<pre><code>#[obake::versioned]                 // create a versioned data-structure\n#[obake(version(\"0.1.0\"))]          // declare some versions\n#[obake(version(\"0.2.0\"))]\n#[derive(PartialEq, Eq, Hash)]      // additional attributes are applied to all versions\nstruct Foo {\n    #[obake(cfg(\"0.1.0\"))]          // enable fields for specific versions with\n    foo: String,                    // semantic version constraints\n   \n    #[obake(cfg(\"&gt;=0.2, &lt;=0.3.0\"))] // any semantic version constraint can appear in\n    bar: u32,                       // a `cfg` attribute \n   \n    #[obake(cfg(\"0.1.0\"))]          // multiple `cfg` attributes are treated as a\n    #[obake(cfg(\"&gt;=0.3\"))]          // disjunction over version constraints\n    baz: char,\n}\n\n// describe migrations between versions using the `From` trait\n// and an automatically generated type-level macro for referring to\n// specific versions of `Foo`\nimpl From&lt;Foo![\"0.1.0\"]&gt; for Foo![\"0.2.0\"] {\n    fn from(foo: Foo![\"0.1.0\"]) -&gt; Self {\n        Self { bar: 0 }\n    }\n}\n\n// an enumeration of all versions of `Foo` is accessed using the\n// `obake::Versioned` trait:\nlet versioned_example: &lt;Foo as obake::Versioned&gt;::Versioned = unimplemented!();\n\n// this enumeration implements `Into&lt;Foo&gt;`, where `Foo` is the latest declared\n// version of `Foo` (in this case, `Foo![\"0.2.0\"]`)\nlet example: Foo = versioned_example.into();\n</code></pre>\n<p>Github<a href=\"https://github.com/doctorn/obake\" rel=\"noopener noreferrer\">链接</a>：https://github.com/doctorn/obake</p>\n<h3>iced，跨平台 GUI 库</h3>\n<p>iced，Rust 的跨平台 GUI 库，专注于简单性和类型安全。 灵感来自<a href=\"https://elm-lang.org/\" rel=\"noopener noreferrer\">Elm</a>。</p>\n<p><img src=\"https://raw.githubusercontent.com/hecrj/iced/master/docs/graphs/ecosystem.png\" alt=\"eco\"></p>\n<p>Github<a href=\"https://github.com/hecrj/iced/\" rel=\"noopener noreferrer\">链接</a>：https://github.com/hecrj/iced/</p>\n<p>示例：https://github.com/hecrj/iced/tree/master/examples</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929\" rel=\"noopener noreferrer\">洋芋</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-28 15:42:07","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-8-27 Rudra Rust 的内存安全和未定义行为检测工具","link":"https://rustcc.cn/article?id=ce7eb559-fdda-45d7-a53e-293af787a813","description":"<h4>Rudra Rust 的内存安全和未定义行为检测工具</h4>\n<p>Rudra 是一个静态分析器，用于检测 Rust 程序中常见的未定义行为。它能够分析单个 Rust 包以及 crates.io 上的所有包。Rudra 及其相关论文将在 Proceedings of the 28th ACM Symposium on Operating Systems Principles 2021 (SOSP '21) 上发表。</p>\n<ul>\n<li>https://github.com/sslab-gatech/Rudra#readme</li>\n</ul>\n<h4>nom 7.0 版本发布</h4>\n<p>nom 是一个用 Rust 编写的解析器组合库。它的目标是提供工具来构建安全的解析器，而不会影响速度或内存消耗。为此，它广泛使用 Rust 的强类型和内存安全来生成快速且正确的解析器，并提供函数、宏和特征来抽象大部分容易出错的管道。目前7.0已经发布</p>\n<ul>\n<li>https://crates.io/crates/nom</li>\n</ul>\n<h4>egui 0.14 版本发布</h4>\n<p>egui 是一个易于使用的纯 Rust 图形用户界面。egui 可以在 Web 上、本机上以及您最喜欢的游戏引擎中运行。egui 旨在成为最容易使用的 Rust GUI 库，以及在 Rust 中制作 Web 应用程序的最简单方法，它可以在任何可以绘制纹理三角形的地方使用，这意味着您可以轻松地将其集成到您选择的游戏引擎中。</p>\n<ul>\n<li>演示文档：https://emilk.github.io/egui/</li>\n<li>https://github.com/emilk/egui</li>\n</ul>\n<hr>\n<p>From 日报小组 北纬27度，侯盛鑫</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 14:27:47","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"开源项目xiu登上了GitHub rust trending榜","link":"https://rustcc.cn/article?id=86c83d9a-8370-42cf-8993-ef15af6932c4","description":"<p><a href=\"https://github.com/harlanc/xiu\" rel=\"noopener noreferrer\">https://github.com/harlanc/xiu</a></p>\n<p><a href=\"https://github.com/trending/rust?since=daily\" rel=\"noopener noreferrer\">https://github.com/trending/rust?since=daily</a></p>\n<p>感谢大家的支持！！</p>\n<p>PS：</p>\n<p>前三名有两个都在论坛里发过，这个论坛有点狠，哈哈</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 10:43:48","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Salvo - 一个简单的 Web 后端框架","link":"https://rustcc.cn/article?id=e5dc5be9-b1ab-488f-8944-dd7cd97b0128","description":"<h2>为什么要写这个框架</h2>\n<p>因为我笨，无法学会使用 actix-web 等现存的框架。当我想把以前的 go 的 web 服务使用 rust 实现时，一眼看去，似乎每个框架都比 go 里存在框架复杂, 本来 Rust 的学习曲线就够陡峭的了, 又何苦把 Web 框架整得那么复杂?</p>\n<h2>如何做到足够简单</h2>\n<p>很多底层的实现 Hyper 都已经实现，所以，一般需求，基于 Hyper 实现应该没有错。Salvo 也是一样。 核心功能是提供还用简单的API，以及一个功能强大并且灵活的路由系统。</p>\n<p>Salvo 里统一了 Handler 和 Middleware. Middleware 就是 Handler. 通过路由的 before 或者 after 添加到 Router 上。本质上, Middleware 和 Handler 都是处理 Request 请求，并且可能向 Response 写入数据。而 Handler 接收的参数是 Request, Depot, Response 三个, 其中 Depot 用于存储请求处理过程中的临时数据. 为方便书写, 在用不着的情况下可以省略掉某些参数.</p>\n<pre><code>use Salvo::prelude::*;\n\n#[fn_handler]\nasync fn hello_world(_req: &amp;mut Request, _depot: &amp;mut Depot, res: &amp;mut Response) {\n    res.render_plain_text(\"Hello World\");\n}\n#[fn_handler]\nasync fn hello_world2(res: &amp;mut Response) {\n    res.render_plain_text(\"Hello World\");\n}\n</code></pre>\n<p>另外路由系统提供的 API 也是极其简单的, 但是, 功能却是强大的. 正常使用需求下, 基本上就是只关注 Router 一个类型即可.</p>\n<h3>路由系统</h3>\n<p>我自己感觉路由系统是跟其他的框架不太一样的. Router 可以写平，也可以写成树状。这里区业务逻辑树与访问目录树。业务逻辑树是根据业务逻辑需求，划分 router 结构，形成 router 树，它不一定与访问目录树一致。</p>\n<p>正常情况下我们是这样写路由的：</p>\n<pre><code>Router::new().path(\"articles\").get(list_articles).post(create_article);\nRouter::new()\n    .path(\"articles/&lt;id&gt;\")\n    .get(show_article)\n    .patch(edit_article)\n    .delete(delete_article);\n</code></pre>\n<p>往往查看文章和文章列表是不需要用户登录的, 但是创建, 编辑, 删除文章等需要用户登录认证权限才可以. Salvo 中支持嵌套的路由系统可以很好地满足这种需求. 我们可以把不需要用户登录的路由写到一起：</p>\n<pre><code>Router::new()\n    .path(\"articles\")\n    .get(list_articles)\n    .push(Router::new().path(\"&lt;id&gt;\").get(show_article));\n</code></pre>\n<p>然后把需要用户登录的路由写到一起， 并且使用相应的中间件验证用户是否登录：</p>\n<pre><code>Router::new()\n    .path(\"articles\")\n    .before(auth_check)\n    .post(list_articles)\n    .push(Router::new().path(\"&lt;id&gt;\").patch(edit_article).delete(delete_article));\n</code></pre>\n<p>虽然这两个路由都有这同样的 <code>path(\"articles\")</code>, 然而它们依然可以被同时添加到同一个父路由, 所以最后的路由长成了这个样子:</p>\n<pre><code>Router::new()\n    .push(\n        Router::new()\n            .path(\"articles\")\n            .get(list_articles)\n            .push(Router::new().path(\"&lt;id&gt;\").get(show_article)),\n    )\n    .push(\n        Router::new()\n            .path(\"articles\")\n            .before(auth_check)\n            .post(list_articles)\n            .push(Router::new().path(\"&lt;id&gt;\").patch(edit_article).delete(delete_article)),\n    );\n</code></pre>\n<p><code>&lt;id&gt;</code>匹配了路径中的一个片段, 正常情况下文章的 <code>id</code> 只是一个数字, 这是我们可以使用正则表达式限制 <code>id</code> 的匹配规则, <code>r\"&lt;id:/\\d+/&gt;\"</code>.</p>\n<p>更多信息可以查看网站 https://salvo.rs</p>\n<p>源码地址: https://github.com/salvo-rs/salvo</p>\n<p>非常欢迎大家为项目贡献力量，可以通过以下方法为项目作出贡献:</p>\n<ul>\n<li>在 issue 中提交功能需求和 bug report;</li>\n<li>在 issues 或者 require feedback 下留下自己的意见;</li>\n<li>通过 pull requests 提交代码;</li>\n<li>在博客或者技术平台发表 Salvo 相关的技术文章。</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 00:23:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"[已解决]println! 严重拖延效能，仅列印一行","link":"https://rustcc.cn/article?id=ab0d06cb-d33d-4e18-b7b3-0b3e889f7b11","description":"<p>当把call函数注解后，或是注解println! 都可以快速运行。</p>\n<p>在 https://play.rust-lang.org/ 上有时候可以 \"\"使用println! \"\" 而且依然编译的很快，有时候则不行，我自己本地电脑都不行。</p>\n<p>这效能差了十万八千里，请大家帮忙，新手总是在 println! 跌坑。</p>\n<p>这边使用 <code>cargo run --release</code> 编译</p>\n<pre><code>use std::time::{Duration, Instant};\n\nstruct Struct {\n    a: String,\n    b: bool,\n}\ntrait Dyn {}\nimpl Dyn for Struct {}\n\nfn main() {\n    let start = Instant::now();\n    let mut count = 0;\n    let count_end = 100_000_000i64;\n\n    while count &lt;= count_end {\n        let m: Box&lt;Struct&gt; = Box::new(Struct {\n            b: false,\n            a: \"str\".to_string(),\n        });\n        if count == count_end {\n            call();               // ---- 这儿\n            m.b;\n            m.a;\n        }\n        count += 1;\n    }\n\n    let duration = start.elapsed();\n    println!(\"Time: {:?}\", duration);\n}\n\nfn call(){\n    println!(\"run call()\\n\");     // ---- 重点在这儿，注解后变超快\n}\n</code></pre>\n<p>Time:</p>\n<table>\n<thead>\n<tr>\n<th align=\"right\">😫使用println!</th>\n<th align=\"right\">😄注解//println!</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"right\">12.863911s</td>\n<td align=\"right\">2.8486ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.2101748s</td>\n<td align=\"right\">2.4661ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.5353751s</td>\n<td align=\"right\">2.0433ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.4852107s</td>\n<td align=\"right\">1.7869ms</td>\n</tr>\n<tr>\n<td align=\"right\">————————</td>\n<td align=\"right\">————————</td>\n</tr>\n</tbody>\n</table>\n<hr>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 16:17:11","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-8-26 Pin,Unpin为什么Rust需要它们","link":"https://rustcc.cn/article?id=59d42687-69e5-4d20-ab8a-e296404fba92","description":"<h3>Pin,Unpin为什么Rust需要它们</h3>\n<p>又是一篇讲<code>Pin</code>的blog，是作者本人在学习Rust异步过程中做的一些总结和理解，方便大家在学习异步时遇到相关疑惑可以查阅。</p>\n<p><a href=\"https://blog.adamchalmers.com/pin-unpin/\" rel=\"noopener noreferrer\">Read More</a>: https://blog.adamchalmers.com/pin-unpin/</p>\n<h3><code>Typing the technical interview</code>从Haskell翻译到Rust</h3>\n<p><code>Typing the technical interview</code>是一篇将计算机知识拟作魔法的小说？鉴于小编学识有限，对这篇blog不是很了解，如有对这篇Blog熟悉的小伙伴，可以帮忙介绍一下。原文提到的相关代码都是使用Haskell写的，现在社区里有人将其用Rust重新实现了一遍：</p>\n<p><a href=\"https://github.com/insou22/typing-the-technical-interview-rust/\" rel=\"noopener noreferrer\">Github</a>: https://github.com/insou22/typing-the-technical-interview-rust/</p>\n<p>同时，如果对这篇原文感兴趣的，链接也在这里：</p>\n<p><a href=\"https://aphyr.com/posts/342-typing-the-technical-interview\" rel=\"noopener noreferrer\">Read More</a>: https://aphyr.com/posts/342-typing-the-technical-interview</p>\n<h3>关于Futures和运行时如何工作的心智模型</h3>\n<blockquote>\n<p>这一部分的主要目标是建立一个高层次的心理模型，说明我们在前一章中读到的不同部分是如何一起工作的。我希望这将使我们在接下来的几章中深入研究特质对象和生成器等主题之前，更容易理解高层次的概念。</p>\n</blockquote>\n<blockquote>\n<p>这并不是创建一个异步系统模型的唯一方法，因为我们要对运行时的具体情况进行假设，而这些情况可能会有很大的不同。这是我认为最容易建立的方式，而且对于理解你在异步生态系统中发现的很多真实的实现也很有意义。</p>\n</blockquote>\n<blockquote>\n<p>最后，请注意，由于需要简洁明了，代码本身是 \"假的\"。</p>\n</blockquote>\n<p><a href=\"https://cfsamson.github.io/books-futures-explained/2_a_mental_model_for_futures.html\" rel=\"noopener noreferrer\">Read More</a>: https://cfsamson.github.io/books-futures-explained/2_a_mental_model_for_futures.html</p>\n<p>From 日报小组 Cupnfish</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rust.cc 论坛: 支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 14:30:26","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【全职远程】30k-50k/硅谷初创公司招/嵌入式开发/中文友好","link":"https://rustcc.cn/article?id=f8bcde1a-4455-455e-ad89-d1e507132c57","description":"<p>公司简介\n我们是一家总部位于硅谷的初创公司，公司的核心开发人员来自于Google, 亚马逊，vmware等一线企业，技术实力雄厚。</p>\n<p>岗位要求\n1、本科以上学历，专业不限；热爱编程，不怕麻烦，具有死磕精神；</p>\n<p>2、深入理解Linux操作内核的一个或多个子系统，譬如进程管理、内存管理、设备管理、网络子系统；</p>\n<p>3、深入参与过嵌入式产品开发的整个生命周期，包括但不局限于Bootloader, Kernel, driver, 应用层；</p>\n<p>4、扎实的C语言编程和调试功底，丰富的应用层开发经验，对内存泄漏和段错误处理有过丰富的处理经验；</p>\n<p>5、有独立开发或者主导开发项目经验的应聘者优先考虑；有独立作品来展示自己水平的应聘者优先考虑。</p>\n<p>除了工作所需的必要技能之外，我们还希望您是一个有责任心和好奇心的开发人员，能跟公司一起快速成长。</p>\n<p>职位要求\n在团队负责人的带领参与公司老产品的维护和新产品的研发。</p>\n<p>薪资福利\n1、月薪30k-50k；</p>\n<p>2、入职满一年，表现合格者可以获得公司的股票或期权；</p>\n<p>3、优秀者提供移民美国，加拿大的机会。</p>\n<p>工作方式\n1、远程办公</p>\n<p>2、工作时间：无固定时间，工作完成后自由安排</p>\n<p>3、很少有跨时区的会议，除特殊、紧急工作任务对接外</p>\n<p>4、工作会议主要为中文交流</p>\n<p>工作语言\n1、中文为主，英文为辅；</p>\n<p>2、不要求很强的听说，只要求读写能力及格。</p>\n<p>录用流程\n1、收到简历后，将安排1到3轮电话语音面试（优秀者一轮面试即可）；</p>\n<p>2、电话语音面试结束后，将进入试用期（全额工资）；</p>\n<p>3、试用期结束后，正式开始工作。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 11:18:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust trait套娃实现,","link":"https://rustcc.cn/article?id=bff10963-a6a9-4cc7-a3ce-4cfde731c72e","description":"<pre><code>impl&lt;'c, C: ?Sized + Completer&gt; Completer for &amp;'c C {\n    type Candidate = C::Candidate;\n\n    fn complete(\n        &amp;self,\n        line: &amp;str,\n        pos: usize,\n        ctx: &amp;Context&lt;'_&gt;,\n    ) -&gt; Result&lt;(usize, Vec&lt;Self::Candidate&gt;)&gt; {\n        (**self).complete(line, pos, ctx)\n    }\n\n    fn update(&amp;self, line: &amp;mut LineBuffer, start: usize, elected: &amp;str) {\n        (**self).update(line, start, elected)\n    }\n}\n</code></pre>\n<p>这种套娃实现trait的方式如何理解啊， 师傅们有了解的吗</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 11:05:42","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"远程办公，不限地域，缴纳社保公积金，周末双休，告别 996，拒绝 007，Nervina Labs 欢迎你！","link":"https://rustcc.cn/article?id=a4789334-4646-4a33-86a2-21bc65a50824","description":"<p>Rust开发工程师\n岗位职责：\n1、负责智能合约的开发及设计；\n2、负责区块链业务系统分析与设计工作；\n3、负责智能合约代码测试、运行和维护。</p>\n<p>任职要求：\n1、计算机相关专业本科及以上学历，3年以上工作经验；\n2、熟练掌握 C/C++、Rust 等系统开发语言至少一种，至少有过两年相关开发经验；\n3、对数据结构和算法，对密码学，安全协议和加密算法有研究者优先；\n4、优秀的英语文档撰写与阅读能力者优先；\n5、了解区块链，有合约开发经验更佳。\n团队介绍：为什么加入我们\n1、100%远程工作，你可以base在全球任何你想待的地方；</p>\n<p>2、每年至少5天以上的年假，2次旅游工作的机会；</p>\n<p>3、全员高温补贴+电脑补助+网络加速补助</p>\n<p>4、五险一金+入职大礼包</p>\n<p>公司产品\n简洁有趣的产品介绍，能让用户最快速度了解公司业务。把自家优秀的产品展示出来吸引人才围观吧！</p>\n<p>公司介绍\n节点互信由前 Nervos (https://www.nervos.org) 核心应用开发者发起。我们的理想是通过技术和商业努力，让区块链技术尽早落地，让普通用户也能够享受区块链技术带来的价值。我们将与广大传统互联网公司合作，在版权、物权、数字身份等领域打造开放互信共享互通的价值网络平台，帮助传统平台的用户将自己的资产、信息、权益在更开放的区块链平台上实现商业模式升级。</p>\n<p>对待人才，我们有3个关键词：开放、自驱、涌现。我们一直奉行开放和开源的精神，坚信透明是信任的基础，开源是区块链的基石，所有的项目代码均在Github开源。我们100%远程工作，你可以 base 在全球任何一个你想待的地方。我们鼓励员工对自我进行管理，为区块链生态添砖加瓦。你认为整个区块链生态缺什么，你可以提出方案、预算和招聘需求，公司内部讨论通过后可以给你资源让你去实现。</p>\n<p>作为团队的传统，我们每年计划有两次封闭开发的“团建”活动，一般会选在杭州、青岛等风景饮食俱佳的城市，包下一个民宿或者别墅，用一周左右的时候供大家学习交流。如果你喜欢这样的工作方式，欢迎加入我们。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 07:28:05","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"来说说rust里你最不喜欢的部分是哪些","link":"https://rustcc.cn/article?id=495cd0ad-4c0b-46db-8585-a2a0de1cb43d","description":"<p>先声明，不是黑RUST哦，只是说说RUST中最不讨喜的一些东西而已。\n对我个人来说，最讨厌RUST的宏功能，为什么呢？因为宏功能让RUST的各种库里出现了各种“方言”，RUST的宏功能很强大这个不假，但是这个功能的出现，使得本来就庞杂的RUST进一步出现了更多根本就不在RUST语言里面的“方言”语法，不同的包里不同的方言不同的用法，这会导致RUST的进一步的碎片化，连IDE都无法有效识别宏及里面的语句，RUST本来就繁杂难学，内容众多，宏又进一步加剧了这种情况，使得阅读RUST代码会进一步不直观，所以我最讨厌RUST的宏。\n比如说在tokio里，会有这样的语法</p>\n<p>#[tokio::main]\npub async fn main() -&gt; Result&lt;()&gt; {\nOk(())\n}</p>\n<p>想这样的语句需要看tokio的文档才能知道它输出的完全体大概是啥？好不好？挺好，能少输入几行代码。好不好？不好，我得先理解宏，再结合tokio得文档代码示例，才能确切得知道其代表得完整含义。\n总体上来说，我认为RUST得宏功能既是一个神器，却也是一个巨坑，很讨厌。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 04:04:57","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"数据表 Timestamp 日期 Serialize","link":"https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0","description":"<p>主要参考：<a href=\"https://github.com/rustcc/forustm\" rel=\"noopener noreferrer\">Rustcc网站源码库</a></p>\n<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，\n查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>\n<h2>1.依赖的库：</h2>\n<pre><code>[dependencies]\n# 日期时间处理 需要开启 serde 特征 支持序列化\nchrono = { version = \"0.4.19\", features = [\"serde\"] }\n\n# 数据库ORM\ndiesel = { version = \"1.4.4\", features = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"] }\ndotenv = \"0.15.0\"\nserde = { version = \"1.0.127\", features = [\"derive\"] }\nserde_json = \"1.0.66\"\nuuid = { version = \"0.8.2\", features = [\"serde\", \"v4\"] }\n</code></pre>\n<h2>2.创建数据表</h2>\n<pre><code>CREATE TABLE characters (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(128) UNIQUE NOT NULL,\n    age INTEGER NOT NULL DEFAULT 0,\n    friends VARCHAR NOT NULL DEFAULT '',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n)\n</code></pre>\n<h2>3.数据表对应的 model</h2>\n<pre><code>use chrono::{NaiveDateTime};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Queryable, Serialize, Deserialize, Debug)]\npub struct Characters {\n    pub id: i32,\n    pub name: String,\n    pub age: i32,\n    pub friends: String,\n    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features\n    pub created_at: NaiveDateTime,\n}\n</code></pre>\n<h2>4.获取数据</h2>\n<pre><code>use db::schema::characters;\nuse db::{get_connection};\nuse db::models::{Characters, NewCharacter};\nuse db::schema::characters::dsl::*;\nuse diesel::QueryDsl;\nuse diesel::prelude::*;\n\nfn main() {\n    let conn = get_connection();\n\n    // 查询年龄大于30的10条数据\n    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))\n        .limit(10)\n        .load::&lt;Characters&gt;(&amp;conn)\n        .expect(\"Loading Error\");\n\n    let date_arr = arr.iter()\n        .map(|item| {\n\t    // 数据格式化\n            let t = item.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n            println!(\"{} {}\", item.name, t);\n            t\n        })\n        .collect::&lt;Vec&lt;String&gt;&gt;();\n}\n</code></pre>\n<p>输出结果类似：</p>\n<pre><code>Box 2021-08-05 09:39:34\nBobe 2021-08-05 09:39:34\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 01:40:35","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Cargo workspace config","link":"https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c","description":"<p><a href=\"https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html\" rel=\"noopener noreferrer\">Workspace 文档链接</a></p>\n<h2>目录结构</h2>\n<pre><code>workspace-test/\n    Cargo.toml\n    db/\n        src/\n            bin/\n                init.rs\n        Cargo.tml\n</code></pre>\n<h2>workspace</h2>\n<p>workspace-test/Cargo.toml</p>\n<pre><code>[workspace]\nmembers = [\"db\"]\ndefault-member = \"db\"\n</code></pre>\n<h2>子项目</h2>\n<p>workspace-test/db/Cargo.toml</p>\n<pre><code>[package]\nname = \"db\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n# 可选的可执行文件配置\n# [[bin]]\n# name = \"init\"\n# path = \"src/bin/init.rs\"\n</code></pre>\n<h2>操作</h2>\n<pre><code># 运行 init\ncargo run --bin init\n# -p 指定项目\ncargo run -p db --bin init\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-04 09:54:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程浅悟（一）","link":"https://rustcc.cn/article?id=120035c3-944d-4a79-9b3a-8390697a6e13","description":"<h1><code>Rust</code>异步编程浅悟（一）</h1>\n<p>不同于<code>javascript</code>的<code>new Promise((resolve, reject) =&gt; {...})</code>构造即运行，<code>Rust</code>中的<code>Future</code>是·惰性·状态机。这体现为：</p>\n<ol>\n<li>【调用异步函数】或【执行异步块】仅只构造一个<code>Future trait object</code>。</li>\n<li>因为<code>Future</code>是惰性状态机，所以它不会自动执行【异步函数】或【异步块】内的任何一行代码 --- 此点与<code>javascript</code>的·活性·状态机完全不同。相反，需要人工激活触发。</li>\n<li>人工启动<code>Future</code>运行，又分为两个场景的两种情况：\n<ol>\n<li>\n<p>已经在<code>async fn</code>内，<code>Future.await</code>激活。但，同时<strong>阻塞</strong>当前异步程序执行流。</p>\n</li>\n<li>\n<p>在<code>async fn</code>外，需要借助由【运行时】提供的【执行器】。就<code>async-std</code>库而言，有两个选择：</p>\n<ol>\n<li><code>task::block_on(Future)</code> 执行<code>Future</code>且阻塞当前线程直到<code>Future</code>被完成。</li>\n<li><code>task::spawn(Future)</code>仅执行<code>Future</code>和不阻塞当前线程。</li>\n</ol>\n<p>无论选择上面哪种方式，若在<code>Future</code>执行期间出现了<code>panic</code>，其都会终止（<code>abort</code>）正在共享同一个执行线程（<code>thread</code>）的所有<code>task</code>（·无栈·协程）的运行。</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>题外话，</p>\n<ol>\n<li>绿色线程是·有栈·协程；异步函数与异步块是·无栈·协程。</li>\n<li>在<code>async-std</code>库的词汇表内，协程被称作<code>task</code>而不是惯例的<code>coroutine</code>。</li>\n<li><code>task::spawn(Future)</code>也能被使用于<code>async fn</code>或<code>async {...}</code>内。它被用来代替<code>.await</code>指令，以<strong>非阻塞</strong><code>async fn</code>或<code>async {...}</code>的方式，激活与执行一个<code>Future</code>实例。</li>\n</ol>\n<h2>例程</h2>\n<pre><code>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {\n    // 1. TcpListener::bind(addr) 返回 Future\n    // 2. .await 于 Future 取得 Result&lt;T, E&gt;\n    // 3. Result&lt;T, E&gt;? 再拿得 Ok&lt;T&gt; 中的 T\n    let listener = TcpListener::bind(addr).await?; // 异步函数内的人工启动 Future\n    let mut incoming = listener.incoming();\n    // 因为没有从语言层面支持 async for loop，所以 while loop + Iterator&lt;Item = T&gt; 来模拟之。\n    while let Some(stream) = incoming.next().await {\n        // TODO\n    }\n    Ok(())\n}\nfn main() {\n    let fut = accept_loop(\"127.0.0.1:8080\");\n    task::block_on(fut); // 异步函数外的人工启动 Future\n}\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-03 00:01:43","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-08-27T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"With One Voice: Composing a Travel Voice Assistant from Re-purposed Models. (arXiv:2108.11463v1 [eess.AS])","link":"http://arxiv.org/abs/2108.11463","description":"<p>Voice assistants provide users a new way of interacting with digital\nproducts, allowing them to retrieve information and complete tasks with an\nincreased sense of control and flexibility. Such products are comprised of\nseveral machine learning models, like Speech-to-Text transcription, Named\nEntity Recognition and Resolution, and Text Classification. Building a voice\nassistant from scratch takes the prolonged efforts of several teams\nconstructing numerous models and orchestrating between components. Alternatives\nsuch as using third-party vendors or re-purposing existing models may be\nconsidered to shorten time-to-market and development costs. However, each\noption has its benefits and drawbacks. We present key insights from building a\nvoice search assistant for Booking.com search and recommendation system. Our\npaper compares the achieved performance and development efforts in dedicated\ntailor-made solutions against existing re-purposed models. We share and discuss\nour data-driven decisions about implementation trade-offs and their estimated\noutcomes in hindsight, showing that a fully functional machine learning product\ncan be built from existing models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Poran_S/0/1/0/all/0/1\">Shachaf Poran</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Amsalem_G/0/1/0/all/0/1\">Gil Amsalem</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Beka_A/0/1/0/all/0/1\">Amit Beka</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Goldenberg_D/0/1/0/all/0/1\">Dmitri Goldenberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Attention in Machine Reading Comprehension. (arXiv:2108.11574v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11574","description":"<p>Achieving human-level performance on some of Machine Reading Comprehension\n(MRC) datasets is no longer challenging with the help of powerful Pre-trained\nLanguage Models (PLMs). However, the internal mechanism of these artifacts\nstill remains unclear, placing an obstacle for further understanding these\nmodels. This paper focuses on conducting a series of analytical experiments to\nexamine the relations between the multi-head self-attention and the final\nperformance, trying to analyze the potential explainability in PLM-based MRC\nmodels. We perform quantitative analyses on SQuAD (English) and CMRC 2018\n(Chinese), two span-extraction MRC datasets, on top of BERT, ALBERT, and\nELECTRA in various aspects. We discover that {\\em passage-to-question} and {\\em\npassage understanding} attentions are the most important ones, showing strong\ncorrelations to the final performance than other parts. Through visualizations\nand case studies, we also observe several general findings on the attention\nmaps, which could be helpful to understand how these models solve the\nquestions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yiming Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Nan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhigang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AVATAR: A Parallel Corpus for Java-Python Program Translation. (arXiv:2108.11590v1 [cs.SE])","link":"http://arxiv.org/abs/2108.11590","description":"<p>Program translation refers to migrating source code from one programming\nlanguage to another. It has a tremendous practical value in software\ndevelopment as porting software across different languages is time-consuming\nand costly. Automating program translation is of paramount importance in\nsoftware migration, and recently researchers explored unsupervised approaches\ndue to the unavailability of parallel corpora. However, the availability of\npre-trained language models for programming languages enable supervised\nfine-tuning with a small amount of labeled examples. In this work, we present a\ncorpus of 8,475 programming problems and their solutions written in two popular\nlanguages, Java and Python. We collect the dataset from competitive programming\nsites, online platforms, and open source repositories. We present several\nbaselines, including models trained from scratch or pre-trained on large-scale\nsource code collection and fine-tuned on our proposed dataset. Experiment\nresults show that while the models perform relatively well in terms of the\nlexical match, they lack in generating code that is accurate in terms of syntax\nand data-flow match.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tushar_M/0/1/0/all/0/1\">Md Golam Rahman Tushar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LayoutReader: Pre-training of Text and Layout for Reading Order Detection. (arXiv:2108.11591v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11591","description":"<p>Reading order detection is the cornerstone to understanding visually-rich\ndocuments (e.g., receipts and forms). Unfortunately, no existing work took\nadvantage of advanced deep learning models because it is too laborious to\nannotate a large enough dataset. We observe that the reading order of WORD\ndocuments is embedded in their XML metadata; meanwhile, it is easy to convert\nWORD documents to PDFs or images. Therefore, in an automated manner, we\nconstruct ReadingBank, a benchmark dataset that contains reading order, text,\nand layout information for 500,000 document images covering a wide spectrum of\ndocument types. This first-ever large-scale dataset unleashes the power of deep\nneural networks for reading order detection. Specifically, our proposed\nLayoutReader captures the text and layout information for reading order\nprediction using the seq2seq model. It performs almost perfectly in reading\norder detection and significantly improves both open-source and commercial OCR\nengines in ordering text lines in their results in our experiments. We will\nrelease the dataset and model at \\url{https://aka.ms/readingbank}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yiheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval Augmented Code Generation and Summarization. (arXiv:2108.11601v1 [cs.SE])","link":"http://arxiv.org/abs/2108.11601","description":"<p>Software developers write a lot of source code and documentation during\nsoftware development. Intrinsically, developers often recall parts of source\ncode or code summaries that they had written in the past while implementing\nsoftware or documenting them. To mimic developers' code or summary generation\nbehavior, we propose a retrieval augmented framework, \\tool, that retrieves\nrelevant code or summaries from a retrieval database and provides them as a\nsupplement to code generation or summarization models. \\tool has a couple of\nuniqueness. First, it extends the state-of-the-art dense retrieval technique to\nsearch for relevant code or summaries. Second, it can work with retrieval\ndatabases that include unimodal (only code or natural language description) or\nbimodal instances (code-description pairs). We conduct experiments and\nextensive analysis on two benchmark datasets of code generation and\nsummarization in Java and Python, and the promising results endorse the\neffectiveness of our proposed retrieval augmented framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parvez_M/0/1/0/all/0/1\">Md Rizwan Parvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Negative Sampling for Unlabeled Entity Problem in Named Entity Recognition. (arXiv:2108.11607v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11607","description":"<p>In many situations (e.g., distant supervision), unlabeled entity problem\nseriously degrades the performances of named entity recognition (NER) models.\nRecently, this issue has been well addressed by a notable approach based on\nnegative sampling. In this work, we perform two studies along this direction.\nFirstly, we analyze why negative sampling succeeds both theoretically and\nempirically. Based on the observation that named entities are highly sparse in\ndatasets, we show a theoretical guarantee that, for a long sentence, the\nprobability of containing no unlabeled entities in sampled negatives is high.\nMissampling tests on synthetic datasets have verified our guarantee in\npractice. Secondly, to mine hard negatives and further reduce missampling\nrates, we propose a weighted and adaptive sampling distribution for negative\nsampling. Experiments on synthetic datasets and well-annotated datasets show\nthat our method significantly improves negative sampling in robustness and\neffectiveness. We also have achieved new state-of-the-art results on real-world\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11626","description":"<p>As the use of interactive machines grow, the task of Emotion Recognition in\nConversation (ERC) became more important. If the machine generated sentences\nreflect emotion, more human-like sympathetic conversations are possible. Since\nemotion recognition in conversation is inaccurate if the previous utterances\nare not taken into account, many studies reflect the dialogue context to\nimprove the performances. We introduce CoMPM, a context embedding module (CoM)\ncombined with a pre-trained memory module (PM) that tracks memory of the\nspeaker's previous utterances within the context, and show that the pre-trained\nmemory significantly improves the final accuracy of emotion recognition. We\nexperimented on both the multi-party datasets (MELD, EmoryNLP) and the\ndyadic-party datasets (IEMOCAP, DailyDialog), showing that our approach achieve\ncompetitive performance on all datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joosung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">Wooin Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scalable End-to-End Training of Knowledge Graph-Enhanced Aspect Embedding for Aspect Level Sentiment Analysis. (arXiv:2108.11656v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11656","description":"<p>Aspect level sentiment classification (ALSC) is a difficult problem with\nstate-of-the-art models showing less than 80% macro-F1 score on benchmark\ndatasets. Existing models do not incorporate information on aspect-aspect\nrelations in knowledge graphs (KGs), e.g. DBpedia. Two main challenges stem\nfrom inaccurate disambiguation of aspects to KG entities, and the inability to\nlearn aspect representations from the large KGs in joint training with ALSC\nmodels.\n</p>\n<p>We propose a two-level global-local entity embedding scheme that allows\nefficient joint training of KG-based aspect embeddings and ALSC models. A novel\nincorrect disambiguation detection technique addresses the problem of\ninaccuracy in aspect disambiguation. The proposed methods show a consistent\nimprovement of $2.5 - 4.1$ percentage points, over the recent BERT-based\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1\">Sk Mainul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Sourangshu Bhattacharya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Technological Approaches to Detecting Online Disinformation and Manipulation. (arXiv:2108.11669v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11669","description":"<p>The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Horak_A/0/1/0/all/0/1\">Ale&#x161; Hor&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baisa_V/0/1/0/all/0/1\">V&#xed;t Baisa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herman_O/0/1/0/all/0/1\">Ond&#x159;ej Herman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Why Intermediate-Task Fine-Tuning Works. (arXiv:2108.11696v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11696","description":"<p>Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a\nwidely applied technique, which first fine-tunes the pretrained language models\non an intermediate task before on the target task of interest. While STILTs is\nable to further improve the performance of pretrained language models, it is\nstill unclear why and when it works. Previous research shows that those\nintermediate tasks involving complex inference, such as commonsense reasoning,\nwork especially well for RoBERTa. In this paper, we discover that the\nimprovement from an intermediate task could be orthogonal to it containing\nreasoning or other complex skills -- a simple real-fake discrimination task\nsynthesized by GPT2 can benefit diverse target tasks. We conduct extensive\nexperiments to study the impact of different factors on STILTs. These findings\nsuggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Yun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chi-Jen Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation for Low-Resource Named Entity Recognition Using Backtranslation. (arXiv:2108.11703v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11703","description":"<p>The state of art natural language processing systems relies on sizable\ntraining datasets to achieve high performance. Lack of such datasets in the\nspecialized low resource domains lead to suboptimal performance. In this work,\nwe adapt backtranslation to generate high quality and linguistically diverse\nsynthetic data for low-resource named entity recognition. We perform\nexperiments on two datasets from the materials science (MaSciP) and biomedical\ndomains (S800). The empirical results demonstrate the effectiveness of our\nproposed augmentation strategy, particularly in the low-resource scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yaseen_U/0/1/0/all/0/1\">Usama Yaseen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1\">Stefan Langer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Statutory Article Retrieval Dataset in French. (arXiv:2108.11792v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11792","description":"<p>Statutory article retrieval is the task of automatically retrieving law\narticles relevant to a legal question. While recent advances in natural\nlanguage processing have sparked considerable interest in many legal tasks,\nstatutory article retrieval remains primarily untouched due to the scarcity of\nlarge-scale and high-quality annotated datasets. To address this bottleneck, we\nintroduce the Belgian Statutory Article Retrieval Dataset (BSARD), which\nconsists of 1,100+ French native legal questions labeled by experienced jurists\nwith relevant articles from a corpus of 22,600+ Belgian law articles. Using\nBSARD, we benchmark several unsupervised information retrieval methods based on\nterm weighting and pooled embeddings. Our best performing baseline achieves\n50.8% R@100, which is promising for the feasibility of the task and indicates\nthat there is still substantial room for improvement. By the specificity of the\ndata domain and addressed task, BSARD presents a unique challenge problem for\nfuture research on legal information retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Antoine Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spanakis_G/0/1/0/all/0/1\">Gerasimos Spanakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijck_G/0/1/0/all/0/1\">Gijs Van Dijck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11809","description":"<p>The massive growth of digital biomedical data is making biomedical text\nindexing and classification increasingly important. Accordingly, previous\nresearch has devised numerous techniques ranging from rule-based systems to\ndeep neural networks, with most focusing on feedforward, convolutional or\nrecurrent neural architectures. More recently, fine-tuned transformers-based\npretrained models (PTMs) have demonstrated superior performance in many natural\nlanguage processing tasks. However, the direct use of PTMs in the biomedical\ndomain is only limited to the target documents, ignoring the rich semantic\ninformation in the label descriptions. In this paper, we develop an improved\nlabel attention-based architecture to inject semantic label description into\nthe fine-tuning process of PTMs. Results on two public medical datasets show\nthat the proposed fine-tuning scheme outperforms the conventionally fine-tuned\nPTMs and prior state-of-the-art models. Furthermore, we show that fine-tuning\nwith the label attention mechanism is interpretable in the interpretability\nstudy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Bruce Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Computational Approach to Measure Empathy and Theory-of-Mind from Written Texts. (arXiv:2108.11810v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11810","description":"<p>Theory-of-mind (ToM), a human ability to infer the intentions and thoughts of\nothers, is an essential part of empathetic experiences. We provide here the\nframework for using NLP models to measure ToM expressed in written texts. For\nthis purpose, we introduce ToM-Diary, a crowdsourced 18,238 diaries with 74,014\nKorean sentences annotated with different ToM levels. Each diary was annotated\nwith ToM levels by trained psychology students and reviewed by selected\npsychology experts. The annotators first divided the diaries based on whether\nthey mentioned other people: self-focused and other-focused. Examples of\nself-focused sentences are \"I am feeling good\". The other-focused sentences\nwere further classified into different levels. These levels differ by whether\nthe writer 1) mentions the presence of others without inferring their mental\nstate(e.g., I saw a man walking down the street), 2) fails to take the\nperspective of others (e.g., I don't understand why they refuse to wear masks),\nor 3) successfully takes the perspective of others (It must have been hard for\nthem to continue working). We tested whether state-of-the-art transformer-based\nmodels (e.g., BERT) could predict underlying ToM levels in sentences. We found\nthat BERT more successfully detected self-focused sentences than other-focused\nones. Sentences that successfully take the perspective of others (the highest\nToM level) were the most difficult to predict. Our study suggests a promising\ndirection for large-scale and computational approaches for identifying the\nability of authors to empathize and take the perspective of others. The dataset\nis at [URL](https://github.com/humanfactorspsych/covid19-tom-empathy-diary)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yoon Kyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Inju Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jae Eun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1\">Yoonwon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiwon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahn_S/0/1/0/all/0/1\">Sowon Hahn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts. (arXiv:2108.11830v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11830","description":"<p>Dialogue models trained on human conversations inadvertently learn to\ngenerate offensive responses. Moreover, models can insult anyone by agreeing\nwith an offensive context. To understand the dynamics of contextually offensive\nlanguage, we study the stance of dialogue model responses in offensive Reddit\nconversations. Specifically, we crowd-annotate ToxiChat, a new dataset of 2,000\nReddit threads and model responses labeled with offensive language and stance.\nOur analysis reveals that 42% of user responses agree with toxic comments; 3x\ntheir agreement with safe comments (13%). Pre-trained transformer-based\nclassifiers fine-tuned on our dataset achieve 0.71 F1 for offensive labels and\n0.53 Macro-F1 for stance labels. Finally, we analyze some existing controllable\ntext generation (CTG) methods to mitigate the contextual offensive behavior of\ndialogue models. Compared to the baseline, our best CTG model obtains a 19%\nreduction in agreement with offensive context and 29% fewer offensive\nresponses. This highlights the need for future work to characterize and analyze\nmore forms of inappropriate behavior in dialogue models to help make them\nsafer. Our code and corpus are available at\nhttps://github.com/abaheti95/ToxiChat .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baheti_A/0/1/0/all/0/1\">Ashutosh Baheti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1\">Mark Riedl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alleviating Exposure Bias via Contrastive Learning for Abstractive Text Summarization. (arXiv:2108.11846v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11846","description":"<p>Encoder-decoder models have achieved remarkable success in abstractive text\nsummarization, which aims to compress one or more documents into a shorter\nversion without the loss of the essential content. Unfortunately, these models\nmostly suffer a discrepancy between training and inference, i.e., the exposure\nbias problem. During the training stage, with teacher forcing these models are\noptimized to maximize the likelihood of the gold summary given the gold summary\ntokens as input to the decoder, while at inference the given tokens are\nreplaced by the generated tokens. Consequently, low-quality summaries are very\nlikely to be generated. To remedy this problem, we propose to leverage\ncontrastive learning to decrease the likelihood of these low-quality summaries,\nand meanwhile increase the likelihood of the gold summary. Since our solution\nexpands the states that the model perceives during training, we expect that the\nexposure bias problem can be alleviated. We experimentally demonstrate that our\nmethod effectively improves the performance of the state-of-the-art model on\ndifferent datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Realistic Study of Auto-regressive Language Models for Named Entity Typing and Recognition. (arXiv:2108.11857v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11857","description":"<p>Despite impressive results of language models for named entity recognition\n(NER), their generalization to varied textual genres, a growing entity type\nset, and new entities remains a challenge. Collecting thousands of annotations\nin each new case for training or fine-tuning is expensive and time-consuming.\nIn contrast, humans can easily identify named entities given some simple\ninstructions. Inspired by this, we challenge the reliance on large datasets and\nstudy pre-trained language models for NER in a meta-learning setup. First, we\ntest named entity typing (NET) in a zero-shot transfer scenario. Then, we\nperform NER by giving few examples at inference. We propose a method to select\nseen and rare / unseen names when having access only to the pre-trained model\nand report results on these groups. The results show: auto-regressive language\nmodels as meta-learners can perform NET and NER fairly well especially for\nregular or seen names; name irregularity when often present for a certain\nentity type can become an effective exploitable cue; names with words foreign\nto the model have the most negative impact on results; the model seems to rely\nmore on name than context cues in few-shot NER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Epure_E/0/1/0/all/0/1\">Elena V. Epure</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1\">Romain Hennequin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Automated Fact-Checking. (arXiv:2108.11896v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11896","description":"<p>Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1\">Michael Schlichtkrull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Similar Scenes arouse Similar Emotions: Parallel Data Augmentation for Stylized Image Captioning. (arXiv:2108.11912v1 [cs.CV])","link":"http://arxiv.org/abs/2108.11912","description":"<p>Stylized image captioning systems aim to generate a caption not only\nsemantically related to a given image but also consistent with a given style\ndescription. One of the biggest challenges with this task is the lack of\nsufficient paired stylized data. Many studies focus on unsupervised approaches,\nwithout considering from the perspective of data augmentation. We begin with\nthe observation that people may recall similar emotions when they are in\nsimilar scenes, and often express similar emotions with similar style phrases,\nwhich underpins our data augmentation idea. In this paper, we propose a novel\nExtract-Retrieve-Generate data augmentation framework to extract style phrases\nfrom small-scale stylized sentences and graft them to large-scale factual\ncaptions. First, we design the emotional signal extractor to extract style\nphrases from small-scale stylized sentences. Second, we construct the plugable\nmulti-modal scene retriever to retrieve scenes represented with pairs of an\nimage and its stylized caption, which are similar to the query image or caption\nin the large-scale factual data. In the end, based on the style phrases of\nsimilar scenes and the factual description of the current scene, we build the\nemotion-aware caption generator to generate fluent and diversified stylized\ncaptions for the current scene. Extensive experimental results show that our\nframework can alleviate the data scarcity problem effectively. It also\nsignificantly boosts the performance of several existing image captioning\nmodels in both supervised and unsupervised settings, which outperforms the\nstate-of-the-art stylized image captioning methods in terms of both sentence\nrelevance and stylishness by a substantial margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guodun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuchen Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HAN: Higher-order Attention Network for Spoken Language Understanding. (arXiv:2108.11916v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11916","description":"<p>Spoken Language Understanding (SLU), including intent detection and slot\nfilling, is a core component in human-computer interaction. The natural\nattributes of the relationship among the two subtasks make higher requirements\non fine-grained feature interaction, i.e., the token-level intent features and\nslot features. Previous works mainly focus on jointly modeling the relationship\nbetween the two subtasks with attention-based models, while ignoring the\nexploration of attention order. In this paper, we propose to replace the\nconventional attention with our proposed Bilinear attention block and show that\nthe introduced Higher-order Attention Network (HAN) brings improvement for the\nSLU task. Importantly, we conduct wide analysis to explore the effectiveness\nbrought from the higher-order attention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dongsheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiqi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Learning for Mediation in Armed Conflicts. (arXiv:2108.11942v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11942","description":"<p>Today's conflicts are becoming increasingly complex, fluid and fragmented,\noften involving a host of national and international actors with multiple and\noften divergent interests. This development poses significant challenges for\nconflict mediation, as mediators struggle to make sense of conflict dynamics,\nsuch as the range of conflict parties and the evolution of their political\npositions, the distinction between relevant and less relevant actors in peace\nmaking, or the identification of key conflict issues and their interdependence.\nInternational peace efforts appear increasingly ill-equipped to successfully\naddress these challenges. While technology is being increasingly used in a\nrange of conflict related fields, such as conflict predicting or information\ngathering, less attention has been given to how technology can contribute to\nconflict mediation. This case study is the first to apply state-of-the-art\nmachine learning technologies to data from an ongoing mediation process. Using\ndialogue transcripts from peace negotiations in Yemen, this study shows how\nmachine-learning tools can effectively support international mediators by\nmanaging knowledge and offering additional conflict analysis tools to assess\ncomplex information. Apart from illustrating the potential of machine learning\ntools in conflict mediation, the paper also emphasises the importance of\ninterdisciplinary and participatory research design for the development of\ncontext-sensitive and targeted tools and to ensure meaningful and responsible\nimplementation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arana_Catania_M/0/1/0/all/0/1\">M. Arana-Catania</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lier_F/0/1/0/all/0/1\">F.A. Van Lier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Procter_R/0/1/0/all/0/1\">Rob Procter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Position-Invariant Truecasing with a Word-and-Character Hierarchical Recurrent Neural Network. (arXiv:2108.11943v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11943","description":"<p>Truecasing is the task of restoring the correct case (uppercase or lowercase)\nof noisy text generated either by an automatic system for speech recognition or\nmachine translation or by humans. It improves the performance of downstream NLP\ntasks such as named entity recognition and language modeling. We propose a\nfast, accurate and compact two-level hierarchical word-and-character-based\nrecurrent neural network model, the first of its kind for this problem. Using\nsequence distillation, we also address the problem of truecasing while ignoring\ntoken positions in the sentence, i.e. in a position-invariant manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">You-Chi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingqing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathews_R/0/1/0/all/0/1\">Rajiv Mathews</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments. (arXiv:2108.11945v1 [cs.RO])","link":"http://arxiv.org/abs/2108.11945","description":"<p>This paper presents a novel approach for the Vision-and-Language Navigation\n(VLN) task in continuous 3D environments, which requires an autonomous agent to\nfollow natural language instructions in unseen environments. Existing\nend-to-end learning-based VLN methods struggle at this task as they focus\nmostly on utilizing raw visual observations and lack the semantic\nspatio-temporal reasoning capabilities which is crucial in generalizing to new\nenvironments. In this regard, we present a hybrid transformer-recurrence model\nwhich focuses on combining classical semantic mapping techniques with a\nlearning-based method. Our method creates a temporal semantic memory by\nbuilding a top-down local ego-centric semantic map and performs cross-modal\ngrounding to align map and language modalities to enable effective learning of\nVLN policy. Empirical results in a photo-realistic long-horizon simulation\nenvironment show that the proposed approach outperforms a variety of\nstate-of-the-art methods and baselines with over 22% relative improvement in\nSPL in prior unseen environments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Irshad_M/0/1/0/all/0/1\">Muhammad Zubair Irshad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mithun_N/0/1/0/all/0/1\">Niluthpol Chowdhury Mithun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seymour_Z/0/1/0/all/0/1\">Zachary Seymour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1\">Han-Pang Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samarasekera_S/0/1/0/all/0/1\">Supun Samarasekera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rakesh Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SAUCE: Truncated Sparse Document Signature Bit-Vectors for Fast Web-Scale Corpus Expansion. (arXiv:2108.11948v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11948","description":"<p>Recent advances in text representation have shown that training on large\namounts of text is crucial for natural language understanding. However, models\ntrained without predefined notions of topical interest typically require\ncareful fine-tuning when transferred to specialized domains. When a sufficient\namount of within-domain text may not be available, expanding a seed corpus of\nrelevant documents from large-scale web data poses several challenges. First,\ncorpus expansion requires scoring and ranking each document in the collection,\nan operation that can quickly become computationally expensive as the web\ncorpora size grows. Relying on dense vector spaces and pairwise similarity adds\nto the computational expense. Secondly, as the domain concept becomes more\nnuanced, capturing the long tail of domain-specific rare terms becomes\nnon-trivial, especially under limited seed corpora scenarios.\n</p>\n<p>In this paper, we consider the problem of fast approximate corpus expansion\ngiven a small seed corpus with a few relevant documents as a query, with the\ngoal of capturing the long tail of a domain-specific set of concept terms. To\nefficiently collect large-scale domain-specific corpora with limited relevance\nfeedback, we propose a novel truncated sparse document bit-vector\nrepresentation, termed Signature Assisted Unsupervised Corpus Expansion\n(SAUCE). Experimental results show that SAUCE can reduce the computational\nburden while ensuring high within-domain lexical coverage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wahed_M/0/1/0/all/0/1\">Muntasir Wahed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruhl_D/0/1/0/all/0/1\">Daniel Gruhl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alba_A/0/1/0/all/0/1\">Alfredo Alba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gentile_A/0/1/0/all/0/1\">Anna Lisa Gentile</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ristoski_P/0/1/0/all/0/1\">Petar Ristoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deluca_C/0/1/0/all/0/1\">Chad Deluca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welch_S/0/1/0/all/0/1\">Steve Welch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1\">Ismini Lourentzou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weisfeiler-Leman in the BAMBOO: Novel AMR Graph Metrics and a Benchmark for AMR Graph Similarity. (arXiv:2108.11949v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11949","description":"<p>Several metrics have been proposed for assessing the similarity of (abstract)\nmeaning representations (AMRs), but little is known about how they relate to\nhuman similarity ratings. Moreover, the current metrics have complementary\nstrengths and weaknesses: some emphasize speed, while others make the alignment\nof graph structures explicit, at the price of a costly alignment step.\n</p>\n<p>In this work we propose new Weisfeiler-Leman AMR similarity metrics that\nunify the strengths of previous metrics, while mitigating their weaknesses.\nSpecifically, our new metrics are able to match contextualized substructures\nand induce n:m alignments between their nodes. Furthermore, we introduce a\nBenchmark for AMR Metrics based on Overt Objectives (BAMBOO), the first\nbenchmark to support empirical assessment of graph-based MR similarity metrics.\nBAMBOO maximizes the interpretability of results by defining multiple overt\nobjectives that range from sentence similarity objectives to stress tests that\nprobe a metric's robustness against meaning-altering and meaning-preserving\ngraph transformations. We show the benefits of BAMBOO by profiling previous\nmetrics and our own metrics. Results indicate that our novel metrics may serve\nas a strong baseline for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Opitz_J/0/1/0/all/0/1\">Juri Opitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_A/0/1/0/all/0/1\">Angel Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LocTex: Learning Data-Efficient Visual Representations from Localized Textual Supervision. (arXiv:2108.11950v1 [cs.CV])","link":"http://arxiv.org/abs/2108.11950","description":"<p>Computer vision tasks such as object detection and semantic/instance\nsegmentation rely on the painstaking annotation of large training datasets. In\nthis paper, we propose LocTex that takes advantage of the low-cost localized\ntextual annotations (i.e., captions and synchronized mouse-over gestures) to\nreduce the annotation effort. We introduce a contrastive pre-training framework\nbetween images and captions and propose to supervise the cross-modal attention\nmap with rendered mouse traces to provide coarse localization signals. Our\nlearned visual features capture rich semantics (from free-form captions) and\naccurate localization (from mouse traces), which are very effective when\ntransferred to various downstream vision tasks. Compared with ImageNet\nsupervised pre-training, LocTex can reduce the size of the pre-training dataset\nby 10x or the target dataset by 2x while achieving comparable or even improved\nperformance on COCO instance segmentation. When provided with the same amount\nof annotations, LocTex achieves around 4% higher accuracy than the previous\nstate-of-the-art \"vision+language\" pre-training approach on the task of PASCAL\nVOC image classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhijian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stent_S/0/1/0/all/0/1\">Simon Stent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gideon_J/0/1/0/all/0/1\">John Gideon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SUMBT+LaRL: Effective Multi-domain End-to-end Neural Task-oriented Dialog System. (arXiv:2009.10447v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.10447","description":"<p>The recent advent of neural approaches for developing each dialog component\nin task-oriented dialog systems has remarkably improved, yet optimizing the\noverall system performance remains a challenge. Besides, previous research on\nmodeling complicated multi-domain goal-oriented dialogs in end-to-end fashion\nhas been limited. In this paper, we present an effective multi-domain\nend-to-end trainable neural dialog system SUMBT+LaRL that incorporates two\nprevious strong models and facilitates them to be fully differentiable.\nSpecifically, the SUMBT+ estimates user-acts as well as dialog belief states,\nand the LaRL models latent system action spaces and generates responses given\nthe estimated contexts. We emphasize that the training framework of three steps\nsignificantly and stably increase dialog success rates: separately pretraining\nthe SUMBT+ and LaRL, fine-tuning the entire system, and then reinforcement\nlearning of dialog policy. We also introduce new reward criteria of\nreinforcement learning for dialog policy training. Then, we discuss\nexperimental results depending on the reward criteria and different dialog\nevaluation methods. Consequently, our model achieved the new state-of-the-art\nsuccess rate of 85.4% on corpus-based evaluation, and a comparable success rate\nof 81.40% on simulator-based evaluation provided by the DSTC8 challenge. To our\nbest knowledge, our work is the first comprehensive study of a modularized E2E\nmulti-domain dialog system that learning from each component to the entire\ndialog policy for task success.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwaran Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_S/0/1/0/all/0/1\">Seokhwan Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">HyungJun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1\">Sangkeun Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Tae-Yoon Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Adversarial Learning for Cross-Lingual Word Embeddings. (arXiv:2010.08432v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.08432","description":"<p>Generative adversarial networks (GANs) have succeeded in inducing\ncross-lingual word embeddings -- maps of matching words across languages --\nwithout supervision. Despite these successes, GANs' performance for the\ndifficult case of distant languages is still not satisfactory. These\nlimitations have been explained by GANs' incorrect assumption that source and\ntarget embedding spaces are related by a single linear mapping and are\napproximately isomorphic. We assume instead that, especially across distant\nlanguages, the mapping is only piece-wise linear, and propose a\nmulti-adversarial learning method. This novel method induces the seed\ncross-lingual dictionary through multiple mappings, each induced to fit the\nmapping for one subspace. Our experiments on unsupervised bilingual lexicon\ninduction show that this method improves performance over previous\nsingle-mapping methods, especially for distant languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merlo_P/0/1/0/all/0/1\">Paola Merlo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ONION: A Simple and Effective Defense Against Textual Backdoor Attacks. (arXiv:2011.10369v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2011.10369","description":"<p>Backdoor attacks are a kind of emergent training-time threat to deep neural\nnetworks (DNNs). They can manipulate the output of DNNs and possess high\ninsidiousness. In the field of natural language processing, some attack methods\nhave been proposed and achieve very high attack success rates on multiple\npopular models. Nevertheless, there are few studies on defending against\ntextual backdoor attacks. In this paper, we propose a simple and effective\ntextual backdoor defense named ONION, which is based on outlier word detection\nand, to the best of our knowledge, is the first method that can handle all the\ntextual backdoor attack situations. Experiments demonstrate the effectiveness\nof our model in defending BiLSTM and BERT against five different backdoor\nattacks. All the code and data will be released to facilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mukai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Transformer-Based Generation of Radiology Reports. (arXiv:2102.09777v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.09777","description":"<p>Inspired by Curriculum Learning, we propose a consecutive (i.e.\nimage-to-text-to-text) generation framework where we divide the problem of\nradiology report generation into two steps. Contrary to generating the full\nradiology report from the image at once, the model generates global concepts\nfrom the image in the first step and then reforms them into finer and coherent\ntexts using transformer-based architecture. We follow the transformer-based\nsequence-to-sequence paradigm at each step. We improve upon the\nstate-of-the-art on two benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nooralahzadeh_F/0/1/0/all/0/1\">Farhad Nooralahzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_N/0/1/0/all/0/1\">Nicolas Perez Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauenfelder_T/0/1/0/all/0/1\">Thomas Frauenfelder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_K/0/1/0/all/0/1\">Koji Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Diversity of Neural Text Generation via Inverse Probability Weighting. (arXiv:2103.07649v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.07649","description":"<p>The neural text generation suffers from the text degeneration issue such as\nrepetition. Traditional stochastic sampling methods only focus on truncating\nthe unreliable \"tail\" of the distribution, and do not address the \"head\" part,\nwhich we show might contain tedious or even repetitive candidates with high\nprobability that lead to repetition loops. They also do not consider the issue\nthat human text does not always favor high-probability words. Inspired by\nthese, in this work we propose a heuristic sampling method. We propose to use\ninterquartile range of the predicted distribution to determine the \"head\" part,\nthen permutate and rescale the \"head\" with inverse probability. This aims at\ndecreasing the probability for the tedious and possibly repetitive candidates\nwith higher probability, and increasing the probability for the rational but\nmore surprising candidates with lower probability. The proposed algorithm\nprovides a reasonable permutation on the predicted distribution which enhances\ndiversity without compromising rationality of the distribution. We use\npre-trained language model to compare our algorithm with traditional methods.\nResults show that our algorithm can effectively increase the diversity of\ngenerated samples while achieving close resemblance to human text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinran Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiafeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaobing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.04670","description":"<p>Large pre-trained language models (LMs) such as GPT-3 have acquired a\nsurprising ability to perform zero-shot learning. For example, to classify\nsentiment without any training examples, we can \"prompt\" the LM with the review\nand the label description \"Does the user like this movie?\", and ask whether the\nnext word is \"yes\" or \"no\". However, the next word prediction training\nobjective is still misaligned with the target zero-shot learning objective. To\naddress this weakness, we propose meta-tuning, which directly optimizes the\nzero-shot learning objective by fine-tuning pre-trained language models on a\ncollection of datasets. We focus on classification tasks, and construct the\nmeta-dataset by aggregating 43 existing datasets and annotating 441 label\ndescriptions in a question-answering (QA) format. When evaluated on unseen\ntasks, meta-tuned models outperform a same-sized QA model and the previous SOTA\nzero-shot learning system based on natural language inference. Additionally,\nincreasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,\nand we forecast that even larger models would perform better. Therefore,\nmeasuring zero-shot learning performance on language models out-of-the-box\nmight underestimate their true potential, and community-wide efforts on\naggregating datasets and unifying their formats can help build models that\nanswer prompts better.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kristy Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data-QuestEval: A Referenceless Metric for Data-to-Text Semantic Evaluation. (arXiv:2104.07555v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07555","description":"<p>QuestEval is a reference-less metric used in text-to-text tasks, that\ncompares the generated summaries directly to the source text, by automatically\nasking and answering questions. Its adaptation to Data-to-Text tasks is not\nstraightforward, as it requires multimodal Question Generation and Answering\nsystems on the considered tasks, which are seldom available. To this purpose,\nwe propose a method to build synthetic multimodal corpora enabling to train\nmultimodal components for a data-QuestEval metric. The resulting metric is\nreference-less and multimodal; it obtains state-of-the-art correlations with\nhuman judgment on the WebNLG and WikiBio benchmarks. We make data-QuestEval's\ncode and models available for reproducibility purpose, as part of the QuestEval\nproject.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rebuffel_C/0/1/0/all/0/1\">Cl&#xe9;ment Rebuffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1\">Thomas Scialom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soulier_L/0/1/0/all/0/1\">Laure Soulier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piwowarski_B/0/1/0/all/0/1\">Benjamin Piwowarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1\">Sylvain Lamprier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1\">Geoffrey Scoutheeten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1\">Patrick Gallinari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Power of Saturated Transformers: A View from Circuit Complexity. (arXiv:2106.16213v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.16213","description":"<p>Transformers have become a standard architecture for many NLP problems. This\nhas motivated theoretically analyzing their capabilities as models of language,\nin order to understand what makes them successful, and what their potential\nweaknesses might be. Recent work has shown that transformers with hard\nattention are quite limited in capacity, and in fact can be simulated by\nconstant-depth circuits. However, hard attention is a restrictive assumption,\nwhich may complicate the relevance of these results for practical transformers.\nIn this work, we analyze the circuit complexity of transformers with saturated\nattention: a generalization of hard attention that more closely captures the\nattention patterns learnable in practical transformers. We show that saturated\ntransformers transcend the limitations of hard-attention transformers. With\nsome minor assumptions, we prove that the number of bits needed to represent a\nsaturated transformer memory vector is $O(\\log n)$, which implies saturated\ntransformers can be simulated by log-depth circuits. Thus, the jump from hard\nto saturated attention can be understood as increasing the transformer's\neffective circuit depth by a factor of $O(\\log n)$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.01198","description":"<p>In this work, we present to the NLP community, and to the wider research\ncommunity as a whole, an application for the diachronic analysis of research\ncorpora. We open source an easy-to-use tool coined: DRIFT, which allows\nresearchers to track research trends and development over the years. The\nanalysis methods are collated from well-cited research works, with a few of our\nown methods added for good measure. Succinctly put, some of the analysis\nmethods are: keyword extraction, word clouds, predicting\ndeclining/stagnant/growing trends using Productivity, tracking bi-grams using\nAcceleration plots, finding the Semantic Drift of words, tracking trends using\nsimilarity, etc. To demonstrate the utility and efficacy of our tool, we\nperform a case study on the cs.CL corpus of the arXiv repository and draw\ninferences from the analysis methods. The toolkit and the associated code are\navailable here: https://github.com/rajaswa/DRIFT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Abheesht Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1\">Gunjan Chhablani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1\">Harshit Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_R/0/1/0/all/0/1\">Rajaswa Patil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentence-T5: Scalable Sentence Encoders from Pre-trained Text-to-Text Models. (arXiv:2108.08877v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08877","description":"<p>We provide the first exploration of text-to-text transformers (T5) sentence\nembeddings. Sentence embeddings are broadly useful for language processing\ntasks. While T5 achieves impressive performance on language tasks cast as\nsequence-to-sequence mapping problems, it is unclear how to produce sentence\nembeddings from encoder-decoder models. We investigate three methods for\nextracting T5 sentence embeddings: two utilize only the T5 encoder and one uses\nthe full T5 encoder-decoder model. Our encoder-only models outperforms\nBERT-based sentence embeddings on both transfer tasks and semantic textual\nsimilarity (STS). Our encoder-decoder method achieves further improvement on\nSTS. Scaling up T5 from millions to billions of parameters is found to produce\nconsistent improvements on downstream tasks. Finally, we introduce a two-stage\ncontrastive learning approach that achieves a new state-of-art on STS using\nsentence embeddings, outperforming both Sentence BERT and SimCSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrego_G/0/1/0/all/0/1\">Gustavo Hern&#xe1;ndez &#xc1;brego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Ji Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_K/0/1/0/all/0/1\">Keith B. Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cer_D/0/1/0/all/0/1\">Daniel Cer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recurrent multiple shared layers in Depth for Neural Machine Translation. (arXiv:2108.10417v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.10417","description":"<p>Learning deeper models is usually a simple and effective approach to improve\nmodel performance, but deeper models have larger model parameters and are more\ndifficult to train. To get a deeper model, simply stacking more layers of the\nmodel seems to work well, but previous works have claimed that it cannot\nbenefit the model. We propose to train a deeper model with recurrent mechanism,\nwhich loops the encoder and decoder blocks of Transformer in the depth\ndirection. To address the increasing of model parameters, we choose to share\nparameters in different recursive moments. We conduct our experiments on WMT16\nEnglish-to-German and WMT14 English-to-France translation tasks, our model\noutperforms the shallow Transformer-Base/Big baseline by 0.35, 1.45 BLEU\npoints, which is 27.23% of Transformer-Big model parameters. Compared to the\ndeep Transformer(20-layer encoder, 6-layer decoder), our model has similar\nmodel performance and infer speed, but our model parameters are 54.72% of the\nformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">GuoLiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiyang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-26T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}