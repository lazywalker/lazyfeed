{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-08-31T01:50:18.329923055Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【Rust日报】2021-08-30 如何来看待 unwrap","link":"https://rustcc.cn/article?id=59dad850-933e-49dd-9ab8-5370d5c77857","description":"<h1>如何来看待 unwrap</h1>\n<p><code>unwrap</code> 方法可能会让新手感到困惑。一些建议:</p>\n<ul>\n<li>可以使用 Expect (&amp;str) 而不是 unwrap() 为 panic 提供上下文。</li>\n<li>使用 unwrap 和 expect 类似于断言。如果他们 panic，那只有在不可挽回的情况下才会发生。</li>\n<li>避免在库代码中使用。</li>\n</ul>\n<p><a href=\"https://owengage.com/writing/2021-08-30-how-to-think-of-unwrap/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>singleton-cell: 一个更强大的 ghost cell 扩展</h1>\n<p>这个库提供了一个安全的、零开销的接口，用于通过访问另一个单例令牌来保护对共享数据的访问。它是 GhostCell的扩展，除了品牌令牌外，它还允许更多普通的单例，使数据成为“静态的”</p>\n<p>这个库本身也提供了两个单例实现:</p>\n<ul>\n<li>通过with_token将限定范围的标记令牌作为 GhostCell</li>\n<li>通过new_singleton简单地创建一次单例结构</li>\n</ul>\n<p><a href=\"https://crates.io/crates/singleton-cell\" rel=\"noopener noreferrer\">crate 地址</a></p>\n<h1>Learning Rust: Interfacing with C</h1>\n<p>通过本文学习如何使用 Rust 调用 C 方法以及如何在 C 中调用 Rust 方法.</p>\n<p><a href=\"https://piware.de/post/2021-08-27-rust-and-c/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>RefineDB: Rust编写的强类型文档数据库</h1>\n<p>运行在任何事务性 键值存储上的 强类型 文档数据库。</p>\n<p>目前支持的 backends 有:</p>\n<ul>\n<li>FoundationDB</li>\n<li>单机部署的 SQLite。</li>\n<li>一个简单的内存键值存储。</li>\n</ul>\n<p><a href=\"https://github.com/losfair/RefineDB\" rel=\"noopener noreferrer\">github 地址</a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-30 12:46:04","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"远程办公，不限地域，缴纳社保公积金，周末双休，告别 996，拒绝 007，Nervina Labs 欢迎你！","link":"https://rustcc.cn/article?id=a90b0635-b332-4e23-9a44-eb9282f519ef","description":"<p>rust开发工程师\n岗位职责：1、负责智能合约的开发及设计；2、负责区块链业务系统分析与设计工作；3、负责智能合约代码测试、运行和维护。任职要求：1、计算机相关专业本科及以上学历，3年以上工作经验；2、熟练掌握 C/C++、Rust 等系统开发语言至少一种，至少有过两年相关开发经验；3、对数据结构和算法，对密码学，安全协议和加密算法有研究者优先；4、优秀的英语文档撰写与阅读能力者优先；5、了解区块链，有合约开发经验更佳。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-30 03:06:51","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"构建安全易用的链表","link":"https://rustcc.cn/article?id=273831e7-932d-476f-9d31-323151afb123","description":"<p>写了一个链表的Crate，愿景是构建安全且易用的链表。</p>\n<p>欢迎大家来找茬（Bug）或提需求 :)</p>\n<p>Crate IO链接：<a href=\"https://crates.io/crates/cyclic_list\" rel=\"noopener noreferrer\">https://crates.io/crates/cyclic_list</a>;</p>\n<p>GitHub链接：<a href=\"https://github.com/whjpji/cyclic_list\" rel=\"noopener noreferrer\">https://github.com/whjpji/cyclic_list</a></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 15:10:34","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-08-29 Tangram：训练、部署和监控机器学习模型","link":"https://rustcc.cn/article?id=4a218f6c-3c77-4aa0-84d6-90ac2bf1fc7c","description":"<h3>Embedded Rust 第一步：选择一块板子</h3>\n<p>内容整理自 <a href=\"https://github.com/robyoung\" rel=\"noopener noreferrer\">robyoung (Rob Young)</a> 的文章：First steps with Embedded Rust: Selecting a board</p>\n<p>有这么多令人眼花缭乱的微控制器和项目，对于嵌入式经验很少的人来说应该从哪里开始？</p>\n<p><strong>我们在开发板中想要什么？</strong></p>\n<ul>\n<li>良好的架构支持</li>\n<li>良好的芯片支持</li>\n<li>活跃的社区</li>\n<li>内置调试器</li>\n</ul>\n<p><strong>我们需要什么架构？</strong></p>\n<p>拥有最完整库、最详尽指南和最大社区的架构是 ARM Cortex-M。 ARM Cortex-M 是面向微控制器应用的低功耗、低成本处理器。 查看 crates.io 上的下载量虽说不是一个完美的指标，但可以让我们了解规模上的差异。在过去的 90 天内，cortex-m 的下载量超过 250k。 RISC-V、AVR 或 Xtensa 最多有 3k 次下载，cortex-a 有大约 18k 次下载。ARM Cortex-M 独树一帜。</p>\n<ul>\n<li>AVR：AVR 是用于嵌入式系统的 8 位微控制器系列。在 Rust 生态系统中，它们并没有得到很好的支持。直到最近，还需要使用 rustc 的一个分支来构建 AVR。 现在有几个不同的选择，awesome-avr-rust 是一个很好的起点。</li>\n<li>ARM Cortex-A：更强大的多核 ARM 处理器，专为运行更大的东西而设计。 通常会在它们上运行完整的操作系统。  例如这是大多数智能手机和掌上游戏机中使用的架构。查看 <a href=\"https://crates.io/crates/cortex-a\" rel=\"noopener noreferrer\">cortex-a - crates.io: Rust Package Registry</a> 了解更多。</li>\n<li>RISC-V：似乎是机器架构的新热点，它是一种免费且开放的指令集架构 (ISA)。  它也从一开始就被设计成模块化的，这意味着芯片设计人员可以创建各种各样的专用芯片，虽然目前开发板的范围很小。有一个活跃的 Rust RISC-V 社区，SiFive 或 www.riscv.org 都是不错的起点，Rust 方面，可以查看 riscv crate。</li>\n<li>Xtensa：最受欢迎的主板组是来自 Espressif 的 ESP32 系列芯片。它们是小型、廉价、支持 WiFi 的电路板。  需要注意的是，并非所有 ESP32 开发板都使用 Xtensa 芯片，新的 ESP32-C3 是基于 RISC-V 的。在 Xtensa 芯片上使用 Rust 的最大障碍可能是 llvm 不支持它，因此需要构建 Rust 的 fork：<a href=\"https://github.com/esp-rs/rust\" rel=\"noopener noreferrer\">esp-rs/rust</a>。</li>\n</ul>\n<p><strong>我们需要什么芯片？</strong></p>\n<p>因此，我们将使用 ARM Cortex-M。  这缩小了搜索范围，但仍有很多选择。如果我们查看 cortex-m <a href=\"https://crates.io/crates/cortex-m/reverse_dependencies\" rel=\"noopener noreferrer\">crate</a> 的依赖项，我们会看到有两组芯片比其他任何一组都使用得更多； <a href=\"https://www.st.com/content/st_com/en/products/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html\" rel=\"noopener noreferrer\">STM32</a> 系列芯片和 <a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy\" rel=\"noopener noreferrer\">nRF5</a> 系列，这是我们要重点搜索的地方。</p>\n<ul>\n<li>STM32：STM32 系列芯片可能是应用最广泛的嵌入式 Rust ARM Cortex-M 芯片。两种最受欢迎的 STM32 板是 Blue Pill 和 Black Pill。主要的缺点是没有板载调试器。如果想要带有调试器的基于 STM32 的电路板，那么获得 STMicroelectronics <a href=\"https://www.st.com/en/evaluation-tools/stm32-discovery-kits.html#overview\" rel=\"noopener noreferrer\">官方套件</a>是一个不错的选择（STM32F3 或 STM32F4 是不错的选择）。Rust Embedded Discovery 书的原始版本是针对 STM32F3 板编写的，因此有非常高质量的初学者文档，可以从那里开始。</li>\n<li>nRF5：用于嵌入式 Rust 的第二个最广泛使用的 ARM Cortex-M 芯片系列是 Nordic Semiconductor 的 <a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy\" rel=\"noopener noreferrer\">nRF5 系列</a>。官方开发<a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy/Development-hardware\" rel=\"noopener noreferrer\">套件</a> (DK) 是很棒的入门板。 Ferrous Systems 的 Knurling-rs 会议使用 nRF52840 <a href=\"https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK\" rel=\"noopener noreferrer\">开发套件</a>。Knurling 课程质量非常高，手把手指导，通过有趣好玩的项目教授嵌入 Rust，是使用 Rust 进行嵌入式开发的最佳切入点。另一个很棒的基于 nRF 的开发板是 <a href=\"https://www.microbit.org/\" rel=\"noopener noreferrer\">BBC micro:bit</a>。它配备了板载调试器和一系列有趣的板载外围设备，如板上的 LED 显示屏、按钮和传感器。BBC micro:bit 被设计为一个教育平台，因此硬件在他们的<a href=\"https://tech.microbit.org/\" rel=\"noopener noreferrer\">开发者社区</a>中以非常适合初学者的方式进行记录，并且互联网上有大量项目创意。</li>\n<li>RP2040：<a href=\"https://www.raspberrypi.org/documentation/rp2040/getting-started/\" rel=\"noopener noreferrer\">RP2040</a> 于 2020 年底发布，是 Raspberry Pi 基金会首次尝试设计自己的芯片。由于如此新，Rust 对它的支持仍在开发中。与 BBC micro:bit 一样，RP2040 旨在成为一个教育平台，因此硬件文档是一流的，并且有大量初学者友好的代码示例和其他编程语言的库（没有多少适合初学者的嵌入式 Rust 文档）。这是一个非常令人兴奋的平台，并且在 Embedded Rust 社区中围绕它进行了大量活动，所以一定要密切关注，但它可能不适合作为入门第一块板。</li>\n</ul>\n<p><strong>板载调试器？</strong></p>\n<p>在主机上运行程序时，可以在 shell 中运行它并查看打印输出。这在嵌入式目标上更加困难，调试器填补了这一空白。除了允许单步调试、断点调试外，它还允许将程序加载到设备上并轻松查看输出。不过有一个问题，它通常是连接到主机然后连接到目标设备的单独设备。第一次开始时，这是一笔不可忽视的费用，也是必须正确设置的另一件事。幸运的是，有些设备带有内置调试器，将它们直接插入主机并在瞬间探测运行的代码（通常需要在主机上进行一些设置才能使调试器正常工作，ferrous 有一个很好的设置<a href=\"https://session20q4.ferrous-systems.com/sessions/installation.html\" rel=\"noopener noreferrer\">指南</a>）。</p>\n<p><strong>结论</strong></p>\n<p>以下这些板都有很棒的 HAL 和 BSP crate、活跃友好的社区和板载调试器。</p>\n<ul>\n<li><a href=\"https://www.microbit.org/\" rel=\"noopener noreferrer\">BBC micro:bit</a>（约 13 英镑）：它是新版 Rust Embedded Discovery 书中使用的板。</li>\n<li><a href=\"https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK\" rel=\"noopener noreferrer\">nRF52840 开发套件</a>（约 35 英镑）；  它是 Ferrous Systems 在 Kunrling 会议和培训中使用的板。</li>\n<li><a href=\"https://www.st.com/en/evaluation-tools/stm32f3discovery.html\" rel=\"noopener noreferrer\">STM32F3 探索套件</a>（约 14 英镑）；  它是 Rust Embedded Discovery 书的第一版中使用的板。</li>\n</ul>\n<p>密切关注：</p>\n<ul>\n<li><a href=\"https://www.raspberrypi.org/products/raspberry-pi-pico/\" rel=\"noopener noreferrer\">Raspberry Pi Pico</a>（约 6 英镑，带预焊引脚）； ARM Cortex-M 但没有内置调试器，HAL 仍在开发中。不过目前有很多活动，进展很快。</li>\n<li><a href=\"https://www.sifive.com/boards/hifive1-rev-b\" rel=\"noopener noreferrer\">HiFive1 Rev B</a>（约 50 英镑）； RISC-V 是新的热点。 Rust 中似乎有很多围绕它的活动，但它目前还没有 ARM Cortex-M 的支持。  其他需要关注的开发板是 <a href=\"https://longan.sipeed.com/en/\" rel=\"noopener noreferrer\">Logan Nano</a> 和 <a href=\"https://hackaday.com/2021/02/08/hands-on-the-risc-v-esp32-c3-will-be-your-new-esp8266/\" rel=\"noopener noreferrer\">ESP32-C3</a>。</li>\n</ul>\n<p>部分内容略有轻微调整，更多可阅读原文：<a href=\"https://robyoung.digital/blog/embedded-rust-selecting-a-board/\" rel=\"noopener noreferrer\">Rob Young | digital</a></p>\n<h3>Tangram：训练、部署和监控机器学习模型</h3>\n<p>一个机器学习套件，使用方法如下：</p>\n<pre><code># 训练\n$ tangram train --file heart_disease.csv --target diagnosis --output heart_disease.tangram\n</code></pre>\n<p>推理支持多种语言：<a href=\"https://hex.pm/packages/tangram\" rel=\"noopener noreferrer\">Elixir</a>, <a href=\"https://pkg.go.dev/github.com/tangramdotdev/tangram-go\" rel=\"noopener noreferrer\">Go</a>, <a href=\"https://www.npmjs.com/package/@tangramdotdev/tangram\" rel=\"noopener noreferrer\">JavaScript</a>, <a href=\"https://pypi.org/project/tangram\" rel=\"noopener noreferrer\">Python</a>, <a href=\"https://rubygems.org/gems/tangram\" rel=\"noopener noreferrer\">Ruby</a> 和 <a href=\"https://lib.rs/tangram\" rel=\"noopener noreferrer\">Rust</a>，以 Rust 为例：</p>\n<pre><code>let model: tangram::Model = tangram::Model::from_path(\"heart_disease.tangram\", None).unwrap();\n\nlet input = tangram::predict_input! {\n  \"age\": 63.0,\n  \"gender\": \"male\",\n  // ...\n};\n\nlet output = model.predict_one(input, None);\n# { className: 'Negative', probability: 0.9381780624389648 }\n</code></pre>\n<p>很好奇训练的时候居然没有要指定模型，发现其将模型共分为三类：回归、二分类和多分类，训练时会根据数据自动选择合适（使用评估方法）的模型，每种模型又有两种不同的训练方法：线性方法和树方法。</p>\n<p>自带的监控功能看起来还不错，比如下面这张可以展示特征对输出的贡献：</p>\n<p><img src=\"https://github.com/tangramdotdev/tangram/raw/main/readme/predictions.png\" alt=\"\"></p>\n<p>项目理论上可以用在简单机器学习场景下，尤其是那些还没有支持机器学习的语言，不过推理并没有 Benchmark，生产中使用需要做好性能测试。</p>\n<p>GitHub：<a href=\"https://github.com/tangramdotdev/tangram\" rel=\"noopener noreferrer\">tangramdotdev/tangram: Tangram makes it easy for programmers to train, deploy, and monitor machine learning models.</a></p>\n<p>文档：<a href=\"https://www.tangram.dev/docs/\" rel=\"noopener noreferrer\">Tangram</a></p>\n<h3>lateral：一个在 x86_64 上启动的模块化内核</h3>\n<p>在本地执行：</p>\n<pre><code>$ make run-release ARCH=x86_64\n</code></pre>\n<p>可以根据自己的情况调整 Makefile 第一行 Bash 的配置。执行后如果有安装 QEMU 的话会自动加载：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/tmp-os-1.jpg\" alt=\"\"></p>\n<p>每个组件都建立在窗口管理器之上，而不是像大多数操作系统那样建立在终端之上。</p>\n<p>GitHub：<a href=\"https://github.com/carterisonline/lateral\" rel=\"noopener noreferrer\">carterisonline/lateral: A clean, custom-built modular kernel ready to boot on x86_64.</a></p>\n<h3>tv：显示表格的 cli 工具</h3>\n<p>就是把 json 或 csv 显示成表格，看起来很不错：</p>\n<pre><code>$ cat test.json\n[\n  {\n    \"name\": \"test\",\n    \"age\": 10,\n    \"lang\": \"ja\"\n  },\n  {\n    \"name\": \"uzimaru\",\n    \"age\": 23,\n    \"lang\": \"ja\"\n  },\n  {\n    \"name\": \"hogehoge\",\n    \"age\": 21,\n    \"lang\": \"en\"\n  },\n  {\n    \"name\": \"hugehuge\",\n    \"age\": 32,\n    \"lang\": \"en\"\n  }\n]\n\n$ tv test.json\n|age|lang|    name|\n|---|----|--------|\n| 10|  ja|    test|\n| 23|  ja| uzimaru|\n| 21|  en|hogehoge|\n| 32|  en|hugehuge|\n\n$ cat test.csv\nname,age,lang\ntest,10,ja\nuzimaru,23,ja\nhogehoge,21,en\nhugehuge,32,en\n\n$ tv test.csv\n|age|lang|    name|\n|---|----|--------|\n| 10|  ja|    test|\n| 23|  ja| uzimaru|\n| 21|  en|hogehoge|\n| 32|  en|hugehuge|\n</code></pre>\n<p>Mac 用户 brew 安装：</p>\n<pre><code>$ brew install uzimaru0000/tap/tv\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/uzimaru0000/tv\" rel=\"noopener noreferrer\">uzimaru0000/tv: CLI tool for displaying table</a></p>\n<h3>minesweeper：使用 Rust，WebAssembly 和 Canvas 的扫雷游戏</h3>\n<p>界面长这样：</p>\n<p><img src=\"https://github.com/KarthikNedunchezhiyan/minesweeper/raw/main/www/assets/stage_bomb_triggered.png\" alt=\"\"></p>\n<p>是很好的学习资料。在这里玩儿：<a href=\"https://karthiknedunchezhiyan.me/minesweeper/\" rel=\"noopener noreferrer\">Minesweeper</a></p>\n<p>GitHub：<a href=\"https://github.com/karthikNedunchezhiyan/minesweeper\" rel=\"noopener noreferrer\">KarthikNedunchezhiyan/minesweeper: Minesweeper game developed with Rust, WebAssembly (Wasm), and Canvas</a></p>\n<h3>copy-translator：划词翻译</h3>\n<p>复制后翻译，使用 DeepL 的 API，不过目前只有 Local 版本好用：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/tmp-rust-1.jpg\" alt=\"\"></p>\n<p>当然，也可以使用 Eudic（欧路词典）。</p>\n<p>GitHub：<a href=\"https://github.com/zu1k/copy-translator\" rel=\"noopener noreferrer\">zu1k/copy-translator: Copy Translator, using DeepL api</a></p>\n<h3>veccentric：小巧的 2-D 向量 Library</h3>\n<p>项目受 <a href=\"https://p5js.org/reference/#/p5.Vector\" rel=\"noopener noreferrer\">p5.Vector</a> 启发，使用方法如下：</p>\n<pre><code>use veccentric::Vecc;\n\nlet a = Vecc::new(3_i32, 4);\nlet b = a * 5;\nlet c = Vecc::new(-10, -8);\nlet d = b - c;\nlet e = -d;\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/micouy/veccentric\" rel=\"noopener noreferrer\">micouy/veccentric: Tiny 2D vector library. Inspired by p5.js's p5.Vector.</a></p>\n<hr>\n<p>From 日报小组 长琴</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc 论坛：支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 12:17:36","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"axum如何使用静态文件目录","link":"https://rustcc.cn/article?id=f3fa9c8e-004b-4d95-8d5f-bdf6609c2e8e","description":"<p>再重构一个简单的单页面小程序的时候打算用<code>axum</code>代替<code>warp</code>的时候遇到了个问题。</p>\n<pre><code>    let post = warp::post()\n        .and(warp::body::bytes())\n        .map(move |content: Bytes| {\n            Response::builder().body(server::handle_post_request(content))\n        });\n\n    let routers = warp::get().and(warp::fs::dir(\"./wwwroot\")).or(post);\n\n    warp::serve(routers).run(([127, 0, 0, 1], 3030)).await;\n</code></pre>\n<p>有如上的简单代码，使用<code>wwwroot</code>文件夹目录来生成页面，文件夹里包含有<code>index.html</code>,JS和CSS文件，怎么使用<code>axum</code>改写呢？看了下doc，只看到</p>\n<pre><code>let app = Router::new()\n    // this route cannot fail\n    .route(\"/foo\", get(|| async {}))\n    // this route can fail with io::Error\n    .route(\n        \"/\",\n        service::get(service_fn(|_req: Request&lt;Body&gt;| async {\n            let contents = tokio::fs::read_to_string(\"some_file\").await?;\n            Ok::&lt;_, io::Error&gt;(Response::new(Body::from(contents)))\n        }))\n        .handle_error(handle_io_error),\n    );\n\nfn handle_io_error(error: io::Error) -&gt; Result&lt;impl IntoResponse, Infallible&gt; {\n    // ...\n}\n</code></pre>\n<p>这种写法。看着头大不说，那个<code>some_file</code>只是简单读取文件，完成不了我的要求。</p>\n<p>有大神说说axum完成了这个部分了吗？这框架的代码看着感觉有点过于复杂了。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 07:28:13","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"自己管理内存的测试方法","link":"https://rustcc.cn/article?id=d4e8f317-f43f-44ea-a041-f39dd3ce1578","description":"<p>很漂亮的一段case，来自std</p>\n<p>library/alloc/tests/linked_list.rs</p>\n<pre><code>#[test]\nfn test_drop() {\n    static mut DROPS: i32 = 0;\n    struct Elem;\n    impl Drop for Elem {\n        fn drop(&amp;mut self) {\n            unsafe {\n                DROPS += 1;\n            }\n        }\n    }\n\n    let mut ring = LinkedList::new();\n    ring.push_back(Elem);\n    ring.push_front(Elem);\n    ring.push_back(Elem);\n    ring.push_front(Elem);\n    drop(ring);\n\n    assert_eq!(unsafe { DROPS }, 4);\n}\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 07:14:22","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"问一个Display trait的问题","link":"https://rustcc.cn/article?id=6b59dfb1-87d8-4b79-8820-e9d5397f178a","description":"<p>请问&amp;str, &amp;&amp;str, &amp;&amp;&amp;str 并没有实现Display 的trait, 为什么这个函数调用没问题?</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 06:12:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-28 开源操作系统夏令营最终报告会安排","link":"https://rustcc.cn/article?id=ef3dd4e8-a8e8-4fec-bc7e-75703e1117ff","description":"<h3>开源操作系统夏令营最终报告会安排</h3>\n<p>会议主题：开源操作系统夏令营最终报告会\n会议时间：2021/08/29 09:00-11:30 (GMT+08:00) 中国标准时间 - 北京\n点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/Mp7T1h5zeQOk?rs=25\n会议 ID：635 194 989</p>\n<p>下面是9位全程参与夏令营活动同学的报告顺序。每人报告时间最长15分钟。</p>\n<ol>\n<li>杨云枫 王涛 Rustsbi的哪吒开发版移植</li>\n<li>兰陈昕 zCore图形支持</li>\n<li>都秉甲 容器技术学习</li>\n<li>薛潇巍 RVM 的 RISC-V 支持</li>\n<li>陈乐 共享调度器</li>\n<li>吴非凡 基于用户态中断的异步系统调用设计与实现</li>\n<li>彭淳毅 陈志扬 基于rCore-Tutorial的性能分析软件实现</li>\n</ol>\n<h3>crates.live：可视化 Rust crates 依赖项</h3>\n<p>crates.live 是来自 crates.io 的 Rust crates 的依赖可视化工具。 它显示了 Rust crates（包）的依赖树。功能包括：</p>\n<ul>\n<li>依赖解析， crates.live 引擎通过匹配依赖版本来完成完整的依赖解析。</li>\n<li>交互式图表，带有标记的板条箱的可缩放交互式图表。</li>\n<li>图像导出， 将图形导出为 PNG。</li>\n<li>开放 API：（即将推出）GraphQL API。</li>\n</ul>\n<p>crates.live 使用了一堆技术框架，技术栈包括：</p>\n<ul>\n<li>Rust， crates.live 后端和爬虫是用 Rust 和开源 Rust 库开发的。</li>\n<li>GraphQl， WASM 驱动的 GraphQL 服务器。</li>\n<li>React/Bulma， 前端库。</li>\n<li>Terraform， 帮助启动和维护我们的基础设施。</li>\n<li>Cloudflare， Cloudflare 工作人员运行 WASM 后端。</li>\n</ul>\n<p>如果在使用此应用程序时有任何疑问、建议或问题； 可以通过 contact@crates.live 联系。 crates.live 由 Abid Omar 开发，可通过 contact@omarabid.com 联系。</p>\n<p><a href=\"https://crates.live/\" rel=\"noopener noreferrer\">链接</a>：https://crates.live/</p>\n<h3>Obake，版本化数据结构</h3>\n<p>Obake 是一个用于声明和维护版本化数据结构的过程宏。 “obake”这个名字取自日语“お化け（おばけ）”，这是日本民间传说中一类会变形的超自然生物。</p>\n<p>在开发应用程序时，配置格式和内部数据结构通常会在版本之间演变。 然而，保持这些版本之间的向后兼容性需要声明和维护遗留格式的数据结构和用于在它们之间迁移的代码。 Obake 的目标是让这个过程变得轻松。</p>\n<pre><code>#[obake::versioned]                 // create a versioned data-structure\n#[obake(version(\"0.1.0\"))]          // declare some versions\n#[obake(version(\"0.2.0\"))]\n#[derive(PartialEq, Eq, Hash)]      // additional attributes are applied to all versions\nstruct Foo {\n    #[obake(cfg(\"0.1.0\"))]          // enable fields for specific versions with\n    foo: String,                    // semantic version constraints\n   \n    #[obake(cfg(\"&gt;=0.2, &lt;=0.3.0\"))] // any semantic version constraint can appear in\n    bar: u32,                       // a `cfg` attribute \n   \n    #[obake(cfg(\"0.1.0\"))]          // multiple `cfg` attributes are treated as a\n    #[obake(cfg(\"&gt;=0.3\"))]          // disjunction over version constraints\n    baz: char,\n}\n\n// describe migrations between versions using the `From` trait\n// and an automatically generated type-level macro for referring to\n// specific versions of `Foo`\nimpl From&lt;Foo![\"0.1.0\"]&gt; for Foo![\"0.2.0\"] {\n    fn from(foo: Foo![\"0.1.0\"]) -&gt; Self {\n        Self { bar: 0 }\n    }\n}\n\n// an enumeration of all versions of `Foo` is accessed using the\n// `obake::Versioned` trait:\nlet versioned_example: &lt;Foo as obake::Versioned&gt;::Versioned = unimplemented!();\n\n// this enumeration implements `Into&lt;Foo&gt;`, where `Foo` is the latest declared\n// version of `Foo` (in this case, `Foo![\"0.2.0\"]`)\nlet example: Foo = versioned_example.into();\n</code></pre>\n<p>Github<a href=\"https://github.com/doctorn/obake\" rel=\"noopener noreferrer\">链接</a>：https://github.com/doctorn/obake</p>\n<h3>iced，跨平台 GUI 库</h3>\n<p>iced，Rust 的跨平台 GUI 库，专注于简单性和类型安全。 灵感来自<a href=\"https://elm-lang.org/\" rel=\"noopener noreferrer\">Elm</a>。</p>\n<p><img src=\"https://raw.githubusercontent.com/hecrj/iced/master/docs/graphs/ecosystem.png\" alt=\"eco\"></p>\n<p>Github<a href=\"https://github.com/hecrj/iced/\" rel=\"noopener noreferrer\">链接</a>：https://github.com/hecrj/iced/</p>\n<p>示例：https://github.com/hecrj/iced/tree/master/examples</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929\" rel=\"noopener noreferrer\">洋芋</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-28 15:42:07","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-8-27 Rudra Rust 的内存安全和未定义行为检测工具","link":"https://rustcc.cn/article?id=ce7eb559-fdda-45d7-a53e-293af787a813","description":"<h4>Rudra Rust 的内存安全和未定义行为检测工具</h4>\n<p>Rudra 是一个静态分析器，用于检测 Rust 程序中常见的未定义行为。它能够分析单个 Rust 包以及 crates.io 上的所有包。Rudra 及其相关论文将在 Proceedings of the 28th ACM Symposium on Operating Systems Principles 2021 (SOSP '21) 上发表。</p>\n<ul>\n<li>https://github.com/sslab-gatech/Rudra#readme</li>\n</ul>\n<h4>nom 7.0 版本发布</h4>\n<p>nom 是一个用 Rust 编写的解析器组合库。它的目标是提供工具来构建安全的解析器，而不会影响速度或内存消耗。为此，它广泛使用 Rust 的强类型和内存安全来生成快速且正确的解析器，并提供函数、宏和特征来抽象大部分容易出错的管道。目前7.0已经发布</p>\n<ul>\n<li>https://crates.io/crates/nom</li>\n</ul>\n<h4>egui 0.14 版本发布</h4>\n<p>egui 是一个易于使用的纯 Rust 图形用户界面。egui 可以在 Web 上、本机上以及您最喜欢的游戏引擎中运行。egui 旨在成为最容易使用的 Rust GUI 库，以及在 Rust 中制作 Web 应用程序的最简单方法，它可以在任何可以绘制纹理三角形的地方使用，这意味着您可以轻松地将其集成到您选择的游戏引擎中。</p>\n<ul>\n<li>演示文档：https://emilk.github.io/egui/</li>\n<li>https://github.com/emilk/egui</li>\n</ul>\n<hr>\n<p>From 日报小组 北纬27度，侯盛鑫</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 14:27:47","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"开源项目xiu登上了GitHub rust trending榜","link":"https://rustcc.cn/article?id=86c83d9a-8370-42cf-8993-ef15af6932c4","description":"<p><a href=\"https://github.com/harlanc/xiu\" rel=\"noopener noreferrer\">https://github.com/harlanc/xiu</a></p>\n<p><a href=\"https://github.com/trending/rust?since=daily\" rel=\"noopener noreferrer\">https://github.com/trending/rust?since=daily</a></p>\n<p>感谢大家的支持！！</p>\n<p>PS：</p>\n<p>前三名有两个都在论坛里发过，这个论坛有点狠，哈哈</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 10:43:48","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"数据表 Timestamp 日期 Serialize","link":"https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0","description":"<p>主要参考：<a href=\"https://github.com/rustcc/forustm\" rel=\"noopener noreferrer\">Rustcc网站源码库</a></p>\n<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，\n查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>\n<h2>1.依赖的库：</h2>\n<pre><code>[dependencies]\n# 日期时间处理 需要开启 serde 特征 支持序列化\nchrono = { version = \"0.4.19\", features = [\"serde\"] }\n\n# 数据库ORM\ndiesel = { version = \"1.4.4\", features = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"] }\ndotenv = \"0.15.0\"\nserde = { version = \"1.0.127\", features = [\"derive\"] }\nserde_json = \"1.0.66\"\nuuid = { version = \"0.8.2\", features = [\"serde\", \"v4\"] }\n</code></pre>\n<h2>2.创建数据表</h2>\n<pre><code>CREATE TABLE characters (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(128) UNIQUE NOT NULL,\n    age INTEGER NOT NULL DEFAULT 0,\n    friends VARCHAR NOT NULL DEFAULT '',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n)\n</code></pre>\n<h2>3.数据表对应的 model</h2>\n<pre><code>use chrono::{NaiveDateTime};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Queryable, Serialize, Deserialize, Debug)]\npub struct Characters {\n    pub id: i32,\n    pub name: String,\n    pub age: i32,\n    pub friends: String,\n    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features\n    pub created_at: NaiveDateTime,\n}\n</code></pre>\n<h2>4.获取数据</h2>\n<pre><code>use db::schema::characters;\nuse db::{get_connection};\nuse db::models::{Characters, NewCharacter};\nuse db::schema::characters::dsl::*;\nuse diesel::QueryDsl;\nuse diesel::prelude::*;\n\nfn main() {\n    let conn = get_connection();\n\n    // 查询年龄大于30的10条数据\n    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))\n        .limit(10)\n        .load::&lt;Characters&gt;(&amp;conn)\n        .expect(\"Loading Error\");\n\n    let date_arr = arr.iter()\n        .map(|item| {\n\t    // 数据格式化\n            let t = item.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n            println!(\"{} {}\", item.name, t);\n            t\n        })\n        .collect::&lt;Vec&lt;String&gt;&gt;();\n}\n</code></pre>\n<p>输出结果类似：</p>\n<pre><code>Box 2021-08-05 09:39:34\nBobe 2021-08-05 09:39:34\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 01:40:35","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Cargo workspace config","link":"https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c","description":"<p><a href=\"https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html\" rel=\"noopener noreferrer\">Workspace 文档链接</a></p>\n<h2>目录结构</h2>\n<pre><code>workspace-test/\n    Cargo.toml\n    db/\n        src/\n            bin/\n                init.rs\n        Cargo.tml\n</code></pre>\n<h2>workspace</h2>\n<p>workspace-test/Cargo.toml</p>\n<pre><code>[workspace]\nmembers = [\"db\"]\ndefault-member = \"db\"\n</code></pre>\n<h2>子项目</h2>\n<p>workspace-test/db/Cargo.toml</p>\n<pre><code>[package]\nname = \"db\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n# 可选的可执行文件配置\n# [[bin]]\n# name = \"init\"\n# path = \"src/bin/init.rs\"\n</code></pre>\n<h2>操作</h2>\n<pre><code># 运行 init\ncargo run --bin init\n# -p 指定项目\ncargo run -p db --bin init\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-04 09:54:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程浅悟（一）","link":"https://rustcc.cn/article?id=120035c3-944d-4a79-9b3a-8390697a6e13","description":"<h1><code>Rust</code>异步编程浅悟（一）</h1>\n<p>不同于<code>javascript</code>的<code>new Promise((resolve, reject) =&gt; {...})</code>构造即运行，<code>Rust</code>中的<code>Future</code>是·惰性·状态机。这体现为：</p>\n<ol>\n<li>【调用异步函数】或【执行异步块】仅只构造一个<code>Future trait object</code>。</li>\n<li>因为<code>Future</code>是惰性状态机，所以它不会自动执行【异步函数】或【异步块】内的任何一行代码 --- 此点与<code>javascript</code>的·活性·状态机完全不同。相反，需要人工激活触发。</li>\n<li>人工启动<code>Future</code>运行，又分为两个场景的两种情况：\n<ol>\n<li>\n<p>已经在<code>async fn</code>内，<code>Future.await</code>激活。但，同时<strong>阻塞</strong>当前异步程序执行流。</p>\n</li>\n<li>\n<p>在<code>async fn</code>外，需要借助由【运行时】提供的【执行器】。就<code>async-std</code>库而言，有两个选择：</p>\n<ol>\n<li><code>task::block_on(Future)</code> 执行<code>Future</code>且阻塞当前线程直到<code>Future</code>被完成。</li>\n<li><code>task::spawn(Future)</code>仅执行<code>Future</code>和不阻塞当前线程。</li>\n</ol>\n<p>无论选择上面哪种方式，若在<code>Future</code>执行期间出现了<code>panic</code>，其都会终止（<code>abort</code>）正在共享同一个执行线程（<code>thread</code>）的所有<code>task</code>（·无栈·协程）的运行。</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>题外话，</p>\n<ol>\n<li>绿色线程是·有栈·协程；异步函数与异步块是·无栈·协程。</li>\n<li>在<code>async-std</code>库的词汇表内，协程被称作<code>task</code>而不是惯例的<code>coroutine</code>。</li>\n<li><code>task::spawn(Future)</code>也能被使用于<code>async fn</code>或<code>async {...}</code>内。它被用来代替<code>.await</code>指令，以<strong>非阻塞</strong><code>async fn</code>或<code>async {...}</code>的方式，激活与执行一个<code>Future</code>实例。</li>\n</ol>\n<h2>例程</h2>\n<pre><code>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {\n    // 1. TcpListener::bind(addr) 返回 Future\n    // 2. .await 于 Future 取得 Result&lt;T, E&gt;\n    // 3. Result&lt;T, E&gt;? 再拿得 Ok&lt;T&gt; 中的 T\n    let listener = TcpListener::bind(addr).await?; // 异步函数内的人工启动 Future\n    let mut incoming = listener.incoming();\n    // 因为没有从语言层面支持 async for loop，所以 while loop + Iterator&lt;Item = T&gt; 来模拟之。\n    while let Some(stream) = incoming.next().await {\n        // TODO\n    }\n    Ok(())\n}\nfn main() {\n    let fut = accept_loop(\"127.0.0.1:8080\");\n    task::block_on(fut); // 异步函数外的人工启动 Future\n}\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-03 00:01:43","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-08-31T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"From Pivots to Graphs: Augmented CycleDensity as a Generalization to One Time InverseConsultation. (arXiv:2108.12459v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12459","description":"<p>This paper describes an approach used to generate new translations using raw\nbilingual dictionaries as part of the 4th Task Inference Across Dictionaries\n(TIAD 2021) shared task. We propose Augmented Cycle Density (ACD) as a\nframework that combines insights from two state of the art methods that require\nno sense information and parallel corpora: Cycle Density (CD) and One Time\nInverse Consultation (OTIC). The task results show that across 3 unseen\nlanguage pairs, ACD's predictions, has more than double (74%) the coverage of\nOTIC at almost the same precision (76%). ACD combines CD's scalability -\nleveraging rich multilingual graphs for better predictions, and OTIC's data\nefficiency - producing good results with the minimum possible resource of one\npivot language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1\">Shashwat Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_K/0/1/0/all/0/1\">Kunwar Shaanjeet Singh Grover</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Text Evaluation through the Lens of Wasserstein Barycenters. (arXiv:2108.12463v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12463","description":"<p>A new metric \\texttt{BaryScore} to evaluate text generation based on deep\ncontextualized embeddings (\\textit{e.g.}, BERT, Roberta, ELMo) is introduced.\nThis metric is motivated by a new framework relying on optimal transport tools,\n\\textit{i.e.}, Wasserstein distance and barycenter. By modelling the layer\noutput of deep contextualized embeddings as a probability distribution rather\nthan by a vector embedding; this framework provides a natural way to aggregate\nthe different outputs through the Wasserstein space topology. In addition, it\nprovides theoretical grounds to our metric and offers an alternative to\navailable solutions (\\textit{e.g.}, MoverScore and BertScore). Numerical\nevaluation is performed on four different tasks: machine translation,\nsummarization, data2text generation and image captioning. Our results show that\n\\texttt{BaryScore} outperforms other BERT based metrics and exhibits more\nconsistent behaviour in particular for text summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Colombo_P/0/1/0/all/0/1\">Pierre Colombo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staerman_G/0/1/0/all/0/1\">Guillaume Staerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1\">Chloe Clavel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1\">Pablo Piantanida</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Code-switched inspired losses for generic spoken dialog representations. (arXiv:2108.12465v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12465","description":"<p>Spoken dialog systems need to be able to handle both multiple languages and\nmultilinguality inside a conversation (\\textit{e.g} in case of code-switching).\nIn this work, we introduce new pretraining losses tailored to learn\nmultilingual spoken dialog representations. The goal of these losses is to\nexpose the model to code-switched language. To scale up training, we\nautomatically build a pretraining corpus composed of multilingual conversations\nin five different languages (French, Italian, English, German and Spanish) from\n\\texttt{OpenSubtitles}, a huge multilingual corpus composed of 24.3G tokens. We\ntest the generic representations on \\texttt{MIAM}, a new benchmark composed of\nfive dialog act corpora on the same aforementioned languages as well as on two\nnovel multilingual downstream tasks (\\textit{i.e} multilingual mask utterance\nretrieval and multilingual inconsistency identification). Our experiments show\nthat our new code switched-inspired losses achieve a better performance in both\nmonolingual and multilingual settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chapuis_E/0/1/0/all/0/1\">Emile Chapuis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colombo_P/0/1/0/all/0/1\">Pierre Colombo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labeau_M/0/1/0/all/0/1\">Matthieu Labeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clave_C/0/1/0/all/0/1\">Chloe Clave</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models. (arXiv:2108.12472v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12472","description":"<p>Automatic construction of relevant Knowledge Bases (KBs) from text, and\ngeneration of semantically meaningful text from KBs are both long-standing\ngoals in Machine Learning. In this paper, we present ReGen, a bidirectional\ngeneration of text and graph leveraging Reinforcement Learning (RL) to improve\nperformance. Graph linearization enables us to re-frame both tasks as a\nsequence to sequence generation problem regardless of the generative direction,\nwhich in turn allows the use of Reinforcement Learning for sequence training\nwhere the model itself is employed as its own critic leading to Self-Critical\nSequence Training (SCST). We present an extensive investigation demonstrating\nthat the use of RL via SCST benefits graph and text generation on WebNLG+ 2020\nand TekGen datasets. Our system provides state-of-the-art results on WebNLG+\n2020 by significantly improving upon published results from the WebNLG 2020+\nChallenge for both text-to-graph and graph-to-text generation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dognin_P/0/1/0/all/0/1\">Pierre L. Dognin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1\">Inkit Padhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melnyk_I/0/1/0/all/0/1\">Igor Melnyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Payel Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opinions are Made to be Changed: Temporally Adaptive Stance Classification. (arXiv:2108.12476v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12476","description":"<p>Given the rapidly evolving nature of social media and people's views, word\nusage changes over time. Consequently, the performance of a classifier trained\non old textual data can drop dramatically when tested on newer data. While\nresearch in stance classification has advanced in recent years, no effort has\nbeen invested in making these classifiers have persistent performance over\ntime. To study this phenomenon we introduce two novel large-scale, longitudinal\nstance datasets. We then evaluate the performance persistence of stance\nclassifiers over time and demonstrate how it decays as the temporal gap between\ntraining and testing data increases. We propose a novel approach to mitigate\nthis performance drop, which is based on temporal adaptation of the word\nembeddings used for training the stance classifier. This enables us to make use\nof readily available unlabelled data from the current time period instead of\nexpensive annotation efforts. We propose and compare several approaches to\nembedding adaptation and find that the Incremental Temporal Alignment (ITA)\nmodel leads to the best results in reducing performance drop over time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alkhalifa_R/0/1/0/all/0/1\">Rabab Alkhalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochkina_E/0/1/0/all/0/1\">Elena Kochkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Table-to-Text Generation with Prototype Memory. (arXiv:2108.12516v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12516","description":"<p>Neural table-to-text generation models have achieved remarkable progress on\nan array of tasks. However, due to the data-hungry nature of neural models,\ntheir performances strongly rely on large-scale training examples, limiting\ntheir applicability in real-world applications. To address this, we propose a\nnew framework: Prototype-to-Generate (P2G), for table-to-text generation under\nthe few-shot scenario. The proposed framework utilizes the retrieved\nprototypes, which are jointly selected by an IR system and a novel prototype\nselector to help the model bridging the structural gap between tables and\ntexts. Experimental results on three benchmark datasets with three\nstate-of-the-art models demonstrate that the proposed framework significantly\nimproves the model performance across various evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baker_S/0/1/0/all/0/1\">Simon Baker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predicting the Factuality of Reporting of News Media Using Observations About User Attention in Their YouTube Channels. (arXiv:2108.12519v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12519","description":"<p>We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bozhanova_K/0/1/0/all/0/1\">Krasimira Bozhanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinkov_Y/0/1/0/all/0/1\">Yoan Dinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castaldo_M/0/1/0/all/0/1\">Maria Castaldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venturini_T/0/1/0/all/0/1\">Tommaso Venturini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TweetBLM: A Hate Speech Dataset and Analysis of Black Lives Matter-related Microblogs on Twitter. (arXiv:2108.12521v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12521","description":"<p>In the past few years, there has been a significant rise in toxic and hateful\ncontent on various social media platforms. Recently Black Lives Matter movement\ncame into the picture, causing an avalanche of user generated responses on the\ninternet. In this paper, we have proposed a Black Lives Matter related tweet\nhate speech dataset TweetBLM. Our dataset comprises 9165 manually annotated\ntweets that target the Black Lives Matter movement. We annotated the tweets\ninto two classes, i.e., HATE and NONHATE based on their content related to\nracism erupted from the movement for the black community. In this work, we also\ngenerated useful statistical insights on our dataset and performed a systematic\nanalysis of various machine learning models such as Random Forest, CNN, LSTM,\nBiLSTM, Fasttext, BERTbase, and BERTlarge for the classification task on our\ndataset. Through our work, we aim at contributing to the substantial efforts of\nthe research community for the identification and mitigation of hate speech on\nthe internet. The dataset is publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sumit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pranesh_R/0/1/0/all/0/1\">Raj Ratn Pranesh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Energy-Based Approximate Inference Networks for Structured Applications in NLP. (arXiv:2108.12522v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12522","description":"<p>Structured prediction in natural language processing (NLP) has a long\nhistory. The complex models of structured application come at the difficulty of\nlearning and inference. These difficulties lead researchers to focus more on\nmodels with simple structure components (e.g., local classifier). Deep\nrepresentation learning has become increasingly popular in recent years. The\nstructure components of their method, on the other hand, are usually relatively\nsimple. We concentrate on complex structured models in this dissertation. We\nprovide a learning framework for complicated structured models as well as an\ninference method with a better speed/accuracy/search error trade-off. The\ndissertation begins with a general introduction to energy-based models. In NLP\nand other applications, an energy function is comparable to the concept of a\nscoring function. In this dissertation, we discuss the concept of the energy\nfunction and structured models with different energy functions. Then, we\npropose a method in which we train a neural network to do argmax inference\nunder a structured energy function, referring to the trained networks as\n\"inference networks\" or \"energy-based inference networks\". We then develop ways\nof jointly learning energy functions and inference networks using an\nadversarial learning framework. Despite the inference and learning difficulties\nof energy-based models, we present approaches in this thesis that enable\nenergy-based models more easily to be applied in structured NLP applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_L/0/1/0/all/0/1\">Lifu Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speech Representations and Phoneme Classification for Preserving the Endangered Language of Ladin. (arXiv:2108.12531v1 [eess.AS])","link":"http://arxiv.org/abs/2108.12531","description":"<p>A vast majority of the world's 7,000 spoken languages are predicted to become\nextinct within this century, including the endangered language of Ladin from\nthe Italian Alps. Linguists who work to preserve a language's phonetic and\nphonological structure can spend hours transcribing each minute of speech from\nnative speakers. To address this problem in the context of Ladin, our paper\npresents the first analysis of speech representations and machine learning\nmodels for classifying 32 phonemes of Ladin. We experimented with a novel\ndataset of the Fascian dialect of Ladin, collected from native speakers in\nItaly. We created frame-level and segment-level speech feature extraction\napproaches and conducted extensive experiments with 8 different classifiers\ntrained on 9 different speech representations. Our speech representations\nranged from traditional features (MFCC, LPC) to features learned with deep\nneural network models (autoencoders, LSTM autoencoders, and WaveNet). Our\nhighest-performing classifier, trained on MFCC representations of speech\nsignals, achieved an 86% average accuracy across all Ladin phonemes. We also\nobtained average accuracies above 77% for all Ladin phoneme subgroups examined.\nOur findings contribute insights for learning discriminative Ladin phoneme\nrepresentations and demonstrate the potential for leveraging machine learning\nand speech signal processing to preserve Ladin and other endangered languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Durante_Z/0/1/0/all/0/1\">Zane Durante</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mathur_L/0/1/0/all/0/1\">Leena Mathur</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_E/0/1/0/all/0/1\">Eric Ye</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1\">Sichong Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ramdas_T/0/1/0/all/0/1\">Tejas Ramdas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Iskarous_K/0/1/0/all/0/1\">Khalil Iskarous</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QACE: Asking Questions to Evaluate an Image Caption. (arXiv:2108.12560v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12560","description":"<p>In this paper, we propose QACE, a new metric based on Question Answering for\nCaption Evaluation. QACE generates questions on the evaluated caption and\nchecks its content by asking the questions on either the reference caption or\nthe source image. We first develop QACE-Ref that compares the answers of the\nevaluated caption to its reference, and report competitive results with the\nstate-of-the-art metrics. To go further, we propose QACE-Img, which asks the\nquestions directly on the image, instead of reference. A Visual-QA system is\nnecessary for QACE-Img. Unfortunately, the standard VQA models are framed as a\nclassification among only a few thousand categories. Instead, we propose\nVisual-T5, an abstractive VQA system. The resulting metric, QACE-Img is\nmulti-modal, reference-less, and explainable. Our experiments show that\nQACE-Img compares favorably w.r.t. other reference-less metrics. We will\nrelease the pre-trained models to compute QACE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwanhee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1\">Thomas Scialom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seunghyun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyomin Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Goal-driven text descriptions for images. (arXiv:2108.12575v1 [cs.CV])","link":"http://arxiv.org/abs/2108.12575","description":"<p>A big part of achieving Artificial General Intelligence(AGI) is to build a\nmachine that can see and listen like humans. Much work has focused on designing\nmodels for image classification, video classification, object detection, pose\nestimation, speech recognition, etc., and has achieved significant progress in\nrecent years thanks to deep learning. However, understanding the world is not\nenough. An AI agent also needs to know how to talk, especially how to\ncommunicate with a human. While perception (vision, for example) is more common\nacross animal species, the use of complicated language is unique to humans and\nis one of the most important aspects of intelligence.\n</p>\n<p>In this thesis, we focus on generating textual output given visual input. In\nChapter 3, we focus on generating the referring expression, a text description\nfor an object in the image so that a receiver can infer which object is being\ndescribed. We use a comprehension machine to directly guide the generated\nreferring expressions to be more discriminative. In Chapter 4, we introduce a\nmethod that encourages discriminability in image caption generation. We show\nthat more discriminative captioning models generate more descriptive captions.\nIn Chapter 5, we study how training objectives and sampling methods affect the\nmodels' ability to generate diverse captions. We find that a popular captioning\ntraining strategy will be detrimental to the diversity of generated captions.\nIn Chapter 6, we propose a model that can control the length of generated\ncaptions. By changing the desired length, one can influence the style and\ndescriptiveness of the captions. Finally, in Chapter 7, we rank/generate\ninformative image tags according to their information utility. The proposed\nmethod better matches what humans think are the most important tags for the\nimages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Ruotian Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12582","description":"<p>Despite the remarkable performance of large-scale generative models in\nopen-domain conversation, they are known to be less practical for building\nreal-time conversation systems due to high latency. On the other hand,\nretrieval models could return responses with much lower latency but show\ninferior performance to the large-scale generative models since the\nconversation quality is bounded by the pre-defined response set. To take\nadvantage of both approaches, we propose a new training method called G2R\n(Generative-to-Retrieval distillation) that preserves the efficiency of a\nretrieval model while leveraging the conversational ability of a large-scale\ngenerative model by infusing the knowledge of the generative model into the\nretrieval model. G2R consists of two distinct techniques of distillation: the\ndata-level G2R augments the dialogue dataset with additional responses\ngenerated by the large-scale generative model, and the model-level G2R\ntransfers the response quality score assessed by the generative model to the\nscore of the retrieval model by the knowledge distillation loss. Through\nextensive experiments including human evaluation, we demonstrate that our\nretrieval-based conversation system trained with G2R shows a substantially\nimproved performance compared to the baseline retrieval model while showing\nsignificantly lower inference latency than the large-scale generative models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Seokjun Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungju Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdenee_E/0/1/0/all/0/1\">Enkhbayar Erdenee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Buru Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems. (arXiv:2108.12589v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12589","description":"<p>As the labeling cost for different modules in task-oriented dialog (ToD)\nsystems is expensive, a major challenge is to train different modules with the\nleast amount of labeled data. Recently, large-scale pre-trained language\nmodels, have shown promising results for few-shot learning in ToD. In this\npaper, we devise a self-training approach to utilize the abundant unlabeled\ndialog data to further improve state-of-the-art pre-trained models in few-shot\nlearning scenarios for ToD systems. Specifically, we propose a self-training\napproach that iteratively labels the most confident unlabeled data to train a\nstronger Student model. Moreover, a new text augmentation technique (GradAug)\nis proposed to better train the Student by replacing non-crucial tokens using a\nmasked language model. We conduct extensive experiments and present analyses on\nfour downstream tasks in ToD, including intent classification, dialog state\ntracking, dialog act prediction, and response selection. Empirical results\ndemonstrate that the proposed self-training approach consistently improves\nstate-of-the-art pre-trained models (BERT, ToD-BERT) when only a small number\nof labeled data are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wanhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_F/0/1/0/all/0/1\">Fengyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingjing Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1\">Boi Faltings</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Layer-wise Model Pruning based on Mutual Information. (arXiv:2108.12594v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12594","description":"<p>The proposed pruning strategy offers merits over weight-based pruning\ntechniques: (1) it avoids irregular memory access since representations and\nmatrices can be squeezed into their smaller but dense counterparts, leading to\ngreater speedup; (2) in a manner of top-down pruning, the proposed method\noperates from a more global perspective based on training signals in the top\nlayer, and prunes each layer by propagating the effect of global signals\nthrough layers, leading to better performances at the same sparsity level.\nExtensive experiments show that at the same sparsity level, the proposed\nstrategy offers both greater speedup and higher performances than weight-based\npruning methods (e.g., magnitude pruning, movement pruning).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1\">Xiang Ao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12599","description":"<p>Conversational machine reading (CMR) requires machines to communicate with\nhumans through multi-turn interactions between two salient dialogue states of\ndecision making and question generation processes. In open CMR settings, as the\nmore realistic scenario, the retrieved background knowledge would be noisy,\nwhich results in severe challenges in the information transmission. Existing\nstudies commonly train independent or pipeline systems for the two subtasks.\nHowever, those methods are trivial by using hard-label decisions to activate\nquestion generation, which eventually hinders the model performance. In this\nwork, we propose an effective gating strategy by smoothing the two dialogue\nstates in only one decoder and bridge decision making and question generation\nto provide a richer dialogue state reference. Experiments on the OR-ShARC\ndataset show the effectiveness of our method, which achieves new\nstate-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siru Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Utiyama_M/0/1/0/all/0/1\">Masao Utiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sumita_E/0/1/0/all/0/1\">Eiichiro Sumita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigation of Diachronic Bias in Fake News Detection Dataset. (arXiv:2108.12601v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12601","description":"<p>Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Murayama_T/0/1/0/all/0/1\">Taichi Murayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wakamiya_S/0/1/0/all/0/1\">Shoko Wakamiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aramaki_E/0/1/0/all/0/1\">Eiji Aramaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WALNUT: A Benchmark on Weakly Supervised Learning for Natural Language Understanding. (arXiv:2108.12603v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12603","description":"<p>Building quality machine learning models for natural language understanding\n(NLU) tasks relies heavily on labeled data. Weak supervision has been shown to\nprovide valuable supervision when large amount of labeled data is unavailable\nor expensive to obtain. Existing works studying weak supervision for NLU either\nmostly focus on a specific task or simulate weak supervision signals from\nground-truth labels. To date a benchmark for NLU with real world weak\nsupervision signals for a collection of NLU tasks is still not available. In\nthis paper, we propose such a benchmark, named WALNUT, to advocate and\nfacilitate research on weak supervision for NLU. WALNUT consists of NLU tasks\nwith different types, including both document-level prediction tasks and\ntoken-level prediction tasks and for each task contains weak labels generated\nby multiple real-world weak sources. We conduct baseline evaluations on the\nbenchmark to systematically test the value of weak supervision for NLU tasks,\nwith various weak supervision methods and model architectures. We demonstrate\nthe benefits of weak supervision for low-resource NLU tasks and expect WALNUT\nto stimulate further research on methodologies to best leverage weak\nsupervision. The benchmark and code for baselines will be publicly available at\naka.ms/walnut_benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamanolakis_G/0/1/0/all/0/1\">Giannis Karamanolakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HeadlineCause: A Dataset of News Headlines for Detecting Casualties. (arXiv:2108.12626v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12626","description":"<p>Detecting implicit causal relations in texts is a task that requires both\ncommon sense and world knowledge. Existing datasets are focused either on\ncommonsense causal reasoning or explicit causal relations. In this work, we\npresent HeadlineCause, a dataset for detecting implicit causal relations\nbetween pairs of news headlines. The dataset includes over 5000 headline pairs\nfrom English news and over 9000 headline pairs from Russian news labeled\nthrough crowdsourcing. The pairs vary from totally unrelated or belonging to\nthe same general topic to the ones including causation and refutation\nrelations. We also present a set of models and experiments that demonstrates\nthe dataset validity, including a multilingual XLM-RoBERTa based model for\ncausality detection and a GPT-2 based model for possible effects prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gusev_I/0/1/0/all/0/1\">Ilya Gusev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Oh My Mistake!: Toward Realistic Dialogue State Tracking including Turnback Utterances. (arXiv:2108.12637v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12637","description":"<p>The primary purpose of dialogue state tracking (DST), a critical component of\nan end-to-end conversational system, is to build a model that responds well to\nreal-world situations. Although we often change our minds during ordinary\nconversations, current benchmark datasets do not adequately reflect such\noccurrences and instead consist of over-simplified conversations, in which no\none changes their mind during a conversation. As the main question inspiring\nthe present study,``Are current benchmark datasets sufficiently diverse to\nhandle casual conversations in which one changes their mind?'' We found that\nthe answer is ``No'' because simply injecting template-based turnback\nutterances significantly degrades the DST model performance. The test joint\ngoal accuracy on the MultiWOZ decreased by over 5\\%p when the simplest form of\nturnback utterance was injected. Moreover, the performance degeneration worsens\nwhen facing more complicated turnback situations. However, we also observed\nthat the performance rebounds when a turnback is appropriately included in the\ntraining dataset, implying that the problem is not with the DST models but\nrather with the construction of the benchmark dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Takyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yukyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1\">Hoonsang Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_P/0/1/0/all/0/1\">Pilsung Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Misuk Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Event Extraction as Natural Language Generation. (arXiv:2108.12724v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12724","description":"<p>Event extraction (EE), the task that identifies event triggers and their\narguments in text, is usually formulated as a classification or structured\nprediction problem. Such models usually reduce labels to numeric identifiers,\nmaking them unable to take advantage of label semantics (e.g. an event type\nnamed Arrest is related to words like arrest, detain, or apprehend). This\nprevents the generalization to new event types. In this work, we formulate EE\nas a natural language generation task and propose GenEE, a model that not only\ncaptures complex dependencies within an event but also generalizes well to\nunseen or rare event types. Given a passage and an event type, GenEE is trained\nto generate a natural sentence following a predefined template for that event\ntype. The generated output is then decoded into trigger and argument\npredictions. The autoregressive generation process naturally models the\ndependencies among the predictions -- each new word predicted depends on those\nalready generated in the output sentence. Using carefully designed input\nprompts during generation, GenEE is able to capture label semantics, which\nenables the generalization to new event types. Empirical results show that our\nmodel achieves strong performance on event extraction tasks under all\nzero-shot, few-shot, and high-resource scenarios. Especially, in the\nhigh-resource setting, GenEE outperforms the state-of-the-art model on argument\nextraction and gets competitive results with the current best on end-to-end EE\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_I/0/1/0/all/0/1\">I-Hung Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boschee_E/0/1/0/all/0/1\">Elizabeth Boschee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_S/0/1/0/all/0/1\">Scott Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Prem Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"$k$Folden: $k$-Fold Ensemble for Out-Of-Distribution Detection. (arXiv:2108.12731v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12731","description":"<p>Out-of-Distribution (OOD) detection is an important problem in natural\nlanguage processing (NLP). In this work, we propose a simple yet effective\nframework $k$Folden, which mimics the behaviors of OOD detection during\ntraining without the use of any external data. For a task with $k$ training\nlabels, $k$Folden induces $k$ sub-models, each of which is trained on a subset\nwith $k-1$ categories with the left category masked unknown to the sub-model.\nExposing an unknown label to the sub-model during training, the model is\nencouraged to learn to equally attribute the probability to the seen $k-1$\nlabels for the unknown label, enabling this framework to simultaneously resolve\nin- and out-distribution examples in a natural way via OOD simulations. Taking\ntext classification as an archetype, we develop benchmarks for OOD detection\nusing existing text classification datasets. By conducting comprehensive\ncomparisons and analyses on the developed benchmarks, we demonstrate the\nsuperiority of $k$Folden against current methods in terms of improving OOD\ndetection performances while maintaining improved in-domain classification\naccuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SummerTime: Text Summarization Toolkit for Non-experts. (arXiv:2108.12738v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12738","description":"<p>Recent advances in summarization provide models that can generate summaries\nof higher quality. Such models now exist for a number of summarization tasks,\nincluding query-based summarization, dialogue summarization, and multi-document\nsummarization. While such models and tasks are rapidly growing in the research\nfield, it has also become challenging for non-experts to keep track of them. To\nmake summarization methods more accessible to a wider audience, we develop\nSummerTime by rethinking the summarization task from the perspective of an NLP\nnon-expert. SummerTime is a complete toolkit for text summarization, including\nvarious models, datasets and evaluation metrics, for a full spectrum of\nsummarization-related tasks. SummerTime integrates with libraries designed for\nNLP researchers, and enables users with easy-to-use APIs. With SummerTime,\nusers can locate pipeline solutions and search for the best model with their\nown data, and visualize the differences, all with a few lines of code. We also\nprovide explanations for models and evaluation metrics to help users understand\nthe model behaviors and select models that best suit their needs. Our library,\nalong with a notebook demo, is available at\nhttps://github.com/Yale-LILY/SummerTime.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_A/0/1/0/all/0/1\">Ansong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azerbayev_Z/0/1/0/all/0/1\">Zhangir Azerbayev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mutuma_M/0/1/0/all/0/1\">Mutethia Mutuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Troy Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yusen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentence Structure and Word Relationship Modeling for Emphasis Selection. (arXiv:2108.12750v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12750","description":"<p>Emphasis Selection is a newly proposed task which focuses on choosing words\nfor emphasis in short sentences. Traditional methods only consider the sequence\ninformation of a sentence while ignoring the rich sentence structure and word\nrelationship information. In this paper, we propose a new framework that\nconsiders sentence structure via a sentence structure graph and word\nrelationship via a word similarity graph. The sentence structure graph is\nderived from the parse tree of a sentence. The word similarity graph allows\nnodes to share information with their neighbors since we argue that in emphasis\nselection, similar words are more likely to be emphasized together. Graph\nneural networks are employed to learn the representation of each node of these\ntwo graphs. Experimental results demonstrate that our framework can achieve\nsuperior performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution. (arXiv:2108.12777v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12777","description":"<p>Recent studies have shown that deep neural networks are vulnerable to\nintentionally crafted adversarial examples, and various methods have been\nproposed to defend against adversarial word-substitution attacks for neural NLP\nmodels. However, there is a lack of systematic study on comparing different\ndefense approaches under the same attacking setting. In this paper, we seek to\nfill the gap of systematic studies through comprehensive researches on\nunderstanding the behavior of neural text classifiers trained by various\ndefense methods under representative adversarial attacks. In addition, we\npropose an effective method to further improve the robustness of neural text\nclassifiers against such attacks and achieved the highest accuracy on both\nclean and adversarial examples on AGNEWS and IMDB datasets by a significant\nmargin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiehang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Propaganda Detection in News Articles. (arXiv:2108.12802v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12802","description":"<p>Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Seunghak Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_G/0/1/0/all/0/1\">Giovanni Da San Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohtarami_M/0/1/0/all/0/1\">Mitra Mohtarami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks. (arXiv:2108.12805v1 [cs.LG])","link":"http://arxiv.org/abs/2108.12805","description":"<p>Adversarial training has been proven to be a powerful regularization method\nto improve the generalization of models. However, current adversarial training\nmethods only attack the original input sample or the embedding vectors, and\ntheir attacks lack coverage and diversity. To further enhance the breadth and\ndepth of attack, we propose a novel masked weight adversarial training method\ncalled DropAttack, which enhances generalization of model by adding\nintentionally worst-case adversarial perturbations to both the input and hidden\nlayers in different dimensions and minimize the adversarial risks generated by\neach layer. DropAttack is a general technique and can be adopt to a wide\nvariety of neural networks with different architectures. To validate the\neffectiveness of the proposed method, we used five public datasets in the\nfields of natural language processing (NLP) and computer vision (CV) for\nexperimental evaluating. We compare the proposed method with other adversarial\ntraining methods and regularization methods, and our method achieves\nstate-of-the-art on all datasets. In addition, Dropattack can achieve the same\nperformance when it use only a half training data compared to other standard\ntraining method. Theoretical analysis reveals that DropAttack can perform\ngradient regularization at random on some of the input and wight parameters of\nthe model. Further visualization experiments show that DropAttack can push the\nminimum risk of the model to a lower and flatter loss landscapes. Our source\ncode is publicly available on https://github.com/nishiwen1214/DropAttack.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_S/0/1/0/all/0/1\">Shiwen Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_H/0/1/0/all/0/1\">Hung-Yu Kao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing and Mitigating Interference in Neural Architecture Search. (arXiv:2108.12821v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12821","description":"<p>Weight sharing has become the \\textit{de facto} approach to reduce the\ntraining cost of neural architecture search (NAS) by reusing the weights of\nshared operators from previously trained child models. However, the estimated\naccuracy of those child models has a low rank correlation with the ground truth\naccuracy due to the interference among different child models caused by weight\nsharing. In this paper, we investigate the interference issue by sampling\ndifferent child models and calculating the gradient similarity of shared\noperators, and observe that: 1) the interference on a shared operator between\ntwo child models is positively correlated to the number of different operators\nbetween them; 2) the interference is smaller when the inputs and outputs of the\nshared operator are more similar. Inspired by these two observations, we\npropose two approaches to mitigate the interference: 1) rather than randomly\nsampling child models for optimization, we propose a gradual modification\nscheme by modifying one operator between adjacent optimization steps to\nminimize the interference on the shared operators; 2) forcing the inputs and\noutputs of the operator across all child models to be similar to reduce the\ninterference. Experiments on a BERT search space verify that mitigating\ninterference via each of our proposed methods improves the rank correlation of\nsuper-pet and combining both methods can achieve better results. Our searched\narchitecture outperforms RoBERTa$_{\\rm base}$ by 1.1 and 0.6 scores and\nELECTRA$_{\\rm base}$ by 1.6 and 1.1 scores on the dev and test set of GLUE\nbenchmark. Extensive results on the BERT compression task, SQuAD datasets and\nother search spaces also demonstrate the effectiveness and generality of our\nproposed methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extractive and Abstractive Sentence Labelling of Sentiment-bearing Topics. (arXiv:2108.12822v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12822","description":"<p>This paper tackles the problem of automatically labelling sentiment-bearing\ntopics with descriptive sentence labels. We propose two approaches to the\nproblem, one extractive and the other abstractive. Both approaches rely on a\nnovel mechanism to automatically learn the relevance of each sentence in a\ncorpus to sentiment-bearing topics extracted from that corpus. The extractive\napproach uses a sentence ranking algorithm for label selection which for the\nfirst time jointly optimises topic--sentence relevance as well as\naspect--sentiment co-coverage. The abstractive approach instead addresses\naspect--sentiment co-coverage by using sentence fusion to generate a sentential\nlabel that includes relevant content from multiple sentences. To our knowledge,\nwe are the first to study the problem of labelling sentiment-bearing topics.\nOur experimental results on three real-world datasets show that both the\nextractive and abstractive approaches outperform four strong baselines in terms\nof facilitating topic understanding and interpretation. In addition, when\ncomparing extractive and abstractive labels, our evaluation shows that our best\nperforming abstractive method is able to provide more topic information\ncoverage in fewer words, at the cost of generating less grammatical labels than\nthe extractive method. We conclude that abstractive methods can effectively\nsynthesise the rich information contained in sentiment-bearing topics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barawi_M/0/1/0/all/0/1\">Mohamad Hardyman Barawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddharthan_A/0/1/0/all/0/1\">Advaith Siddharthan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yinbin Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Behind the Scenes: An Exploration of Trigger Biases Problem in Few-Shot Event Classification. (arXiv:2108.12844v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12844","description":"<p>Few-Shot Event Classification (FSEC) aims at developing a model for event\nprediction, which can generalize to new event types with a limited number of\nannotated data. Existing FSEC studies have achieved high accuracy on different\nbenchmarks. However, we find they suffer from trigger biases that signify the\nstatistical homogeneity between some trigger words and target event types,\nwhich we summarize as trigger overlapping and trigger separability. The biases\ncan result in context-bypassing problem, i.e., correct classifications can be\ngained by looking at only the trigger words while ignoring the entire context.\nTherefore, existing models can be weak in generalizing to unseen data in real\nscenarios. To further uncover the trigger biases and assess the generalization\nability of the models, we propose two new sampling methods, Trigger-Uniform\nSampling (TUS) and COnfusion Sampling (COS), for the meta tasks construction\nduring evaluation. Besides, to cope with the context-bypassing problem in FSEC\nmodels, we introduce adversarial training and trigger reconstruction\ntechniques. Experiments show these techniques help not only improve the\nperformance, but also enhance the generalization ability of models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Runxin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Span Fine-tuning for Pre-trained Language Models. (arXiv:2108.12848v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12848","description":"<p>Pre-trained language models (PrLM) have to carefully manage input units when\ntraining on a very large text with a vocabulary consisting of millions of\nwords. Previous works have shown that incorporating span-level information over\nconsecutive words in pre-training could further improve the performance of\nPrLMs. However, given that span-level clues are introduced and fixed in\npre-training, previous methods are time-consuming and lack of flexibility. To\nalleviate the inconvenience, this paper presents a novel span fine-tuning\nmethod for PrLMs, which facilitates the span setting to be adaptively\ndetermined by specific downstream tasks during the fine-tuning phase. In\ndetail, any sentences processed by the PrLM will be segmented into multiple\nspans according to a pre-sampled dictionary. Then the segmentation information\nwill be sent through a hierarchical CNN module together with the representation\noutputs of the PrLM and ultimately generate a span-enhanced representation.\nExperiments on GLUE benchmark show that the proposed span fine-tuning method\nsignificantly enhances the PrLM, and at the same time, offer more flexibility\nin an efficient way.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_R/0/1/0/all/0/1\">Rongzhou Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiplex Graph Neural Network for Extractive Text Summarization. (arXiv:2108.12870v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12870","description":"<p>Extractive text summarization aims at extracting the most representative\nsentences from a given document as its summary. To extract a good summary from\na long text document, sentence embedding plays an important role. Recent\nstudies have leveraged graph neural networks to capture the inter-sentential\nrelationship (e.g., the discourse graph) to learn contextual sentence\nembedding. However, those approaches neither consider multiple types of\ninter-sentential relationships (e.g., semantic similarity &amp; natural\nconnection), nor model intra-sentential relationships (e.g, semantic &amp;\nsyntactic relationship among words). To address these problems, we propose a\nnovel Multiplex Graph Convolutional Network (Multi-GCN) to jointly model\ndifferent types of relationships among sentences and words. Based on Multi-GCN,\nwe propose a Multiplex Graph Summarization (Multi-GraS) model for extractive\ntext summarization. Finally, we evaluate the proposed models on the\nCNN/DailyMail benchmark dataset to demonstrate the effectiveness and\nsuperiority of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jing_B/0/1/0/all/0/1\">Baoyu Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1\">Zeyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigations on Speech Recognition Systems for Low-Resource Dialectal Arabic-English Code-Switching Speech. (arXiv:2108.12881v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12881","description":"<p>Code-switching (CS), defined as the mixing of languages in conversations, has\nbecome a worldwide phenomenon. The prevalence of CS has been recently met with\na growing demand and interest to build CS ASR systems. In this paper, we\npresent our work on code-switched Egyptian Arabic-English automatic speech\nrecognition (ASR). We first contribute in filling the huge gap in resources by\ncollecting, analyzing and publishing our spontaneous CS Egyptian Arabic-English\nspeech corpus. We build our ASR systems using DNN-based hybrid and\nTransformer-based end-to-end models. In this paper, we present a thorough\ncomparison between both approaches under the setting of a low-resource,\northographically unstandardized, and morphologically rich language pair. We\nshow that while both systems give comparable overall recognition results, each\nsystem provides complementary sets of strength points. We show that recognition\ncan be improved by combining the outputs of both systems. We propose several\neffective system combination approaches, where hypotheses of both systems are\nmerged on sentence- and word-levels. Our approaches result in overall WER\nrelative improvement of 4.7%, over a baseline performance of 32.1% WER. In the\ncase of intra-sentential CS sentences, we achieve WER relative improvement of\n4.8%. Our best performing system achieves 30.6% WER on ArzEn test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamed_I/0/1/0/all/0/1\">Injy Hamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denisov_P/0/1/0/all/0/1\">Pavel Denisov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chia-Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmahdy_M/0/1/0/all/0/1\">Mohamed Elmahdy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdennadher_S/0/1/0/all/0/1\">Slim Abdennadher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Answer Candidates for Quizzes and Answer-Aware Question Generators. (arXiv:2108.12898v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12898","description":"<p>In education, open-ended quiz questions have become an important tool for\nassessing the knowledge of students. Yet, manually preparing such questions is\na tedious task, and thus automatic question generation has been proposed as a\npossible alternative. So far, the vast majority of research has focused on\ngenerating the question text, relying on question answering datasets with\nreadily picked answers, and the problem of how to come up with answer\ncandidates in the first place has been largely ignored. Here, we aim to bridge\nthis gap. In particular, we propose a model that can generate a specified\nnumber of answer candidates for a given passage of text, which can then be used\nby instructors to write questions manually or can be passed as an input to\nautomatic answer-aware question generators. Our experiments show that our\nproposed answer candidate generation model outperforms several baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vachev_K/0/1/0/all/0/1\">Kristiyan Vachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardalov_M/0/1/0/all/0/1\">Momchil Hardalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karadzhov_G/0/1/0/all/0/1\">Georgi Karadzhov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Georgiev_G/0/1/0/all/0/1\">Georgi Georgiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation. (arXiv:2108.12899v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12899","description":"<p>Automated knowledge discovery from trending chemical literature is essential\nfor more efficient biomedical research. How to extract detailed knowledge about\nchemical reactions from the core chemistry literature is a new emerging\nchallenge that has not been well studied. In this paper, we study the new\nproblem of fine-grained chemical entity typing, which poses interesting new\nchallenges especially because of the complex name mentions frequently occurring\nin chemistry literature and graphic representation of entities. We introduce a\nnew benchmark data set (CHEMET) to facilitate the study of the new task and\npropose a novel multi-modal representation learning framework to solve the\nproblem of fine-grained chemical entity typing by leveraging external resources\nwith chemical structures and using cross-modal attention to learn effective\nrepresentation of text in the chemistry domain. Experiment results show that\nthe proposed framework outperforms multiple state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chenkai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Weijiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jinfeng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parulian_N/0/1/0/all/0/1\">Nikolaus Nova Parulian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mischievous Nominal Constructions in Universal Dependencies. (arXiv:2108.12928v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12928","description":"<p>While the highly multilingual Universal Dependencies (UD) project provides\nextensive guidelines for clausal structure as well as structure within\ncanonical nominal phrases, a standard treatment is lacking for many\n\"mischievous\" nominal phenomena that break the mold. As a result, numerous\ninconsistencies within and across corpora can be found, even in languages with\nextensive UD treebanking work, such as English. This paper surveys the kinds of\nmischievous nominal expressions attested in English UD corpora and proposes\nsolutions primarily with English in mind, but which may offer paths to\nsolutions for a variety of UD languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeldes_A/0/1/0/all/0/1\">Amir Zeldes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RetroGAN: A Cyclic Post-Specialization System for Improving Out-of-Knowledge and Rare Word Representations. (arXiv:2108.12941v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12941","description":"<p>Retrofitting is a technique used to move word vectors closer together or\nfurther apart in their space to reflect their relationships in a Knowledge Base\n(KB). However, retrofitting only works on concepts that are present in that KB.\nRetroGAN uses a pair of Generative Adversarial Networks (GANs) to learn a\none-to-one mapping between concepts and their retrofitted counterparts. It\napplies that mapping (post-specializes) to handle concepts that do not appear\nin the original KB in a manner similar to how some natural language systems\nhandle out-of-vocabulary entries. We test our system on three word-similarity\nbenchmarks and a downstream sentence simplification task and achieve the state\nof the art (CARD-660). Altogether, our results demonstrate our system's\neffectiveness for out-of-knowledge and rare word generalization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Colon_Hernandez_P/0/1/0/all/0/1\">Pedro Colon-Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_Y/0/1/0/all/0/1\">Yida Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lieberman_H/0/1/0/all/0/1\">Henry Lieberman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havasi_C/0/1/0/all/0/1\">Catherine Havasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Breazeal_C/0/1/0/all/0/1\">Cynthia Breazeal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1\">Peter Chin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Selective Differential Privacy for Language Modeling. (arXiv:2108.12944v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12944","description":"<p>With the increasing adoption of language models in applications involving\nsensitive data, it has become crucial to protect these models from leaking\nprivate information. Previous work has attempted to tackle this challenge by\ntraining RNN-based language models with differential privacy guarantees.\nHowever, applying classical differential privacy to language models leads to\npoor model performance as the underlying privacy notion is over-pessimistic and\nprovides undifferentiated protection for all tokens of the data. Given that the\nprivate information in natural language is sparse (for example, the bulk of an\nemail might not carry personally identifiable information), we propose a new\nprivacy notion, selective differential privacy, to provide rigorous privacy\nguarantees on the sensitive portion of the data to improve model utility. To\nrealize such a new notion, we develop a corresponding privacy mechanism,\nSelective-DPSGD, for RNN-based language models. Besides language modeling, we\nalso apply the method to a more concrete application -- dialog systems.\nExperiments on both language modeling and dialog system building show that the\nproposed privacy-preserving mechanism achieves better utilities while remaining\nsafe under various privacy attacks compared to the baselines. The data, code\nand models are available at https://github.com/wyshi/lm_privacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_A/0/1/0/all/0/1\">Aiqi Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1\">Evan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LOT: A Benchmark for Evaluating Chinese Long Text Understanding and Generation. (arXiv:2108.12960v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12960","description":"<p>Standard multi-task benchmarks are essential for driving the progress of\ngeneral pretraining models to generalize to various downstream tasks. However,\nexisting benchmarks such as GLUE and GLGE tend to focus on short text\nunderstanding and generation tasks, without considering long text modeling,\nwhich requires many distinct capabilities such as modeling long-range\ncommonsense and discourse relations, as well as the coherence and\ncontrollability of generation. The lack of standardized benchmarks makes it\ndifficult to fully evaluate these capabilities of a model and fairly compare\ndifferent models, especially Chinese pretraining models. Therefore, we propose\nLOT, a benchmark including two understanding and two generation tasks for\nChinese long text modeling evaluation. We construct the datasets for the tasks\nbased on various kinds of human-written Chinese stories. Besides, we release an\nencoder-decoder Chinese long text pretraining model named LongLM with up to 1\nbillion parameters. We pretrain LongLM on 120G Chinese novels with two\ngenerative tasks including text infilling and conditional continuation.\nExtensive experiments on LOT demonstrate that LongLM matches the performance of\nsimilar-sized pretraining models on the understanding tasks and outperforms\nstrong baselines substantially on the generation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jian Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhuoer Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yamei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ruilin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xiaoxi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Changjie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scheduled Sampling Based on Decoding Steps for Neural Machine Translation. (arXiv:2108.12963v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12963","description":"<p>Scheduled sampling is widely used to mitigate the exposure bias problem for\nneural machine translation. Its core motivation is to simulate the inference\nscene during training by replacing ground-truth tokens with predicted tokens,\nthus bridging the gap between training and inference. However, vanilla\nscheduled sampling is merely based on training steps and equally treats all\ndecoding steps. Namely, it simulates an inference scene with uniform error\nrates, which disobeys the real inference scene, where larger decoding steps\nusually have higher error rates due to error accumulations. To alleviate the\nabove discrepancy, we propose scheduled sampling methods based on decoding\nsteps, increasing the selection chance of predicted tokens with the growth of\ndecoding steps. Consequently, we can more realistically simulate the inference\nscene during training, thus better bridging the gap between training and\ninference. Moreover, we investigate scheduled sampling based on both training\nsteps and decoding steps for further improvements. Experimentally, our\napproaches significantly outperform the Transformer baseline and vanilla\nscheduled sampling on three large-scale WMT tasks. Additionally, our approaches\nalso generalize well to the text summarization task on two popular benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement Types. (arXiv:2108.12971v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12971","description":"<p>A smart contract is a program executed on a blockchain, based on which many\ncryptocurrencies are implemented, and is being used for automating\ntransactions. Due to the large amount of money that smart contracts deal with,\nthere is a surging demand for a method that can statically and formally verify\nthem.\n</p>\n<p>This article describes our type-based static verification tool HELMHOLTZ for\nMichelson, which is a statically typed stack-based language for writing smart\ncontracts that are executed on the blockchain platform Tezos. HELMHOLTZ is\ndesigned on top of our extension of Michelson's type system with refinement\ntypes. HELMHOLTZ takes a Michelson program annotated with a user-defined\nspecification written in the form of a refinement type as input; it then\ntypechecks the program against the specification based on the refinement type\nsystem, discharging the generated verification conditions with the SMT solver\nZ3. We briefly introduce our refinement type system for the core calculus\nMini-Michelson of Michelson, which incorporates the characteristic features\nsuch as compound datatypes (e.g., lists and pairs), higher-order functions, and\ninvocation of another contract. \\HELMHOLTZ{} successfully verifies several\npractical Michelson programs, including one that transfers money to an account\nand that checks a digital signature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nishida_Y/0/1/0/all/0/1\">Yuki Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1\">Hiromasa Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawata_A/0/1/0/all/0/1\">Akira Kawata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuse_J/0/1/0/all/0/1\">Jun Furuse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suenaga_K/0/1/0/all/0/1\">Kohei Suenaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igarashi_A/0/1/0/all/0/1\">Atsushi Igarashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shatter: An Efficient Transformer Encoder with Single-Headed Self-Attention and Relative Sequence Partitioning. (arXiv:2108.13032v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13032","description":"<p>The highly popular Transformer architecture, based on self-attention, is the\nfoundation of large pretrained models such as BERT, that have become an\nenduring paradigm in NLP. While powerful, the computational resources and time\nrequired to pretrain such models can be prohibitive. In this work, we present\nan alternative self-attention architecture, Shatter, that more efficiently\nencodes sequence information by softly partitioning the space of relative\npositions and applying different value matrices to different parts of the\nsequence. This mechanism further allows us to simplify the multi-headed\nattention in Transformer to single-headed. We conduct extensive experiments\nshowing that Shatter achieves better performance than BERT, with pretraining\nbeing faster per step (15% on TPU), converging in fewer steps, and offering\nconsiderable memory savings (&gt;50%). Put together, Shatter can be pretrained on\n8 V100 GPUs in 7 days, and match the performance of BERT_Base -- making the\ncost of pretraining much more affordable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1\">Ran Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_A/0/1/0/all/0/1\">Ankur P. Parikh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding. (arXiv:2108.13048v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13048","description":"<p>Language understanding in speech-based systems have attracted much attention\nin recent years with the growing demand for voice interface applications.\nHowever, the robustness of natural language understanding (NLU) systems to\nerrors introduced by automatic speech recognition (ASR) is under-examined. %To\nfacilitate the research on ASR-robust general language understanding, In this\npaper, we propose ASR-GLUE benchmark, a new collection of 6 different NLU tasks\nfor evaluating the performance of models under ASR error across 3 different\nlevels of background noise and 6 speakers with various voice characteristics.\nBased on the proposed benchmark, we systematically investigate the effect of\nASR error on NLU tasks in terms of noise intensity, error type and speaker\nvariants. We further purpose two ways, correction-based method and data\naugmentation-based method to improve robustness of the NLU systems. Extensive\nexperimental results and analysises show that the proposed methods are\neffective to some extent, but still far from human performance, demonstrating\nthat NLU under ASR error is still very challenging and requires further\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lingyun Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianwei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Songxiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Haitao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Base Completion Meets Transfer Learning. (arXiv:2108.13073v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13073","description":"<p>The aim of knowledge base completion is to predict unseen facts from existing\nfacts in knowledge bases. In this work, we introduce the first approach for\ntransfer of knowledge from one collection of facts to another without the need\nfor entity or relation matching. The method works for both canonicalized\nknowledge bases and uncanonicalized or open knowledge bases, i.e., knowledge\nbases where more than one copy of a real-world entity or relation may exist.\nSuch knowledge bases are a natural output of automated information extraction\ntools that extract structured data from unstructured text. Our main\ncontribution is a method that can make use of a large-scale pre-training on\nfacts, collected from unstructured text, to improve predictions on structured\ndata from a specific domain. The introduced method is the most impactful on\nsmall datasets such as ReVerb20K, where we obtained 6% absolute increase of\nmean reciprocal rank and 65% relative decrease of mean rank over the previously\nbest method, despite not relying on large pre-trained models like BERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocijan_V/0/1/0/all/0/1\">Vid Kocijan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NEREL: A Russian Dataset with Nested Named Entities and Relations. (arXiv:2108.13112v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13112","description":"<p>In this paper, we present NEREL, a Russian dataset for named entity\nrecognition and relation extraction. NEREL is significantly larger than\nexisting Russian datasets: to date it contains 56K annotated named entities and\n39K annotated relations. Its important difference from previous datasets is\nannotation of nested named entities, as well as relations within nested\nentities and at the discourse level. NEREL can facilitate development of novel\nmodels that can extract relations between nested named entities, as well as\nrelations on both sentence and document levels. NEREL also contains the\nannotation of events involving named entities and their roles in the events.\nThe NEREL collection is available via https://github.com/nerel-ds/NEREL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loukachevitch_N/0/1/0/all/0/1\">Natalia Loukachevitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1\">Ekaterina Artemova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1\">Tatiana Batura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braslavski_P/0/1/0/all/0/1\">Pavel Braslavski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denisov_I/0/1/0/all/0/1\">Ilia Denisov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_V/0/1/0/all/0/1\">Vladimir Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manandhar_S/0/1/0/all/0/1\">Suresh Manandhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pugachev_A/0/1/0/all/0/1\">Alexander Pugachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutubalina_E/0/1/0/all/0/1\">Elena Tutubalina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Factual Consistency Evaluation for Text Summarization via Counterfactual Estimation. (arXiv:2108.13134v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13134","description":"<p>Despite significant progress has been achieved in text summarization, factual\ninconsistency in generated summaries still severely limits its practical\napplications. Among the key factors to ensure factual consistency, a reliable\nautomatic evaluation metric is the first and the most crucial one. However,\nexisting metrics either neglect the intrinsic cause of the factual\ninconsistency or rely on auxiliary tasks, leading to an unsatisfied correlation\nwith human judgments or increasing the inconvenience of usage in practice. In\nlight of these challenges, we propose a novel metric to evaluate the factual\nconsistency in text summarization via counterfactual estimation, which\nformulates the causal relationship among the source document, the generated\nsummary, and the language prior. We remove the effect of language prior, which\ncan cause factual inconsistency, from the total causal effect on the generated\nsummary, and provides a simple yet effective way to evaluate consistency\nwithout relying on other auxiliary tasks. We conduct a series of experiments on\nthree public abstractive text summarization datasets, and demonstrate the\nadvantages of the proposed metric in both improving the correlation with human\njudgments and the convenience of usage. The source code is available at\nhttps://github.com/xieyxclack/factual_coco.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuexiang Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neuron-level Interpretation of Deep NLP Models: A Survey. (arXiv:2108.13138v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13138","description":"<p>The proliferation of deep neural networks in various domains has seen an\nincreased need for interpretability of these methods. A plethora of research\nhas been carried out to analyze and understand components of the deep neural\nnetwork models. Preliminary work done along these lines and papers that\nsurveyed such, were focused on a more high-level representation analysis.\nHowever, a recent branch of work has concentrated on interpretability at a more\ngranular level, analyzing neurons and groups of neurons in these large models.\nIn this paper, we survey work done on fine-grained neuron analysis including:\ni) methods developed to discover and understand neurons in a network, ii) their\nlimitations and evaluation, iii) major findings including cross architectural\ncomparison that such analyses unravel and iv) direct applications of neuron\nanalysis such as model behavior control and domain adaptation along with\npotential directions for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CSDS: A Fine-grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13139","description":"<p>Dialogue summarization has drawn much attention recently. Especially in the\ncustomer service domain, agents could use dialogue summaries to help boost\ntheir works by quickly knowing customers' issues and service progress. These\napplications require summaries to contain the perspective of a single speaker\nand have a clear topic flow structure. Neither are available in existing\ndatasets. Therefore, in this paper, we introduce a novel Chinese dataset for\nCustomer Service Dialogue Summarization (CSDS). CSDS improves the abstractive\nsummaries in two aspects: (1) In addition to the overall summary for the whole\ndialogue, role-oriented summaries are also provided to acquire different\nspeakers' viewpoints. (2) All the summaries sum up each topic separately, thus\ncontaining the topic-level structure of the dialogue. We define tasks in CSDS\nas generating the overall summary and different role-oriented summaries for a\ngiven dialogue. Next, we compare various summarization methods on CSDS, and\nexperiment results show that existing methods are prone to generate redundant\nand incoherent summaries. Besides, the performance becomes much worse when\nanalyzing the performance on role-oriented summaries and topic structures. We\nhope that this study could benchmark Chinese dialogue summarization and benefit\nfurther studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liqun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Junnan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Lu Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_C/0/1/0/all/0/1\">Chengqing Zong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Sentiment Analysis Dataset for Trustworthiness Evaluation. (arXiv:2108.13140v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13140","description":"<p>While deep learning models have greatly improved the performance of most\nartificial intelligence tasks, they are often criticized to be untrustworthy\ndue to the black-box problem. Consequently, many works have been proposed to\nstudy the trustworthiness of deep learning. However, as most open datasets are\ndesigned for evaluating the accuracy of model outputs, there is still a lack of\nappropriate datasets for evaluating the inner workings of neural networks. The\nlack of datasets obviously hinders the development of trustworthiness research.\nTherefore, in order to systematically evaluate the factors for building\ntrustworthy systems, we propose a novel and well-annotated sentiment analysis\ndataset to evaluate robustness and interpretability. To evaluate these factors,\nour dataset contains diverse annotations about the challenging distribution of\ninstances, manual adversarial instances and sentiment explanations. Several\nevaluation metrics are further proposed for interpretability and robustness.\nBased on the dataset and metrics, we conduct comprehensive comparisons for the\ntrustworthiness of three typical models, and also study the relations between\naccuracy, robustness and interpretability. We release this trustworthiness\nevaluation dataset at \\url{https://github/xyz} and hope our work can facilitate\nthe progress on building more trustworthy systems for real-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shuyuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hongxuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Ying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13161","description":"<p>Large-scale pre-trained language models have contributed significantly to\nnatural language processing by demonstrating remarkable abilities as few-shot\nlearners. However, their effectiveness depends mainly on scaling the model\nparameters and prompt design, hindering their implementation in most real-world\napplications. This study proposes a novel pluggable, extensible, and efficient\napproach named DifferentiAble pRompT (DART), which can convert small language\nmodels into better few-shot learners without any prompt engineering. The main\nprinciple behind this approach involves reformulating potential natural\nlanguage processing tasks into the task of a pre-trained language model and\ndifferentially optimizing the prompt template as well as the target label with\nbackpropagation. Furthermore, the proposed approach can be: (i) Plugged to any\npre-trained language models; (ii) Extended to widespread classification tasks.\nA comprehensive evaluation of standard NLP tasks demonstrates that the proposed\napproach achieves a better few-shot performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luoqiu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?. (arXiv:1905.10617v9 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/1905.10617","description":"<p>Exposure bias has been regarded as a central problem for auto-regressive\nlanguage models (LM). It claims that teacher forcing would cause the test-time\ngeneration to be incrementally distorted due to the training-generation\ndiscrepancy. Although a lot of algorithms have been proposed to avoid teacher\nforcing and therefore alleviate exposure bias, there is little work showing how\nserious the exposure bias problem actually is. In this work, we focus on the\ntask of open-ended language generation, propose metrics to quantify the impact\nof exposure bias in the aspects of quality, diversity, and consistency. Our key\nintuition is that if we feed ground-truth data prefixes (instead of prefixes\ngenerated by the model itself) into the model and ask it to continue the\ngeneration, the performance should become much better because the\ntraining-generation discrepancy in the prefix is removed. Both automatic and\nhuman evaluations are conducted in our experiments. On the contrary to the\npopular belief in exposure bias, we find that the the distortion induced by the\nprefix discrepancy is limited, and does not seem to be incremental during the\ngeneration. Moreover, our analysis reveals an interesting self-recovery ability\nof the LM, which we hypothesize to be countering the harmful effects from\nexposure bias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Keeping it simple: Implementation and performance of the proto-principle of adaptation and learning in the language sciences. (arXiv:2003.03813v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2003.03813","description":"<p>In this paper we present the Widrow-Hoff rule and its applications to\nlanguage data. After contextualizing the rule historically and placing it in\nthe chain of neurally inspired artificial learning models, we explain its\nrationale and implementational considerations. Using a number of case studies\nwe illustrate how the Widrow-Hoff rule offers unexpected opportunities for the\ncomputational simulation of a range of language phenomena that make it possible\nto approach old problems from a novel perspective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Milin_P/0/1/0/all/0/1\">Petar Milin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madabushi_H/0/1/0/all/0/1\">Harish Tayyar Madabushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Croucher_M/0/1/0/all/0/1\">Michael Croucher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divjak_D/0/1/0/all/0/1\">Dagmar Divjak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Learning with Common Sense Knowledge Graphs. (arXiv:2006.10713v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2006.10713","description":"<p>Zero-shot learning relies on semantic class representations such as\nhand-engineered attributes or learned embeddings to predict classes without any\nlabeled examples. We propose to learn class representations by embedding nodes\nfrom common sense knowledge graphs in a vector space. Common sense knowledge\ngraphs are an untapped source of explicit high-level knowledge that requires\nlittle human effort to apply to a range of tasks. To capture the knowledge in\nthe graph, we introduce ZSL-KG, a general-purpose framework with a novel\ntransformer graph convolutional network (TrGCN) for generating class\nrepresentations. Our proposed TrGCN architecture computes non-linear\ncombinations of node neighbourhoods. Our results show that ZSL-KG improves over\nexisting WordNet-based methods on five out of six zero-shot benchmark datasets\nin language and vision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal V. Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Best-First Beam Search. (arXiv:2007.03909v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2007.03909","description":"<p>Decoding for many NLP tasks requires an effective heuristic algorithm for\napproximating exact search since the problem of searching the full output space\nis often intractable, or impractical in many settings. The default algorithm\nfor this job is beam search -- a pruned version of breadth-first search. Quite\nsurprisingly, beam search often returns better results than exact inference due\nto beneficial search bias for NLP tasks. In this work, we show that the\nstandard implementation of beam search can be made up to 10x faster in\npractice. Our method assumes that the scoring function is monotonic in the\nsequence length, which allows us to safely prune hypotheses that cannot be in\nthe final set of hypotheses early on. We devise effective monotonic\napproximations to popular nonmonontic scoring functions, including length\nnormalization and mutual information decoding. Lastly, we propose a\nmemory-reduced variant of Best-First Beam Search, which has a similar\nbeneficial search bias in terms of downstream performance, but runs in a\nfraction of the time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audiovisual Speech Synthesis using Tacotron2. (arXiv:2008.00620v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2008.00620","description":"<p>Audiovisual speech synthesis is the problem of synthesizing a talking face\nwhile maximizing the coherency of the acoustic and visual speech. In this\npaper, we propose and compare two audiovisual speech synthesis systems for 3D\nface models. The first system is the AVTacotron2, which is an end-to-end\ntext-to-audiovisual speech synthesizer based on the Tacotron2 architecture.\nAVTacotron2 converts a sequence of phonemes representing the sentence to\nsynthesize into a sequence of acoustic features and the corresponding\ncontrollers of a face model. The output acoustic features are used to condition\na WaveRNN to reconstruct the speech waveform, and the output facial controllers\nare used to generate the corresponding video of the talking face. The second\naudiovisual speech synthesis system is modular, where acoustic speech is\nsynthesized from text using the traditional Tacotron2. The reconstructed\nacoustic speech signal is then used to drive the facial controls of the face\nmodel using an independently trained audio-to-facial-animation neural network.\nWe further condition both the end-to-end and modular approaches on emotion\nembeddings that encode the required prosody to generate emotional audiovisual\nspeech. We analyze the performance of the two systems and compare them to the\nground truth videos using subjective evaluation tests. The end-to-end and\nmodular systems are able to synthesize close to human-like audiovisual speech\nwith mean opinion scores (MOS) of 4.1 and 3.9, respectively, compared to a MOS\nof 4.1 for the ground truth generated from professionally recorded videos.\nWhile the end-to-end system gives a better overall quality, the modular\napproach is more flexible and the quality of acoustic speech and visual speech\nsynthesis is almost independent of each other.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Abdelaziz_A/0/1/0/all/0/1\">Ahmed Hussen Abdelaziz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1\">Anushree Prasanna Kumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Seivwright_C/0/1/0/all/0/1\">Chloe Seivwright</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fanelli_G/0/1/0/all/0/1\">Gabriele Fanelli</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Binder_J/0/1/0/all/0/1\">Justin Binder</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Stylianou_Y/0/1/0/all/0/1\">Yannis Stylianou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kajarekar_S/0/1/0/all/0/1\">Sachin Kajarekar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rank over Class: The Untapped Potential of Ranking in Natural Language Processing. (arXiv:2009.05160v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.05160","description":"<p>Text classification has long been a staple within Natural Language Processing\n(NLP) with applications spanning across diverse areas such as sentiment\nanalysis, recommender systems and spam detection. With such a powerful\nsolution, it is often tempting to use it as the go-to tool for all NLP problems\nsince when you are holding a hammer, everything looks like a nail. However, we\nargue here that many tasks which are currently addressed using classification\nare in fact being shoehorned into a classification mould and that if we instead\naddress them as a ranking problem, we not only improve the model, but we\nachieve better performance. We propose a novel end- to-end ranking approach\nconsisting of a Transformer network responsible for producing representations\nfor a pair of text sequences, which are in turn passed into a context\naggregating network outputting ranking scores used to determine an ordering to\nthe sequences based on some notion of relevance. We perform numerous\nexperiments on publicly-available datasets and investigate the applications of\nranking in problems often solved using classification. In an experiment on a\nheavily-skewed sentiment analysis dataset, converting ranking results to\nclassification labels yields an approximately 22% improvement over\nstate-of-the-art text classification, demonstrating the efficacy of text\nranking over text classification in certain scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Atapour_Abarghouei_A/0/1/0/all/0/1\">Amir Atapour-Abarghouei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonner_S/0/1/0/all/0/1\">Stephen Bonner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGough_A/0/1/0/all/0/1\">Andrew Stephen McGough</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weight Squeezing: Reparameterization for Knowledge Transfer and Model Compression. (arXiv:2010.06993v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2010.06993","description":"<p>In this work, we present a novel approach for simultaneous knowledge transfer\nand model compression called Weight Squeezing. With this method, we perform\nknowledge transfer from a teacher model by learning the mapping from its\nweights to smaller student model weights.\n</p>\n<p>We applied Weight Squeezing to a pre-trained text classification model based\non BERT-Medium model and compared our method to various other knowledge\ntransfer and model compression methods on GLUE multitask benchmark. We observed\nthat our approach produces better results while being significantly faster than\nother methods for training student models.\n</p>\n<p>We also proposed a variant of Weight Squeezing called Gated Weight Squeezing,\nfor which we combined fine-tuning of BERT-Medium model and learning mapping\nfrom BERT-Base weights. We showed that fine-tuning with Gated Weight Squeezing\noutperforms plain fine-tuning of BERT-Medium model as well as other concurrent\nSoTA approaches while much being easier to implement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chumachenko_A/0/1/0/all/0/1\">Artem Chumachenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalaidin_P/0/1/0/all/0/1\">Pavel Kalaidin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic-Guided Abstractive Text Summarization: a Joint Learning Approach. (arXiv:2010.10323v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.10323","description":"<p>We introduce a new approach for abstractive text summarization, Topic-Guided\nAbstractive Summarization, which calibrates long-range dependencies from\ntopic-level features with globally salient content. The idea is to incorporate\nneural topic modeling with a Transformer-based sequence-to-sequence (seq2seq)\nmodel in a joint learning framework. This design can learn and preserve the\nglobal semantics of the document, which can provide additional contextual\nguidance for capturing important ideas of the document, thereby enhancing the\ngeneration of summary. We conduct extensive experiments on two datasets and the\nresults show that our proposed model outperforms many extractive and\nabstractive systems in terms of both ROUGE measurements and human evaluation.\nOur code is available at: https://github.com/chz816/tas.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kunpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Harry Jiannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Ling Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhe Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SlimIPL: Language-Model-Free Iterative Pseudo-Labeling. (arXiv:2010.11524v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.11524","description":"<p>Recent results in end-to-end automatic speech recognition have demonstrated\nthe efficacy of pseudo-labeling for semi-supervised models trained both with\nConnectionist Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq)\nlosses. Iterative Pseudo-Labeling (IPL), which continuously trains a single\nmodel using pseudo-labels iteratively re-generated as the model learns, has\nbeen shown to further improve performance in ASR. We improve upon the IPL\nalgorithm: as the model learns, we propose to iteratively re-generate\ntranscriptions with hard labels (the most probable tokens), that is, without a\nlanguage model. We call this approach Language-Model-Free IPL (slimIPL) and\ngive a resultant training setup for low-resource settings with CTC-based\nmodels. slimIPL features a dynamic cache for pseudo-labels which reduces\nsensitivity to changes in relabeling hyperparameters and results in improves\ntraining stability. slimIPL is also highly-efficient and requires 3.5-4x fewer\ncomputational resources to converge than other state-of-the-art\nsemi/self-supervised approaches. With only 10 hours of labeled audio, slimIPL\nis competitive with self-supervised approaches, and is state-of-the-art with\n100 hours of labeled audio without the use of a language model both at test\ntime and during pseudo-label generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_J/0/1/0/all/0/1\">Jacob Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1\">Ronan Collobert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BanglaBERT: Combating Embedding Barrier in Multilingual Models for Low-Resource Language Understanding. (arXiv:2101.00204v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00204","description":"<p>In this paper, we introduce ``Embedding Barrier'', a phenomenon that limits\nthe monolingual performance of multilingual models on low-resource languages\nhaving unique typologies. We build `BanglaBERT', a Bangla language model\npretrained on 18.6 GB Internet-crawled data and benchmark on five standard NLU\ntasks. We discover a significant drop in the performance of the\nstate-of-the-art multilingual model (XLM-R) from BanglaBERT and attribute this\nto the Embedding Barrier through comprehensive experiments. We identify that a\nmultilingual model's performance on a low-resource language is hurt when its\nwriting script is not similar to any of the high-resource languages. To tackle\nthe barrier, we propose a straightforward solution by transcribing languages to\na common script, which can effectively improve the performance of a\nmultilingual model for the Bangla language. As a bi-product of the standard NLU\nbenchmarks, we introduce a new downstream dataset on natural language inference\n(NLI) and show that BanglaBERT outperforms previous state-of-the-art results on\nall tasks by up to 3.5%. We are making the BanglaBERT language model and the\nnew Bangla NLI dataset publicly available in the hope of advancing the\ncommunity. The resources can be found at\n\\url{https://github.com/csebuetnlp/banglabert}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_A/0/1/0/all/0/1\">Abhik Bhattacharjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1\">Tahmid Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samin_K/0/1/0/all/0/1\">Kazi Samin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Saiful Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">M. Sohel Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iqbal_A/0/1/0/all/0/1\">Anindya Iqbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahriyar_R/0/1/0/all/0/1\">Rifat Shahriyar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast End-to-End Speech Recognition via Non-Autoregressive Models and Cross-Modal Knowledge Transferring from BERT. (arXiv:2102.07594v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.07594","description":"<p>Attention-based encoder-decoder (AED) models have achieved promising\nperformance in speech recognition. However, because the decoder predicts text\ntokens (such as characters or words) in an autoregressive manner, it is\ndifficult for an AED model to predict all tokens in parallel. This makes the\ninference speed relatively slow. We believe that because the encoder already\ncaptures the whole speech utterance, which has the token-level relationship\nimplicitly, we can predict a token without explicitly autoregressive language\nmodeling. When the prediction of a token does not rely on other tokens, the\nparallel prediction of all tokens in the sequence is realizable. Based on this\nidea, we propose a non-autoregressive speech recognition model called LASO\n(Listen Attentively, and Spell Once). The model consists of an encoder, a\ndecoder, and a position dependent summarizer (PDS). The three modules are based\non basic attention blocks. The encoder extracts high-level representations from\nthe speech. The PDS uses positional encodings corresponding to tokens to\nconvert the acoustic representations into token-level representations. The\ndecoder further captures token-level relationships with the self-attention\nmechanism. At last, the probability distribution on the vocabulary is computed\nfor each token position. Therefore, speech recognition is re-formulated as a\nposition-wise classification problem. Further, we propose a cross-modal\ntransfer learning method to refine semantics from a large-scale pre-trained\nlanguage model BERT for improving the performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Ye Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhengkun Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhengqi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuai Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task. (arXiv:2103.15255v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.15255","description":"<p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term,\nsentiment and opinion term triplets from sentences and tries to provide a\ncomplete solution for aspect-based sentiment analysis (ABSA). However, some\ntriplets extracted by ASTE are confusing, since the sentiment in a triplet\nextracted by ASTE is the sentiment that the sentence expresses toward the\naspect term rather than the sentiment of the aspect term and opinion term pair.\nIn this paper, we introduce a more fine-grained Aspect-Sentiment-Opinion\nTriplet Extraction (ASOTE) Task. ASOTE also extracts aspect term, sentiment and\nopinion term triplets. However, the sentiment in a triplet extracted by ASOTE\nis the sentiment of the aspect term and opinion term pair. We build four\ndatasets for ASOTE based on several popular ABSA benchmarks. We propose a\nPosition-aware BERT-based Framework (PBF) to address this task. PBF first\nextracts aspect terms from sentences. For each extracted aspect term, PBF first\ngenerates aspect term-specific sentence representations considering both the\nmeaning and the position of the aspect term, then extracts associated opinion\nterms and predicts the sentiments of the aspect term and opinion term pairs\nbased on the sentence representations. Experimental results on the four\ndatasets show the effectiveness of PBF.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuncong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Sheng-hua Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Cunxiang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yancheng He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting of a Patient's Condition From Clinical Narratives Using Natural Language Representation. (arXiv:2104.03969v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.03969","description":"<p>The rapid progress in clinical data management systems and artificial\nintelligence approaches enable the era of personalized medicine. Intensive care\nunits (ICUs) are the ideal clinical research environment for such development\nbecause they collect many clinical data and are highly computerized\nenvironments. We designed a retrospective clinical study on a prospective ICU\ndatabase using clinical natural language to help in the early diagnosis of\nheart failure in critically ill children. The methodology consisted of\nempirical experiments of a learning algorithm to learn the hidden\ninterpretation and presentation of the French clinical note data. This study\nincluded 1386 patients' clinical notes with 5444 single lines of notes. There\nwere 1941 positive cases (36 % of total) and 3503 negative cases classified by\ntwo independent physicians using a standardized approach. The multilayer\nperceptron neural network outperforms other discriminative and generative\nclassifiers. Consequently, the proposed framework yields an overall\nclassification performance with 89 % accuracy, 88 % recall, and 89 % precision.\nThis study successfully applied learning representation and machine learning\nalgorithms to detect heart failure from clinical natural language in a single\nFrench institution. Further work is needed to use the same methodology in other\ninstitutions and other languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thanh-Dung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noumeir_R/0/1/0/all/0/1\">Rita Noumeir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambaud_J/0/1/0/all/0/1\">Jerome Rambaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sans_G/0/1/0/all/0/1\">Guillaume Sans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jouvet_P/0/1/0/all/0/1\">Philippe Jouvet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07650","description":"<p>Recently, prompt-tuning has achieved promising results on some few-shot\nclassification tasks. The core idea of prompt-tuning is to insert text pieces,\ni.e., templates, into the input and transform a classification task into a\nmasked language modeling problem. However, as for relation extraction,\ndetermining the appropriate prompt template requires domain expertise. Single\nlabel word handcrafted or auto-searched is cumbersome and time-consuming to\nverify their effectiveness in non-few-shot scenarios. Further, there exist\nabundant semantic knowledge among the entities and relation labels which cannot\nbe ignored. To this end, we focus on incorporating knowledge into prompt-tuning\nfor relation extraction and propose a Knowledge-aware prompt-tuning with\nsynergistic optimization (KNIGHT) approach. Specifically, we inject entity and\nrelation knowledge into prompt construction with learnable virtual template\nwords and answer words and jointly optimize their representation with knowledge\nconstraints. Extensive experimental results on five datasets with standard and\nlow-resource settings demonstrate the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cost-effective End-to-end Information Extraction for Semi-structured Document Images. (arXiv:2104.08041v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08041","description":"<p>A real-world information extraction (IE) system for semi-structured document\nimages often involves a long pipeline of multiple modules, whose complexity\ndramatically increases its development and maintenance cost. One can instead\nconsider an end-to-end model that directly maps the input to the target output\nand simplify the entire process. However, such generation approach is known to\nlead to unstable performance if not designed carefully. Here we present our\nrecent effort on transitioning from our existing pipeline-based IE system to an\nend-to-end system focusing on practical challenges that are associated with\nreplacing and deploying the system in real, large-scale production. By\ncarefully formulating document IE as a sequence generation task, we show that a\nsingle end-to-end IE system can be built and still achieve competent\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1\">Wonseok Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyunji Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yim_J/0/1/0/all/0/1\">Jinyeong Yim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Geewook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model Evaluation Beyond Perplexity. (arXiv:2106.00085v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.00085","description":"<p>We propose an alternate approach to quantifying how well language models\nlearn natural language: we ask how well they match the statistical tendencies\nof natural language. To answer this question, we analyze whether text generated\nfrom language models exhibits the statistical tendencies present in the\nhuman-generated text on which they were trained. We provide a framework--paired\nwith significance tests--for evaluating the fit of language models to these\ntrends. We find that neural language models appear to learn only a subset of\nthe tendencies considered, but align much more closely with empirical trends\nthan proposed theoretical distributions (when present). Further, the fit to\ndifferent distributions is highly-dependent on both model architecture and\ngeneration strategy. As concrete examples, text generated under the nucleus\nsampling scheme adheres more closely to the type--token relationship of natural\nlanguage than text produced using standard ancestral sampling; text from LSTMs\nreflects the natural language distributions over length, stopwords, and symbols\nsurprisingly well.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.08087","description":"<p>Artificial Intelligence (AI), along with the recent progress in biomedical\nlanguage understanding, is gradually changing medical practice. With the\ndevelopment of biomedical language understanding benchmarks, AI applications\nare widely used in the medical field. However, most benchmarks are limited to\nEnglish, which makes it challenging to replicate many of the successes in\nEnglish for other languages. To facilitate research in this direction, we\ncollect real-world biomedical data and present the first Chinese Biomedical\nLanguage Understanding Evaluation (CBLUE) benchmark: a collection of natural\nlanguage understanding tasks including named entity recognition, information\nextraction, clinical diagnosis normalization, single-sentence/sentence-pair\nclassification, and an associated online platform for model evaluation,\ncomparison, and analysis. To establish evaluation on these tasks, we report\nempirical results with the current 11 pre-trained Chinese models, and\nexperimental results show that state-of-the-art neural models perform by far\nworse than the human ceiling. Our benchmark is released at\n\\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&amp;lang=en-us}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mosha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1\">Xin Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1\">Kangping Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1\">Yuan Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1\">Guotong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_H/0/1/0/all/0/1\">Hui Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_H/0/1/0/all/0/1\">Hongying Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kunli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.14463","description":"<p>Extracting structured clinical information from free-text radiology reports\ncan enable the use of radiology report information for a variety of critical\nhealthcare applications. In our work, we present RadGraph, a dataset of\nentities and relations in full-text chest X-ray radiology reports based on a\nnovel information extraction schema we designed to structure radiology reports.\nWe release a development dataset, which contains board-certified radiologist\nannotations for 500 radiology reports from the MIMIC-CXR dataset (14,579\nentities and 10,889 relations), and a test dataset, which contains two\nindependent sets of board-certified radiologist annotations for 100 radiology\nreports split equally across the MIMIC-CXR and CheXpert datasets. Using these\ndatasets, we train and test a deep learning model, RadGraph Benchmark, that\nachieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR\nand CheXpert test sets respectively. Additionally, we release an inference\ndataset, which contains annotations automatically generated by RadGraph\nBenchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4\nmillion relations) and 500 CheXpert reports (13,783 entities and 9,908\nrelations) with mappings to associated chest radiographs. Our freely available\ndataset can facilitate a wide range of research in medical natural language\nprocessing, as well as computer vision and multi-modal learning when linked to\nchest radiographs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Saahil Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Ashwin Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saporta_A/0/1/0/all/0/1\">Adriel Saporta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_S/0/1/0/all/0/1\">Steven QH Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1\">Du Nguyen Duong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Tan Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chambon_P/0/1/0/all/0/1\">Pierre Chambon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P. Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1\">Andrew Y. Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1\">Curtis P. Langlotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2107.08264","description":"<p>Multimodal sentiment analysis aims to recognize people's attitudes from\nmultiple communication channels such as verbal content (i.e., text), voice, and\nfacial expressions. It has become a vibrant and important research topic in\nnatural language processing. Much research focuses on modeling the complex\nintra- and inter-modal interactions between different communication channels.\nHowever, current multimodal models with strong performance are often\ndeep-learning-based techniques and work like black boxes. It is not clear how\nmodels utilize multimodal information for sentiment predictions. Despite recent\nadvances in techniques for enhancing the explainability of machine learning\nmodels, they often target unimodal scenarios (e.g., images, sentences), and\nlittle research has been done on explaining multimodal models. In this paper,\nwe present an interactive visual analytics system, M2Lens, to visualize and\nexplain multimodal models for sentiment analysis. M2Lens provides explanations\non intra- and inter-modal interactions at the global, subset, and local levels.\nSpecifically, it summarizes the influence of three typical interaction types\n(i.e., dominance, complement, and conflict) on the model predictions. Moreover,\nM2Lens identifies frequent and influential multimodal features and supports the\nmulti-faceted exploration of model behaviors from language, acoustic, and\nvisual modalities. Through two case studies and expert interviews, we\ndemonstrate our system can help users gain deep insights into the multimodal\nmodels for sentiment analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhihua Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Huamin Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link Prediction. (arXiv:2108.02314v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.02314","description":"<p>Enormous hope in the efficacy of vaccines became recently a successful\nreality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,\nfueled by exposure to social media misinformation about COVID-19 vaccines\nbecame a major hurdle. Therefore, it is essential to automatically detect where\nmisinformation about COVID-19 vaccines on social media is spread and what kind\nof misinformation is discussed, such that inoculation interventions can be\ndelivered at the right time and in the right place, in addition to\ninterventions designed to address vaccine hesitancy. This paper is addressing\nthe first step in tackling hesitancy against COVID-19 vaccines, namely the\nautomatic detection of known misinformation about the vaccines on Twitter, the\nsocial media platform that has the highest volume of conversations about\nCOVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged\nrelevant to several misinformation targets about COVID-19 vaccines on which a\nnovel method of detecting misinformation was developed. Our method organizes\nCoVaxLies in a Misinformation Knowledge Graph as it casts misinformation\ndetection as a graph link prediction problem. The misinformation detection\nmethod detailed in this paper takes advantage of the link scoring functions\nprovided by several knowledge embedding methods. The experimental results\ndemonstrate the superiority of this method when compared with\nclassification-based methods, widely used currently.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weinzierl_M/0/1/0/all/0/1\">Maxwell A. Weinzierl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harabagiu_S/0/1/0/all/0/1\">Sanda M. Harabagiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing. (arXiv:2108.05542v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.05542","description":"<p>Transformer-based pretrained language models (T-PTLMs) have achieved great\nsuccess in almost every NLP task. The evolution of these models started with\nGPT and BERT. These models are built on the top of transformers,\nself-supervised learning and transfer learning. Transformed-based PTLMs learn\nuniversal language representations from large volumes of text data using\nself-supervised learning and transfer this knowledge to downstream tasks. These\nmodels provide good background knowledge to downstream tasks which avoids\ntraining of downstream models from scratch. In this comprehensive survey paper,\nwe initially give a brief overview of self-supervised learning. Next, we\nexplain various core concepts like pretraining, pretraining methods,\npretraining tasks, embeddings and downstream adaptation methods. Next, we\npresent a new taxonomy of T-PTLMs and then give brief overview of various\nbenchmarks including both intrinsic and extrinsic. We present a summary of\nvarious useful libraries to work with T-PTLMs. Finally, we highlight some of\nthe future research directions which will further improve these models. We\nstrongly believe that this comprehensive survey paper will serve as a good\nreference to learn the core concepts as well as to stay updated with the recent\nhappenings in T-PTLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_K/0/1/0/all/0/1\">Katikapalli Subramanyam Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajasekharan_A/0/1/0/all/0/1\">Ajit Rajasekharan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sangeetha_S/0/1/0/all/0/1\">Sivanesan Sangeetha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.06712","description":"<p>Tables are often created with hierarchies, but existing works on table\nreasoning mainly focus on flat tables and neglect hierarchical tables.\nHierarchical tables challenge existing methods by hierarchical indexing, as\nwell as implicit relationships of calculation and semantics. This work presents\nHiTab, a free and open dataset to study question answering (QA) and natural\nlanguage generation (NLG) over hierarchical tables. HiTab is a cross-domain\ndataset constructed from a wealth of statistical reports (analyses) and\nWikipedia pages, and has unique characteristics: (1) nearly all tables are\nhierarchical, and (2) both target sentences for NLG and questions for QA are\nrevised from original, meaningful, and diverse descriptive sentences authored\nby analysts and professions of reports. (3) to reveal complex numerical\nreasoning in statistical analyses, we provide fine-grained annotations of\nentity and quantity alignment. HiTab provides 10,686 QA pairs and descriptive\nsentences with well-annotated quantity and entity alignment on 3,597 tables\nwith broad coverage of table hierarchies and numerical reasoning types.\n</p>\n<p>Targeting hierarchical structure, we devise a novel hierarchy-aware logical\nform for symbolic reasoning over tables, which shows high effectiveness.\nTargeting complex numerical reasoning, we propose partially supervised training\ngiven annotations of entity and quantity alignment, which helps models to\nlargely reduce spurious predictions in the QA task. In the NLG task, we find\nthat entity and quantity alignment also helps NLG models to generate better\nresults in a conditional generation setting. Experiment results of\nstate-of-the-art baselines suggest that this dataset presents a strong\nchallenge and a valuable benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhoujun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Haoyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ran Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09084","description":"<p>Transformer is a powerful model for text understanding. However, it is\ninefficient due to its quadratic complexity to input sequence length. Although\nthere are many methods on Transformer acceleration, they are still either\ninefficient on long sequences or not effective enough. In this paper, we\npropose Fastformer, which is an efficient Transformer model based on additive\nattention. In Fastformer, instead of modeling the pair-wise interactions\nbetween tokens, we first use additive attention mechanism to model global\ncontexts, and then further transform each token representation based on its\ninteraction with global context representations. In this way, Fastformer can\nachieve effective context modeling with linear complexity. Extensive\nexperiments on five datasets show that Fastformer is much more efficient than\nmany existing Transformer models and can meanwhile achieve comparable or even\nbetter long text modeling performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11809","description":"<p>The massive growth of digital biomedical data is making biomedical text\nindexing and classification increasingly important. Accordingly, previous\nresearch has devised numerous deep learning techniques focused on using\nfeedforward, convolutional or recurrent neural architectures. More recently,\nfine-tuned transformers-based pretrained models (PTMs) have demonstrated\nsuperior performance compared to such models in many natural language\nprocessing tasks. However, the direct use of PTMs in the biomedical domain is\nonly limited to the target documents, ignoring the rich semantic information in\nthe label descriptions. In this paper, we develop an improved label\nattention-based architecture to inject semantic label description into the\nfine-tuning process of PTMs. Results on two public medical datasets show that\nthe proposed fine-tuning scheme outperforms the conventionally fine-tuned PTMs\nand prior state-of-the-art models. Furthermore, we show that fine-tuning with\nthe label attention mechanism is interpretable in the interpretability study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1\">Bruce Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12202","description":"<p>In joint entity and relation extraction, existing work either sequentially\nencode task-specific features, leading to an imbalance in inter-task feature\ninteraction where features extracted later have no direct contact with those\nthat come first. Or they encode entity features and relation features in a\nparallel manner, meaning that feature representation learning for each task is\nlargely independent of each other except for input sharing. We propose a\npartition filter network to model two-way interaction between tasks properly,\nwhere feature encoding is decomposed into two steps: partition and filter. In\nour encoder, we leverage two gates: entity and relation gate, to segment\nneurons into two task partitions and one shared partition. The shared partition\nrepresents inter-task information valuable to both tasks and is evenly shared\nacross two tasks to ensure proper two-way interaction. The task partitions\nrepresent intra-task information and are formed through concerted efforts of\nboth gates, making sure that encoding of task-specific features are dependent\nupon each other. Experiment results on five public datasets show that our model\nperforms significantly better than previous approaches. The source code can be\nfound in https://github.com/Coopercoppers/PFN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12229","description":"<p>The ability to detect Out-of-Domain (OOD) inputs has been a critical\nrequirement in many real-world NLP applications since the inclusion of\nunsupported OOD inputs may lead to catastrophic failure of systems. However, it\nremains an empirical question whether current algorithms can tackle such\nproblem reliably in a realistic scenario where zero OOD training data is\navailable. In this study, we propose ProtoInfoMax, a new architecture that\nextends Prototypical Networks to simultaneously process In-Domain (ID) and OOD\nsentences via Mutual Information Maximization (InfoMax) objective. Experimental\nresults show that our proposed method can substantially improve performance up\nto 20% for OOD detection in low resource settings of text classification. We\nalso show that ProtoInfoMax is less prone to typical over-confidence Error of\nNeural Networks, leading to more reliable ID and OOD prediction outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nimah_I/0/1/0/all/0/1\">Iftitahu Ni&#x27;mah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1\">Vlado Menkovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-30T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}