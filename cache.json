{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-15T04:21:13.586220901Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【Rust日报】2021-09-06 Why Rust for offensive security","link":"https://rustcc.cn/article?id=7750136c-b31b-4e85-ab94-ae1459b4150e","description":"<h2>Why Rust for offensive security</h2>\n<blockquote>\n<p>想象一下：你的坦克都是纸板做的。然后你的飞机也都是用纸做的，你的海军也全都是纸船，那也太惨了吧？</p>\n<p>虽然很荒唐，但是这就是现在的黑客技术的状态。</p>\n<p>Imagine: all the tanks of your army are made of cardboard. Now imagine that not only your tanks but also all your airforce is composed of paper planes and your navy of paper vessels. It would be a pretty bad situation, don’t you think?</p>\n<p>While it sounds absurd, this is the sad state of hacking today.</p>\n</blockquote>\n<h3>TL;DR</h3>\n<p>文章指出，过去的编程语言（c, Java， python）等都只能局限在一个领域应用，然而现在我们等来了 Rust 救场——不再有奇怪的包管理器、二级制打包工具或者脆弱的网络代码，这些方面的可靠性一旦被黑客们意识到，就可能带来安全攻防的变革。</p>\n<p>为了安利可靠的 Rust，作者还写了本书 <a href=\"https://academy.kerkour.com/black-hat-rust?coupon=BLOG\" rel=\"noopener noreferrer\">Black Hat Rust</a>, 来总结自己通过 Rust 在黑客技术中的实践，以其让读者少踩坑，更好地理解 Rust 的可靠。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-14 14:09:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-13 Rust 在 linux 内核中的最新进展","link":"https://rustcc.cn/article?id=1c26513e-c4c2-4d52-becf-8c39379474e9","description":"<h1>Rust 在 linux 内核中的最新进展</h1>\n<p>虽然Rust编程语言在内核中使用的支持还没有登陆到本周末结束的 <code>Linux 5.15</code> 合并窗口，但这项工作仍在进行中。本周，关于Rust在Linux内核中的使用的最新进展被分享了出来。</p>\n<p>作为Rust for Linux项目的主要开发人员之一，Miguel Ojeda在本周的Linaro Connect虚拟会议上介绍了该项目，他目前正在为谷歌的合同工作。</p>\n<p>对周五的演讲感兴趣的人可以查看下面的 Presentation。</p>\n<p><a href=\"https://bigthinkbuzz.com/the-latest-progress-on-rust-for-the-linux-kernel/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<p><a href=\"https://static.linaro.org/connect/lvc21f/presentations/LVC21F-317.pdf\" rel=\"noopener noreferrer\">Presentation地址</a></p>\n<h1>Matchbox: Rust wasm 中的 p2p 网络解决方案</h1>\n<p>Matchbox 的诞生是因为作者在<code>rust</code> 中制作了一款多人网页游戏，遇到了以下问题:</p>\n<p>如何使用不可靠的、无序的 p2p connection 连接 N 个web浏览器?</p>\n<p><a href=\"https://johanhelsing.studio/posts/introducing-matchbox\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>Learn Wgpu 更新了</h1>\n<p><code>wgrpu</code> 是 <code>WebGPU API spec</code> 的 Rust 实现, 目前这个教程已经更新到了 0.10 版本, 有大量的原理和代码示例讲解.</p>\n<p><a href=\"https://sotrh.github.io/learn-wgpu/beginner/tutorial2-surface/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>Sycamore: v0.6.0 版本发布了</h1>\n<p>Sycamore是一个用 Rust 和 WebAssembly 构建同构web应用程序的库. 目前发布了 0.6.0 版本了.</p>\n<ul>\n<li>静态生成</li>\n<li>服务端渲染</li>\n<li>重验证</li>\n<li>增量构建</li>\n<li>开放构建矩阵</li>\n<li>CLI利用，让您轻松和自信地构建应用程序</li>\n<li>充分利用 Fluent 开箱即用的 i18n 支持</li>\n</ul>\n<p><a href=\"https://sycamore-rs.netlify.app/news/announcing-v0.6.0\" rel=\"noopener noreferrer\">原文链接</a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 13:10:04","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【成都】招聘Rust开发工程师","link":"https://rustcc.cn/article?id=ed86a028-a5b8-41e6-9849-e43a55ff7faf","description":"<h2>Rust开发工程师招聘</h2>\n<h3>岗位职责：</h3>\n<ul>\n<li>1、负责电商产品后端功能接口的开发；</li>\n<li>2、负责电商产品业务功能开发、迭代和维护，对业务数据进行处理和分析；</li>\n<li>3、配合前端开发完成功能的前后台功能联调；</li>\n<li>4、配合完成产品测试，BUG修改。</li>\n</ul>\n<h3>任职要求：</h3>\n<ul>\n<li>1、后端开发语言基础扎实，有电商产品后端开发经验；</li>\n<li>2、熟练使用使用Mysql关系型数据库；</li>\n<li>3、至少了解并使用过RocketMQ、RabbitMQ、Kafka中的一种；</li>\n<li>4、有Rust语言的基础，或者愿意转Rust开发；</li>\n<li>5、三年以上的互联网开发工作经验；</li>\n<li>6、熟习微服务或ServicesMesh架构者优先；</li>\n</ul>\n<p>工作地点四川成都环球时代中心\n有意者请发邮件至：shaipe@sina.com 或直接添加微信号：shaipe</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 10:59:47","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"read_dir 返回的 io::Result<DirEntry> 会在什么情况下返回 Error 呢？","link":"https://rustcc.cn/article?id=c1f3f464-9146-4b43-8467-7eacc8f53bf8","description":"<p><code>read_dir</code> 迭代的时候给到的是一个 <code>io::Result&lt;DirEntry&gt;</code>，文档里面只是简单说了 <strong>New errors may be encountered after an iterator is initially constructed.</strong></p>\n<p>但是具体这个 New errors 到底是什么？</p>\n<p>我试过了在迭代的时候对文件夹或者里面的文件作删除、重命名、改变权限，都没有返回 error；\n（测试平台包括 Mac 和 Linux，没有 windows 暂时没测）。</p>\n<p><img src=\"https://i.loli.net/2021/09/13/AbE9KdTL1sSxWJg.png\" alt=\"screenshot-20210913-174925.png\"></p>\n<pre><code>/// Iterator over the entries in a directory.\n///\n/// This iterator is returned from the [`read_dir`] function of this module and\n/// will yield instances of [`io::Result`]`&lt;`[`DirEntry`]`&gt;`. Through a [`DirEntry`]\n/// information like the entry's path and possibly other metadata can be\n/// learned.\n///\n/// The order in which this iterator returns entries is platform and filesystem\n/// dependent.\n///\n/// # Errors\n///\n/// This [`io::Result`] will be an [`Err`] if there's some sort of intermittent\n/// IO error during iteration.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Debug)]\npub struct ReadDir(fs_imp::ReadDir);\n</code></pre>\n<p>This [<code>io::Result</code>] will be an [<code>Err</code>] if there's some sort of intermittent IO error during iteration.</p>\n<p>看起来一定要是比较罕见的 IO 错误？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 09:45:42","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"关于我前些天，在 GitHub 上 Rust 的 repo 的那些事","link":"https://rustcc.cn/article?id=111d596f-f53f-44dc-9a59-69ccf2ff7563","description":"<p>上周我在 GitHub 上整理的 <a href=\"https://github.com/0voice/Understanding_in_Rust\" rel=\"noopener noreferrer\">《 Rust 工程师枕边资料》</a> ,涉及了侵权行为。在这里向大家赔礼道歉。并且在第一时间，处理了相关内容。\n我在整理的之前的初衷只是单纯为了给大家提供更好、更多、更全、更专业地的 Rust 学习资料。并没有丝毫的商业化手段。\n我收集的内容全部来源于互联网，由于我的疏忽没有注明文章出处链接，确实是不应该的。</p>\n<p>再一次，给作品的作者道歉。</p>\n<p>我将在以后 repo 里将不会出现类似的错误事件，同时也希望广大开发者们监督。如果有任何问题，可以邮箱至：wchao_isvip@163.com ，我会在第一时间处理的。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 08:11:56","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"filecoin项目RUST大牛招聘","link":"https://rustcc.cn/article?id=3a173b77-c75e-4cbb-a8c9-8c0496b17619","description":"<p>该岗位薪资面谈\n岗位职责：\n1.参与区块链项目开发，以C++/rust为主；\n2.理解业务逻辑与对后端服务的需求，能够分析需求并产生合理技术方案；\n3.负责平台对外接口，相关数据服务的设计与实现；\n4.根据技术需求部署Filecoin环境，编写脚本，对环境进行测试部署；\n5.参与公司项目专利的编写；\n岗位要求：\n1.大专以上学历，计算机或者相关专业，精通rust语言；\n2.至少熟悉两种其他开发语言，如C++、go、Python等；\n3.2年以上后端开发工作经验，做过区块链项目开发经验的可优先考虑；\n4.熟悉Ethereum、EOS、Bitcoin、Filecoin中至少两个项目的基本原理和设计；\n5.熟悉区块链项目中常见的共识机制、加密算法、P2P网络等；\n6.思路清晰，具备良好的沟通能力、团队合作意识，能抗压，能主动承担，乐于分享。</p>\n<p>详情可联系yhcaozyyz@qq.com or 18109055866</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 06:45:02","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【招聘  杭州，上海】Rust开发工程师（30K-50K）","link":"https://rustcc.cn/article?id=4f8da484-d0fc-4f56-88ca-c19e7ea32b5a","description":"<p>【岗位职责】</p>\n<ol>\n<li>负责分布式计算及存储系统的高可扩展后端系统，服务和API；</li>\n<li>设计高性能、高可靠性的服务，建立快速、稳定、安全的后端代码&nbsp;；</li>\n<li>为其他开发人员提供指导，参与算法设计和实现。</li>\n<li>负责设计和优化协议、弱网通信、存储、网络并发、并行计算、加密以及安全等；</li>\n<li>保证工程质量和开发效率。</li>\n<li>设计和维护性能测试用例；</li>\n</ol>\n<p>【岗位要求】</p>\n<ol>\n<li>计算机或者相关专业本科以上学历，两年以上相关工作经验</li>\n<li>技术扎实，熟悉Rust语言编程</li>\n<li>理解ownership, trait, async等语言机制。</li>\n<li>熟练使用tokio。熟练使用rust常用库</li>\n<li>有丰富的多线程应用和平台构建经验，可熟练构建稳定、高效率和安全的代码&nbsp;；</li>\n<li>有强烈的上进心和求知欲，善于学习和运用新知识，善于沟通和逻辑表达，有强烈的团队意识和执行力。</li>\n<li>熟悉Linux下多线程/多进程编程模型，进程间通讯，消息事件通知，同步/异步。</li>\n<li>熟悉Linux下内存管理机制，低延迟、高并发无锁化编程。</li>\n</ol>\n<p>【特别备注】</p>\n<ol>\n<li>了解安全加密相关算法者优先&nbsp;；</li>\n<li>有丰富的c++、python编程经验者优先</li>\n<li>参与大型系统的开发，并成功部署、广泛应用者优先；</li>\n<li>熟悉大数据、机器学习框架，如:spark，flink, tensorflow者优先。</li>\n</ol>\n<p>【工作地点】\nbase1: 杭州市西湖区中电万谷园区\nbase2: 上海市浦东新区前滩东方广场一期\n杭州上海均有岗位。</p>\n<p>联系方式：朝歌13732914991（微信同号） 邮箱：zhaoge@fudata.cn</p>\n<p>【公司介绍】\n上海富数科技有限公司 简称“富数科技”，是国内领先的金融AI和安全计算技术领跑者，核心团队来自CapitalOne，Alibaba和IBM，公司自2016年成立以来受国内顶级风投青睐，已完成C轮融资。富数科技坚持以“以数据安全驱动人工智能”，依托于安全计算和机器学习AI技术，助力金融和各行业机构组织提高智能风控、营销和运营的效率，实现数据合规安全地融合计算和价值流通。</p>\n<p>富数科技是中国通信标准化协会会员、工信部信通院大数据安全及流通标准组成员、安全多方计算标准参与方，为行业规范标准制定贡献创新技术成果。富数科技结合最新密码学和区块链技术研发创新，其安全计算和联邦学习开创性地采用“松弛迭代法”，在智能合约、ML算法优化、代码编译和计算硬件芯片融合方面改善性能，在同等条件下实现了收敛速度的大幅提升，精度和准确度损失低于1%，速度较行业水平提高了3倍。</p>\n<p>富数科技致力于驱动安全可信的人工智能科技与各行业场景的深度融合赋能，在兼顾隐私保护下发挥大数据的商业价值。富数科技自2017年投入数据安全计算领域研发创新，拥有多项专利发明和软著，并与国内外金融机构和科研机构（上海交大等）联合研发和推动工程化商业化落地。富数科技安全计算解决方案已经落地在智能风控、智能营销、监管和科研统计分析、异业或同业数据安全融合计算等场景，目前已在银行、持牌消金、政务、医疗、运营商等领域积累上百案例，在安全的机器学习领域具有突出的领先优势。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-12 15:57:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-09-12 Rust 的 Logging 推荐","link":"https://rustcc.cn/article?id=91b91a60-cbe9-4f8a-a5ec-8825da34457b","description":"<h3>Rust 的 Logging 推荐</h3>\n<p>内容整理自 Reddit 的讨论：<a href=\"https://www.reddit.com/r/rust/comments/pmdh6a/what_is_the_current_recommendation_for_logging_in/\" rel=\"noopener noreferrer\">What is the current recommendation for logging in Rust? : rust</a>。</p>\n<p>问题简述：除了标准的 <code>log</code>，还有不少选择：<code>env_logger</code>，<code>tracing</code>，<code>slog</code>，<code>simplelog</code> 等等，最佳实践是什么？</p>\n<p>来自 <a href=\"https://www.reddit.com/user/Koxiaet/\" rel=\"noopener noreferrer\">Koxiaet</a> 的答复：通常有两类与日志相关的 crate：日志接口和日志消费者。接口提供了想要记录某些东西时调用的函数，消费者处理将结构化日志数据格式化到某个地方（stderr 或文件）。两个主要的接口是 <code>log</code> 和 <code>tracing</code>，后者功能更强大因为它支持结构化日志记录，但前者更普遍。还有另一个结构化日志接口 slog，比 <code>tracing</code> 更古老但用的较少。每个日志接口都有自己生态系统，可以根据自己的需要选择。如果在写一个库，<code>log</code> 是个不错的选择，因为所有的日志记录接口都与它兼容。但如果你确实需要结构化日志记录，则可以改用 <code>tracing</code>，这取决于你的需求，比如你是需要写到文件还是只是终端。</p>\n<p>其他网友的推荐：</p>\n<ul>\n<li>File Logging：<a href=\"https://github.com/emabee/flexi_logger\" rel=\"noopener noreferrer\">emabee/flexi_logger: A flexible logger for rust programs that can write to stderr or to log files</a>。（来自 cfsamson）</li>\n<li><code>tracing</code> 的接口：<a href=\"https://docs.rs/tracing-log/0.1.2/tracing_log/\" rel=\"noopener noreferrer\">tracing_log - Rust</a>，有多个同时操作交错日志消息时特别方便，可以按某些属性对它们进行分组并单独查看它们。（来自 class_two_perversion）</li>\n<li><a href=\"https://github.com/estk/log4rs\" rel=\"noopener noreferrer\">estk/log4rs: A highly configurable logging framework for Rust</a>，log4rs 是一个高度可配置的日志框架，以 Java 的 Logback 和 log4j 库为模型。通过 Yaml 配置，到 sdout 和文件，带有文件大小限制选项，还可以配置不同级别的日志。（来自 tms102）</li>\n<li><a href=\"https://crates.io/crates/tracing-appender\" rel=\"noopener noreferrer\">tracing-appender - crates.io: Rust Package Registry</a>，推荐者所知道的唯一线程外日志记录解决方案，不仅适用于异步应用程序。（来自 Pand9）</li>\n<li><a href=\"https://github.com/daboross/fern\" rel=\"noopener noreferrer\">daboross/fern: Simple, efficient logging for Rust</a>，像 Python 的 <code>logging</code> 和 JS 的 <code>Winston</code>。（来自 RapBeautician）</li>\n</ul>\n<h3>Rust 全栈</h3>\n<p>本文是一篇博客翻译，来自：<a href=\"https://www.justinm.one/blog/2021/09/11/fullstackrust/\" rel=\"noopener noreferrer\">Full Stack Rust - Blog</a>。</p>\n<p>一年前，我的首选语言如下：</p>\n<ul>\n<li>Python 用于高级代码快速原型设计，或用于需要第三方功能的代码</li>\n<li>C/C++ 用于长期的 low-level 项目</li>\n</ul>\n<p>当时只听过 Rust 并简单使用过，我的经验来自用 Rust 写了一个处理大文件（&gt;4GB）的事务并从中挖掘一些统计信息的小工具。我用了一个库将文件映射到内存，缤瑞按照顺序对其进行分析。有一些很酷的概念，比如编译器静态地强制内存映射在它被取消映射后无法访问——如果你不小心，C++ 中可能就会发生这种错误。</p>\n<p>不过当时并没有真正吸引我，因为那只是一个小新奇。当我向 <a href=\"https://github.com/DrChat/pdblister\" rel=\"noopener noreferrer\">pdblister</a> 添加新功能以并行获取数千个 PDB 文件时诀窍来了。由于 GIL，在 CPython 中几乎不可能，而在 C/C++ 中做到不面临并行错误是极其困难的。然而 Rust 让这变得容易。我添加了 tokio 驱动的异步，使用 <code>tokio::spawn</code> 生成新任务来下载 PDB，并修复了编译器报的错误，它可以正常工作了。Rust 编译器输出一个二进制文件，它可以在任何地方运行，没有运行时依赖。</p>\n<p><strong>取代 Python</strong></p>\n<p>这是第一点，Rust 是 Python 作为中长期工具语言的绝佳替代品。Python 的好处是庞大的库和生态系统，通过 pip 可以直接拿到，想要快速制作与 API 交互的原型，可以使用 <code>requests</code>，只要 <code>import requests</code> 就可以使用了。Rust 的 <code>reqwest\t</code> 也是如此，只要输入 <code>cargo add reqwest</code> 就可以在代码中使用它。</p>\n<p>然而当进入更长期的生命周期时，Python 就显示出劣势，<code>requests</code> 是程序的依赖，用户需要后去后才能使用。此外，由于弱类型和错误处理能力（与 Rust 比），Python 变得更加劣势。这一点上，我可以使用 Rust 比使用 Python 更快地编写原型工具，并且我可以自信地知道我的工具比等效的 Python 更易于维护且寿命更长。但是，对于短期工具，Python 可能仍然更好，因为它不需要启动项目即可在 VSCode 中获得智能感知支持。 Rust 的 cargo-script 接近将 Rust 推入脚本语言的领域，但不幸的是，我还没有在 VSCode 中找到与之集成的插件。</p>\n<p><strong>取代 C</strong></p>\n<p>Rust 也是 C 的直接替代品，它在各方面都更好，并且可以与遗留 C 代码原生互操作以进行增量替换。Rust 最大的改进是生态系统：如上所述，利用 Rust 生态中已有的库是很容易的。如果你从未使用过 C，那很幸运，实际上 C 中使用高级功能的最佳方法是自己写。</p>\n<p>C 生态系统是支离破碎的，而且很脆弱。ABI 或构建系统没有一致的标准：</p>\n<ul>\n<li>由于缺乏 ABI 一致性，你不能跨平台或操作系统使用相同的二进制文件。  所以你必须从源代码构建。</li>\n<li>由于缺乏一致的构建系统，你不能简单地和应用程序一起构建 C 库，必须修补或重写要使其与你的库兼容的库的构建系统。</li>\n<li>C 库很少跨平台兼容，因为它们缺乏可以依赖的共享抽象。</li>\n</ul>\n<p>然后还有 Rust 最特色的安全改进——我就不展开了。但根据我的经验 - 安全性在很大程度上是一种工具，可以让第三方库开发人员更容易强迫我正确使用他们的库，这是 C 库不能做的事情。</p>\n<p><strong>全栈 Rust</strong></p>\n<p>总而言之，在过去的一年中，我一直在堆栈的所有部分使用 Rust，而我之前使用过其他语言。我已经使用 Rust 来实现引导加载程序：<a href=\"https://github.com/xenia-project/xell-rs\" rel=\"noopener noreferrer\">xenia-project/xell-rs: Xell Bootloader, rewritten in Rust because ¯_(ツ)_/¯，</a>我已经使用它通过 <a href=\"https://github.com/DrChat/pdblister\" rel=\"noopener noreferrer\">pdblister</a> 和 <a href=\"https://github.com/panamax-rs/panamax\" rel=\"noopener noreferrer\">panamax</a> 中的高级 HTTP/HTTPS 和其他技术来镜像文件。我利用并贡献了优秀的 <a href=\"https://github.com/DrChat/gdbstub\" rel=\"noopener noreferrer\">gdbstub</a> 库，用于控制由自定义 VMM 运行的 VM。这些项目都是在堆栈的不同级别完成的，而 Rust 非常适合所有级别。  我已经开始在我的个人项目中专门使用 Rust，并在适合的时候推动它在我的工作中使用。</p>\n<h3>tagged_cell：快速、可初始化和线程安全的静态变量</h3>\n<p>通过 <code>TaggedCell</code> 和 <code>Tag</code> 类型实现，为了安全操作，<code>TaggedCell</code> 的每个实例都必须是唯一的。然后必须通过 <code>TaggedCell::init ()</code> 初始化 <code>TaggedCell</code>，它使用用户提供的函数或闭包初始化底层数据，然后返回一个特殊的零大小的 <code>Init&lt;Tag&gt;</code> 用于访问 Cell 的数据。为了确保每个单元格使用唯一的标签类型，<code>tagged_cell!</code> 提供宏。该宏根据变量的名称创建一个新的标记类型，并将其应用到声明中。</p>\n<pre><code>use tagged_cell::tagged_cell;\ntagged_cell!{\n   static BAR: TaggedCell&lt;Vec&lt;usize&gt;, _&gt; = TaggedCell::new();\n}\n\nlet tag = BAR.init(|| vec![0, 10, 20]);\nlet vec = BAR.get(tag);\n\nassert_eq!(vec[2], 20);\n</code></pre>\n<p>为了允许跨线程使用，只有第一次调用 <code>TaggedCell::init</code> 才会初始化 Cell 的数据。所有未来的 <code>TaggedCell::init</code> 调用都将返回一个新标签。未确定哪个线程将初始化 Cell 的数据。</p>\n<pre><code>use std::thread;\nuse tagged_cell::tagged_cell;\n\ntagged_cell!{\n    static TABLE: TaggedCell&lt;Vec&lt;usize&gt;, _&gt; = TaggedCell::new();\n}\n\nthread::spawn(move || {\n    let tag = TABLE.init(|| vec![0, 10, 20]);\n    let table = TABLE.get(tag);\n    assert_eq!(table[2], 20);\n});\n\nthread::spawn(move || {\n    let tag = TABLE.init(|| vec![0, 10, 20]);\n    let table = TABLE.get(tag);\n    assert_eq!(table[1], 10);\n});\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/Dasch0/tagged_cell\" rel=\"noopener noreferrer\">Dasch0/tagged_cell: Fast, initializable, and thread safe static variables</a></p>\n<h3>ukanren-rs：µKanren 的 Rust 实现</h3>\n<p>µKanren 是一种轻量级关系编程语言</p>\n<ul>\n<li>原始的 Schema 实现在这里：<a href=\"https://github.com/jasonhemann/microKanren\" rel=\"noopener noreferrer\">jasonhemann/microKanren: The implementation of microKanren, a featherweight relational programming language</a></li>\n<li>相关参考：<a href=\"http://minikanren.org/\" rel=\"noopener noreferrer\">miniKanren.org</a></li>\n</ul>\n<pre><code>use ukanren::*;\n\nfn appendo(first: Value, second: Value, out: Value) -&gt; BoxedGoal&lt;impl Iterator&lt;Item = State&gt;&gt; {\n    eq(&amp;first, &amp;())\n        .and(eq(&amp;second, &amp;out))\n        .or(fresh(move |a: Value, d: Value, res: Value| {\n            eq(&amp;(a.clone(), d.clone()), &amp;first)\n                .and(eq(&amp;(a.clone(), res.clone()), &amp;out))\n                .and(appendo(d.clone(), second.clone(), res))\n        }))\n        .boxed()\n}\n\nlet goal = fresh(|x, y| appendo(x, y, [1, 2, 3, 4, 5].to_value()));\nassert_eq!(\n    goal.run(2).collect::&lt;Vec&lt;_&gt;&gt;(),\n    vec![\n        state![(), [1, 2, 3, 4, 5]],\n        state![[1], [2, 3, 4, 5]],\n        state![[1, 2], [3, 4, 5]],\n        state![[1, 2, 3], [4, 5]],\n        state![[1, 2, 3, 4], [5]],\n        state![[1, 2, 3, 4, 5], ()],\n    ],\n);\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/ekzhang/ukanren-rs\" rel=\"noopener noreferrer\">ekzhang/ukanren-rs: Rust implementation of µKanren, a featherweight relational programming language.</a></p>\n<h3>rust-counter-strings：快速定位字符串位置</h3>\n<p>字符串中的每个星号都出现在由紧接前面的数字指定的位置。因此，29 后面的星号是该字符串中的第 29 个字符。可以在任何地方砍掉字符串的末尾，并且确切地知道它在哪里被剪掉了。比如不用数就知道字符串 <code>2*4*6*8*11*14*17*2</code> 正好有 18 个字符。当处理 50 万个字符时会比较省事。</p>\n<pre><code>$ ./rust-counter-strings 50\n# 2*4*6*8*11*14*17*20*23*26*29*32*35*38*41*44*47*50*\n</code></pre>\n<p>这就是个小工具，代码也只有几十行。</p>\n<p>GitHub：<a href=\"https://github.com/thomaschaplin/rust-counter-strings\" rel=\"noopener noreferrer\">thomaschaplin/rust-counter-strings: 🧵 Generate self-describing strings of a given length to help aid software testing</a></p>\n<hr>\n<p>From 日报小组 长琴</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc 论坛：支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-12 14:30:38","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-11 Tabled 发布v0.3, bma-benchmark, ferros, Veloren发布v0.11","link":"https://rustcc.cn/article?id=db077b1a-5af6-4fb2-b065-ff8be974fd62","description":"<h3>Tabled 发布v0.3</h3>\n<p>Tabled 是一个易于使用的库，用于美化 Rust 结构和枚举的输出。</p>\n<p>Github<a href=\"https://github.com/zhiburt/tabled\" rel=\"noopener noreferrer\">链接</a>，https://github.com/zhiburt/tabled</p>\n<h3>bma-benchmark 一个友好的基准测试工具</h3>\n<p>使用 <code>bma_benchmark</code></p>\n<pre><code>#[macro_use]\nextern crate bma_benchmark;\n\nuse std::sync::Mutex;\n\nlet n = 100_000_000;\nlet mutex = Mutex::new(0);\nbenchmark_start!();\nfor _ in 0..n {\n    let _a = mutex.lock().unwrap();\n}\nbenchmark_print!(n);\n</code></pre>\n<p>使用宏 <code>benchmark!</code></p>\n<pre><code>#[macro_use]\nextern crate bma_benchmark;\n\nuse std::sync::Mutex;\n\nlet mutex = Mutex::new(0);\nbenchmark!(100_000_000, {\n    let _a = mutex.lock().unwrap();\n    });\n</code></pre>\n<p><img src=\"https://raw.githubusercontent.com/alttch/bma-benchmark/main/simple.png\" alt=\"结果\"></p>\n<p>Crate <a href=\"https://crates.io/crates/bma-benchmark\" rel=\"noopener noreferrer\">链接</a>，https://crates.io/crates/bma-benchmark</p>\n<h3>ferros</h3>\n<p>seL4 是一个用于构建操作系统和嵌入式程序的工具包，这个开源项目是使 Rust 中的 seL4 编程变得更好。</p>\n<p>以下代码演练假定使用示例 sel4_start 库执行 selfe，并介绍了 ferros 的某些方面。</p>\n<pre><code>use selfe_sys;\nuse ferros::alloc::{self, micro_alloc, smart_alloc};\nuse ferros::userland::{root_cnode, BootInfo};\n\n// The raw boot info is provided by the sel4_start library\nlet raw_boot_info: &amp;'static selfe_sys::seL4_BootInfo = unsafe { &amp;*sel4_start::BOOTINFO };\n\n\n// Utility for finding and claiming `Untyped` instances supplied by the boot info.\nlet mut allocator = micro_alloc::Allocator::bootstrap(&amp;raw_boot_info)?;\nlet initial_untyped = allocator\n    .get_untyped::&lt;U20&gt;() // The size of the Untyped instance, as bits\n    .expect(\"Couldn't find an untyped instance of the desired size\");\n\n// Create the top-level CNode wrapper with type-level-tracked remaining slot capacity\nlet (root_cnode, local_slots) = root_cnode(&amp;raw_boot_info);\n\n// Once we have an initial Untyped instance, memory distribution from it\n// can be tracked with compile-time checks. The smart_alloc macro synthesizes\n// the allocation code, and the capacity bounds are statically verified by\n// the type checker. The effect is that you can write 'slots' in the macro body \n// anywhere you need some slots, and you'll get the right number allocated\n// with type inference. A reference to 'ut' does the same for untyped memory. \nsmart_alloc!(|slots from local_slots, ut from uts| {\n\n    // Create a page table seL4 kernel object and return a capability pointer to it.\n    // Here we use a variable binding type annotation and Rust's type system can figure out\n    // if it can allocate a large enough Untyped instance and enough cnode slots\n    // to represent this particular kernel object.\n    let example_page_table: LocalCap&lt;UnmappedPageTable&gt; = retype(ut, slots)?;\n\n    // Create a resource-tracking wrapper around the raw boot info to assist in\n    // virtual memory related operations.\n    let boot_info  = BootInfo::wrap(raw_boot_info, ut, slots);\n    let (root_page_table, boot_info) = boot_info.map_page_table(root_page_table)?;\n});\n\n</code></pre>\n<p>Github<a href=\"https://github.com/auxoncorp/ferros\" rel=\"noopener noreferrer\">链接</a>，https://github.com/auxoncorp/ferros</p>\n<h3>Veloren发布v0.11</h3>\n<p>今天，Veloren 发布了 0.11。 这个版本已经制作了 3 个月，其一大重点是让世界各地的战斗更具活力。这是以新的地点系统的形式出现，以及 NPC 和生物如何与世界互动。</p>\n<p>要了解还有哪些新功能！请继续阅读 V0.11 变更日志<a href=\"https://veloren.net/release-0-11/\" rel=\"noopener noreferrer\">链接</a>，https://veloren.net/release-0-11/</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929\" rel=\"noopener noreferrer\">洋芋</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-11 15:33:08","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"cargo fix 如何自动修复warning？","link":"https://rustcc.cn/article?id=0d747849-2064-4ba2-a725-2fe64f6ab556","description":"<p>代码中有些外面copy过来的enum，导致很多的“should have an upper camel case name”warning。就是编码风格的问题，可是<code>cargo fix</code>没有办法按照rust给的建议自动帮我改掉。。。。</p>\n<p>有办法吗？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-11 14:31:22","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 培养提高计划 Vol. 7 - 8 | Rust 项目工程来了","link":"https://rustcc.cn/article?id=9dec6eeb-38d8-4ec4-b75e-783bd11bf24b","description":"<p>我们的 Rust 公开课进行了 6 期了，带大家了解了 ：</p>\n<ol>\n<li>认识面向基础架构语言</li>\n<li>理解 Rust 所有权</li>\n<li>通过实战理解 Rust 宏</li>\n<li>通过 Datafuse 理解全链路跟踪</li>\n<li>Rust 异步编程入门 Future Part 1</li>\n<li>Rust 异步编程入门 Future Part 2</li>\n</ol>\n<p>目前视频回放传到 B 站收获许多好评，赞，也给我们很大的鼓励。希望我们的 Rust 培养提高计划 | Datafuse 可以帮助更多的朋友快速的使用上 Rust 。\n本周给大家排两个公开课：周四晚上，周日晚上。我们 Rust 培养提高计划邀请到第二位分享嘉宾 董泽润老师， 另外 Rust 培养提高计划 的内容上也做了一些调整。</p>\n<hr>\n<p>分享主题：《深入了解rust 闭包》 | Vol. 7</p>\n<p>分享时间： 周四晚上2021-09-09 20:00-21:00</p>\n<p>分享讲师： 董泽润</p>\n<p>内容介绍： 深入浅出了解 rust 闭包工作原理，让大家了解底层实现\n讲师介绍：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/07-%E8%91%A3%E6%B3%BD%E6%B6%A6.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<hr>\n<p>分享主题：《利用 Tokio 实现一个高性能 Mini Http server》 | Vol. 8</p>\n<p>分享时间：  周日晚上2021-09-12 20:00-21:00</p>\n<p>分享讲师： 苏林</p>\n<p>首先感谢苏林老师的坚持付出， 带我们学习 Rust 的重点知识。 经过和苏琳老师沟通，我们后续的课程，会更加往实战方向转变。接下是一个系列的内容：</p>\n<ol>\n<li>利用 Tokio 实现一个 Mini Http server</li>\n<li>基于 Http server提供内容动态的 API 网关</li>\n<li>利用 Redis 实现对 API 网关加速</li>\n<li>学习 Rust RPC 调用，实现微服务调用</li>\n</ol>\n<p>这个内容可能需要4次左右的公开课，目的是带着大家做一些小项目，带大家熟悉一下 Rust 工程，让大家可以快速把 Rust 用到后端开发中。</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<p>Rust 异步编程入门 Future Part 1   | Vol. 5\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<p>Rust 异步编程入门 Future Part 2  | Vol. 6\nhttps://www.bilibili.com/video/bv1oy4y1G7jC</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-07 02:23:16","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust 学习随笔","link":"https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8","description":"<h1>切换镜像源</h1>\n<p>crm =&gt; https://github.com/wtklbm/crm</p>\n<p>常用命令就是 <code>crm best</code></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 14:35:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"pretree 补全文档发布了,再次谢谢大神的指点终于入门了。","link":"https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827","description":"<h1>Pretree</h1>\n<p>pretree is a package for storing and querying routing rules with prefix tree .</p>\n<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>\n<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>\n<p>Inspired by <a href=\"https://github.com/obity/pretree\" rel=\"noopener noreferrer\">obity/pretree</a> (golang)</p>\n<h1>Doc</h1>\n<p>See this document at <a href=\"https://docs.rs/pretree\" rel=\"noopener noreferrer\">API documentation</a></p>\n<h1>Install</h1>\n<p>Add the following line to your Cargo.toml file:</p>\n<pre><code>pretree = \"1.0.0\"\n</code></pre>\n<h1>Example</h1>\n<pre><code>use pretree::Pretree;\nlet mut p = Pretree::new();\np.store(\"GET\",\"account/{id}/info/:name\");\np.store(\"GET\",\"account/:id/login\");\np.store(\"GET\",\"account/{id}\");\np.store(\"GET\",\"bacteria/count_number_by_month\");\nlet (ok,rule,vars) = p.query(\"GET\",\"account/929239\");\nprintln!(\"ok:{} rule:{} vars:{:#?}\",ok,rule,vars);\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 09:37:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-15T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"The Emergence of the Shape Bias Results from Communicative Efficiency. (arXiv:2109.06232v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06232","description":"<p>By the age of two, children tend to assume that new word categories are based\non objects' shape, rather than their color or texture; this assumption is\ncalled the shape bias. They are thought to learn this bias by observing that\ntheir caregiver's language is biased towards shape based categories. This\npresents a chicken and egg problem: if the shape bias must be present in the\nlanguage in order for children to learn it, how did it arise in language in the\nfirst place? In this paper, we propose that communicative efficiency explains\nboth how the shape bias emerged and why it persists across generations. We\nmodel this process with neural emergent language agents that learn to\ncommunicate about raw pixelated images. First, we show that the shape bias\nemerges as a result of efficient communication strategies employed by agents.\nSecond, we show that pressure brought on by communicative need is also\nnecessary for it to persist across generations; simply having a shape bias in\nan agent's input language is insufficient. These results suggest that, over and\nabove the operation of other learning strategies, the shape bias in human\nlearners may emerge and be sustained by communicative pressures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Portelance_E/0/1/0/all/0/1\">Eva Portelance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_M/0/1/0/all/0/1\">Michael C. Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sordoni_A/0/1/0/all/0/1\">Alessandro Sordoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laroche_R/0/1/0/all/0/1\">Romain Laroche</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation. (arXiv:2109.06243v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06243","description":"<p>The development of over-parameterized pre-trained language models has made a\nsignificant contribution toward the success of natural language processing.\nWhile over-parameterization of these models is the key to their generalization\npower, it makes them unsuitable for deployment on low-capacity devices. We push\nthe limits of state-of-the-art Transformer-based pre-trained language model\ncompression using Kronecker decomposition. We use this decomposition for\ncompression of the embedding layer, all linear mappings in the multi-head\nattention, and the feed-forward network modules in the Transformer layer. We\nperform intermediate-layer knowledge distillation using the uncompressed model\nas the teacher to improve the performance of the compressed model. We present\nour KroneckerBERT, a compressed version of the BERT_BASE model obtained using\nthis framework. We evaluate the performance of KroneckerBERT on well-known NLP\nbenchmarks and show that for a high compression factor of 19 (5% of the size of\nthe BERT_BASE model), our KroneckerBERT outperforms state-of-the-art\ncompression methods on the GLUE. Our experiments indicate that the proposed\nmodel has promising out-of-distribution robustness and is superior to the\nstate-of-the-art compression methods on SQuAD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tahaei_M/0/1/0/all/0/1\">Marzieh S. Tahaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charlaix_E/0/1/0/all/0/1\">Ella Charlaix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nia_V/0/1/0/all/0/1\">Vahid Partovi Nia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Sentence Resampling: A Simple Approach to Alleviate Dataset Length Bias and Beam-Search Degradation. (arXiv:2109.06253v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06253","description":"<p>Neural Machine Translation (NMT) is known to suffer from a beam-search\nproblem: after a certain point, increasing beam size causes an overall drop in\ntranslation quality. This effect is especially pronounced for long sentences.\nWhile much work was done analyzing this phenomenon, primarily for\nautoregressive NMT models, there is still no consensus on its underlying cause.\nIn this work, we analyze errors that cause major quality degradation with large\nbeams in NMT and Automatic Speech Recognition (ASR). We show that a factor that\nstrongly contributes to the quality degradation with large beams is\n\\textit{dataset length-bias} - \\textit{NMT datasets are strongly biased towards\nshort sentences}. To mitigate this issue, we propose a new data augmentation\ntechnique -- \\textit{Multi-Sentence Resampling (MSR)}. This technique extends\nthe training examples by concatenating several sentences from the original\ndataset to make a long training example. We demonstrate that MSR significantly\nreduces degradation with growing beam size and improves final translation\nquality on the IWSTL$15$ En-Vi, IWSTL$17$ En-Fr, and WMT$14$ En-De datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Provilkov_I/0/1/0/all/0/1\">Ivan Provilkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malinin_A/0/1/0/all/0/1\">Andrey Malinin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Multiway Multilingual NMT in the Turkic Languages. (arXiv:2109.06262v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06262","description":"<p>Despite the increasing number of large and comprehensive machine translation\n(MT) systems, evaluation of these methods in various languages has been\nrestrained by the lack of high-quality parallel corpora as well as engagement\nwith the people that speak these languages. In this study, we present an\nevaluation of state-of-the-art approaches to training and evaluating MT systems\nin 22 languages from the Turkic language family, most of which being extremely\nunder-explored. First, we adopt the TIL Corpus with a few key improvements to\nthe training and the evaluation sets. Then, we train 26 bilingual baselines as\nwell as a multi-way neural MT (MNMT) model using the corpus and perform an\nextensive analysis using automatic metrics as well as human evaluations. We\nfind that the MNMT model outperforms almost all bilingual baselines in the\nout-of-domain test sets and finetuning the model on a downstream task of a\nsingle pair also results in a huge performance boost in both low- and\nhigh-resource scenarios. Our attentive analysis of evaluation criteria for MT\nmodels in Turkic languages also points to the necessity for further research in\nthis direction. We release the corpus splits, test sets as well as models to\nthe public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mirzakhalov_J/0/1/0/all/0/1\">Jamshidbek Mirzakhalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1\">Anoop Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunafin_A/0/1/0/all/0/1\">Aigiz Kunafin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahab_A/0/1/0/all/0/1\">Ahsan Wahab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moydinboyev_B/0/1/0/all/0/1\">Behzod Moydinboyev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanova_S/0/1/0/all/0/1\">Sardana Ivanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uzokova_M/0/1/0/all/0/1\">Mokhiyakhon Uzokova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pulatova_S/0/1/0/all/0/1\">Shaxnoza Pulatova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ataman_D/0/1/0/all/0/1\">Duygu Ataman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyers_F/0/1/0/all/0/1\">Francis Tyers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Licato_J/0/1/0/all/0/1\">John Licato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chellappan_S/0/1/0/all/0/1\">Sriram Chellappan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Post-OCR Document Correction with large Ensembles of Character Sequence Models. (arXiv:2109.06264v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06264","description":"<p>In this paper, we propose a novel method based on character\nsequence-to-sequence models to correct documents already processed with Optical\nCharacter Recognition (OCR) systems. The main contribution of this paper is a\nset of strategies to accurately process strings much longer than the ones used\nto train the sequence model while being sample- and resource-efficient,\nsupported by thorough experimentation. The strategy with the best performance\ninvolves splitting the input document in character n-grams and combining their\nindividual corrections into the final output using a voting scheme that is\nequivalent to an ensemble of a large number of sequence models. We further\ninvestigate how to weigh the contributions from each one of the members of this\nensemble. We test our method on nine languages of the ICDAR 2019 competition on\npost-OCR text correction and achieve a new state-of-the-art performance in five\nof them. Our code for post-OCR correction is shared at\nhttps://github.com/jarobyte91/post_ocr_correction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_Orta_J/0/1/0/all/0/1\">Juan Ramirez-Orta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xamena_E/0/1/0/all/0/1\">Eduardo Xamena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maguitman_A/0/1/0/all/0/1\">Ana Maguitman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1\">Evangelos Milios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1\">Axel J. Soto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"STraTA: Self-Training with Task Augmentation for Better Few-shot Learning. (arXiv:2109.06270v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06270","description":"<p>Despite their recent successes in tackling many NLP tasks, large-scale\npre-trained language models do not perform as well in few-shot settings where\nonly a handful of training examples are available. To address this shortcoming,\nwe propose STraTA, which stands for Self-Training with Task Augmentation, an\napproach that builds on two key ideas for effective leverage of unlabeled data.\nFirst, STraTA uses task augmentation, a novel technique that synthesizes a\nlarge amount of data for auxiliary-task fine-tuning from target-task unlabeled\ntexts. Second, STraTA performs self-training by further fine-tuning the strong\nbase model created by task augmentation on a broad distribution of\npseudo-labeled data. Our experiments demonstrate that STraTA can substantially\nimprove sample efficiency across 12 few-shot benchmarks. Remarkably, on the\nSST-2 sentiment dataset, STraTA, with only 8 training examples per class,\nachieves comparable results to standard fine-tuning with 67K training examples.\nOur analyses reveal that task augmentation and self-training are both\ncomplementary and independently effective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tu Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_M/0/1/0/all/0/1\">Minh-Thang Luong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simon_G/0/1/0/all/0/1\">Grady Simon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindCraft: Theory of Mind Modeling for Situated Dialogue in Collaborative Tasks. (arXiv:2109.06275v1 [cs.AI])","link":"http://arxiv.org/abs/2109.06275","description":"<p>An ideal integration of autonomous agents in a human world implies that they\nare able to collaborate on human terms. In particular, theory of mind plays an\nimportant role in maintaining common ground during human collaboration and\ncommunication. To enable theory of mind modeling in situated interactions, we\nintroduce a fine-grained dataset of collaborative tasks performed by pairs of\nhuman subjects in the 3D virtual blocks world of Minecraft. It provides\ninformation that captures partners' beliefs of the world and of each other as\nan interaction unfolds, bringing abundant opportunities to study human\ncollaborative behaviors in situated language communication. As a first step\ntowards our goal of developing embodied AI agents able to infer belief states\nof collaborative partners in situ, we build and present results on\ncomputational models for several theory of mind tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bara_C/0/1/0/all/0/1\">Cristian-Paul Bara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+CH_Wang_S/0/1/0/all/0/1\">Sky CH-Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1\">Joyce Chai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graph Algorithms for Multiparallel Word Alignment. (arXiv:2109.06283v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06283","description":"<p>With the advent of end-to-end deep learning approaches in machine\ntranslation, interest in word alignments initially decreased; however, they\nhave again become a focus of research more recently. Alignments are useful for\ntypological research, transferring formatting like markup to translated texts,\nand can be used in the decoding of machine translation systems. At the same\ntime, massively multilingual processing is becoming an important NLP scenario,\nand pretrained language and machine translation models that are truly\nmultilingual are proposed. However, most alignment algorithms rely on bitexts\nonly and do not leverage the fact that many parallel corpora are multiparallel.\nIn this work, we exploit the multiparallelity of corpora by representing an\ninitial set of bilingual alignments as a graph and then predicting additional\nedges in the graph. We present two graph algorithms for edge prediction: one\ninspired by recommender systems and one based on network link prediction. Our\nexperimental results show absolute improvements in $F_1$ of up to 28% over the\nbaseline bilingual word aligner in different datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imani_A/0/1/0/all/0/1\">Ayyoob Imani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabet_M/0/1/0/all/0/1\">Masoud Jalili Sabet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senel_L/0/1/0/all/0/1\">L&#xfc;tfi Kerem &#x15e;enel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dufter_P/0/1/0/all/0/1\">Philipp Dufter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to Corpus Exploration. (arXiv:2109.06304v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06304","description":"<p>Phrase representations derived from BERT often do not exhibit complex phrasal\ncompositionality, as the model relies instead on lexical similarity to\ndetermine semantic relatedness. In this paper, we propose a contrastive\nfine-tuning objective that enables BERT to produce more powerful phrase\nembeddings. Our approach (Phrase-BERT) relies on a dataset of diverse phrasal\nparaphrases, which is automatically generated using a paraphrase generation\nmodel, as well as a large-scale dataset of phrases in context mined from the\nBooks3 corpus. Phrase-BERT outperforms baselines across a variety of\nphrase-level similarity tasks, while also demonstrating increased lexical\ndiversity between nearest neighbors in the vector space. Finally, as a case\nstudy, we show that Phrase-BERT embeddings can be easily integrated with a\nsimple autoencoder to build a phrase-based neural topic model that interprets\ntopics as mixtures of words and phrases by performing a nearest neighbor search\nin the embedding space. Crowdsourced evaluations demonstrate that this\nphrase-based topic model produces more coherent and meaningful topics than\nbaseline word and phrase-level topic models, further validating the utility of\nPhrase-BERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shufan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_L/0/1/0/all/0/1\">Laure Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Catastrophic Forgetting in Scheduled Sampling with Elastic Weight Consolidation in Neural Machine Translation. (arXiv:2109.06308v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06308","description":"<p>Despite strong performance in many sequence-to-sequence tasks, autoregressive\nmodels trained with maximum likelihood estimation suffer from exposure bias,\ni.e. a discrepancy between the ground-truth prefixes used during training and\nthe model-generated prefixes used at inference time. Scheduled sampling is a\nsimple and often empirically successful approach which addresses this issue by\nincorporating model-generated prefixes into the training process. However, it\nhas been argued that it is an inconsistent training objective leading to models\nignoring the prefixes altogether. In this paper, we conduct systematic\nexperiments and find that it ameliorates exposure bias by increasing model\nreliance on the input sequence. We also observe that as a side-effect, it\nworsens performance when the model-generated prefix is correct, a form of\ncatastrophic forgetting. We propose using Elastic Weight Consolidation as\ntrade-off between mitigating exposure bias and retaining output quality.\nExperiments on two IWSLT'14 translation tasks demonstrate that our approach\nalleviates catastrophic forgetting and significantly improves BLEU compared to\nstandard scheduled sampling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Korakakis_M/0/1/0/all/0/1\">Michalis Korakakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Constraints and Descriptive Segmentation for Subevent Detection. (arXiv:2109.06316v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06316","description":"<p>Event mentions in text correspond to real-world events of varying degrees of\ngranularity. The task of subevent detection aims to resolve this granularity\nissue, recognizing the membership of multi-granular events in event complexes.\nSince knowing the span of descriptive contexts of event complexes helps infer\nthe membership of events, we propose the task of event-based text segmentation\n(EventSeg) as an auxiliary task to improve the learning for subevent detection.\nTo bridge the two tasks together, we propose an approach to learning and\nenforcing constraints that capture dependencies between subevent detection and\nEventSeg prediction, as well as guiding the model to make globally consistent\ninference. Specifically, we adopt Rectifier Networks for constraint learning\nand then convert the learned constraints to a regularization term in the loss\nfunction of the neural model. Experimental results show that the proposed\nmethod outperforms baseline methods by 2.3% and 2.5% on benchmark datasets for\nsubevent detection, HiEve and IC, respectively, while achieving a decent\nperformance on EventSeg prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Massively Multilingual Analysis of Cross-linguality in Shared Embedding Space. (arXiv:2109.06324v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06324","description":"<p>In cross-lingual language models, representations for many different\nlanguages live in the same space. Here, we investigate the linguistic and\nnon-linguistic factors affecting sentence-level alignment in cross-lingual\npretrained language models for 101 languages and 5,050 language pairs. Using\nBERT-based LaBSE and BiLSTM-based LASER as our models, and the Bible as our\ncorpus, we compute a task-based measure of cross-lingual alignment in the form\nof bitext retrieval performance, as well as four intrinsic measures of vector\nspace alignment and isomorphism. We then examine a range of linguistic,\nquasi-linguistic, and training-related features as potential predictors of\nthese alignment metrics. The results of our analyses show that word order\nagreement and agreement in morphological complexity are two of the strongest\nlinguistic predictors of cross-linguality. We also note in-family training data\nas a stronger predictor than language-specific training data across the board.\nWe verify some of our linguistic findings by looking at the effect of\nmorphological segmentation on English-Inuktitut alignment, in addition to\nexamining the effect of word order agreement on isomorphism for 66 zero-shot\nlanguage pairs from a different corpus. We make the data and code for our\nexperiments publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jones_A/0/1/0/all/0/1\">Alex Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Transferability of BERT Models on Uralic Languages. (arXiv:2109.06327v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06327","description":"<p>Transformer-based language models such as BERT have outperformed previous\nmodels on a large number of English benchmarks, but their evaluation is often\nlimited to English or a small number of well-resourced languages. In this work,\nwe evaluate monolingual, multilingual, and randomly initialized language models\nfrom the BERT family on a variety of Uralic languages including Estonian,\nFinnish, Hungarian, Erzya, Moksha, Karelian, Livvi, Komi Permyak, Komi Zyrian,\nNorthern S\\'ami, and Skolt S\\'ami. When monolingual models are available\n(currently only et, fi, hu), these perform better on their native language, but\nin general they transfer worse than multilingual models or models of\ngenetically unrelated languages that share the same character set. Remarkably,\nstraightforward transfer of high-resource models, even without special efforts\ntoward hyperparameter optimization, yields what appear to be state of the art\nPOS and NER tools for the minority Uralic languages where there is sufficient\ndata for finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Acs_J/0/1/0/all/0/1\">Judit &#xc1;cs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levai_D/0/1/0/all/0/1\">D&#xe1;niel L&#xe9;vai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornai_A/0/1/0/all/0/1\">Andr&#xe1;s Kornai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Old BERT, New Tricks: Artificial Language Learning for Pre-Trained Language Models. (arXiv:2109.06333v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06333","description":"<p>We extend the artificial language learning experimental paradigm from\npsycholinguistics and apply it to pre-trained language models -- specifically,\nBERT (Devlin et al., 2019). We treat the model as a subject in an artificial\nlanguage learning experimental setting: in order to learn the relation between\ntwo linguistic properties A and B, we introduce a set of new, non-existent,\nlinguistic items, give the model information about their variation along\nproperty A, then measure to what extent the model learns property B for these\nitems as a result of training. We show this method at work for degree modifiers\n(expressions like \"slightly\", \"very\", \"rather\", \"extremely\") and test the\nhypothesis that the degree expressed by modifiers (low, medium or high degree)\nis related to their sensitivity to sentence polarity (whether they show\npreference for affirmative or negative sentences or neither). Our experimental\nresults are compatible with existing linguistic observations that relate degree\nsemantics to polarity-sensitivity, including the main one: low degree semantics\nleads to positive polarity sensitivity (that is, to preference towards\naffirmative contexts). The method can be used in linguistics to elaborate on\nhypotheses and interpret experimental results, as well as for more insightful\nevaluation of linguistic representations in language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bylinina_L/0/1/0/all/0/1\">Lisa Bylinina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garmash_E/0/1/0/all/0/1\">Ekaterina Garmash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning. (arXiv:2109.06349v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06349","description":"<p>In this work, we focus on a more challenging few-shot intent detection\nscenario where many intents are fine-grained and semantically similar. We\npresent a simple yet effective few-shot intent detection schema via contrastive\npre-training and fine-tuning. Specifically, we first conduct self-supervised\ncontrastive pre-training on collected intent datasets, which implicitly learns\nto discriminate semantically similar utterances without using any labels. We\nthen perform few-shot intent detection together with supervised contrastive\nlearning, which explicitly pulls utterances from the same intent closer and\npushes utterances across different intents farther. Experimental results show\nthat our proposed method achieves state-of-the-art performance on three\nchallenging intent detection datasets under 5-shot and 10-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Trung Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seunghyun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Congying Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_Q/0/1/0/all/0/1\">Quan Hung Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1\">Walter Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncertainty-Aware Machine Translation Evaluation. (arXiv:2109.06352v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06352","description":"<p>Several neural-based metrics have been recently proposed to evaluate machine\ntranslation quality. However, all of them resort to point estimates, which\nprovide limited information at segment level. This is made worse as they are\ntrained on noisy, biased and scarce human judgements, often resulting in\nunreliable quality predictions. In this paper, we introduce uncertainty-aware\nMT evaluation and analyze the trustworthiness of the predicted quality. We\ncombine the COMET framework with two uncertainty estimation methods, Monte\nCarlo dropout and deep ensembles, to obtain quality scores along with\nconfidence intervals. We compare the performance of our uncertainty-aware MT\nevaluation methods across multiple language pairs from the QT21 dataset and the\nWMT20 metrics task, augmented with MQM annotations. We experiment with varying\nnumbers of references and further discuss the usefulness of uncertainty-aware\nquality estimation (without references) to flag possibly critical translation\nmistakes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glushkova_T/0/1/0/all/0/1\">Taisiya Glushkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zerva_C/0/1/0/all/0/1\">Chrysoula Zerva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rei_R/0/1/0/all/0/1\">Ricardo Rei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hunspell for Sorani Kurdish Spell Checking and Morphological Analysis. (arXiv:2109.06374v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06374","description":"<p>Spell checking and morphological analysis are two fundamental tasks in text\nand natural language processing and are addressed in the early stages of the\ndevelopment of language technology. Despite the previous efforts, there is no\nprogress in open-source to create such tools for Sorani Kurdish, also known as\nCentral Kurdish, as a less-resourced language. In this paper, we present our\nefforts in annotating a lexicon with morphosyntactic tags and also, extracting\nmorphological rules of Sorani Kurdish to build a morphological analyzer, a\nstemmer and a spell-checking system using Hunspell. This implementation can be\nused for further developments in the field by researchers and also, be\nintegrated into text editors under a publicly available license.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmadi_S/0/1/0/all/0/1\">Sina Ahmadi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation. (arXiv:2109.06379v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06379","description":"<p>Natural language generation (NLG) spans a broad range of tasks, each of which\nserves for specific objectives and desires different properties of generated\ntext. The complexity makes automatic evaluation of NLG particularly\nchallenging. Previous work has typically focused on a single task and developed\nindividual evaluation metrics based on specific intuitions. In this paper, we\npropose a unifying perspective based on the nature of information change in NLG\ntasks, including compression (e.g., summarization), transduction (e.g., text\nrewriting), and creation (e.g., dialog). Information alignment between input,\ncontext, and output text plays a common central role in characterizing the\ngeneration. With automatic alignment prediction models, we develop a family of\ninterpretable metrics that are suitable for evaluating key aspects of different\nNLG tasks, often without need of gold reference data. Experiments show the\nuniformly designed metrics achieve stronger or comparable correlations with\nhuman judgement compared to state-of-the-art metrics in each of diverse tasks,\nincluding text summarization, style transfer, and knowledge-grounded dialog.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1\">Mingkai Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1\">Bowen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rationales for Sequential Predictions. (arXiv:2109.06387v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06387","description":"<p>Sequence models are a critical component of modern NLP systems, but their\npredictions are difficult to explain. We consider model explanations though\nrationales, subsets of context that can explain individual model predictions.\nWe find sequential rationales by solving a combinatorial optimization: the best\nrationale is the smallest subset of input tokens that would predict the same\noutput as the full sequence. Enumerating all subsets is intractable, so we\npropose an efficient greedy algorithm to approximate this objective. The\nalgorithm, which is called greedy rationalization, applies to any model. For\nthis approach to be effective, the model should form compatible conditional\ndistributions when making predictions on incomplete subsets of the context.\nThis condition can be enforced with a short fine-tuning step. We study greedy\nrationalization on language modeling and machine translation. Compared to\nexisting baselines, greedy rationalization is best at optimizing the\ncombinatorial objective and provides the most faithful rationales. On a new\ndataset of annotated sequential rationales, greedy rationales are most similar\nto human rationales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vafa_K/0/1/0/all/0/1\">Keyon Vafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yuntian Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David M. Blei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Proposal Generation Network for Temporal Sentence Localization in Videos. (arXiv:2109.06398v1 [cs.CV])","link":"http://arxiv.org/abs/2109.06398","description":"<p>We address the problem of temporal sentence localization in videos (TSLV).\nTraditional methods follow a top-down framework which localizes the target\nsegment with pre-defined segment proposals. Although they have achieved decent\nperformance, the proposals are handcrafted and redundant. Recently, bottom-up\nframework attracts increasing attention due to its superior efficiency. It\ndirectly predicts the probabilities for each frame as a boundary. However, the\nperformance of bottom-up model is inferior to the top-down counterpart as it\nfails to exploit the segment-level interaction. In this paper, we propose an\nAdaptive Proposal Generation Network (APGN) to maintain the segment-level\ninteraction while speeding up the efficiency. Specifically, we first perform a\nforeground-background classification upon the video and regress on the\nforeground frames to adaptively generate proposals. In this way, the\nhandcrafted proposal design is discarded and the redundant proposals are\ndecreased. Then, a proposal consolidation module is further developed to\nenhance the semantic of the generated proposals. Finally, we locate the target\nmoments with these generated proposals following the top-down framework.\nExtensive experiments on three challenging benchmarks show that our proposed\nAPGN significantly outperforms previous state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Daizong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoye Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jianfeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pan Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressively Guide to Attend: An Iterative Alignment Framework for Temporal Sentence Grounding. (arXiv:2109.06400v1 [cs.CV])","link":"http://arxiv.org/abs/2109.06400","description":"<p>A key solution to temporal sentence grounding (TSG) exists in how to learn\neffective alignment between vision and language features extracted from an\nuntrimmed video and a sentence description. Existing methods mainly leverage\nvanilla soft attention to perform the alignment in a single-step process.\nHowever, such single-step attention is insufficient in practice, since\ncomplicated relations between inter- and intra-modality are usually obtained\nthrough multi-step reasoning. In this paper, we propose an Iterative Alignment\nNetwork (IA-Net) for TSG task, which iteratively interacts inter- and\nintra-modal features within multiple steps for more accurate grounding.\nSpecifically, during the iterative reasoning process, we pad multi-modal\nfeatures with learnable parameters to alleviate the nowhere-to-attend problem\nof non-matched frame-word pairs, and enhance the basic co-attention mechanism\nin a parallel manner. To further calibrate the misaligned attention caused by\neach reasoning step, we also devise a calibration module following each\nattention module to refine the alignment knowledge. With such iterative\nalignment scheme, our IA-Net can robustly capture the fine-grained relations\nbetween vision and language domains step-by-step for progressively reasoning\nthe temporal boundaries. Extensive experiments conducted on three challenging\nbenchmarks demonstrate that our proposed model performs better than the\nstate-of-the-arts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Daizong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoye Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pan Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Personality and Online Social Engagement: An Investigation of MBTI Users on Twitter. (arXiv:2109.06402v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06402","description":"<p>Text-based personality prediction by computational models is an emerging\nfield with the potential to significantly improve on key weaknesses of\nsurvey-based personality assessment. We investigate 3848 profiles from Twitter\nwith self-labeled Myers-Briggs personality traits (MBTI) - a framework closely\nrelated to the Five Factor Model of personality - to better understand how\ntext-based digital traces from social engagement online can be used to predict\nuser personality traits. We leverage BERT, a state-of-the-art NLP architecture\nbased on deep learning, to analyze various sources of text that hold most\npredictive power for our task. We find that biographies, statuses, and liked\ntweets contain significant predictive power for all dimensions of the MBTI\nsystem. We discuss our findings and their implications for the validity of the\nMBTI and the lexical hypothesis, a foundational theory underlying the Five\nFactor Model that links language use and behavior. Our results hold optimistic\nimplications for personality psychologists, computational linguists, and other\nsocial scientists aiming to predict personality from observational text data\nand explore the links between language and core behavioral traits.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kadambi_P/0/1/0/all/0/1\">Partha Kadambi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient Imitation Reinforcement Learning for Low Resource Relation Extraction. (arXiv:2109.06415v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06415","description":"<p>Low-resource Relation Extraction (LRE) aims to extract relation facts from\nlimited labeled corpora when human annotation is scarce. Existing works either\nutilize self-training scheme to generate pseudo labels that will cause the\ngradual drift problem, or leverage meta-learning scheme which does not solicit\nfeedback explicitly. To alleviate selection bias due to the lack of feedback\nloops in existing LRE learning paradigms, we developed a Gradient Imitation\nReinforcement Learning method to encourage pseudo label data to imitate the\ngradient descent direction on labeled data and bootstrap its optimization\ncapability through trial and error. We also propose a framework called GradLRE,\nwhich handles two major scenarios in low-resource relation extraction. Besides\nthe scenario where unlabeled data is sufficient, GradLRE handles the situation\nwhere no unlabeled data is available, by exploiting a contextualized\naugmentation method to generate data. Experimental results on two public\ndatasets demonstrate the effectiveness of GradLRE on low resource relation\nextraction when comparing with baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yawen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaohe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Li Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-document Event Identity via Dense Annotation. (arXiv:2109.06417v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06417","description":"<p>In this paper, we study the identity of textual events from different\ndocuments. While the complex nature of event identity is previously studied\n(Hovy et al., 2013), the case of events across documents is unclear. Prior work\non cross-document event coreference has two main drawbacks. First, they\nrestrict the annotations to a limited set of event types. Second, they\ninsufficiently tackle the concept of event identity. Such annotation setup\nreduces the pool of event mentions and prevents one from considering the\npossibility of quasi-identity relations. We propose a dense annotation approach\nfor cross-document event coreference, comprising a rich source of event\nmentions and a dense annotation effort between related document pairs. To this\nend, we design a new annotation workflow with careful quality control and an\neasy-to-use annotation interface. In addition to the links, we further collect\noverlapping event contexts, including time, location, and participants, to shed\nsome light on the relation between identity decisions and context. We present\nan open-access dataset for cross-document event coreference, CDEC-WN, collected\nfrom English Wikinews and open-source our annotation toolkit to encourage\nfurther research on cross-document tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pratapa_A/0/1/0/all/0/1\">Adithya Pratapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_K/0/1/0/all/0/1\">Kimihiro Hasegawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamakawa_Y/0/1/0/all/0/1\">Yukari Yamakawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Commonsense-Focused Dialogues for Response Generation: An Empirical Study. (arXiv:2109.06427v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06427","description":"<p>Smooth and effective communication requires the ability to perform latent or\nexplicit commonsense inference. Prior commonsense reasoning benchmarks (such as\nSocialIQA and CommonsenseQA) mainly focus on the discriminative task of\nchoosing the right answer from a set of candidates, and do not involve\ninteractive language generation as in dialogue. Moreover, existing dialogue\ndatasets do not explicitly focus on exhibiting commonsense as a facet. In this\npaper, we present an empirical study of commonsense in dialogue response\ngeneration. We first auto-extract commonsensical dialogues from existing\ndialogue datasets by leveraging ConceptNet, a commonsense knowledge graph.\nFurthermore, building on social contexts/situations in SocialIQA, we collect a\nnew dialogue dataset with 25K dialogues aimed at exhibiting social commonsense\nin an interactive setting. We evaluate response generation models trained using\nthese datasets and find that models trained on both extracted and our collected\ndata produce responses that consistently exhibit more commonsense than\nbaselines. Finally we propose an approach for automatic evaluation of\ncommonsense that relies on features derived from ConceptNet and pre-trained\nlanguage and dialog models, and show reasonable correlation with human\nevaluation of responses' commonsense quality. We are releasing a subset of our\ncollected data, Commonsense-Dialogues, containing about 11K dialogs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Karthik Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujara_J/0/1/0/all/0/1\">Jay Pujara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YES SIR!Optimizing Semantic Space of Negatives with Self-Involvement Ranker. (arXiv:2109.06436v1 [cs.IR])","link":"http://arxiv.org/abs/2109.06436","description":"<p>Pre-trained model such as BERT has been proved to be an effective tool for\ndealing with Information Retrieval (IR) problems. Due to its inspiring\nperformance, it has been widely used to tackle with real-world IR problems such\nas document ranking. Recently, researchers have found that selecting \"hard\"\nrather than \"random\" negative samples would be beneficial for fine-tuning\npre-trained models on ranking tasks. However, it remains elusive how to\nleverage hard negative samples in a principled way. To address the\naforementioned issues, we propose a fine-tuning strategy for document ranking,\nnamely Self-Involvement Ranker (SIR), to dynamically select hard negative\nsamples to construct high-quality semantic space for training a high-quality\nranking model. Specifically, SIR consists of sequential compressors implemented\nwith pre-trained models. Front compressor selects hard negative samples for\nrear compressor. Moreover, SIR leverages supervisory signal to adaptively\nadjust semantic space of negative samples. Finally, supervisory signal in rear\ncompressor is computed based on condition probability and thus can control\nsample dynamic and further enhance the model performance. SIR is a lightweight\nand general framework for pre-trained models, which simplifies the ranking\nprocess in industry practice. We test our proposed solution on MS MARCO with\ndocument ranking setting, and the results show that SIR can significantly\nimprove the ranking performance of various pre-trained models. Moreover, our\nmethod became the new SOTA model anonymously on MS MARCO Document ranking\nleaderboard in May 2021.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pu_R/0/1/0/all/0/1\">Ruizhi Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_R/0/1/0/all/0/1\">Ruofei Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zikai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinxia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yongkang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yantao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1\">Zhicheng Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhao Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncovering Implicit Gender Bias in Narratives through Commonsense Inference. (arXiv:2109.06437v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06437","description":"<p>Pre-trained language models learn socially harmful biases from their training\ncorpora, and may repeat these biases when used for generation. We study gender\nbiases associated with the protagonist in model-generated stories. Such biases\nmay be expressed either explicitly (\"women can't park\") or implicitly (e.g. an\nunsolicited male character guides her into a parking space). We focus on\nimplicit biases, and use a commonsense reasoning engine to uncover them.\nSpecifically, we infer and analyze the protagonist's motivations, attributes,\nmental states, and implications on others. Our findings regarding implicit\nbiases are in line with prior work that studied explicit biases, for example\nshowing that female characters' portrayal is centered around appearance, while\nmale figures' focus on intellect.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Tenghao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1\">Snigdha Chaturvedi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-adaptive Pre-training and Self-training are Complementary for Natural Language Understanding. (arXiv:2109.06466v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06466","description":"<p>Task-adaptive pre-training (TAPT) and Self-training (ST) have emerged as the\nmajor semi-supervised approaches to improve natural language understanding\n(NLU) tasks with massive amount of unlabeled data. However, it's unclear\nwhether they learn similar representations or they can be effectively combined.\nIn this paper, we show that TAPT and ST can be complementary with simple TFS\nprotocol by following TAPT -&gt; Finetuning -&gt; Self-training (TFS) process.\nExperimental results show that TFS protocol can effectively utilize unlabeled\ndata to achieve strong combined gains consistently across six datasets covering\nsentiment classification, paraphrase identification, natural language\ninference, named entity recognition and dialogue slot classification. We\ninvestigate various semi-supervised settings and consistently show that gains\nfrom TAPT and ST can be strongly additive by following TFS procedure. We hope\nthat TFS could serve as an important semi-supervised baseline for future NLP\nstudies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1\">Xifeng Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying Untrustworthy Samples: Data Filtering for Open-domain Dialogues with Bayesian Optimization. (arXiv:2109.06471v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06471","description":"<p>Being able to reply with a related, fluent, and informative response is an\nindispensable requirement for building high-quality conversational agents. In\norder to generate better responses, some approaches have been proposed, such as\nfeeding extra information by collecting large-scale datasets with human\nannotations, designing neural conversational models (NCMs) with complex\narchitecture and loss functions, or filtering out untrustworthy samples based\non a dialogue attribute, e.g., Relatedness or Genericness. In this paper, we\nfollow the third research branch and present a data filtering method for\nopen-domain dialogues, which identifies untrustworthy samples from training\ndata with a quality measure that linearly combines seven dialogue attributes.\nThe attribute weights are obtained via Bayesian Optimization (BayesOpt) that\naims to optimize an objective function for dialogue generation iteratively on\nthe validation set. Then we score training samples with the quality measure,\nsort them in descending order, and filter out those at the bottom. Furthermore,\nto accelerate the \"filter-train-evaluate\" iterations involved in BayesOpt on\nlarge-scale datasets, we propose a training framework that integrates maximum\nlikelihood estimation (MLE) and negative training method (NEG). The training\nmethod updates parameters of a trained NCMs on two small sets with newly\nmaintained and removed samples, respectively. Specifically, MLE is applied to\nmaximize the log-likelihood of newly maintained samples, while NEG is used to\nminimize the log-likelihood of newly removed ones. Experimental results on two\ndatasets show that our method can effectively identify untrustworthy samples,\nand NCMs trained on the filtered datasets achieve better performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1\">Haolan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongshen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logic-level Evidence Retrieval and Graph-based Verification Network for Table-based Fact Verification. (arXiv:2109.06480v1 [cs.AI])","link":"http://arxiv.org/abs/2109.06480","description":"<p>Table-based fact verification task aims to verify whether the given statement\nis supported by the given semi-structured table. Symbolic reasoning with\nlogical operations plays a crucial role in this task. Existing methods leverage\nprograms that contain rich logical information to enhance the verification\nprocess. However, due to the lack of fully supervised signals in the program\ngeneration process, spurious programs can be derived and employed, which leads\nto the inability of the model to catch helpful logical operations. To address\nthe aforementioned problems, in this work, we formulate the table-based fact\nverification task as an evidence retrieval and reasoning framework, proposing\nthe Logic-level Evidence Retrieval and Graph-based Verification network\n(LERGV). Specifically, we first retrieve logic-level program-like evidence from\nthe given table and statement as supplementary evidence for the table. After\nthat, we construct a logic-level graph to capture the logical relations between\nentities and functions in the retrieved evidence, and design a graph-based\nverification network to perform logic-level graph-based reasoning based on the\nconstructed graph to classify the final entailment relation. Experimental\nresults on the large-scale benchmark TABFACT show the effectiveness of the\nproposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Q/0/1/0/all/0/1\">Qingyu Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AligNART: Non-autoregressive Neural Machine Translation by Jointly Learning to Estimate Alignment and Translate. (arXiv:2109.06481v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06481","description":"<p>Non-autoregressive neural machine translation (NART) models suffer from the\nmulti-modality problem which causes translation inconsistency such as token\nrepetition. Most recent approaches have attempted to solve this problem by\nimplicitly modeling dependencies between outputs. In this paper, we introduce\nAligNART, which leverages full alignment information to explicitly reduce the\nmodality of the target distribution. AligNART divides the machine translation\ntask into $(i)$ alignment estimation and $(ii)$ translation with aligned\ndecoder inputs, guiding the decoder to focus on simplified one-to-one\ntranslation. To alleviate the alignment estimation problem, we further propose\na novel alignment decomposition method. Our experiments show that AligNART\noutperforms previous non-iterative NART models that focus on explicit modality\nreduction on WMT14 En$\\leftrightarrow$De and WMT16 Ro$\\rightarrow$En.\nFurthermore, AligNART achieves BLEU scores comparable to those of the\nstate-of-the-art connectionist temporal classification based models on WMT14\nEn$\\leftrightarrow$De. We also observe that AligNART effectively addresses the\ntoken repetition problem even without sequence-level knowledge distillation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jongyoon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungwon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilevel profiling of situation and dialogue-based deep networks for movie genre classification using movie trailers. (arXiv:2109.06488v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06488","description":"<p>Automated movie genre classification has emerged as an active and essential\narea of research and exploration. Short duration movie trailers provide useful\ninsights about the movie as video content consists of the cognitive and the\naffective level features. Previous approaches were focused upon either\ncognitive or affective content analysis. In this paper, we propose a novel\nmulti-modality: situation, dialogue, and metadata-based movie genre\nclassification framework that takes both cognition and affect-based features\ninto consideration. A pre-features fusion-based framework that takes into\naccount: situation-based features from a regular snapshot of a trailer that\nincludes nouns and verbs providing the useful affect-based mapping with the\ncorresponding genres, dialogue (speech) based feature from audio, metadata\nwhich together provides the relevant information for cognitive and affect based\nvideo analysis. We also develop the English movie trailer dataset (EMTD), which\ncontains 2000 Hollywood movie trailers belonging to five popular genres:\nAction, Romance, Comedy, Horror, and Science Fiction, and perform\ncross-validation on the standard LMTD-9 dataset for validating the proposed\nframework. The results demonstrate that the proposed methodology for movie\ngenre classification has performed excellently as depicted by the F1 scores,\nprecision, recall, and area under the precision-recall curves.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vishwakarma_D/0/1/0/all/0/1\">Dinesh Kumar Vishwakarma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_M/0/1/0/all/0/1\">Mayank Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1\">Ayush Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Aditya Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"conSultantBERT: Fine-tuned Siamese Sentence-BERT for Matching Jobs and Job Seekers. (arXiv:2109.06501v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06501","description":"<p>In this paper we focus on constructing useful embeddings of textual\ninformation in vacancies and resumes, which we aim to incorporate as features\ninto job to job seeker matching models alongside other features. We explain our\ntask where noisy data from parsed resumes, heterogeneous nature of the\ndifferent sources of data, and crosslinguality and multilinguality present\ndomain-specific challenges.\n</p>\n<p>We address these challenges by fine-tuning a Siamese Sentence-BERT (SBERT)\nmodel, which we call conSultantBERT, using a large-scale, real-world, and high\nquality dataset of over 270,000 resume-vacancy pairs labeled by our staffing\nconsultants. We show how our fine-tuned model significantly outperforms\nunsupervised and supervised baselines that rely on TF-IDF-weighted feature\nvectors and BERT embeddings. In addition, we find our model successfully\nmatches cross-lingual and multilingual textual content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lavi_D/0/1/0/all/0/1\">Dor Lavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medentsiy_V/0/1/0/all/0/1\">Volodymyr Medentsiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graus_D/0/1/0/all/0/1\">David Graus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tribrid: Stance Classification with Neural Inconsistency Detection. (arXiv:2109.06508v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06508","description":"<p>We study the problem of performing automatic stance classification on social\nmedia with neural architectures such as BERT. Although these architectures\ndeliver impressive results, their level is not yet comparable to the one of\nhumans and they might produce errors that have a significant impact on the\ndownstream task (e.g., fact-checking). To improve the performance, we present a\nnew neural architecture where the input also includes automatically generated\nnegated perspectives over a given claim. The model is jointly learned to make\nsimultaneously multiple predictions, which can be used either to improve the\nclassification of the original perspective or to filter out doubtful\npredictions. In the first case, we propose a weakly supervised method for\ncombining the predictions into a final one. In the second case, we show that\nusing the confidence scores to remove doubtful predictions allows our method to\nachieve human-like performance over the retained information, which is still a\nsizable part of the original input.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Song Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Urbani_J/0/1/0/all/0/1\">Jacopo Urbani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation. (arXiv:2109.06513v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06513","description":"<p>Dialog grounding enables conversational models to make full use of external\ninformation to establish multiple desired qualities, such as knowledgeable,\nengaging and empathetic. However, naturally grounded dialog corpora are usually\nnot directly available, which puts forward requirements for the few-shot\nlearning ability of conversational models. Motivated by recent advances in\npre-trained language models and prompt-based learning, in this paper we explore\nprompt-based few-shot learning for grounded dialog generation (GDG). We first\nformulate the prompt construction for GDG tasks, based on which we then conduct\ncomprehensive empirical analysis on two common types of prompting methods:\ntemplate-based prompting and soft-prompting. We demonstrate the potential of\nprompt-based methods in few-shot learning for GDG and provide directions of\nimprovement for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Netmarble AI Center's WMT21 Automatic Post-Editing Shared Task Submission. (arXiv:2109.06515v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06515","description":"<p>This paper describes Netmarble's submission to WMT21 Automatic Post-Editing\n(APE) Shared Task for the English-German language pair. First, we propose a\nCurriculum Training Strategy in training stages. Facebook Fair's WMT19 news\ntranslation model was chosen to engage the large and powerful pre-trained\nneural networks. Then, we post-train the translation model with different\nlevels of data at each training stages. As the training stages go on, we make\nthe system learn to solve multiple tasks by adding extra information at\ndifferent training stages gradually. We also show a way to utilize the\nadditional data in large volume for APE tasks. For further improvement, we\napply Multi-Task Learning Strategy with the Dynamic Weight Average during the\nfine-tuning stage. To fine-tune the APE corpus with limited data, we add some\nrelated subtasks to learn a unified representation. Finally, for better\nperformance, we leverage external translations as augmented machine translation\n(MT) during the post-training and fine-tuning. As experimental results show,\nour APE system significantly improves the translations of provided MT results\nby -2.848 and +3.74 on the development dataset in terms of TER and BLEU,\nrespectively. It also demonstrates its effectiveness on the test dataset with\nhigher quality than the development dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Shinhyeok Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Sion Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1\">Shounan An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_I/0/1/0/all/0/1\">Insoo Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Sampling of Dependency Structures. (arXiv:2109.06521v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06521","description":"<p>Probabilistic distributions over spanning trees in directed graphs are a\nfundamental model of dependency structure in natural language processing,\nsyntactic dependency trees. In NLP, dependency trees often have an additional\nroot constraint: only one edge may emanate from the root. However, no sampling\nalgorithm has been presented in the literature to account for this additional\nconstraint. In this paper, we adapt two spanning tree sampling algorithms to\nfaithfully sample dependency trees from a graph subject to the root constraint.\nWilson (1996)'s sampling algorithm has a running time of $\\mathcal{O}(H)$ where\n$H$ is the mean hitting time of the graph. Colbourn (1996)'s sampling algorithm\nhas a running time of $\\mathcal{O}(N^3)$, which is often greater than the mean\nhitting time of a directed graph. Additionally, we build upon Colbourn's\nalgorithm and present a novel extension that can sample $K$ trees without\nreplacement in $\\mathcal{O}(K N^3 + K^2 N)$ time. To the best of our knowledge,\nno algorithm has been given for sampling spanning trees without replacement\nfrom a directed graph.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1\">Ran Zmigrod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Different Strokes for Different Folks: Investigating Appropriate Further Pre-training Approaches for Diverse Dialogue Tasks. (arXiv:2109.06524v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06524","description":"<p>Loading models pre-trained on the large-scale corpus in the general domain\nand fine-tuning them on specific downstream tasks is gradually becoming a\nparadigm in Natural Language Processing. Previous investigations prove that\nintroducing a further pre-training phase between pre-training and fine-tuning\nphases to adapt the model on the domain-specific unlabeled data can bring\npositive effects. However, most of these further pre-training works just keep\nrunning the conventional pre-training task, e.g., masked language model, which\ncan be regarded as the domain adaptation to bridge the data distribution gap.\nAfter observing diverse downstream tasks, we suggest that different tasks may\nalso need a further pre-training phase with appropriate training tasks to\nbridge the task formulation gap. To investigate this, we carry out a study for\nimproving multiple task-oriented dialogue downstream tasks through designing\nvarious tasks at the further pre-training phase. The experiment shows that\ndifferent downstream tasks prefer different further pre-training tasks, which\nhave intrinsic correlation and most further pre-training tasks significantly\nimprove certain target tasks rather than all. Our investigation indicates that\nit is of great importance and effectiveness to design appropriate further\npre-training tasks modeling specific information that benefit downstream tasks.\nBesides, we present multiple constructive empirical conclusions for enhancing\ntask-oriented dialogues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Bill Similarity with Annotated and Augmented Corpora of Bills. (arXiv:2109.06527v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06527","description":"<p>Bill writing is a critical element of representative democracy. However, it\nis often overlooked that most legislative bills are derived, or even directly\ncopied, from other bills. Despite the significance of bill-to-bill linkages for\nunderstanding the legislative process, existing approaches fail to address\nsemantic similarities across bills, let alone reordering or paraphrasing which\nare prevalent in legal document writing. In this paper, we overcome these\nlimitations by proposing a 5-class classification task that closely reflects\nthe nature of the bill generation process. In doing so, we construct a\nhuman-labeled dataset of 4,721 bill-to-bill relationships at the\nsubsection-level and release this annotated dataset to the research community.\nTo augment the dataset, we generate synthetic data with varying degrees of\nsimilarity, mimicking the complex bill writing process. We use BERT variants\nand apply multi-stage training, sequentially fine-tuning our models with\nsynthetic and human-labeled datasets. We find that the predictive performance\nsignificantly improves when training with both human-labeled and synthetic\ndata. Finally, we apply our trained model to infer section- and bill-level\nsimilarities. Our analysis shows that the proposed methodology successfully\ncaptures the similarities across legal documents at various levels of\naggregation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiseon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griggs_E/0/1/0/all/0/1\">Elden Griggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1\">In Song Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Gradient-based Adversarial Training for Text Classification by Contrastive Learning and Auto-Encoder. (arXiv:2109.06536v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06536","description":"<p>Recent work has proposed several efficient approaches for generating\ngradient-based adversarial perturbations on embeddings and proved that the\nmodel's performance and robustness can be improved when they are trained with\nthese contaminated embeddings. While they paid little attention to how to help\nthe model to learn these adversarial samples more efficiently. In this work, we\nfocus on enhancing the model's ability to defend gradient-based adversarial\nattack during the model's training process and propose two novel adversarial\ntraining approaches: (1) CARL narrows the original sample and its adversarial\nsample in the representation space while enlarging their distance from\ndifferent labeled samples. (2) RAR forces the model to reconstruct the original\nsample from its adversarial representation. Experiments show that the proposed\ntwo approaches outperform strong baselines on various text classification\ndatasets. Analysis experiments find that when using our approaches, the\nsemantic representation of the input sentence won't be significantly affected\nby adversarial perturbations, and the model's performance drops less under\nadversarial attack. That is to say, our approaches can effectively improve the\nrobustness of the model. Besides, RAR can also be used to generate text-form\nadversarial samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenging Instances are Worth Learning: Generating Valuable Negative Samples for Response Selection Training. (arXiv:2109.06538v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06538","description":"<p>Retrieval-based chatbot selects the appropriate response from candidates\naccording to the context, which heavily depends on a response selection module.\nA response selection module is generally a scoring model to evaluate candidates\nand is usually trained on the annotated positive response and sampled negative\nresponses. Sampling negative responses lead to two risks: a). The sampled\nnegative instances, especially that from random sampling methods, are mostly\nirrelevant to the dialogue context and too easy to be fitted at the training\nstage while causing a weak model in the real scenario. b). The so-called\nnegative instances may be positive, which is known as the fake negative\nproblem. To address the above issue, we employ pre-trained language models,\nsuch as the DialoGPT to construct more challenging negative instances to\nenhance the model robustness. Specifically, we provide garbled context to the\npre-trained model to generate responses and filter the fake negative ones. In\nthis way, our negative instances are fluent, context-related, and more\nchallenging for the model to learn, while can not be positive. Extensive\nexperiments show that our method brings significant and stable improvements on\nthe dialogue response selection capacity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Huiying Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Talking Space: inference from spatial linguistic meanings. (arXiv:2109.06554v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06554","description":"<p>This paper concerns the intersection of natural language and the physical\nspace around us in which we live, that we observe and/or imagine things within.\nMany important features of language have spatial connotations, for example,\nmany prepositions (like in, next to, after, on, etc.) are fundamentally\nspatial. Space is also a key factor of the meanings of many\nwords/phrases/sentences/text, and space is a, if not the key, context for\nreferencing (e.g. pointing) and embodiment.\n</p>\n<p>We propose a mechanism for how space and linguistic structure can be made to\ninteract in a matching compositional fashion. Examples include Cartesian space,\nsubway stations, chesspieces on a chess-board, and Penrose's staircase. The\nstarting point for our construction is the DisCoCat model of compositional\nnatural language meaning, which we relax to accommodate physical space. We\naddress the issue of having multiple agents/objects in a space, including the\ncase that each agent has different capabilities with respect to that space,\ne.g., the specific moves each chesspiece can make, or the different velocities\none may be able to reach.\n</p>\n<p>Once our model is in place, we show how inferences drawing from the structure\nof physical space can be made. We also how how linguistic model of space can\ninteract with other such models related to our senses and/or embodiment, such\nas the conceptual spaces of colour, taste and smell, resulting in a rich\ncompositional model of meaning that is close to human experience and embodiment\nin the world.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Mascianica_V/0/1/0/all/0/1\">Vincent Wang-Mascianica</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coecke_B/0/1/0/all/0/1\">Bob Coecke</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Just What do You Think You're Doing, Dave?' A Checklist for Responsible Data Use in NLP. (arXiv:2109.06598v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06598","description":"<p>A key part of the NLP ethics movement is responsible use of data, but exactly\nwhat that means or how it can be best achieved remain unclear. This position\npaper discusses the core legal and ethical principles for collection and\nsharing of textual data, and the tensions between them. We propose a potential\nchecklist for responsible data (re-)use that could both standardise the peer\nreview of conference submissions, as well as enable a more in-depth view of\npublished research across the community. Our proposal aims to contribute to the\ndevelopment of a consistent standard for data (re-)use, embraced across NLP\nconferences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1\">Anna Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Tim Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leins_K/0/1/0/all/0/1\">Kobi Leins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation. (arXiv:2109.06604v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06604","description":"<p>Recently, $k$NN-MT has shown the promising capability of directly\nincorporating the pre-trained neural machine translation (NMT) model with\ndomain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve\ndomain adaptation without retraining. Despite being conceptually attractive, it\nheavily relies on high-quality in-domain parallel corpora, limiting its\ncapability on unsupervised domain adaptation, where in-domain parallel corpora\nare scarce or nonexistent. In this paper, we propose a novel framework that\ndirectly uses in-domain monolingual sentences in the target language to\nconstruct an effective datastore for $k$-nearest-neighbor retrieval. To this\nend, we first introduce an autoencoder task based on the target language, and\nthen insert lightweight adapters into the original NMT model to map the\ntoken-level representation of this task to the ideal representation of\ntranslation task. Experiments on multi-domain datasets demonstrate that our\nproposed approach significantly improves the translation accuracy with\ntarget-side monolingual data, while achieving comparable performance with\nback-translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Boxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MDAPT: Multilingual Domain Adaptive Pretraining in a Single Model. (arXiv:2109.06605v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06605","description":"<p>Domain adaptive pretraining, i.e. the continued unsupervised pretraining of a\nlanguage model on domain-specific text, improves the modelling of text for\ndownstream tasks within the domain. Numerous real-world applications are based\non domain-specific text, e.g. working with financial or biomedical documents,\nand these applications often need to support multiple languages. However,\nlarge-scale domain-specific multilingual pretraining data for such scenarios\ncan be difficult to obtain, due to regulations, legislation, or simply a lack\nof language- and domain-specific text. One solution is to train a single\nmultilingual model, taking advantage of the data available in as many languages\nas possible. In this work, we explore the benefits of domain adaptive\npretraining with a focus on adapting to multiple languages within a specific\ndomain. We propose different techniques to compose pretraining corpora that\nenable a language model to both become domain-specific and multilingual.\nEvaluation on nine domain-specific datasets-for biomedical named entity\nrecognition and financial sentence classification-covering seven different\nlanguages show that a single multilingual domain-specific model can outperform\nthe general multilingual model, and performs close to its monolingual\ncounterpart. This finding holds across two different pretraining methods,\nadapter-based pretraining and full model pretraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_R/0/1/0/all/0/1\">Rasmus K&#xe6;r J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_M/0/1/0/all/0/1\">Mareike Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xiang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scalable Font Reconstruction with Dual Latent Manifolds. (arXiv:2109.06627v1 [cs.CV])","link":"http://arxiv.org/abs/2109.06627","description":"<p>We propose a deep generative model that performs typography analysis and font\nreconstruction by learning disentangled manifolds of both font style and\ncharacter shape. Our approach enables us to massively scale up the number of\ncharacter types we can effectively model compared to previous methods.\nSpecifically, we infer separate latent variables representing character and\nfont via a pair of inference networks which take as input sets of glyphs that\neither all share a character type, or belong to the same font. This design\nallows our model to generalize to characters that were not observed during\ntraining time, an important task in light of the relative sparsity of most\nfonts. We also put forward a new loss, adapted from prior work that measures\nlikelihood using an adaptive distribution in a projected space, resulting in\nmore natural images without requiring a discriminator. We evaluate on the task\nof font reconstruction over various datasets representing character types of\nmany languages, and compare favorably to modern style transfer systems\naccording to both automatic and manually-evaluated metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivatsan_N/0/1/0/all/0/1\">Nikita Srivatsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Si Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1\">Jonathan T. Barron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An MRC Framework for Semantic Role Labeling. (arXiv:2109.06660v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06660","description":"<p>Semantic Role Labeling (SRL) aims at recognizing the predicate-argument\nstructure of a sentence and can be decomposed into two subtasks: predicate\ndisambiguation and argument labeling. Prior work deals with these two tasks\nindependently, which ignores the semantic connection between the two tasks. In\nthis paper, we propose to use the machine reading comprehension (MRC) framework\nto bridge this gap. We formalize predicate disambiguation as multiple-choice\nmachine reading comprehension, where the descriptions of candidate senses of a\ngiven predicate are used as options to select the correct sense. The chosen\npredicate sense is then used to determine the semantic roles for that\npredicate, and these semantic roles are used to construct the query for another\nMRC model for argument labeling. In this way, we are able to leverage both the\npredicate semantics and the semantic role semantics for argument labeling. We\nalso propose to select a subset of all the possible semantic roles for\ncomputational efficiency. Experiments show that the proposed framework achieves\nstate-of-the-art results on both span and dependency benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yuxian Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jun He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expert Knowledge-Guided Length-Variant Hierarchical Label Generation for Proposal Classification. (arXiv:2109.06661v1 [cs.LG])","link":"http://arxiv.org/abs/2109.06661","description":"<p>To advance the development of science and technology, research proposals are\nsubmitted to open-court competitive programs developed by government agencies\n(e.g., NSF). Proposal classification is one of the most important tasks to\nachieve effective and fair review assignments. Proposal classification aims to\nclassify a proposal into a length-variant sequence of labels. In this paper, we\nformulate the proposal classification problem into a hierarchical multi-label\nclassification task. Although there are certain prior studies, proposal\nclassification exhibit unique features: 1) the classification result of a\nproposal is in a hierarchical discipline structure with different levels of\ngranularity; 2) proposals contain multiple types of documents; 3) domain\nexperts can empirically provide partial labels that can be leveraged to improve\ntask performances. In this paper, we focus on developing a new deep proposal\nclassification framework to jointly model the three features. In particular, to\nsequentially generate labels, we leverage previously-generated labels to\npredict the label of next level; to integrate partial labels from experts, we\nuse the embedding of these empirical partial labels to initialize the state of\nneural networks. Our model can automatically identify the best length of label\nsequence to stop next label prediction. Finally, we present extensive results\nto demonstrate that our method can jointly model partial labels, textual\ninformation, and semantic dependencies in label sequences, and, thus, achieve\nadvanced performances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1\">Meng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1\">Ziyue Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yanjie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yi Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Inference for Multilingual Neural Machine Translation. (arXiv:2109.06679v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06679","description":"<p>Multilingual NMT has become an attractive solution for MT deployment in\nproduction. But to match bilingual quality, it comes at the cost of larger and\nslower models. In this work, we consider several ways to make multilingual NMT\nfaster at inference without degrading its quality. We experiment with several\n\"light decoder\" architectures in two 20-language multi-parallel settings:\nsmall-scale on TED Talks and large-scale on ParaCrawl. Our experiments\ndemonstrate that combining a shallow decoder with vocabulary filtering leads to\nmore than twice faster inference with no loss in translation quality. We\nvalidate our findings with BLEU and chrF (on 380 language pairs), robustness\nevaluation and human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berard_A/0/1/0/all/0/1\">Alexandre Berard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dain Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clinchant_S/0/1/0/all/0/1\">St&#xe9;phane Clinchant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kweonwoo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-autoregressive Transformer with Unified Bidirectional Decoder for Automatic Speech Recognition. (arXiv:2109.06684v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06684","description":"<p>Non-autoregressive (NAR) transformer models have been studied intensively in\nautomatic speech recognition (ASR), and a substantial part of NAR transformer\nmodels is to use the casual mask to limit token dependencies. However, the\ncasual mask is designed for the left-to-right decoding process of the\nnon-parallel autoregressive (AR) transformer, which is inappropriate for the\nparallel NAR transformer since it ignores the right-to-left contexts. Some\nmodels are proposed to utilize right-to-left contexts with an extra decoder,\nbut these methods increase the model complexity. To tackle the above problems,\nwe propose a new non-autoregressive transformer with a unified bidirectional\ndecoder (NAT-UBD), which can simultaneously utilize left-to-right and\nright-to-left contexts. However, direct use of bidirectional contexts will\ncause information leakage, which means the decoder output can be affected by\nthe character information from the input of the same position. To avoid\ninformation leakage, we propose a novel attention mask and modify vanilla\nqueries, keys, and values matrices for NAT-UBD. Experimental results verify\nthat NAT-UBD can achieve character error rates (CERs) of 5.0%/5.5% on the\nAishell1 dev/test sets, outperforming all previous NAR transformer models.\nMoreover, NAT-UBD can run 49.8x faster than the AR transformer baseline when\ndecoding in a single step.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuan-Fei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tian-Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Song-Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1\">Xu-Cheng Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A system for information extraction from scientific texts in Russian. (arXiv:2109.06703v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06703","description":"<p>In this paper, we present a system for information extraction from scientific\ntexts in the Russian language. The system performs several tasks in an\nend-to-end manner: term recognition, extraction of relations between terms, and\nterm linking with entities from the knowledge base. These tasks are extremely\nimportant for information retrieval, recommendation systems, and\nclassification. The advantage of the implemented methods is that the system\ndoes not require a large amount of labeled data, which saves time and effort\nfor data labeling and therefore can be applied in low- and mid-resource\nsettings. The source code is publicly available and can be used for different\nresearch purposes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bruches_E/0/1/0/all/0/1\">Elena Bruches</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mezentseva_A/0/1/0/all/0/1\">Anastasia Mezentseva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1\">Tatiana Batura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KFCNet: Knowledge Filtering and Contrastive Learning Network for Generative Commonsense Reasoning. (arXiv:2109.06704v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06704","description":"<p>Pre-trained language models have led to substantial gains over a broad range\nof natural language processing (NLP) tasks, but have been shown to have\nlimitations for natural language generation tasks with high-quality\nrequirements on the output, such as commonsense generation and ad keyword\ngeneration. In this work, we present a novel Knowledge Filtering and\nContrastive learning Network (KFCNet) which references external knowledge and\nachieves better generation performance. Specifically, we propose a BERT-based\nfilter model to remove low-quality candidates, and apply contrastive learning\nseparately to each of the encoder and decoder, within a general\nencoder--decoder architecture. The encoder contrastive module helps to capture\nglobal target semantics during encoding, and the decoder contrastive module\nenhances the utility of retrieved prototypes while learning general features.\nExtensive experiments on the CommonGen benchmark show that our model\noutperforms the previous state of the art by a large margin: +6.6 points (42.5\nvs. 35.9) for BLEU-4, +3.7 points (33.3 vs. 29.6) for SPICE, and +1.3 points\n(18.3 vs. 17.0) for CIDEr. We further verify the effectiveness of the proposed\ncontrastive module on ad keyword generation, and show that our model has\npotential commercial value.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jian Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling. (arXiv:2109.06705v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06705","description":"<p>Table filling based relational triple extraction methods are attracting\ngrowing research interests due to their promising performance and their\nabilities on extracting triples from complex sentences. However, this kind of\nmethods are far from their full potential because most of them only focus on\nusing local features but ignore the global associations of relations and of\ntoken pairs, which increases the possibility of overlooking some important\ninformation during triple extraction. To overcome this deficiency, we propose a\nglobal feature-oriented triple extraction model that makes full use of the\nmentioned two kinds of global associations. Specifically, we first generate a\ntable feature for each relation. Then two kinds of global associations are\nmined from the generated table features. Next, the mined global associations\nare integrated into the table feature of each relation. This\n\"generate-mine-integrate\" process is performed multiple times so that the table\nfeature of each relation is refined step by step. Finally, each relation's\ntable is filled based on its refined table feature, and all triples linked to\nthis relation are extracted based on its filled table. We evaluate the proposed\nmodel on three benchmark datasets. Experimental results show our model is\neffective and it achieves state-of-the-art results on all of these datasets.\nThe source code of our work is available at: https://github.com/neukg/GRTE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1\">Feiliang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Longhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1\">Shujuan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shilei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bochao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaduo Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Answer Type Prediction using BERT: IAI at the ISWC SMART Task 2020. (arXiv:2109.06714v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06714","description":"<p>This paper summarizes our participation in the SMART Task of the ISWC 2020\nChallenge. A particular question we are interested in answering is how well\nneural methods, and specifically transformer models, such as BERT, perform on\nthe answer type prediction task compared to traditional approaches. Our main\nfinding is that coarse-grained answer types can be identified effectively with\nstandard text classification methods, with over 95% accuracy, and BERT can\nbring only marginal improvements. For fine-grained type detection, on the other\nhand, BERT clearly outperforms previous retrieval-based approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Setty_V/0/1/0/all/0/1\">Vinay Setty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balog_K/0/1/0/all/0/1\">Krisztian Balog</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Dialogue Generation with Disentangled Multi-grained Style Specification and Attribute Consistency Reward. (arXiv:2109.06717v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06717","description":"<p>Controllable text generation is an appealing but challenging task, which\nallows users to specify particular attributes of the generated outputs. In this\npaper, we propose a controllable dialogue generation model to steer response\ngeneration under multi-attribute constraints. Specifically, we define and\ncategorize the commonly used control attributes into global and local ones,\nwhich possess different granularities of effects on response generation. Then,\nwe significantly extend the conventional seq2seq framework by introducing a\nnovel two-stage decoder, which first uses a multi-grained style specification\nlayer to impose the stylistic constraints and determine word-level control\nstates of responses based on the attributes, and then employs a response\ngeneration layer to generate final responses maintaining both semantic\nrelevancy to the contexts and fidelity to the attributes. Furthermore, we train\nour model with an attribute consistency reward to promote response control with\nexplicit supervision signals. Extensive experiments and in-depth analyses on\ntwo datasets indicate that our model can significantly outperform competitive\nbaselines in terms of response quality, content diversity and controllability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhe Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhiwei Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1\">Hou Pong Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiachen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sparse Fuzzy Attention for Structural Sentiment Analysis. (arXiv:2109.06719v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06719","description":"<p>Attention scorers have achieved success in parsing tasks like semantic and\nsyntactic dependency parsing. However, in tasks modeled into parsing, like\nstructural sentiment analysis, \"dependency edges\" are very sparse which hinders\nparser performance. Thus we propose a sparse and fuzzy attention scorer with\npooling layers which improves parser performance and sets the new\nstate-of-the-art on structural sentiment analysis. We further explore the\nparsing modeling on structural sentiment analysis with second-order parsing and\nintroduce a novel sparse second-order edge building procedure that leads to\nsignificant improvement in parsing performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Letain Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequential Modelling with Applications to Music Recommendation, Fact-Checking, and Speed Reading. (arXiv:2109.06736v1 [cs.IR])","link":"http://arxiv.org/abs/2109.06736","description":"<p>Sequential modelling entails making sense of sequential data, which naturally\noccurs in a wide array of domains. One example is systems that interact with\nusers, log user actions and behaviour, and make recommendations of items of\npotential interest to users on the basis of their previous interactions. In\nsuch cases, the sequential order of user interactions is often indicative of\nwhat the user is interested in next. Similarly, for systems that automatically\ninfer the semantics of text, capturing the sequential order of words in a\nsentence is essential, as even a slight re-ordering could significantly alter\nits original meaning. This thesis makes methodological contributions and new\ninvestigations of sequential modelling for the specific application areas of\nsystems that recommend music tracks to listeners and systems that process text\nsemantics in order to automatically fact-check claims, or \"speed read\" text for\nefficient further classification. (Rest of abstract omitted due to arXiv\nabstract limit)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hansen_C/0/1/0/all/0/1\">Christian Hansen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive Information Seeking for Open-Domain Question Answering. (arXiv:2109.06747v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06747","description":"<p>Information seeking is an essential step for open-domain question answering\nto efficiently gather evidence from a large corpus. Recently, iterative\napproaches have been proven to be effective for complex questions, by\nrecursively retrieving new evidence at each step. However, almost all existing\niterative approaches use predefined strategies, either applying the same\nretrieval function multiple times or fixing the order of different retrieval\nfunctions, which cannot fulfill the diverse requirements of various questions.\nIn this paper, we propose a novel adaptive information-seeking strategy for\nopen-domain question answering, namely AISO. Specifically, the whole retrieval\nand answer process is modeled as a partially observed Markov decision process,\nwhere three types of retrieval operations (e.g., BM25, DPR, and hyperlink) and\none answer operation are defined as actions. According to the learned policy,\nAISO could adaptively select a proper retrieval action to seek the missing\nevidence at each step, based on the collected evidence and the reformulated\nquery, or directly output the answer when the evidence set is sufficient for\nthe question. Experiments on SQuAD Open and HotpotQA fullwiki, which serve as\nsingle-hop and multi-hop open-domain QA benchmarks, show that AISO outperforms\nall baseline methods with predefined strategies in terms of both retrieval and\nanswer evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yunchang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Zero-shot Cross-lingual Transfer between Closely Related Languages by injecting Character-level Noise. (arXiv:2109.06772v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06772","description":"<p>Cross-lingual transfer between a high-resource language and its dialects or\nclosely related language varieties should be facilitated by their similarity,\nbut current approaches that operate in the embedding space do not take surface\nsimilarity into account. In this work, we present a simple yet effective\nstrategy to improve cross-lingual transfer between closely related varieties by\naugmenting the data of the high-resource parent language with character-level\nnoise to make the model more robust towards spelling variations. Our strategy\nshows consistent improvements over several languages and tasks: Zero-shot\ntransfer of POS tagging and topic identification between language varieties\nfrom the Germanic, Uralic, and Romance language genera. Our work provides\nevidence for the usefulness of simple surface-level noise in improving transfer\nbetween language varieties.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aepli_N/0/1/0/all/0/1\">No&#xeb;mi Aepli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Everything Is All It Takes: A Multipronged Strategy for Zero-Shot Cross-Lingual Information Extraction. (arXiv:2109.06798v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06798","description":"<p>Zero-shot cross-lingual information extraction (IE) describes the\nconstruction of an IE model for some target language, given existing\nannotations exclusively in some other language, typically English. While the\nadvance of pretrained multilingual encoders suggests an easy optimism of \"train\non English, run on any language\", we find through a thorough exploration and\nextension of techniques that a combination of approaches, both new and old,\nleads to better performance than any one cross-lingual strategy in particular.\nWe explore techniques including data projection and self-training, and how\ndifferent pretrained encoders impact them. We use English-to-Arabic IE as our\ninitial example, demonstrating strong performance in this setting for event\nextraction, named entity recognition, part-of-speech tagging, and dependency\nparsing. We then apply data projection and self-training to three tasks across\neight target languages. Because no single set of techniques performs the best\nacross all tasks, we encourage practitioners to explore various configurations\nof the techniques described in this work when seeking to improve on zero-shot\ntraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yarmohammadi_M/0/1/0/all/0/1\">Mahsa Yarmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shijie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marone_M/0/1/0/all/0/1\">Marc Marone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebner_S/0/1/0/all/0/1\">Seth Ebner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_G/0/1/0/all/0/1\">Guanghui Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jialiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harman_C/0/1/0/all/0/1\">Craig Harman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1\">Kenton Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Aaron Steven White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dredze_M/0/1/0/all/0/1\">Mark Dredze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Temporal Variational Model for Story Generation. (arXiv:2109.06807v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06807","description":"<p>Recent language models can generate interesting and grammatically correct\ntext in story generation but often lack plot development and long-term\ncoherence. This paper experiments with a latent vector planning approach based\non a TD-VAE (Temporal Difference Variational Autoencoder), using the model for\nconditioning and reranking for text generation. The results demonstrate strong\nperformance in automatic cloze and swapping evaluations. The human judgments\nshow stories generated with TD-VAE reranking improve on a GPT-2 medium baseline\nand show comparable performance to a hierarchical LSTM reranking model.\nConditioning on the latent vectors proves disappointing and deteriorates\nperformance in human evaluation because it reduces the diversity of generation,\nand the models don't learn to progress the narrative. This highlights an\nimportant difference between technical task performance (e.g. cloze) and\ngenerating interesting stories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_D/0/1/0/all/0/1\">David Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1\">Frank Keller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What are the attackers doing now? Automating cyber threat intelligence extraction from text on pace with the changing threat landscape: A survey. (arXiv:2109.06808v1 [cs.CR])","link":"http://arxiv.org/abs/2109.06808","description":"<p>Cybersecurity researchers have contributed to the automated extraction of CTI\nfrom textual sources, such as threat reports and online articles, where\ncyberattack strategies, procedures, and tools are described. The goal of this\narticle is to aid cybersecurity researchers understand the current techniques\nused for cyberthreat intelligence extraction from text through a survey of\nrelevant studies in the literature. We systematically collect \"CTI extraction\nfrom text\"-related studies from the literature and categorize the CTI\nextraction purposes. We propose a CTI extraction pipeline abstracted from these\nstudies. We identify the data sources, techniques, and CTI sharing formats\nutilized in the context of the proposed pipeline. Our work finds ten types of\nextraction purposes, such as extraction indicators of compromise extraction,\nTTPs (tactics, techniques, procedures of attack), and cybersecurity keywords.\nWe also identify seven types of textual sources for CTI extraction, and textual\ndata obtained from hacker forums, threat reports, social media posts, and\nonline news articles have been used by almost 90% of the studies. Natural\nlanguage processing along with both supervised and unsupervised machine\nlearning techniques such as named entity recognition, topic modelling,\ndependency parsing, supervised classification, and clustering are used for CTI\nextraction. We observe the technical challenges associated with these studies\nrelated to obtaining available clean, labelled data which could assure\nreplication, validation, and further extension of the studies. As we find the\nstudies focusing on CTI information extraction from text, we advocate for\nbuilding upon the current CTI extraction work to help cybersecurity\npractitioners with proactive decision making such as threat prioritization,\nautomated threat modelling to utilize knowledge from past cybersecurity\nincidents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Rayhanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdavi_Hezaveh_R/0/1/0/all/0/1\">Rezvan Mahdavi-Hezaveh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1\">Laurie Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LM-Critic: Language Models for Unsupervised Grammatical Error Correction. (arXiv:2109.06822v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06822","description":"<p>Training a model for grammatical error correction (GEC) requires a set of\nlabeled ungrammatical / grammatical sentence pairs, but manually annotating\nsuch pairs can be expensive. Recently, the Break-It-Fix-It (BIFI) framework has\ndemonstrated strong results on learning to repair a broken program without any\nlabeled examples, but this relies on a perfect critic (e.g., a compiler) that\nreturns whether an example is valid or not, which does not exist for the GEC\ntask. In this work, we show how to leverage a pretrained language model (LM) in\ndefining an LM-Critic, which judges a sentence to be grammatical if the LM\nassigns it a higher probability than its local perturbations. We apply this\nLM-Critic and BIFI along with a large set of unlabeled sentences to bootstrap\nrealistic ungrammatical / grammatical pairs for training a corrector. We\nevaluate our approach on GEC datasets across multiple domains (CoNLL-2014,\nBEA-2019, GMEG-wiki and GMEG-yahoo) and show that it outperforms existing\nmethods in both the unsupervised setting (+7.7 F0.5) and the supervised setting\n(+0.5 F0.5).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Types of Out-of-Distribution Texts and How to Detect Them. (arXiv:2109.06827v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06827","description":"<p>Despite agreement on the importance of detecting out-of-distribution (OOD)\nexamples, there is little consensus on the formal definition of OOD examples\nand how to best detect them. We categorize these examples by whether they\nexhibit a background shift or a semantic shift, and find that the two major\napproaches to OOD detection, model calibration and density estimation (language\nmodeling for text), have distinct behavior on these types of OOD data. Across\n14 pairs of in-distribution and OOD English natural language understanding\ndatasets, we find that density estimation methods consistently beat calibration\nmethods in background shift settings, while performing worse in semantic shift\nsettings. In addition, we find that both methods generally fail to detect\nexamples from challenge data, highlighting a weak spot for current methods.\nSince no single method works well across all settings, our results call for an\nexplicit definition of OOD examples when evaluating different detection\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_U/0/1/0/all/0/1\">Udit Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">William Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Perils of Using Mechanical Turk to Evaluate Open-Ended Text Generation. (arXiv:2109.06835v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06835","description":"<p>Recent text generation research has increasingly focused on open-ended\ndomains such as story and poetry generation. Because models built for such\ntasks are difficult to evaluate automatically, most researchers in the space\njustify their modeling choices by collecting crowdsourced human judgments of\ntext quality (e.g., Likert scores of coherence or grammaticality) from Amazon\nMechanical Turk (AMT). In this paper, we first conduct a survey of 45\nopen-ended text generation papers and find that the vast majority of them fail\nto report crucial details about their AMT tasks, hindering reproducibility. We\nthen run a series of story evaluation experiments with both AMT workers and\nEnglish teachers and discover that even with strict qualification filters, AMT\nworkers (unlike teachers) fail to distinguish between model-generated text and\nhuman-generated references. We show that AMT worker judgments improve when they\nare shown model-generated output alongside human-generated references, which\nenables the workers to better calibrate their ratings. Finally, interviews with\nthe English teachers provide deeper insights into the challenges of the\nevaluation process, particularly when rating model-generated text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Karpinska_M/0/1/0/all/0/1\">Marzena Karpinska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akoury_N/0/1/0/all/0/1\">Nader Akoury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language Understanding. (arXiv:2109.06838v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06838","description":"<p>While large language models have shown exciting progress on several NLP\nbenchmarks, evaluating their ability for complex analogical reasoning remains\nunder-explored. Here, we introduce a high-quality crowdsourced dataset of\nnarratives for employing proverbs in context as a benchmark for abstract\nlanguage understanding. The dataset provides fine-grained annotation of aligned\nspans between proverbs and narratives, and contains minimal lexical overlaps\nbetween narratives and proverbs, ensuring that models need to go beyond\nsurface-level reasoning to succeed. We explore three tasks: (1) proverb\nrecommendation and alignment prediction, (2) narrative generation for a given\nproverb and topic, and (3) identifying narratives with similar motifs. Our\nexperiments show that neural language models struggle in our tasks compared to\nhumans, and the tasks pose multiple learning challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sayan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BenchIE: Open Information Extraction Evaluation Based on Facts, Not Tokens. (arXiv:2109.06850v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06850","description":"<p>Intrinsic evaluations of OIE systems are carried out either manually -- with\nhuman evaluators judging the correctness of extractions -- or automatically, on\nstandardized benchmarks. The latter, while much more cost-effective, is less\nreliable, primarily because of the incompleteness of the existing OIE\nbenchmarks: the ground truth extractions do not include all acceptable variants\nof the same fact, leading to unreliable assessment of models' performance.\nMoreover, the existing OIE benchmarks are available for English only. In this\nwork, we introduce BenchIE: a benchmark and evaluation framework for\ncomprehensive evaluation of OIE systems for English, Chinese and German. In\ncontrast to existing OIE benchmarks, BenchIE takes into account informational\nequivalence of extractions: our gold standard consists of fact synsets,\nclusters in which we exhaustively list all surface forms of the same fact. We\nbenchmark several state-of-the-art OIE systems using BenchIE and demonstrate\nthat these systems are significantly less effective than indicated by existing\nOIE benchmarks. We make BenchIE (data and evaluation code) publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gashteovski_K/0/1/0/all/0/1\">Kiril Gashteovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mingying Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotnis_B/0/1/0/all/0/1\">Bhushan Kotnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1\">Carolin Lawrence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1\">Goran Glavas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1\">Mathias Niepert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summarize-then-Answer: Generating Concise Explanations for Multi-hop Reading Comprehension. (arXiv:2109.06853v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06853","description":"<p>How can we generate concise explanations for multi-hop Reading Comprehension\n(RC)? The current strategies of identifying supporting sentences can be seen as\nan extractive question-focused summarization of the input text. However, these\nextractive explanations are not necessarily concise i.e. not minimally\nsufficient for answering a question. Instead, we advocate for an abstractive\napproach, where we propose to generate a question-focused, abstractive summary\nof input paragraphs and then feed it to an RC system. Given a limited amount of\nhuman-annotated abstractive explanations, we train the abstractive explainer in\na semi-supervised manner, where we start from the supervised model and then\ntrain it further through trial and error maximizing a conciseness-promoted\nreward function. Our experiments demonstrate that the proposed abstractive\nexplainer can generate more compact explanations than an extractive explainer\nwith limited supervision (only 2k instances) while maintaining sufficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_N/0/1/0/all/0/1\">Naoya Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1\">Harsh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Steven Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning. (arXiv:2109.06860v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06860","description":"<p>Commonsense is defined as the knowledge that is shared by everyone. However,\ncertain types of commonsense knowledge are correlated with culture and\ngeographic locations and they are only shared locally. For example, the\nscenarios of wedding ceremonies vary across regions due to different customs\ninfluenced by historical and religious factors. Such regional characteristics,\nhowever, are generally omitted in prior work. In this paper, we construct a\nGeo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test\nvision-and-language models' ability to understand cultural and\ngeo-location-specific commonsense. In particular, we study two state-of-the-art\nVision-and-Language models, VisualBERT and ViLBERT trained on VCR, a standard\nmultimodal commonsense benchmark with images primarily from Western regions. We\nthen evaluate how well the trained models can generalize to answering the\nquestions in GD-VCR. We find that the performance of both models for\nnon-Western regions including East Asia, South Asia, and Africa is\nsignificantly lower than that for Western region. We analyze the reasons behind\nthe performance disparity and find that the performance gap is larger on QA\npairs that: 1) are concerned with culture-related scenarios, e.g., weddings,\nreligious activities, and festivals; 2) require high-level geo-diverse\ncommonsense reasoning rather than low-order perception and recognition. Dataset\nand code are released at https://github.com/WadeYin9712/GD-VCR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liunian Harold Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Ziniu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Legal Transformer Models May Not Always Help. (arXiv:2109.06862v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06862","description":"<p>Deep learning-based Natural Language Processing methods, especially\ntransformers, have achieved impressive performance in the last few years.\nApplying those state-of-the-art NLP methods to legal activities to automate or\nsimplify some simple work is of great value. This work investigates the value\nof domain adaptive pre-training and language adapters in legal NLP tasks. By\ncomparing the performance of language models with domain adaptive pre-training\non different tasks and different dataset splits, we show that domain adaptive\npre-training is only helpful with low-resource downstream tasks, thus far from\nbeing a panacea. We also benchmark the performance of adapters in a typical\nlegal NLP task and show that they can yield similar performance to full model\ntuning with much smaller training costs. As an additional result, we release\nLegalRoBERTa, a RoBERTa model further pre-trained on legal corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Sakbo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebret_R/0/1/0/all/0/1\">R&#xe9;mi Lebret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberer_K/0/1/0/all/0/1\">Karl Aberer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition. (arXiv:2109.06870v1 [cs.CL])","link":"http://arxiv.org/abs/2109.06870","description":"<p>This paper is a study of performance-efficiency trade-offs in pre-trained\nmodels for automatic speech recognition (ASR). We focus on wav2vec 2.0, and\nformalize several architecture designs that influence both the model\nperformance and its efficiency. Putting together all our observations, we\nintroduce SEW (Squeezed and Efficient Wav2vec), a pre-trained model\narchitecture with significant improvements along both performance and\nefficiency dimensions across a variety of training setups. For example, under\nthe 100h-960h semi-supervised setup on LibriSpeech, SEW achieves a 1.9x\ninference speedup compared to wav2vec 2.0, with a 13.5% relative reduction in\nword error rate. With a similar inference time, SEW reduces word error rate by\n25-50% across different model sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Felix Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kwangyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Hyper-Parameter Optimization for Neural Machine Translation on GPU Architectures. (arXiv:1805.02094v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1805.02094","description":"<p>Neural machine translation (NMT) has been accelerated by deep learning neural\nnetworks over statistical-based approaches, due to the plethora and\nprogrammability of commodity heterogeneous computing architectures such as\nFPGAs and GPUs and the massive amount of training corpuses generated from news\noutlets, government agencies and social media. Training a learning classifier\nfor neural networks entails tuning hyper-parameters that would yield the best\nperformance. Unfortunately, the number of parameters for machine translation\ninclude discrete categories as well as continuous options, which makes for a\ncombinatorial explosive problem. This research explores optimizing\nhyper-parameters when training deep learning neural networks for machine\ntranslation. Specifically, our work investigates training a language model with\nMarian NMT. Results compare NMT under various hyper-parameter settings across a\nvariety of modern GPU architecture generations in single node and multi-node\nsettings, revealing insights on which hyper-parameters matter most in terms of\nperformance, such as words processed per second, convergence rates, and\ntranslation accuracy, and provides insights on how to best achieve\nhigh-performing NMT systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lim_R/0/1/0/all/0/1\">Robert Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heafield_K/0/1/0/all/0/1\">Kenneth Heafield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_H/0/1/0/all/0/1\">Hieu Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briers_M/0/1/0/all/0/1\">Mark Briers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malony_A/0/1/0/all/0/1\">Allen Malony</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fighting the COVID-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society. (arXiv:2005.00033v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2005.00033","description":"<p>With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic has been\ndeclared one of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Ad-dressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nTo address this gap, we release a large dataset of 16K manually annotated\ntweets for fine-grained disinformation analysis that (i) focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society, and (iii) covers Arabic,\nBulgarian, Dutch, and English. Finally, we show strong evaluation results using\npretrained Transformers, thus con-firming the practical utility of the dataset\nin monolingual vs. multilingual, and single task vs. multitask settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1\">Shaden Shaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1\">Alex Nikolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mubarak_H/0/1/0/all/0/1\">Hamdy Mubarak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_G/0/1/0/all/0/1\">Giovanni Da San Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelali_A/0/1/0/all/0/1\">Ahmed Abdelali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darwish_K/0/1/0/all/0/1\">Kareem Darwish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Homaid_A/0/1/0/all/0/1\">Abdulaziz Al-Homaid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaghouani_W/0/1/0/all/0/1\">Wajdi Zaghouani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caselli_T/0/1/0/all/0/1\">Tommaso Caselli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danoe_G/0/1/0/all/0/1\">Gijs Danoe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stolk_F/0/1/0/all/0/1\">Friso Stolk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruntink_B/0/1/0/all/0/1\">Britt Bruntink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L2R2: Leveraging Ranking for Abductive Reasoning. (arXiv:2005.11223v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2005.11223","description":"<p>The abductive natural language inference task ($\\alpha$NLI) is proposed to\nevaluate the abductive reasoning ability of a learning system. In the\n$\\alpha$NLI task, two observations are given and the most plausible hypothesis\nis asked to pick out from the candidates. Existing methods simply formulate it\nas a classification problem, thus a cross-entropy log-loss objective is used\nduring training. However, discriminating true from false does not measure the\nplausibility of a hypothesis, for all the hypotheses have a chance to happen,\nonly the probabilities are different. To fill this gap, we switch to a ranking\nperspective that sorts the hypotheses in order of their plausibilities. With\nthis new perspective, a novel $L2R^2$ approach is proposed under the\nlearning-to-rank framework. Firstly, training samples are reorganized into a\nranking form, where two observations and their hypotheses are treated as the\nquery and a set of candidate documents respectively. Then, an ESIM model or\npre-trained language model, e.g. BERT or RoBERTa, is obtained as the scoring\nfunction. Finally, the loss functions for the ranking task can be either\npair-wise or list-wise for training. The experimental results on the ART\ndataset reach the state-of-the-art in the public leaderboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yunchang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document Graph for Neural Machine Translation. (arXiv:2012.03477v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.03477","description":"<p>Previous works have shown that contextual information can improve the\nperformance of neural machine translation (NMT). However, most existing\ndocument-level NMT methods only consider a few number of previous sentences.\nHow to make use of the whole document as global contexts is still a challenge.\nTo address this issue, we hypothesize that a document can be represented as a\ngraph that connects relevant contexts regardless of their distances. We employ\nseveral types of relations, including adjacency, syntactic dependency, lexical\nconsistency, and coreference, to construct the document graph. Then, we\nincorporate both source and target graphs into the conventional Transformer\narchitecture with graph convolutional networks. Experiments on various NMT\nbenchmarks, including IWSLT English--French, Chinese-English, WMT\nEnglish--German and Opensubtitle English--Russian, demonstrate that using\ndocument graphs can significantly improve the translation quality. Extensive\nanalysis verifies that the document graph is beneficial for capturing discourse\nphenomena.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingzhou Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek. F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_L/0/1/0/all/0/1\">Lidia S. Chao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantum Mathematics in Artificial Intelligence. (arXiv:2101.04255v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2101.04255","description":"<p>In the decade since 2010, successes in artificial intelligence have been at\nthe forefront of computer science and technology, and vector space models have\nsolidified a position at the forefront of artificial intelligence. At the same\ntime, quantum computers have become much more powerful, and announcements of\nmajor advances are frequently in the news.\n</p>\n<p>The mathematical techniques underlying both these areas have more in common\nthan is sometimes realized. Vector spaces took a position at the axiomatic\nheart of quantum mechanics in the 1930s, and this adoption was a key motivation\nfor the derivation of logic and probability from the linear geometry of vector\nspaces. Quantum interactions between particles are modelled using the tensor\nproduct, which is also used to express objects and operations in artificial\nneural networks.\n</p>\n<p>This paper describes some of these common mathematical areas, including\nexamples of how they are used in artificial intelligence (AI), particularly in\nautomated reasoning and natural language processing (NLP). Techniques discussed\ninclude vector spaces, scalar products, subspaces and implication, orthogonal\nprojection and negation, dual vectors, density matrices, positive operators,\nand tensor products. Application areas include information retrieval,\ncategorization and implication, modelling word-senses and disambiguation,\ninference in knowledge bases, and semantic composition.\n</p>\n<p>Some of these approaches can potentially be implemented on quantum hardware.\nMany of the practical steps in this implementation are in early stages, and\nsome are already realized. Explaining some of the common mathematical tools can\nhelp researchers in both AI and quantum computing further exploit these\noverlaps, recognizing and exploring new directions along the way.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Widdows_D/0/1/0/all/0/1\">Dominic Widdows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitto_K/0/1/0/all/0/1\">Kirsty Kitto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Trevor Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining and Speech Translation. (arXiv:2102.05766v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.05766","description":"<p>Recently, representation learning for text and speech has successfully\nimproved many language related tasks. However, all existing methods suffer from\ntwo limitations: (a) they only learn from one input modality, while a unified\nrepresentation for both speech and text is needed by tasks such as end-to-end\nspeech translation, and as a result,(b) they can not exploit various\nlarge-scale text and speech data and their performance is limited by the\nscarcity of parallel speech translation data.To address these problems, we\npropose a Fused Acoustic and Text Masked Language Model (FAT-MLM) which jointly\nlearns a unified representation for both acoustic and text input from various\ntypes of corpora including parallel data for speech recognition and machine\ntranslation, and even pure speech and text data. Within this cross-modal\nrepresentation learning framework, we further present an end-to-end model for\nFused Acoustic and Text Speech Translation (FAT-ST). Experiments on three\ntranslation directions show that by fine-tuning from FAT-MLM, our proposed\nspeech translation models substantially improve translation quality by up to\n+5.9 BLEU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Renjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Liang Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Explanations for Model Interpretability. (arXiv:2103.01378v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.01378","description":"<p>Contrastive explanations clarify why an event occurred in contrast to\nanother. They are more inherently intuitive to humans to both produce and\ncomprehend. We propose a methodology to produce contrastive explanations for\nclassification models by modifying the representation to disregard\nnon-contrastive information, and modifying model behavior to only be based on\ncontrastive reasoning. Our method is based on projecting model representation\nto a latent space that captures only the features that are useful (to the\nmodel) to differentiate two potential decisions. We demonstrate the value of\ncontrastive explanations by analyzing two different scenarios, using both\nhigh-level abstract concept attribution and low-level input token/span\nattribution, on two widely used text classification tasks. Specifically, we\nproduce explanations for answering: for which label, and against which\nalternative label, is some aspect of the input useful? And which aspects of the\ninput are useful for and against particular decisions? Overall, our findings\nshed light on the ability of label-contrastive explanations to provide a more\naccurate and finer-grained interpretability of a model's decision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacovi_A/0/1/0/all/0/1\">Alon Jacovi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elazar_Y/0/1/0/all/0/1\">Yanai Elazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving and Simplifying Pattern Exploiting Training. (arXiv:2103.11955v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.11955","description":"<p>Recently, pre-trained language models (LMs) have achieved strong performance\nwhen fine-tuned on difficult benchmarks like SuperGLUE. However, performance\ncan suffer when there are very few labeled examples available for fine-tuning.\nPattern Exploiting Training (PET) is a recent approach that leverages patterns\nfor few-shot learning. However, PET uses task-specific unlabeled data. In this\npaper, we focus on few-shot learning without any unlabeled data and introduce\nADAPET, which modifies PET's objective to provide denser supervision during\nfine-tuning. As a result, ADAPET outperforms PET on SuperGLUE without any\ntask-specific unlabeled data. Our code can be found at\nhttps://github.com/rrmenon10/ADAPET.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tam_D/0/1/0/all/0/1\">Derek Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1\">Rakesh R Menon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging pre-trained representations to improve access to untranscribed speech from endangered languages. (arXiv:2103.14583v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.14583","description":"<p>Pre-trained speech representations like wav2vec 2.0 are a powerful tool for\nautomatic speech recognition (ASR). Yet many endangered languages lack\nsufficient data for pre-training such models, or are predominantly oral\nvernaculars without a standardised writing system, precluding fine-tuning.\nQuery-by-example spoken term detection (QbE-STD) offers an alternative for\niteratively indexing untranscribed speech corpora by locating spoken query\nterms. Using data from 7 Australian Aboriginal languages and a regional variety\nof Dutch, all of which are endangered or vulnerable, we show that QbE-STD can\nbe improved by leveraging representations developed for ASR (wav2vec 2.0: the\nEnglish monolingual model and XLSR53 multilingual model). Surprisingly, the\nEnglish model outperformed the multilingual model on 4 Australian language\ndatasets, raising questions around how to optimally leverage self-supervised\nspeech representations for QbE-STD. Nevertheless, we find that wav2vec 2.0\nrepresentations (either English or XLSR53) offer large improvements (56-86%\nrelative) over state-of-the-art approaches on our endangered language datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+San_N/0/1/0/all/0/1\">Nay San</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelds_M/0/1/0/all/0/1\">Martijn Bartelds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Browne_M/0/1/0/all/0/1\">Mitchell Browne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifford_L/0/1/0/all/0/1\">Lily Clifford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibson_F/0/1/0/all/0/1\">Fiona Gibson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansfield_J/0/1/0/all/0/1\">John Mansfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nash_D/0/1/0/all/0/1\">David Nash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simpson_J/0/1/0/all/0/1\">Jane Simpson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turpin_M/0/1/0/all/0/1\">Myfany Turpin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vollmer_M/0/1/0/all/0/1\">Maria Vollmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilmoth_S/0/1/0/all/0/1\">Sasha Wilmoth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Connecting Attributions and QA Model Behavior on Realistic Counterfactuals. (arXiv:2104.04515v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.04515","description":"<p>When a model attribution technique highlights a particular part of the input,\na user might understand this highlight as making a statement about\ncounterfactuals (Miller, 2019): if that part of the input were to change, the\nmodel's prediction might change as well. This paper investigates how well\ndifferent attribution techniques align with this assumption on realistic\ncounterfactuals in the case of reading comprehension (RC). RC is a particularly\nchallenging test case, as token-level attributions that have been extensively\nstudied in other NLP tasks such as sentiment analysis are less suitable to\nrepresent the reasoning that RC models perform. We construct counterfactual\nsets for three different RC settings, and through heuristics that can connect\nattribution methods' outputs to high-level model behavior, we can evaluate how\nuseful different attribution methods and even different formats are for\nunderstanding counterfactuals. We find that pairwise attributions are better\nsuited to RC than token-level attributions across these different RC settings,\nwith our best performance coming from a modification that we propose to an\nexisting pairwise attribution method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xi Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_R/0/1/0/all/0/1\">Rohan Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Zero-Shot Multifaceted Visually Grounded Word Embeddings via Multi-Task Training. (arXiv:2104.07500v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07500","description":"<p>Language grounding aims at linking the symbolic representation of language\n(e.g., words) into the rich perceptual knowledge of the outside world. The\ngeneral approach is to embed both textual and visual information into a common\nspace -the grounded space-confined by an explicit relationship between both\nmodalities. We argue that this approach sacrifices the abstract knowledge\nobtained from linguistic co-occurrence statistics in the process of acquiring\nperceptual information. The focus of this paper is to solve this issue by\nimplicitly grounding the word embeddings. Rather than learning two mappings\ninto a joint space, our approach integrates modalities by determining a\nreversible grounded mapping between the textual and the grounded space by means\nof multi-task learning. Evaluations on intrinsic and extrinsic tasks show that\nour embeddings are highly beneficial for both abstract and concrete words. They\nare strongly correlated with human judgments and outperform previous works on a\nwide range of benchmarks. Our grounded embeddings are publicly available here.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahmohammadi_H/0/1/0/all/0/1\">Hassan Shahmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lensch_H/0/1/0/all/0/1\">Hendrik P. A. Lensch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1\">R. Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path Grounding. (arXiv:2104.08455v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08455","description":"<p>Dialogue systems powered by large pre-trained language models (LM) exhibit an\ninnate ability to deliver fluent and natural-looking responses. Despite their\nimpressive generation performance, these models can often generate factually\nincorrect statements impeding their widespread adoption. In this paper, we\nfocus on the task of improving the faithfulness -- and thus reduce\nhallucination -- of Neural Dialogue Systems to known facts supplied by a\nKnowledge Graph (KG). We propose Neural Path Hunter which follows a\ngenerate-then-refine strategy whereby a generated response is amended using the\nk-hop subgraph of a KG. Neural Path Hunter leverages a separate token-level\nfact critic to identify plausible sources of hallucination followed by a\nrefinement stage consisting of a chain of two neural LM's that retrieves\ncorrect entities by crafting a query signal that is propagated over the k-hop\nsubgraph. Our proposed model can easily be applied to any dialogue generated\nresponses without retraining the model. We empirically validate our proposed\napproach on the OpenDialKG dataset against a suite of metrics and report a\nrelative improvement of faithfulness over dialogue responses by 20.35% based on\nFeQA (Durmus et al., 2020).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dziri_N/0/1/0/all/0/1\">Nouha Dziri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaiane_O/0/1/0/all/0/1\">Osmar Zaiane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1\">Avishek Joey Bose</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Attention is All You Need: Adapting Pretrained Transformers for Machine Translation. (arXiv:2104.08771v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08771","description":"<p>We study the power of cross-attention in the Transformer architecture within\nthe context of transfer learning for machine translation, and extend the\nfindings of studies into cross-attention when training from scratch. We conduct\na series of experiments through fine-tuning a translation model on data where\neither the source or target language has changed. These experiments reveal that\nfine-tuning only the cross-attention parameters is nearly as effective as\nfine-tuning all parameters (i.e., the entire translation model). We provide\ninsights into why this is the case and observe that limiting fine-tuning in\nthis manner yields cross-lingually aligned embeddings. The implications of this\nfinding for researchers and practitioners include a mitigation of catastrophic\nforgetting, the potential for zero-shot translation, and the ability to extend\nmachine translation models to several new language pairs with reduced parameter\nstorage overhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gheini_M/0/1/0/all/0/1\">Mozhdeh Gheini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Low-Dimensional Linear Geometry of Contextualized Word Representations. (arXiv:2105.07109v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.07109","description":"<p>Black-box probing models can reliably extract linguistic features like tense,\nnumber, and syntactic role from pretrained word representations. However, the\nmanner in which these features are encoded in representations remains poorly\nunderstood. We present a systematic study of the linear geometry of\ncontextualized word representations in ELMO and BERT. We show that a variety of\nlinguistic features (including structured dependency relationships) are encoded\nin low-dimensional subspaces. We then refine this geometric picture, showing\nthat there are hierarchical relations between the subspaces encoding general\nlinguistic categories and more specific ones, and that low-dimensional feature\nencodings are distributed rather than aligned to individual neurons. Finally,\nwe demonstrate that these linear subspaces are causally related to model\nbehavior, and can be used to perform fine-grained manipulation of BERT's output\ndistribution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_E/0/1/0/all/0/1\">Evan Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coreference-Aware Dialogue Summarization. (arXiv:2106.08556v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.08556","description":"<p>Summarizing conversations via neural approaches has been gaining research\ntraction lately, yet it is still challenging to obtain practical solutions.\nExamples of such challenges include unstructured information exchange in\ndialogues, informal interactions between speakers, and dynamic role changes of\nspeakers as the dialogue evolves. Many of such challenges result in complex\ncoreference links. Therefore, in this work, we investigate different approaches\nto explicitly incorporate coreference information in neural abstractive\ndialogue summarization models to tackle the aforementioned challenges.\nExperimental results show that the proposed approaches achieve state-of-the-art\nperformance, implying it is useful to utilize coreference information in\ndialogue summarization. Evaluation results on factual correctness suggest such\ncoreference-aware models are better at tracing the information flow among\ninterlocutors and associating accurate status/actions with the corresponding\ninterlocutors and person mentions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Ke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Natural Language Understanding Pipeline for Bangla Conversational Agents. (arXiv:2107.05541v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.05541","description":"<p>Chatbots are intelligent software built to be used as a replacement for human\ninteraction. However, existing studies typically do not provide enough support\nfor low-resource languages like Bangla. Moreover, due to the increasing\npopularity of social media, we can also see the rise of interactions in Bangla\ntransliteration (mostly in English) among the native Bangla speakers. In this\npaper, we propose a novel approach to build a Bangla chatbot aimed to be used\nas a business assistant which can communicate in Bangla and Bangla\nTransliteration in English with high confidence consistently. Since annotated\ndata was not available for this purpose, we had to work on the whole machine\nlearning life cycle (data preparation, machine learning modeling, and model\ndeployment) using Rasa Open Source Framework, fastText embeddings, Polyglot\nembeddings, Flask, and other systems as building blocks. While working with the\nskewed annotated dataset, we try out different setups and pipelines to evaluate\nwhich works best and provide possible reasoning behind the observed results.\nFinally, we present a pipeline for intent classification and entity extraction\nwhich achieves reasonable performance (accuracy: 83.02%, precision: 80.82%,\nrecall: 83.02%, F1-score: 80%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1\">Fahim Shahriar Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mushabbir_M/0/1/0/all/0/1\">Mueeze Al Mushabbir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irbaz_M/0/1/0/all/0/1\">Mohammad Sabik Irbaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasim_M/0/1/0/all/0/1\">MD Abdullah Al Nasim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation. (arXiv:2107.10821v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.10821","description":"<p>Automatic metrics are commonly used as the exclusive tool for declaring the\nsuperiority of one machine translation system's quality over another. The\ncommunity choice of automatic metric guides research directions and industrial\ndevelopments by deciding which models are deemed better. Evaluating metrics\ncorrelations with sets of human judgements has been limited by the size of\nthese sets. In this paper, we corroborate how reliable metrics are in contrast\nto human judgements on -- to the best of our knowledge -- the largest\ncollection of judgements reported in the literature. Arguably, pairwise\nrankings of two systems are the most common evaluation tasks in research or\ndeployment scenarios. Taking human judgement as a gold standard, we investigate\nwhich metrics have the highest accuracy in predicting translation quality\nrankings for such system pairs. Furthermore, we evaluate the performance of\nvarious metrics across different language pairs and domains. Lastly, we show\nthat the sole use of BLEU impeded the development of improved models leading to\nbad deployment decisions. We release the collection of 2.3M sentence-level\nhuman judgements for 4380 systems for further analysis and replication of our\nwork.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocmi_T/0/1/0/all/0/1\">Tom Kocmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Federmann_C/0/1/0/all/0/1\">Christian Federmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grundkiewicz_R/0/1/0/all/0/1\">Roman Grundkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junczys_Dowmunt_M/0/1/0/all/0/1\">Marcin Junczys-Dowmunt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsushita_H/0/1/0/all/0/1\">Hitokazu Matsushita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menezes_A/0/1/0/all/0/1\">Arul Menezes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UNIQORN: Unified Question Answering over RDF Knowledge Graphs and Natural Language Text. (arXiv:2108.08614v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2108.08614","description":"<p>Question answering over knowledge graphs and other RDF data has been greatly\nadvanced, with a number of good systems providing crisp answers for natural\nlanguage questions or telegraphic queries. Some of these systems incorporate\ntextual sources as additional evidence for the answering process, but cannot\ncompute answers that are present in text alone. Conversely, systems from the IR\nand NLP communities have addressed QA over text, but barely utilize semantic\ndata and knowledge. This paper presents the first QA system that can seamlessly\noperate over RDF datasets and text corpora, or both together, in a unified\nframework. Our method, called UNIQORN, builds a context graph on the fly, by\nretrieving question-relevant triples from the RDF data and/or the text corpus,\nwhere the latter case is handled by automatic information extraction. The\nresulting graph is typically rich but highly noisy. UNIQORN copes with this\ninput by advanced graph algorithms for Group Steiner Trees, that identify the\nbest answer candidates in the context graph. Experimental results on several\nbenchmarks of complex questions with multiple entities and relations, show that\nUNIQORN, an unsupervised method with only five parameters, produces results\ncomparable to the state-of-the-art on KGs, text corpora, and heterogeneous\nsources. The graph-based methodology provides user-interpretable evidence for\nthe complete answering process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pramanik_S/0/1/0/all/0/1\">Soumajit Pramanik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1\">Gerhard Weikum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DEGREE: A Data-Efficient Generative Event Extraction Model. (arXiv:2108.12724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12724","description":"<p>Event extraction (EE) aims to identify structured events, including event\ntriggers and their corresponding arguments, from unstructured text. Most of the\nexisting works rely on a large number of labeled instances to train models,\nwhile the labeled data could be expensive to be obtained. In this work, we\npresent a data-efficient event extraction method by formulating event\nextraction as a natural language generation problem. The formulation allows us\nto inject knowledge of label semantics, event structure, and output\ndependencies into the model. Given a passage and an event type, our model\nlearns to summarize this passage into a templated sentence in a predefined\nstructure. The template is event-type-specific, manually created, and contains\nevent trigger and argument information. Lastly, a rule-based algorithm is used\nto derive the trigger and argument predictions from the generated sentence. Our\nmethod inherently enjoys the following benefits: (1) The pretraining of the\ngenerative language models help incorporate the semantics of the labels for\ngenerative EE. (2) The autoregressive generation process and our end-to-end\ndesign for extracting triggers and arguments force the model to capture the\ndependencies among the output triggers and their arguments. (3) The predefined\ntemplates form concrete yet flexible rules to hint the models about the valid\npatterns for each event type, reducing the models' burden to learn structures\nfrom the data. Empirical results show that our model achieves superior\nperformance over strong baselines on EE tasks in the low data regime and\nachieves competitive results to the current state-of-the-art when more data\nbecomes available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_I/0/1/0/all/0/1\">I-Hung Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boschee_E/0/1/0/all/0/1\">Elizabeth Boschee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miller_S/0/1/0/all/0/1\">Scott Miller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Prem Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Retrieval Augmented Generation for Zero-shot Slot Filling. (arXiv:2108.13934v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13934","description":"<p>Automatically inducing high quality knowledge graphs from a given collection\nof documents still remains a challenging problem in AI. One way to make headway\nfor this problem is through advancements in a related task known as slot\nfilling. In this task, given an entity query in form of [Entity, Slot, ?], a\nsystem is asked to fill the slot by generating or extracting the missing value\nexploiting evidence extracted from relevant passage(s) in the given document\ncollection. The recent works in the field try to solve this task in an\nend-to-end fashion using retrieval-based language models. In this paper, we\npresent a novel approach to zero-shot slot filling that extends dense passage\nretrieval with hard negatives and robust training procedures for retrieval\naugmented generation models. Our model reports large improvements on both T-REx\nand zsRE slot filling datasets, improving both passage retrieval and slot value\ngeneration, and ranking at the top-1 position in the KILT leaderboard.\nMoreover, we demonstrate the robustness of our system showing its domain\nadaptation capability on a new variant of the TACRED dataset for slot filling,\nthrough a combination of zero/few-shot learning. We release the source code and\npre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Md Faisal Mahbub Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mixup Decoding for Diverse Machine Translation. (arXiv:2109.03402v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.03402","description":"<p>Diverse machine translation aims at generating various target language\ntranslations for a given source language sentence. Leveraging the linear\nrelationship in the sentence latent space introduced by the mixup training, we\npropose a novel method, MixDiversity, to generate different translations for\nthe input sentence by linearly interpolating it with different sentence pairs\nsampled from the training corpus when decoding. To further improve the\nfaithfulness and diversity of the translations, we propose two simple but\neffective approaches to select diverse sentence pairs in the training corpus\nand adjust the interpolation weight for each pair correspondingly. Moreover, by\ncontrolling the interpolation weight, our method can achieve the trade-off\nbetween faithfulness and diversity without any additional training, which is\nrequired in most of the previous methods. Experiments on WMT'16 en-ro, WMT'14\nen-de, and WMT'17 zh-en are conducted to show that our method substantially\noutperforms all previous diverse machine translation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jicheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Pengzhi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xuanfu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhongjun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories. (arXiv:2109.03754v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.03754","description":"<p>Measuring event salience is essential in the understanding of stories. This\npaper takes a recent unsupervised method for salience detection derived from\nBarthes Cardinal Functions and theories of surprise and applies it to longer\nnarrative forms. We improve the standard transformer language model by\nincorporating an external knowledgebase (derived from Retrieval Augmented\nGeneration) and adding a memory mechanism to enhance performance on longer\nworks. We use a novel approach to derive salience annotation using\nchapter-aligned summaries from the Shmoop corpus for classic literary works.\nOur evaluation against this data demonstrates that our salience detection model\nimproves performance over and above a non-knowledgebase and memory augmented\nlanguage model, both of which are crucial to this improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wilmot_D/0/1/0/all/0/1\">David Wilmot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1\">Frank Keller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PPT: Pre-trained Prompt Tuning for Few-shot Learning. (arXiv:2109.04332v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04332","description":"<p>Prompts for pre-trained language models (PLMs) have shown remarkable\nperformance by bridging the gap between pre-training tasks and various\ndownstream tasks. Among these methods, prompt tuning, which freezes PLMs and\nonly tunes soft prompts, provides an efficient and effective solution for\nadapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to\nbe fully explored. In our pilot experiments, we find that prompt tuning\nperforms comparably with conventional full-model fine-tuning when downstream\ndata are sufficient, whereas it performs much worse under few-shot learning\nsettings, which may hinder the application of prompt tuning in practice. We\nattribute this low performance to the manner of initializing soft prompts.\nTherefore, in this work, we propose to pre-train prompts by adding soft prompts\ninto the pre-training stage to obtain a better initialization. We name this\nPre-trained Prompt Tuning framework \"PPT\". To ensure the generalization of PPT,\nwe formulate similar classification tasks into a unified task form and\npre-train soft prompts for this unified task. Extensive experiments show that\ntuning pre-trained prompts for downstream tasks can reach or even outperform\nfull-model fine-tuning under both full-data and few-shot settings. Our approach\nis effective and efficient for using large-scale PLMs in practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuxian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How May I Help You? Using Neural Text Simplification to Improve Downstream NLP Tasks. (arXiv:2109.04604v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04604","description":"<p>The general goal of text simplification (TS) is to reduce text complexity for\nhuman consumption. This paper investigates another potential use of neural TS:\nassisting machines performing natural language processing (NLP) tasks. We\nevaluate the use of neural TS in two ways: simplifying input texts at\nprediction time and augmenting data to provide machines with additional\ninformation during training. We demonstrate that the latter scenario provides\npositive effects on machine performance on two separate datasets. In\nparticular, the latter use of TS improves the performances of LSTM (1.82-1.98%)\nand SpanBERT (0.7-1.3%) extractors on TACRED, a complex, large-scale,\nreal-world relation extraction task. Further, the same setting yields\nimprovements of up to 0.65% matched and 0.62% mismatched accuracies for a BERT\ntext classifier on MNLI, a practical natural language inference dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Van_H/0/1/0/all/0/1\">Hoang Van</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CINS: Comprehensive Instruction for Few-shot Learning in Task-oriented Dialog Systems. (arXiv:2109.04645v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04645","description":"<p>As labeling cost for different modules in task-oriented dialog (ToD) systems\nis high, a major challenge in practice is to learn different tasks with the\nleast amount of labeled data. Recently, prompting methods over pre-trained\nlanguage models (PLMs) have shown promising results for few-shot learning in\nToD. To better utilize the power of PLMs, this paper proposes Comprehensive\nInstruction (CINS) that exploits PLMs with extra task-specific instructions. We\ndesign a schema (definition, constraint, prompt) of instructions and their\ncustomized realizations for three important downstream tasks in ToD, i.e.\nintent classification, dialog state tracking, and natural language generation.\nA sequence-to-sequence model (T5) is adopted to solve these three tasks in a\nunified framework. Extensive experiments are conducted on these ToD tasks in\nrealistic few-shot learning scenarios with small validation data. Empirical\nresults demonstrate that the proposed CINS approach consistently improves\ntechniques that finetune PLMs with raw input or short prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yitong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoR: Read-over-Read for Long Document Machine Reading Comprehension. (arXiv:2109.04780v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04780","description":"<p>Transformer-based pre-trained models, such as BERT, have achieved remarkable\nresults on machine reading comprehension. However, due to the constraint of\nencoding length (e.g., 512 WordPiece tokens), a long document is usually split\ninto multiple chunks that are independently read. It results in the reading\nfield being limited to individual chunks without information collaboration for\nlong document machine reading comprehension. To address this problem, we\npropose RoR, a read-over-read method, which expands the reading field from\nchunk to document. Specifically, RoR includes a chunk reader and a document\nreader. The former first predicts a set of regional answers for each chunk,\nwhich are then compacted into a highly-condensed version of the original\ndocument, guaranteeing to be encoded once. The latter further predicts the\nglobal answers from this condensed document. Eventually, a voting strategy is\nutilized to aggregate and rerank the regional and global answers for final\nprediction. Extensive experiments on two benchmarks QuAC and TriviaQA\ndemonstrate the effectiveness of RoR for long document reading. Notably, RoR\nranks 1st place on the QuAC leaderboard (https://quac.ai/) at the time of\nsubmission (May 17th, 2021).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Junwei Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yongwei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Youzheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy. (arXiv:2109.05238v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05238","description":"<p>Simultaneous machine translation (SiMT) generates translation before reading\nthe entire source sentence and hence it has to trade off between translation\nquality and latency. To fulfill the requirements of different translation\nquality and latency in practical applications, the previous methods usually\nneed to train multiple SiMT models for different latency levels, resulting in\nlarge computational costs. In this paper, we propose a universal SiMT model\nwith Mixture-of-Experts Wait-k Policy to achieve the best translation quality\nunder arbitrary latency with only one trained model. Specifically, our method\nemploys multi-head attention to accomplish the mixture of experts where each\nhead is treated as a wait-k expert with its own waiting words number, and given\na test latency and source inputs, the weights of the experts are accordingly\nadjusted to produce the best translation. Experiments on three datasets show\nthat our method outperforms all the strong baselines under different latency,\nincluding the state-of-the-art adaptive policy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model. (arXiv:2109.05244v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05244","description":"<p>Cross-attention is an important component of neural machine translation\n(NMT), which is always realized by dot-product attention in previous methods.\nHowever, dot-product attention only considers the pair-wise correlation between\nwords, resulting in dispersion when dealing with long sentences and neglect of\nsource neighboring relationships. Inspired by linguistics, the above issues are\ncaused by ignoring a type of cross-attention, called concentrated attention,\nwhich focuses on several central words and then spreads around them. In this\nwork, we apply Gaussian Mixture Model (GMM) to model the concentrated attention\nin cross-attention. Experiments and analyses we conducted on three datasets\nshow that the proposed method outperforms the baseline and has significant\nimprovement on alignment quality, N-gram accuracy, and long sentence\ntranslation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora. (arXiv:2109.05406v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05406","description":"<p>Human conversations consist of reasonable and natural topic flows, which are\nobserved as the shifts of the mentioned concepts across utterances. Previous\nchatbots that incorporate the external commonsense knowledge graph prove that\nmodeling the concept shifts can effectively alleviate the dull and\nuninformative response dilemma. However, there still exists a gap between the\nconcept relations in the natural conversation and those in the external\ncommonsense knowledge graph, which is an issue to solve. Specifically, the\nconcept relations in the external commonsense knowledge graph are not\nintuitively built from the conversational scenario but the world knowledge,\nwhich makes them insufficient for the chatbot construction. To bridge the above\ngap, we propose the method to supply more concept relations extracted from the\nconversational corpora and reconstruct an enhanced concept graph for the\nchatbot construction. In addition, we present a novel, powerful, and fast graph\nencoding architecture named the Edge-Transformer to replace the traditional GNN\narchitecture. Experimental results on the Reddit conversation dataset indicate\nour proposed method significantly outperforms strong baseline systems and\nachieves new SOTA results. Further analysis individually proves the\neffectiveness of the enhanced concept graph and the Edge-Transformer\narchitecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_P/0/1/0/all/0/1\">Pengda Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Language-Dependent Ethnic Bias in BERT. (arXiv:2109.05704v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05704","description":"<p>BERT and other large-scale language models (LMs) contain gender and racial\nbias. They also exhibit other dimensions of social bias, most of which have not\nbeen studied in depth, and some of which vary depending on the language. In\nthis paper, we study ethnic bias and how it varies across languages by\nanalyzing and mitigating ethnic bias in monolingual BERT for English, German,\nSpanish, Korean, Turkish, and Chinese. To observe and quantify ethnic bias, we\ndevelop a novel metric called Categorical Bias score. Then we propose two\nmethods for mitigation; first using a multilingual model, and second using\ncontextual word alignment of two monolingual models. We compare our proposed\nmethods with monolingual BERT and show that these methods effectively alleviate\nthe ethnic bias. Which of the two methods works better depends on the amount of\nNLP resources available for that language. We additionally experiment with\nArabic and Greek to verify that our proposed methods work for a wider variety\nof languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahn_J/0/1/0/all/0/1\">Jaimeen Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language Understanding and Generation. (arXiv:2109.05729v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05729","description":"<p>In this paper, we take the advantage of previous pre-trained models (PTMs)\nand propose a novel Chinese Pre-trained Unbalanced Transformer (CPT). Different\nfrom previous Chinese PTMs, CPT is designed for both natural language\nunderstanding (NLU) and natural language generation (NLG) tasks. CPT consists\nof three parts: a shared encoder, an understanding decoder, and a generation\ndecoder. Two specific decoders with a shared encoder are pre-trained with\nmasked language modeling (MLM) and denoising auto-encoding (DAE) tasks,\nrespectively. With the partially shared architecture and multi-task\npre-training, CPT can (1) learn specific knowledge of both NLU or NLG tasks\nwith two decoders and (2) be fine-tuned flexibly that fully exploits the\npotential of the model. Moreover, the unbalanced Transformer saves the\ncomputational and storage cost, which makes CPT competitive and greatly\naccelerates the inference of text generation. Experimental results on a wide\nrange of Chinese NLU and NLG tasks show the effectiveness of CPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Z/0/1/0/all/0/1\">Zhichao Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yitao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1\">Junqi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhe_L/0/1/0/all/0/1\">Li Zhe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Hujun Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Categorical Semantics of Reversible Pattern-Matching. (arXiv:2109.05837v2 [cs.LO] UPDATED)","link":"http://arxiv.org/abs/2109.05837","description":"<p>This paper is concerned with categorical structures for reversible\ncomputation. In particular, we focus on a typed, functional reversible language\nbased on Theseus. We discuss how join inverse rig categories do not in general\ncapture pattern-matching, the core construct Theseus uses to enforce\nreversibility. We then derive a categorical structure to add to join inverse\nrig categories in order to capture pattern-matching. We show how such a\nstructure makes an adequate model for reversible pattern-matching.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lemonnier_L/0/1/0/all/0/1\">Louis Lemonnier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chardonnet_K/0/1/0/all/0/1\">Kostia Chardonnet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valiron_B/0/1/0/all/0/1\">Beno&#xee;t Valiron</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Question Answering over Electronic Devices: A New Benchmark Dataset and a Multi-Task Learning based QA Framework. (arXiv:2109.05897v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.05897","description":"<p>Answering questions asked from instructional corpora such as E-manuals,\nrecipe books, etc., has been far less studied than open-domain factoid\ncontext-based question answering. This can be primarily attributed to the\nabsence of standard benchmark datasets. In this paper we meticulously create a\nlarge amount of data connected with E-manuals and develop suitable algorithm to\nexploit it. We collect E-Manual Corpus, a huge corpus of 307,957 E-manuals and\npretrain RoBERTa on this large corpus. We create various benchmark QA datasets\nwhich include question answer pairs curated by experts based upon two\nE-manuals, real user questions from Community Question Answering Forum\npertaining to E-manuals etc. We introduce EMQAP (E-Manual Question Answering\nPipeline) that answers questions pertaining to electronics devices. Built upon\nthe pretrained RoBERTa, it harbors a supervised multi-task learning framework\nwhich efficiently performs the dual tasks of identifying the section in the\nE-manual where the answer can be found and the exact answer span within that\nsection. For E-Manual annotated question-answer pairs, we show an improvement\nof about 40% in ROUGE-L F1 scores over the most competitive baseline. We\nperform a detailed ablation study and establish the versatility of EMQAP across\ndifferent circumstances. The code and datasets are shared at\nhttps://github.com/abhi1nandy2/EMNLP-2021-Findings, and the corresponding\nproject website is https://sites.google.com/view/emanualqa/home.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1\">Abhilash Nandy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Soumya Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddhashiya_S/0/1/0/all/0/1\">Shubham Maddhashiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_K/0/1/0/all/0/1\">Kapil Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Language Models Encode Perceptual Structure Without Grounding? A Case Study in Color. (arXiv:2109.06129v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2109.06129","description":"<p>Pretrained language models have been shown to encode relational information,\nsuch as the relations between entities or concepts in knowledge-bases --\n(Paris, Capital, France). However, simple relations of this type can often be\nrecovered heuristically and the extent to which models implicitly reflect\ntopological structure that is grounded in world, such as perceptual structure,\nis unknown. To explore this question, we conduct a thorough case study on\ncolor. Namely, we employ a dataset of monolexemic color terms and color chips\nrepresented in CIELAB, a color space with a perceptually meaningful distance\nmetric.\n</p>\n<p>Using two methods of evaluating the structural alignment of colors in this\nspace with text-derived color term representations, we find significant\ncorrespondence. Analyzing the differences in alignment across the color\nspectrum, we find that warmer colors are, on average, better aligned to the\nperceptual color space than cooler ones, suggesting an intriguing connection to\nfindings from recent work on efficient communication in color naming. Further\nanalysis suggests that differences in alignment are, in part, mediated by\ncollocationality and differences in syntactic usage, posing questions as to the\nrelationship between color perception and usage and context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdou_M/0/1/0/all/0/1\">Mostafa Abdou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulmizev_A/0/1/0/all/0/1\">Artur Kulmizev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_S/0/1/0/all/0/1\">Stella Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-14T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}