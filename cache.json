{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-01T01:56:19.980087076Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【全职远程】15K-30K/硅谷无码AI团队招/后端开发工程师/Java or Scala","link":"https://rustcc.cn/article?id=6c2bed71-6adf-45ac-bd60-904427c5c51c","description":"<p>公司简介\n我们是一个刚刚成立在上海的创业公司。创始人在硅谷，全员远程，致力于打造下一代无码AI数据产品，技术氛围浓厚。目前和国内一家知名CDP平台厂商合理推出了第一版无代码机器学习预测平台，帮助企业实现运营的智能化。</p>\n<p>工作职责\n1、负责机器学习平台的后端技术架构;</p>\n<p>2、负责机器学习平台的后端代码实现及单元测试；</p>\n<p>3、负责编写技术设计文档、API文档。</p>\n<p>任职要求\n1、计算机相关专业，本科及以上学历；</p>\n<p>2、 熟练使用Java 或 Scala 开发，5年以上的开发经验；</p>\n<p>3、熟练使用SprintBoot，熟悉相关的生态和使用方法；</p>\n<p>4、有大数据处理经验优先。</p>\n<p>关于沟通\n1、使用飞书作为沟通和文档工具；</p>\n<p>2、每天上午 9 点（冬令时，夏令时是 上午 8:30 ）会有简单的同步；</p>\n<p>3、每天写日报，说明任务的进度，以及发现哪些问题和需要什么帮助；</p>\n<p>4、每个 Sprint 会花时间拆解 Story 和分配任务，需要各自分析出各个需求点和关键点，发现风险和不确定的地方及早确认。</p>\n<p>薪资待遇\n15K-30K，全职（不接受兼职），提供五险一金。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-01 01:52:23","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Mike Tang 张汉东 老油条各位大佬请进，素数多线程问题","link":"https://rustcc.cn/article?id=b10b7a68-e2bf-42b6-a583-ef99478e50d3","description":"<p>各位大佬：</p>\n<p>昨天腾讯视频聊的比较开心，留了一个尾巴。我现在把我的困惑放出来，大家尽情拍砖。</p>\n<p>这个是我写的文章，文章分了两章 ：</p>\n<p><a href=\"https://github.com/sunnyrust/rustBible/blob/master/books/6.2.md\" rel=\"noopener noreferrer\">6.2 多线程——channel</a></p>\n<p><a href=\"https://github.com/sunnyrust/rustBible/blob/master/books/6.3.md\" rel=\"noopener noreferrer\">6.3 多线程——future</a></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-01 00:56:14","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-31 Rust edition","link":"https://rustcc.cn/article?id=d6a7f8d7-4d99-4488-a933-1d70cefcd2cd","description":"<h2><code>delicate</code> 分布式调度系统</h2>\n<p>周二的唠嗑室主题\n主持人：槟橙炮炮\n简介：Rust社区之前没有活跃的分布式调度系统项目，为了填补这个空白我开始调研实现项目，目前已经快要发布V1.1了。</p>\n<p>在项目设计与底层库的实现从smol套件中获得了很多灵感，也会简单跟大家介绍下 smol &amp; tokio 一些各自的设计哲学，async-process async-io async-task 一些漂亮的代码片段。</p>\n<ul>\n<li>文档地址：https://delicate-rs.github.io/</li>\n<li>源码：https://github.com/BinChengZhao/delicate</li>\n</ul>\n<h2>datafusion-5.0.0 发布</h2>\n<p>datafusion 是基于 Apache Arrow 列格式、使用 Rust 实现的可扩展查询执行框架，支持SQL 和 DataFrame API，也可以通过 ballista crate(也发布了 v0.5.0) 支持分布式查询</p>\n<ul>\n<li>发布页：https://arrow.apache.org/blog/2021/08/18/datafusion-5.0.0/</li>\n<li>仓库： https://github.com/apache/arrow-datafusion</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-31 14:24:01","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【原创】Rust tokio 如何以异步非阻塞方式运行大量任务","link":"https://rustcc.cn/article?id=ba4f86c6-667d-4acb-89a1-e2fb0617f524","description":"<p>tokio 官方给了一个完整的<a href=\"https://tokio.rs/tokio/topics/bridging#spawning-things-on-a-runtime\" rel=\"noopener noreferrer\">例子</a>：手动构建 runtime ，利用 block_on 来运行多个任务。\ntokio 的任务是由 <code>tokio::spawn</code> 之类的函数产生的 <code>JoinHandle</code> 类型，而且是个 <code>Future</code> 。</p>\n<p>而下面利用 <code>#[tokio::main]</code> 和 await 编写了等价的版本（为了直观对比任务完成的实际顺序和总耗时，我对 sleep 的时间做了一些简化）：</p>\n<pre><code>use std::time::Instant;\nuse tokio::time::{sleep, Duration};\n\n#[tokio::main]\nasync fn main() -&gt; std::io::Result&lt;()&gt; {\n    let now = Instant::now();\n\n    let mut handles = Vec::with_capacity(10);\n    for i in 0..10 {\n        handles.push(tokio::spawn(my_bg_task(i)));\n    }\n\n    // Do something time-consuming while the background tasks execute.\n    std::thread::sleep(Duration::from_millis(120));\n    println!(\"Finished time-consuming task.\");\n\n    // Wait for all of them to complete.\n    for handle in handles {\n        handle.await?;\n    }\n\n    println!(\"总耗时：{} ms\", now.elapsed().as_millis());\n    Ok(())\n}\n\nasync fn my_bg_task(i: u64) {\n    let millis = 100;\n    println!(\"Task {} sleeping for {} ms.\", i, millis);\n    sleep(Duration::from_millis(millis)).await;\n    println!(\"Task {} stopping.\", i);\n}\n</code></pre>\n<p>输出结果：</p>\n<pre><code>Task 0 sleeping for 100 ms.\nTask 1 sleeping for 100 ms.\nTask 2 sleeping for 100 ms.\nTask 3 sleeping for 100 ms.\nTask 4 sleeping for 100 ms.\nTask 5 sleeping for 100 ms.\nTask 6 sleeping for 100 ms.\nTask 7 sleeping for 100 ms.\nTask 8 sleeping for 100 ms.\nTask 9 sleeping for 100 ms.\nTask 9 stopping.\nTask 0 stopping.\nTask 1 stopping.\nTask 2 stopping.\nTask 3 stopping.\nTask 4 stopping.\nTask 5 stopping.\nTask 6 stopping.\nTask 7 stopping.\nTask 8 stopping.\nFinished time-consuming task.\n总耗时：120 ms\n</code></pre>\n<p>如果把主线程的的 sleep 时间改成 100 ms：<code>std::thread::sleep(Duration::from_millis(100));</code>\n则产生下面的结果：</p>\n<pre><code>Task 0 sleeping for 100 ms.\nTask 1 sleeping for 100 ms.\nTask 2 sleeping for 100 ms.\nTask 3 sleeping for 100 ms.\nTask 4 sleeping for 100 ms.\nTask 5 sleeping for 100 ms.\nTask 6 sleeping for 100 ms.\nTask 7 sleeping for 100 ms.\nTask 8 sleeping for 100 ms.\nTask 9 sleeping for 100 ms.\nFinished time-consuming task.\nTask 3 stopping.\nTask 0 stopping.\nTask 1 stopping.\nTask 2 stopping.\nTask 9 stopping.\nTask 4 stopping.\nTask 5 stopping.\nTask 6 stopping.\nTask 7 stopping.\nTask 8 stopping.\n总耗时：103 ms\n</code></pre>\n<p>可以看到，<code>my_bg_task</code> 实际是异步非阻塞执行的 👍 ：</p>\n<ul>\n<li>异步：因为每个任务不必等待其结果就可以开始下一个任务，即；</li>\n</ul>\n<pre><code>// 异步\nTask 0 sleeping for 100 ms.\nTask 1 sleeping for 100 ms.\n...\n\n// 同步\nTask 0 sleeping for 100 ms.\nTask 0 stopping.\nTask 1 sleeping for 100 ms.\nTask 1 stopping.\n...\n</code></pre>\n<ul>\n<li>非阻塞：每个任务之间可以快速切换，不必等待其他任务完成才切换，这个例子表现在：\n<ul>\n<li>任务 0-9 以乱序方式 stop</li>\n<li><code>Finished time-consuming task.</code> 与 <code>Task x stopping.</code>  的打印顺序只与任务各自的运行 (sleep) 时间有关，与源代码的声明执行顺序无关。只有任务之间快速切换才能做到这一点。回顾官网的例子：10 个任务的 sleep 时间线性递减 （<code>let millis = 1000 - 50 * i;</code>），从 6 个任务开始小于主线程 sleep 任务的时间（750 ms），而等待 10 个任务执行的语句 <code>for handle in handles { ... }</code> 显然位于 <code>std::thread::sleep</code> 之后，所以任务之间非阻塞执行的话，打印结果为 sleep 时间越短的任务先完成，时间越长的任务后完成，总耗时为任务中的最长耗时：</li>\n</ul>\n</li>\n</ul>\n<pre><code>Task 0 sleeping for 1000 ms.\nTask 1 sleeping for 950 ms.\nTask 2 sleeping for 900 ms.\nTask 3 sleeping for 850 ms.\nTask 4 sleeping for 800 ms.\nTask 5 sleeping for 750 ms.\nTask 6 sleeping for 700 ms.\nTask 7 sleeping for 650 ms.\nTask 8 sleeping for 600 ms.\nTask 9 sleeping for 550 ms.\nTask 9 stopping.\nTask 8 stopping.\nTask 7 stopping.\nTask 6 stopping.\nFinished time-consuming task.\nTask 5 stopping.\nTask 4 stopping.\nTask 3 stopping.\nTask 2 stopping.\nTask 1 stopping.\nTask 0 stopping.\n总耗时：1001 ms // 非常完美\n</code></pre>\n<p>一般情况下，对于 async block/fn 你至少有以下一些做法：</p>\n<ol>\n<li>对 async block/fn 调用 <code>.await</code> 来等待结果；</li>\n<li>对可列举的少数 Future 调用 <code>join!</code> 或者 <code>select!</code> 来同时等待多个结果 或者 等待多个分支的第一个结果；</li>\n<li>对大量 Future 调用 <a href=\"https://docs.rs/futures/0.3.17/futures/?search=join\" rel=\"noopener noreferrer\">join</a> 或者 <a href=\"https://docs.rs/futures/0.3.17/futures/?search=select\" rel=\"noopener noreferrer\">select</a> 一类支持传入 Vec / iter 参数类型的函数，比如这个例子中的 <code>for handle in handles { ... }</code> 部分就可以改写成 <code>futures::future::join_all(handles).await;</code> ；</li>\n<li>把 async block/fn 变成任务，然后调用 <code>Runtime::block_on</code> （等价地，对任务 await）来执行许多任务。</li>\n</ol>\n<p>容易犯的错误是，希望异步非阻塞时，对所有 async block/fn 进行了 await，而没有进行任务化处理（即 把 Future 通过 spwan 函数转化成任务）：</p>\n<pre><code>use std::time::Instant;\nuse tokio::time::{sleep, Duration};\n\n#[tokio::main]\nasync fn main() {\n    let now = Instant::now();\n\n    let mut handles = Vec::with_capacity(10);\n    for i in 0..10 {\n        handles.push(my_bg_task(i)); // 没有把 Future 变成任务\n    }\n\n    std::thread::sleep(Duration::from_millis(120));\n    println!(\"Finished time-consuming task.\");\n\n    for handle in handles {\n        handle.await; // 而且每个 handle 必须执行完才能执行下一个 handle\n    }\n    println!(\"总耗时：{} ms\", now.elapsed().as_millis());\n}\n\nasync fn my_bg_task(i: u64) {\n    let millis = 100;\n    println!(\"Task {} sleeping for {} ms.\", i, millis);\n    sleep(Duration::from_millis(millis)).await;\n    println!(\"Task {} stopping.\", i);\n}\n</code></pre>\n<p>运行结果：同步阻塞</p>\n<pre><code>Finished time-consuming task.\nTask 0 sleeping for 100 ms.\nTask 0 stopping.\nTask 1 sleeping for 100 ms.\nTask 1 stopping.\nTask 2 sleeping for 100 ms.\nTask 2 stopping.\nTask 3 sleeping for 100 ms.\nTask 3 stopping.\nTask 4 sleeping for 100 ms.\nTask 4 stopping.\nTask 5 sleeping for 100 ms.\nTask 5 stopping.\nTask 6 sleeping for 100 ms.\nTask 6 stopping.\nTask 7 sleeping for 100 ms.\nTask 7 stopping.\nTask 8 sleeping for 100 ms.\nTask 8 stopping.\nTask 9 sleeping for 100 ms.\nTask 9 stopping.\n总耗时：1130 ms\n</code></pre>\n<hr>\n<p>或者像这样：</p>\n<pre><code>use std::time::Instant;\nuse tokio::time::{sleep, Duration};\n\n#[tokio::main]\nasync fn main() {\n    let now = Instant::now();\n\n    let mut handles = Vec::with_capacity(10);\n    for i in 0..10 {\n        handles.push(my_bg_task(i)); // 没有把 Future 变成任务\n    }\n\n    std::thread::sleep(Duration::from_millis(120));\n    println!(\"Finished time-consuming task.\");\n\n    futures::future::join_all(handles).await; // 但是 join_all 会等待所有 Future 并发执行完\n    println!(\"总耗时：{} ms\", now.elapsed().as_millis());\n}\n\nasync fn my_bg_task(i: u64) {\n    let millis = 100;\n    println!(\"Task {} sleeping for {} ms.\", i, millis);\n    sleep(Duration::from_millis(millis)).await;\n    println!(\"Task {} stopping.\", i);\n}\n</code></pre>\n<p>运行结果：异步阻塞</p>\n<pre><code>Finished time-consuming task.\nTask 0 sleeping for 100 ms.\nTask 1 sleeping for 100 ms.\nTask 2 sleeping for 100 ms.\nTask 3 sleeping for 100 ms.\nTask 4 sleeping for 100 ms.\nTask 5 sleeping for 100 ms.\nTask 6 sleeping for 100 ms.\nTask 7 sleeping for 100 ms.\nTask 8 sleeping for 100 ms.\nTask 9 sleeping for 100 ms.\nTask 0 stopping.\nTask 1 stopping.\nTask 2 stopping.\nTask 3 stopping.\nTask 4 stopping.\nTask 5 stopping.\nTask 6 stopping.\nTask 7 stopping.\nTask 8 stopping.\nTask 9 stopping.\n总耗时：221 ms\n</code></pre>\n<p>​</p>\n<p><em>P.S. 关于代码中 <code>std::thread::sleep</code> 和 <code>tokio::time::sleep</code> 的区别，参考这篇文章 <a href=\"https://ryhl.io/blog/async-what-is-blocking/\" rel=\"noopener noreferrer\">Async: What is blocking? (by Alice Ryhl)</a> 。</em></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-31 12:35:12","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"[问题已解决，非常适合新手看]新手求助指针的使用问题，写了个前缀树算法一直不能编译有谁帮忙看一下。请高手赐教。","link":"https://rustcc.cn/article?id=56e27ff0-860c-41c8-81d4-4756fffd5abc","description":"<pre><code>fn insert(mut self, url_rule: &amp;str) {\n        let mut current = self.clone(); // 作为游标指针使用，好像没有达到游标的效果\n        let list = parse_path(url_rule);\n        for word in &amp;list {\n            let mut is_exist = false;\n            for n in current.child() {\n                if n.name == word.to_string() {\n                    is_exist = true;\n                    current = n.clone();\n                    break;\n                }\n            }\n\n            if is_exist {\n                continue;\n            }\n            let mut node = Tree::new(word);\n            if is_variable(word) {\n                node.is_variable = true\n            };\n            current.append_child(&amp;node);\n            current = node.clone()\n        }\n\n        current.rule = url_rule.to_string();\n        current.is_end = true;\n    }\n\n</code></pre>\n<p>上面的current游标我应该用什么类型指针，因为是自定义类型Tree，绑定只能用Clone。怎么用引用指针修改子节点的数据\ngolang的实现在https://github.com/obity/pretree/blob/main/pretree.go这个是没有问题的。rust实在是不会写。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-31 08:10:17","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust进程关闭时的回调钩子","link":"https://rustcc.cn/article?id=77a67a30-75d9-49f5-bf60-7a650477f552","description":"<p>请教一下进程关闭时的回调函数怎么实现？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-31 03:38:13","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"如何把rust编译的可执行文件中的众多文件名去除","link":"https://rustcc.cn/article?id=fdd79d8b-5b4f-471a-84ea-47f832d1f4c1","description":"<p>下面是从可执行文件中截取的一段。里面包含大量的文件名和字符串。这些文件名占用很多空间。请问如何不让这个文件名编译到可执行文件中？</p>\n<pre><code>library/core/src/fmt/mod.rs^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^A^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^B^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^D^D^D^D^D^@^@^@^@^@^@^@^@^@^@^@attempted to index str up to maximum usizelibrary/core/src/str/pattern.rs^@library/core/src/str/lossy.rsassertion failed: broken.is_empty()EmptyParseIntErrorInvalidDigitPosOverflowNegOverflowUtf8Errorvalid_up_toerror_len.debug_str_offsets.debug_str.debug_rnglists.debug_ranges.debug_line_str.debug_line.debug_info.debug_addr.debug_abbrevassertion failed: src.len() == dst.len()assertion failed: edge.height == self.height - 1assertion failed: idx &lt; CAPACITY/rustc/a15f484b918a4533ad633ea903ccce82910af342/library/alloc/src/collections/btree/node.rs/rustc/a15f484b918a4533ad633ea903ccce82910af342/library/alloc/src/collections/btree/map/entry.rs/Users/runner/.cargo/registry/src/github.com-1ecc6299db9ec823/gimli-0.23.0/src/read/abbrev.rsJimI am hello world\n^@^@^@^@^@^@^@^@^@^@^@^@^@Invalid archive member headerInvalid archive terminatorInvalid archive member sizeArchive member size is too large^@^@^@Invalid archive extended name offsetInvalid archive extended name length::@*&amp;&lt;&gt;(,/Users/runner/.cargo/registry/src/github.com-1ecc6299db9ec823/rustc-demangle-0.1.18/src/legacy.rs?[]::{closure#}, _-false...!f64f32usizeu64u32u16u8isizei64i32i16i8()str/Users/runner/.cargo/registry/src/github.com-1ecc6299db9ec823/rustc-demangle-0.1.18/src/v0.rs0x' const ; &gt;  +  = Cunsafe \" fn(punycode{.llvm.^@^@^@^@^@^@^@^@^@^@/Users/runner/.cargo/registry/src/github.com-1ecc6299db9ec823/rustc-demangle-0.1.18/src/lib.rsAccessErroruse of std::thread::current() is not possible after the thread's local data has been destroyedalready mutably borrowedcalled `Option::unwrap()` on a `None` valuelibrary/std/src/sys_common/thread_info.rsthread name may not contain interior null bytesfailed to generate unique thread ID: bitspace exhausted^@^@^@»±°&lt;^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@§«ª2^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@called `Result::unwrap()` on an `Err` valuelibrary/std/src/sys/unix/mutex.rsOsmessageCustomerrorUnexpectedEofConnectionRefusedConnectionResetConnectionAbortedNotConnectedAddrInUseBrokenPipeAlreadyExistsWouldBlockInvalidInputInvalidDataWriteZeroInterruptedOtherstrerror_r failurelibrary/std/src/sys/unix/os.rslibrary/std/src/ffi/c_str.rslibrary/std/src/thread/mod.rscannot access a Thread Local Storage value during or after destruction^@^@^@^@^@^@rwlock maximum reader count exceededrwlock read lock would result in deadlockfatal runtime error:\nthread panicked while panicking. aborting.\nRUST_BACKTRACE&lt;unnamed&gt;formatter errorfailed to write whole bufferlibrary/std/src/io/mod.rsnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\nnote: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace.\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-31 03:36:54","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-30 如何来看待 unwrap","link":"https://rustcc.cn/article?id=59dad850-933e-49dd-9ab8-5370d5c77857","description":"<h1>如何来看待 unwrap</h1>\n<p><code>unwrap</code> 方法可能会让新手感到困惑。一些建议:</p>\n<ul>\n<li>可以使用 Expect (&amp;str) 而不是 unwrap() 为 panic 提供上下文。</li>\n<li>使用 unwrap 和 expect 类似于断言。如果他们 panic，那只有在不可挽回的情况下才会发生。</li>\n<li>避免在库代码中使用。</li>\n</ul>\n<p><a href=\"https://owengage.com/writing/2021-08-30-how-to-think-of-unwrap/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>singleton-cell: 一个更强大的 ghost cell 扩展</h1>\n<p>这个库提供了一个安全的、零开销的接口，用于通过访问另一个单例令牌来保护对共享数据的访问。它是 GhostCell的扩展，除了品牌令牌外，它还允许更多普通的单例，使数据成为“静态的”</p>\n<p>这个库本身也提供了两个单例实现:</p>\n<ul>\n<li>通过with_token将限定范围的标记令牌作为 GhostCell</li>\n<li>通过new_singleton简单地创建一次单例结构</li>\n</ul>\n<p><a href=\"https://crates.io/crates/singleton-cell\" rel=\"noopener noreferrer\">crate 地址</a></p>\n<h1>Learning Rust: Interfacing with C</h1>\n<p>通过本文学习如何使用 Rust 调用 C 方法以及如何在 C 中调用 Rust 方法.</p>\n<p><a href=\"https://piware.de/post/2021-08-27-rust-and-c/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>RefineDB: Rust编写的强类型文档数据库</h1>\n<p>运行在任何事务性 键值存储上的 强类型 文档数据库。</p>\n<p>目前支持的 backends 有:</p>\n<ul>\n<li>FoundationDB</li>\n<li>单机部署的 SQLite。</li>\n<li>一个简单的内存键值存储。</li>\n</ul>\n<p><a href=\"https://github.com/losfair/RefineDB\" rel=\"noopener noreferrer\">github 地址</a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-30 12:46:04","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"远程办公，不限地域，缴纳社保公积金，周末双休，告别 996，拒绝 007，Nervina Labs 欢迎你！","link":"https://rustcc.cn/article?id=a90b0635-b332-4e23-9a44-eb9282f519ef","description":"<p>rust开发工程师\n岗位职责：1、负责智能合约的开发及设计；2、负责区块链业务系统分析与设计工作；3、负责智能合约代码测试、运行和维护。任职要求：1、计算机相关专业本科及以上学历，3年以上工作经验；2、熟练掌握 C/C++、Rust 等系统开发语言至少一种，至少有过两年相关开发经验；3、对数据结构和算法，对密码学，安全协议和加密算法有研究者优先；4、优秀的英语文档撰写与阅读能力者优先；5、了解区块链，有合约开发经验更佳。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-30 03:06:51","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"构建安全易用的链表","link":"https://rustcc.cn/article?id=273831e7-932d-476f-9d31-323151afb123","description":"<p>写了一个链表的Crate，愿景是构建安全且易用的链表。</p>\n<p>欢迎大家来找茬（Bug）或提需求 :)</p>\n<p>Crate IO链接：<a href=\"https://crates.io/crates/cyclic_list\" rel=\"noopener noreferrer\">https://crates.io/crates/cyclic_list</a>;</p>\n<p>GitHub链接：<a href=\"https://github.com/whjpji/cyclic_list\" rel=\"noopener noreferrer\">https://github.com/whjpji/cyclic_list</a></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 15:10:34","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"数据表 Timestamp 日期 Serialize","link":"https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0","description":"<p>主要参考：<a href=\"https://github.com/rustcc/forustm\" rel=\"noopener noreferrer\">Rustcc网站源码库</a></p>\n<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，\n查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>\n<h2>1.依赖的库：</h2>\n<pre><code>[dependencies]\n# 日期时间处理 需要开启 serde 特征 支持序列化\nchrono = { version = \"0.4.19\", features = [\"serde\"] }\n\n# 数据库ORM\ndiesel = { version = \"1.4.4\", features = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"] }\ndotenv = \"0.15.0\"\nserde = { version = \"1.0.127\", features = [\"derive\"] }\nserde_json = \"1.0.66\"\nuuid = { version = \"0.8.2\", features = [\"serde\", \"v4\"] }\n</code></pre>\n<h2>2.创建数据表</h2>\n<pre><code>CREATE TABLE characters (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(128) UNIQUE NOT NULL,\n    age INTEGER NOT NULL DEFAULT 0,\n    friends VARCHAR NOT NULL DEFAULT '',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n)\n</code></pre>\n<h2>3.数据表对应的 model</h2>\n<pre><code>use chrono::{NaiveDateTime};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Queryable, Serialize, Deserialize, Debug)]\npub struct Characters {\n    pub id: i32,\n    pub name: String,\n    pub age: i32,\n    pub friends: String,\n    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features\n    pub created_at: NaiveDateTime,\n}\n</code></pre>\n<h2>4.获取数据</h2>\n<pre><code>use db::schema::characters;\nuse db::{get_connection};\nuse db::models::{Characters, NewCharacter};\nuse db::schema::characters::dsl::*;\nuse diesel::QueryDsl;\nuse diesel::prelude::*;\n\nfn main() {\n    let conn = get_connection();\n\n    // 查询年龄大于30的10条数据\n    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))\n        .limit(10)\n        .load::&lt;Characters&gt;(&amp;conn)\n        .expect(\"Loading Error\");\n\n    let date_arr = arr.iter()\n        .map(|item| {\n\t    // 数据格式化\n            let t = item.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n            println!(\"{} {}\", item.name, t);\n            t\n        })\n        .collect::&lt;Vec&lt;String&gt;&gt;();\n}\n</code></pre>\n<p>输出结果类似：</p>\n<pre><code>Box 2021-08-05 09:39:34\nBobe 2021-08-05 09:39:34\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 01:40:35","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Cargo workspace config","link":"https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c","description":"<p><a href=\"https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html\" rel=\"noopener noreferrer\">Workspace 文档链接</a></p>\n<h2>目录结构</h2>\n<pre><code>workspace-test/\n    Cargo.toml\n    db/\n        src/\n            bin/\n                init.rs\n        Cargo.tml\n</code></pre>\n<h2>workspace</h2>\n<p>workspace-test/Cargo.toml</p>\n<pre><code>[workspace]\nmembers = [\"db\"]\ndefault-member = \"db\"\n</code></pre>\n<h2>子项目</h2>\n<p>workspace-test/db/Cargo.toml</p>\n<pre><code>[package]\nname = \"db\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n# 可选的可执行文件配置\n# [[bin]]\n# name = \"init\"\n# path = \"src/bin/init.rs\"\n</code></pre>\n<h2>操作</h2>\n<pre><code># 运行 init\ncargo run --bin init\n# -p 指定项目\ncargo run -p db --bin init\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-04 09:54:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程浅悟（一）","link":"https://rustcc.cn/article?id=120035c3-944d-4a79-9b3a-8390697a6e13","description":"<h1><code>Rust</code>异步编程浅悟（一）</h1>\n<p>不同于<code>javascript</code>的<code>new Promise((resolve, reject) =&gt; {...})</code>构造即运行，<code>Rust</code>中的<code>Future</code>是·惰性·状态机。这体现为：</p>\n<ol>\n<li>【调用异步函数】或【执行异步块】仅只构造一个<code>Future trait object</code>。</li>\n<li>因为<code>Future</code>是惰性状态机，所以它不会自动执行【异步函数】或【异步块】内的任何一行代码 --- 此点与<code>javascript</code>的·活性·状态机完全不同。相反，需要人工激活触发。</li>\n<li>人工启动<code>Future</code>运行，又分为两个场景的两种情况：\n<ol>\n<li>\n<p>已经在<code>async fn</code>内，<code>Future.await</code>激活。但，同时<strong>阻塞</strong>当前异步程序执行流。</p>\n</li>\n<li>\n<p>在<code>async fn</code>外，需要借助由【运行时】提供的【执行器】。就<code>async-std</code>库而言，有两个选择：</p>\n<ol>\n<li><code>task::block_on(Future)</code> 执行<code>Future</code>且阻塞当前线程直到<code>Future</code>被完成。</li>\n<li><code>task::spawn(Future)</code>仅执行<code>Future</code>和不阻塞当前线程。</li>\n</ol>\n<p>无论选择上面哪种方式，若在<code>Future</code>执行期间出现了<code>panic</code>，其都会终止（<code>abort</code>）正在共享同一个执行线程（<code>thread</code>）的所有<code>task</code>（·无栈·协程）的运行。</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>题外话，</p>\n<ol>\n<li>绿色线程是·有栈·协程；异步函数与异步块是·无栈·协程。</li>\n<li>在<code>async-std</code>库的词汇表内，协程被称作<code>task</code>而不是惯例的<code>coroutine</code>。</li>\n<li><code>task::spawn(Future)</code>也能被使用于<code>async fn</code>或<code>async {...}</code>内。它被用来代替<code>.await</code>指令，以<strong>非阻塞</strong><code>async fn</code>或<code>async {...}</code>的方式，激活与执行一个<code>Future</code>实例。</li>\n</ol>\n<h2>例程</h2>\n<pre><code>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {\n    // 1. TcpListener::bind(addr) 返回 Future\n    // 2. .await 于 Future 取得 Result&lt;T, E&gt;\n    // 3. Result&lt;T, E&gt;? 再拿得 Ok&lt;T&gt; 中的 T\n    let listener = TcpListener::bind(addr).await?; // 异步函数内的人工启动 Future\n    let mut incoming = listener.incoming();\n    // 因为没有从语言层面支持 async for loop，所以 while loop + Iterator&lt;Item = T&gt; 来模拟之。\n    while let Some(stream) = incoming.next().await {\n        // TODO\n    }\n    Ok(())\n}\nfn main() {\n    let fut = accept_loop(\"127.0.0.1:8080\");\n    task::block_on(fut); // 异步函数外的人工启动 Future\n}\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-03 00:01:43","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-01T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Want To Reduce Labeling Cost? GPT-3 Can Help. (arXiv:2108.13487v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13487","description":"<p>Data annotation is a time-consuming and labor-intensive process for many NLP\ntasks. Although there exist various methods to produce pseudo data labels, they\nare often task-specific and require a decent amount of labeled data to start\nwith. Recently, the immense language model GPT-3 with 175 billion parameters\nhas achieved tremendous improvement across many few-shot learning tasks. In\nthis paper, we explore ways to leverage GPT-3 as a low-cost data labeler to\ntrain other models. We find that, to make the downstream model achieve the same\nperformance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use\nlabels from GPT-3 than using labels from humans. Furthermore, we propose a\nnovel framework of combining pseudo labels from GPT-3 with human labels, which\nleads to even better performance with limited labeling budget. These results\npresent a cost-effective data labeling methodology that is generalizable to\nmany practical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semi-Supervised Exaggeration Detection of Health Science Press Releases. (arXiv:2108.13493v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13493","description":"<p>Public trust in science depends on honest and factual communication of\nscientific papers. However, recent studies have demonstrated a tendency of news\nmedia to misrepresent scientific papers by exaggerating their findings. Given\nthis, we present a formalization of and study into the problem of exaggeration\ndetection in science communication. While there are an abundance of scientific\npapers and popular media articles written about them, very rarely do the\narticles include a direct link to the original paper, making data collection\nchallenging. We address this by curating a set of labeled press\nrelease/abstract pairs from existing expert annotated studies on exaggeration\nin press releases of scientific papers suitable for benchmarking the\nperformance of machine learning models on the task. Using limited data from\nthis and previous studies on exaggeration detection in science, we introduce\nMT-PET, a multi-task version of Pattern Exploiting Training (PET), which\nleverages knowledge from complementary cloze-style QA tasks to improve few-shot\nlearning. We demonstrate that MT-PET outperforms PET and supervised learning\nboth when data is limited, as well as when there is an abundance of data for\nthe main task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Dustin Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConVIScope: Visual Analytics for Exploring Patient Conversations. (arXiv:2108.13514v1 [cs.HC])","link":"http://arxiv.org/abs/2108.13514","description":"<p>The proliferation of text messaging for mobile health is generating a large\namount of patient-doctor conversations that can be extremely valuable to health\ncare professionals. We present ConVIScope, a visual text analytic system that\ntightly integrates interactive visualization with natural language processing\nin analyzing patient-doctor conversations. ConVIScope was developed in\ncollaboration with healthcare professionals following a user-centered iterative\ndesign. Case studies with six domain experts suggest the potential utility of\nConVIScope and reveal lessons for further developments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Raymond Li</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hoque_E/0/1/0/all/0/1\">Enamul Hoque</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Lester_R/0/1/0/all/0/1\">Richard Lester</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Chau_R/0/1/0/all/0/1\">Raymond Chau</a> (3) ((1) Department of Computer Science, University of British Columbia, (2) School of Information Technology, York University, (3) Department of Medicine, University of British Columbia)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Consistent Document-level Entity Linking: Joint Models for Entity Linking and Coreference Resolution. (arXiv:2108.13530v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13530","description":"<p>We consider the task of document-level entity linking (EL), where it is\nimportant to make consistent decisions for entity mentions over the full\ndocument jointly. We aim to leverage explicit \"connections\" among mentions\nwithin the document itself: we propose to join the EL task with that of\ncoreference resolution (coref). This is complementary to related works that\nexploit either (i) implicit document information (e.g., latent relations among\nentity mentions, or general language models) or (ii) connections between the\ncandidate links (e.g, as inferred from the external knowledge base).\nSpecifically, we cluster mentions that are linked via coreference, and enforce\na single EL for all of the clustered mentions together. The latter constraint\nhas the added benefit of increased coverage by joining EL candidate lists for\nthe thus clustered mentions. We formulate the coref+EL problem as a structured\nprediction task over directed trees and use a globally normalized model to\nsolve it. Experimental results on two datasets show a boost of up to +5%\nF1-score on both coref and EL tasks, compared to their standalone counterparts.\nFor a subset of hard cases, with individual mentions lacking the correct EL in\ntheir candidate entity list, we obtain a +50% increase in accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zaporojets_K/0/1/0/all/0/1\">Klim Zaporojets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1\">Johannes Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic Characterization of Divisive Topics Online: Case Studies on Contentiousness in Abortion, Climate Change, and Gun Control. (arXiv:2108.13556v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13556","description":"<p>As public discourse continues to move and grow online, conversations about\ndivisive topics on social media platforms have also increased. These divisive\ntopics prompt both contentious and non-contentious conversations. Although what\ndistinguishes these conversations, often framed as what makes these\nconversations contentious, is known in broad strokes, much less is known about\nthe linguistic signature of these conversations. Prior work has shown that\ncontentious content and structure can be a predictor for this task, however,\nmost of them have been focused on conversation in general, very specific\nevents, or complex structural analysis. Additionally, many models used in prior\nwork have lacked interpret-ability, a key factor in online moderation. Our work\nfills these gaps by focusing on conversations from highly divisive topics\n(abortion, climate change, and gun control), operationalizing a set of novel\nlinguistic and conversational characteristics and user factors, and\nincorporating them to build interpretable models. We demonstrate that such\ncharacteristics can largely improve the performance of prediction on this task,\nand also enable nuanced interpretability. Our case studies on these three\ncontentious topics suggest that certain generic linguistic characteristics are\nhighly correlated with contentiousness in conversations while others\ndemonstrate significant contextual influences on specific divisive topics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beel_J/0/1/0/all/0/1\">Jacob Beel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tong Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soni_S/0/1/0/all/0/1\">Sandeep Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T3-Vis: a visual analytic framework for Training and fine-Tuning Transformers in NLP. (arXiv:2108.13587v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13587","description":"<p>Transformers are the dominant architecture in NLP, but their training and\nfine-tuning is still very challenging. In this paper, we present the design and\nimplementation of a visual analytic framework for assisting researchers in such\nprocess, by providing them with valuable insights about the model's intrinsic\nproperties and behaviours. Our framework offers an intuitive overview that\nallows the user to explore different facets of the model (e.g., hidden states,\nattention) through interactive visualization, and allows a suite of built-in\nalgorithms that compute the importance of model components and different parts\nof the input sequence. Case studies and feedback from a user focus group\nindicate that the framework is useful, and suggest several improvements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Raymond Li</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wen Xiao</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanjun Wang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1\">Hyeju Jang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1\">Giuseppe Carenini</a> (1) ((1) University of British Columbia, (2) Huawei Cananda Technologies Co. Ltd.)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Does Adversarial Fine-Tuning Benefit BERT?. (arXiv:2108.13602v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13602","description":"<p>Adversarial training (AT) is one of the most reliable methods for defending\nagainst adversarial attacks in machine learning. Variants of this method have\nbeen used as regularization mechanisms to achieve SOTA results on NLP\nbenchmarks, and they have been found to be useful for transfer learning and\ncontinual learning. We search for the reasons for the effectiveness of AT by\ncontrasting vanilla and adversarially fine-tuned BERT models. We identify\npartial preservation of BERT's syntactic abilities during fine-tuning as the\nkey to the success of AT. We observe that adversarially fine-tuned models\nremain more faithful to BERT's language modeling behavior and are more\nsensitive to the word order. As concrete examples of syntactic abilities, an\nadversarially fine-tuned model could have an advantage of up to 38% on anaphora\nagreement and up to 11% on dependency parsing. Our analysis demonstrates that\nvanilla fine-tuning oversimplifies the sentence representation by focusing\nheavily on one or a few label-indicative words. AT, however, moderates the\neffect of these influential words and encourages representational diversity.\nThis allows for a more hierarchical representation of a sentence and leads to\nthe mitigation of BERT's loss of syntactic abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1\">Javid Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Text Classification of Transliterated Hindi and Malayalam. (arXiv:2108.13620v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13620","description":"<p>Transliteration is very common on social media, but transliterated text is\nnot adequately handled by modern neural models for various NLP tasks. In this\nwork, we combine data augmentation approaches with a Teacher-Student training\nscheme to address this issue in a cross-lingual transfer setting for\nfine-tuning state-of-the-art pre-trained multilingual language models such as\nmBERT and XLM-R. We evaluate our method on transliterated Hindi and Malayalam,\nalso introducing new datasets for benchmarking on real-world scenarios: one on\nsentiment classification in transliterated Malayalam, and another on crisis\ntweet classification in transliterated Hindi and Malayalam (related to the 2013\nNorth India and 2018 Kerala floods). Our method yielded an average improvement\nof +5.6% on mBERT and +4.7% on XLM-R in F1 scores over their strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_J/0/1/0/all/0/1\">Jitin Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purohit_H/0/1/0/all/0/1\">Hemant Purohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Sliding Window for Meeting Summarization. (arXiv:2108.13629v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13629","description":"<p>Recently abstractive spoken language summarization raises emerging research\ninterest, and neural sequence-to-sequence approaches have brought significant\nperformance improvement. However, summarizing long meeting transcripts remains\nchallenging. Due to the large length of source contents and targeted summaries,\nneural models are prone to be distracted on the context, and produce summaries\nwith degraded quality. Moreover, pre-trained language models with input length\nlimitations cannot be readily applied to long sequences. In this work, we first\nanalyze the linguistic characteristics of meeting transcripts on a\nrepresentative corpus, and find that the sentences comprising the summary\ncorrelate with the meeting agenda. Based on this observation, we propose a\ndynamic sliding window strategy for meeting summarization. Experimental results\nshow that performance benefit from the proposed method, and outputs obtain\nhigher factual consistency than the base model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided Adaptive Memory. (arXiv:2108.13630v1 [cs.CV])","link":"http://arxiv.org/abs/2108.13630","description":"<p>Lip reading, aiming to recognize spoken sentences according to the given\nvideo of lip movements without relying on the audio stream, has attracted great\ninterest due to its application in many scenarios. Although prior works that\nexplore lip reading have obtained salient achievements, they are all trained in\na non-simultaneous manner where the predictions are generated requiring access\nto the full video. To breakthrough this constraint, we study the task of\nsimultaneous lip reading and devise SimulLR, a simultaneous lip Reading\ntransducer with attention-guided adaptive memory from three aspects: (1) To\naddress the challenge of monotonic alignments while considering the syntactic\nstructure of the generated sentences under simultaneous setting, we build a\ntransducer-based model and design several effective training strategies\nincluding CTC pre-training, model warm-up and curriculum learning to promote\nthe training of the lip reading transducer. (2) To learn better spatio-temporal\nrepresentations for simultaneous encoder, we construct a truncated 3D\nconvolution and time-restricted self-attention layer to perform the\nframe-to-frame interaction within a video segment containing fixed number of\nframes. (3) The history information is always limited due to the storage in\nreal-time scenarios, especially for massive video data. Therefore, we devise a\nnovel attention-guided adaptive memory to organize semantic information of\nhistory segments and enhance the visual representations with acceptable\ncomputation-aware latency. The experiments show that the SimulLR achieves the\ntranslation speedup 9.10$\\times$ compared with the state-of-the-art\nnon-simultaneous methods, and also obtains competitive results, which indicates\nthe effectiveness of our proposed methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhijie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explaining Classes through Word Attribution. (arXiv:2108.13653v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13653","description":"<p>In recent years, several methods have been proposed for explaining individual\npredictions of deep learning models, yet there has been little study of how to\naggregate these predictions to explain how such models view classes as a whole\nin text classification tasks. In this work, we propose a method for explaining\nclasses using deep learning models and the Integrated Gradients feature\nattribution technique by aggregating explanations of individual examples in\ntext classification to general descriptions of the classes. We demonstrate the\napproach on Web register (genre) classification using the XML-R model and the\nCorpus of Online Registers of English (CORE), finding that the method\nidentifies plausible and discriminative keywords characterizing all but the\nsmallest class.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ronnqvist_S/0/1/0/all/0/1\">Samuel R&#xf6;nnqvist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myntti_A/0/1/0/all/0/1\">Amanda Myntti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrolainen_A/0/1/0/all/0/1\">Aki-Juhani Kyr&#xf6;l&#xe4;inen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyysalo_S/0/1/0/all/0/1\">Sampo Pyysalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laippala_V/0/1/0/all/0/1\">Veronika Laippala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginter_F/0/1/0/all/0/1\">Filip Ginter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discretized Integrated Gradients for Explaining Language Models. (arXiv:2108.13654v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13654","description":"<p>As a prominent attribution-based explanation algorithm, Integrated Gradients\n(IG) is widely adopted due to its desirable explanation axioms and the ease of\ngradient computation. It measures feature importance by averaging the model's\noutput gradient interpolated along a straight-line path in the input data\nspace. However, such straight-line interpolated points are not representative\nof text data due to the inherent discreteness of the word embedding space. This\nquestions the faithfulness of the gradients computed at the interpolated points\nand consequently, the quality of the generated explanations. Here we propose\nDiscretized Integrated Gradients (DIG), which allows effective attribution\nalong non-linear interpolation paths. We develop two interpolation strategies\nfor the discrete word embedding space that generates interpolation points that\nlie close to actual words in the embedding space, yielding more faithful\ngradient computation. We demonstrate the effectiveness of DIG over IG through\nexperimental and human evaluations on multiple sentiment classification\ndatasets. We provide the source code of DIG to encourage reproducible research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1\">Soumya Sanyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MELM: Data Augmentation with Masked Entity Language Modeling for Cross-lingual NER. (arXiv:2108.13655v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13655","description":"<p>Data augmentation for cross-lingual NER requires fine-grained control over\ntoken labels of the augmented text. Existing augmentation approach based on\nmasked language modeling may replace a labeled entity with words of a different\nclass, which makes the augmented sentence incompatible with the original label\nsequence, and thus hurts the performance.We propose a data augmentation\nframework with Masked-Entity Language Modeling (MELM) which effectively ensures\nthe replacing entities fit the original labels. Specifically, MELM linearizes\nNER labels into sentence context, and thus the fine-tuned MELM is able to\npredict masked tokens by explicitly conditioning on their labels. Our MELM is\nagnostic to the source of data to be augmented. Specifically, when MELM is\napplied to augment training data of the source language, it achieves up to 3.5%\nF1 score improvement for cross-lingual NER. When unlabeled target data is\navailable and MELM can be further applied to augment pseudo-labeled target\ndata, the performance gain reaches 5.7%. Moreover, MELM consistently\noutperforms multiple baseline methods for data augmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ran Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ruidan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Rule Generation for Time Expression Normalization. (arXiv:2108.13658v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13658","description":"<p>The understanding of time expressions includes two sub-tasks: recognition and\nnormalization. In recent years, significant progress has been made in the\nrecognition of time expressions while research on normalization has lagged\nbehind. Existing SOTA normalization methods highly rely on rules or grammars\ndesigned by experts, which limits their performance on emerging corpora, such\nas social media texts. In this paper, we model time expression normalization as\na sequence of operations to construct the normalized temporal value, and we\npresent a novel method called ARTime, which can automatically generate\nnormalization rules from training data without expert interventions.\nSpecifically, ARTime automatically captures possible operation sequences from\nannotated data and generates normalization rules on time expressions with\ncommon surface forms. The experimental results show that ARTime can\nsignificantly surpass SOTA methods on the Tweets benchmark, and achieves\ncompetitive results with existing expert-engineered rule methods on the\nTempEval-3 benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wentao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinmao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yuzhong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gray Cycles of Maximum Length Related to k-Character Substitutions. (arXiv:2108.13659v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13659","description":"<p>Given a word binary relation $\\tau$ we define a $\\tau$-Gray cycle over a\nfinite language $X$ to be a permutation $\\left(w_{[i]}\\right)_{0\\le i\\le\n|X|-1}$ of $X$ such that each word $w_i$ is an image of the previous word\n$w_{i-1}$ by $\\tau$. In that framework, we introduce the complexity measure\n$\\lambda(n)$, equal to the largest cardinality of a language $X$ having words\nof length at most $n$, and such that a $\\tau$-Gray cycle over $X$ exists. The\npresent paper is concerned with the relation $\\tau=\\sigma_k$, the so-called\n$k$-character substitution, where $(u,v)$ belongs to $\\sigma_k$ if, and only\nif, the Hamming distance of $u$ and $v$ is $k$. We compute the bound\n$\\lambda(n)$ for all cases of the alphabet cardinality and the argument $n$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Neraud_J/0/1/0/all/0/1\">Jean N&#xe9;raud</a> (LITIS, UNIROUEN)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-Oriented Dialogue System as Natural Language Generation. (arXiv:2108.13679v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13679","description":"<p>In this paper, we propose to formulate the task-oriented dialogue system as\nthe purely natural language generation task, so as to fully leverage the\nlarge-scale pre-trained models like GPT-2 and simplify complicated\ndelexicalization prepossessing. However, directly applying this method heavily\nsuffers from the dialogue entity inconsistency caused by the removal of\ndelexicalized tokens, as well as the catastrophic forgetting problem of the\npre-trained model during fine-tuning, leading to unsatisfactory performance. To\nalleviate these problems, we design a novel GPT-Adapter-CopyNet network, which\nincorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve\nbetter performance on transfer learning and dialogue entity generation.\nExperimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ\ndataset demonstrate that our proposed approach significantly outperforms\nbaseline models with a remarkable performance on automatic and human\nevaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weizhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Junliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Boxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization. (arXiv:2108.13684v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13684","description":"<p>Despite recent progress in abstractive summarization, systems still suffer\nfrom faithfulness errors. While prior work has proposed models that improve\nfaithfulness, it is unclear whether the improvement comes from an increased\nlevel of extractiveness of the model outputs as one naive way to improve\nfaithfulness is to make summarization models more extractive. In this work, we\npresent a framework for evaluating the effective faithfulness of summarization\nsystems, by generating a faithfulnessabstractiveness trade-off curve that\nserves as a control at different operating points on the abstractiveness\nspectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as\nwell as a recently proposed method for improving faithfulness, are both worse\nthan the control at the same level of abstractiveness. Finally, we learn a\nselector to identify the most faithful and abstractive summary for a given\ndocument, and show that this system can attain higher faithfulness scores in\nhuman evaluations while being more abstractive than the baseline system on two\ndatasets. Moreover, we show that our system is able to achieve a better\nfaithfulness-abstractiveness trade-off than the control at the same level of\nabstractiveness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1\">Claire Cardie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection. (arXiv:2108.13686v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13686","description":"<p>Knowledge-grounded dialogue is a task of generating a fluent and informative\nresponse based on both conversation context and a collection of external\nknowledge, in which knowledge selection plays an important role and attracts\nmore and more research interest. However, most existing models either select\nonly one knowledge or use all knowledge for responses generation. The former\nmay lose valuable information in discarded knowledge, while the latter may\nbring a lot of noise. At the same time, many approaches need to train the\nknowledge selector with knowledge labels that indicate ground-truth knowledge,\nbut these labels are difficult to obtain and require a large number of manual\nannotations. Motivated by these issues, we propose Knoformer, a dialogue\nresponse generation model based on reinforcement learning, which can\nautomatically select one or more related knowledge from the knowledge pool and\ndoes not need knowledge labels during training. Knoformer is evaluated on two\nknowledge-guided conversation datasets, and achieves state-of-the-art\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shilei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bochao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1\">Feiliang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TNNT: The Named Entity Recognition Toolkit. (arXiv:2108.13700v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13700","description":"<p>Extraction of categorised named entities from text is a complex task given\nthe availability of a variety of Named Entity Recognition (NER) models and the\nunstructured information encoded in different source document formats.\nProcessing the documents to extract text, identifying suitable NER models for a\ntask, and obtaining statistical information is important in data analysis to\nmake informed decisions. This paper presents TNNT, a toolkit that automates the\nextraction of categorised named entities from unstructured information encoded\nin source documents, using diverse state-of-the-art Natural Language Processing\n(NLP) tools and NER models. TNNT integrates 21 different NER models as part of\na Knowledge Graph Construction Pipeline (KGCP) that takes a document set as\ninput and processes it based on the defined settings, applying the selected\nblocks of NER models to output the results. The toolkit generates all results\nwith an integrated summary of the extracted entities, enabling enhanced data\nanalysis to support the KGCP, and also, to aid further NLP tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1\">Sandaru Seneviratne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendez_S/0/1/0/all/0/1\">Sergio J. Rodr&#xed;guez M&#xe9;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuecheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omran_P/0/1/0/all/0/1\">Pouya G. Omran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_K/0/1/0/all/0/1\">Kerry Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haller_A/0/1/0/all/0/1\">Armin Haller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Plan-then-Generate: Controlled Data-to-Text Generation via Planning. (arXiv:2108.13740v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13740","description":"<p>Recent developments in neural networks have led to the advance in\ndata-to-text generation. However, the lack of ability of neural models to\ncontrol the structure of generated output can be limiting in certain real-world\napplications. In this study, we propose a novel Plan-then-Generate (PlanGen)\nframework to improve the controllability of neural data-to-text models.\nExtensive experiments and analyses are conducted on two benchmark datasets,\nToTTo and WebNLG. The results show that our model is able to control both the\nintra-sentence and inter-sentence structure of the generated output.\nFurthermore, empirical comparisons against previous state-of-the-art methods\nshow that our model improves the generation quality as well as the output\ndiversity as judged by human and automatic evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandyke_D/0/1/0/all/0/1\">David Vandyke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sihui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yimai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Monolingual versus Multilingual BERTology for Vietnamese Extractive Multi-Document Summarization. (arXiv:2108.13741v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13741","description":"<p>Recent researches have demonstrated that BERT shows potential in a wide range\nof natural language processing tasks. It is adopted as an encoder for many\nstate-of-the-art automatic summarizing systems, which achieve excellent\nperformance. However, so far, there is not much work done for Vietnamese. In\nthis paper, we showcase how BERT can be implemented for extractive text\nsummarization in Vietnamese. We introduce a novel comparison between different\nmultilingual and monolingual BERT models. The experiment results indicate that\nmonolingual models produce promising results compared to other multilingual\nmodels and previous text summarizing models for Vietnamese.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Quoc_H/0/1/0/all/0/1\">Huy To Quoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1\">Anh Gia-Tuan Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Search Engine for Discovery of Biomedical Challenges and Directions. (arXiv:2108.13751v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13751","description":"<p>The ability to keep track of scientific challenges, advances and emerging\ndirections is a fundamental part of research. However, researchers face a flood\nof papers that hinders discovery of important knowledge. In biomedicine, this\ndirectly impacts human lives. To address this problem, we present a novel task\nof extraction and search of scientific challenges and directions, to facilitate\nrapid knowledge discovery. We construct and release an expert-annotated corpus\nof texts sampled from full-length papers, labeled with novel semantic\ncategories that generalize across many types of challenges and directions. We\nfocus on a large corpus of interdisciplinary work relating to the COVID-19\npandemic, ranging from biomedicine to areas such as AI and economics. We apply\na model trained on our data to identify challenges and directions across the\ncorpus and build a dedicated search engine for this information. In studies\nwith researchers, including those working directly on COVID-19, we outperform a\npopular scientific search engine in assisting knowledge discovery. Finally, we\nshow that models trained on our resource generalize to the wider biomedical\ndomain, highlighting its broad utility. We make our data, model and search\nengine publicly available. https://challenges.apps.allenai.org\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lahav_D/0/1/0/all/0/1\">Dan Lahav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falcon_J/0/1/0/all/0/1\">Jon Saad Falcon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1\">Bailey Kuehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1\">Sophie Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parasa_S/0/1/0/all/0/1\">Sravanthi Parasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shomron_N/0/1/0/all/0/1\">Noam Shomron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel S. Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enjoy the Salience: Towards Better Transformer-based Faithful Explanations with Word Salience. (arXiv:2108.13759v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13759","description":"<p>Pretrained transformer-based models such as BERT have demonstrated\nstate-of-the-art predictive performance when adapted into a range of natural\nlanguage processing tasks. An open problem is how to improve the faithfulness\nof explanations (rationales) for the predictions of these models. In this\npaper, we hypothesize that salient information extracted a priori from the\ntraining data can complement the task-specific information learned by the model\nduring fine-tuning on a downstream task. In this way, we aim to help BERT not\nto forget assigning importance to informative input tokens when making\npredictions by proposing SaLoss; an auxiliary loss function for guiding the\nmulti-head attention mechanism during training to be close to salient\ninformation extracted a priori using TextRank. Experiments for explanation\nfaithfulness across five datasets, show that models trained with SaLoss\nconsistently provide more faithful explanations across four different feature\nattribution methods compared to vanilla BERT. Using the rationales extracted\nfrom vanilla BERT and SaLoss models to train inherently faithful classifiers,\nwe further show that the latter result in higher predictive performance in\ndownstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chrysostomou_G/0/1/0/all/0/1\">George Chrysostomou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The five Is: Key principles for interpretable and safe conversational AI. (arXiv:2108.13766v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13766","description":"<p>In this position paper, we present five key principles, namely\ninterpretability, inherent capability to explain, independent data, interactive\nlearning, and inquisitiveness, for the development of conversational AI that,\nunlike the currently popular black box approaches, is transparent and\naccountable. At present, there is a growing concern with the use of black box\nstatistical language models: While displaying impressive average performance,\nsuch systems are also prone to occasional spectacular failures, for which there\nis no clear remedy. In an effort to initiate a discussion on possible\nalternatives, we outline and exemplify how our five principles enable the\ndevelopment of conversational AI systems that are transparent and thus safer\nfor use. We also present some of the challenges inherent in the implementation\nof those principles.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wahde_M/0/1/0/all/0/1\">Mattias Wahde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Virgolin_M/0/1/0/all/0/1\">Marco Virgolin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Network psychometrics and cognitive network science open new ways for detecting, understanding and tackling the complexity of math anxiety: A review. (arXiv:2108.13800v1 [cs.SI])","link":"http://arxiv.org/abs/2108.13800","description":"<p>Math anxiety is a clinical pathology impairing cognitive processing in\nmath-related contexts. Originally thought to affect only inexperienced,\nlow-achieving students, recent investigations show how math anxiety is vastly\ndiffused even among high-performing learners. This review of data-informed\nstudies outlines math anxiety as a complex system that: (i) cripples\nwell-being, self-confidence and information processing on both conscious and\nsubconscious levels, (ii) can be transmitted by social interactions, like a\npathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of\nstudents in 63 out of 64 worldwide educational systems but correlates weakly\nwith academic performance, and (iv) poses a concrete threat to students'\nwell-being, computational literacy and career prospects in science. These\npatterns underline the crucial need to go beyond performance for estimating\nmath anxiety. Recent advances with network psychometrics and cognitive network\nscience provide ideal frameworks for detecting, interpreting and intervening\nupon such clinical condition. Merging education research, psychology and data\nscience, the approaches reviewed here reconstruct psychological constructs as\ncomplex systems, represented either as multivariate correlation models (e.g.\ngraph exploratory analysis) or as cognitive networks of semantic/emotional\nassociations (e.g. free association networks or forma mentis networks). Not\nonly can these interconnected networks detect otherwise hidden levels of math\nanxiety but - more crucially - they can unveil the specific layout of\ninteracting factors, e.g. key sources and targets, behind math anxiety in a\ngiven cohort. As discussed here, these network approaches open concrete ways\nfor unveiling students' perceptions, emotions and mental well-being, and can\nenable future powerful data-informed interventions untangling math anxiety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stella_M/0/1/0/all/0/1\">Massimo Stella</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues. (arXiv:2108.13811v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13811","description":"<p>The goal of dialogue relation extraction (DRE) is to identify the relation\nbetween two entities in a given dialogue. During conversations, speakers may\nexpose their relations to certain entities by some clues, such evidences called\n\"triggers\". However, none of the existing work on DRE tried to detect triggers\nand leverage the information for enhancing the performance. This paper proposes\nTREND, a multi-tasking BERT-based model which learns to identify triggers for\nimproving relation extraction. The experimental results show that the proposed\nmethod achieves the state-of-the-art on the benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Po-Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Shang-Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Open-Domain Question Answering. (arXiv:2108.13817v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13817","description":"<p>Open-domain Question Answering (ODQA) has achieved significant results in\nterms of supervised learning manner. However, data annotation cannot also be\nirresistible for its huge demand in an open domain. Though unsupervised QA or\nunsupervised Machine Reading Comprehension (MRC) has been tried more or less,\nunsupervised ODQA has not been touched according to our best knowledge. This\npaper thus pioneers the work of unsupervised ODQA by formally introducing the\ntask and proposing a series of key data construction methods. Our exploration\nin this work inspiringly shows unsupervised ODQA can reach up to 86%\nperformance of supervised ones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1\">Pengfei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Domain Adaptation for Question Answering using Limited Text Corpora. (arXiv:2108.13854v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13854","description":"<p>Question generation has recently shown impressive results in customizing\nquestion answering (QA) systems to new domains. These approaches circumvent the\nneed for manually annotated training data from the new domain and, instead,\ngenerate synthetic question-answer pairs that are used for training. However,\nexisting methods for question generation rely on large amounts of synthetically\ngenerated datasets and costly computational resources, which render these\ntechniques widely inaccessible when the text corpora is of limited size. This\nis problematic as many niche domains rely on small text corpora, which\nnaturally restricts the amount of synthetic data that can be generated. In this\npaper, we propose a novel framework for domain adaptation called contrastive\ndomain adaptation for QA (CAQA). Specifically, CAQA combines techniques from\nquestion generation and domain-invariant learning to answer out-of-domain\nquestions in settings with limited text corpora. Here, we train a QA system on\nboth source data and generated data from the target domain with a contrastive\nadaptation loss that is incorporated in the training objective. By combining\ntechniques from question generation and domain-invariant learning, our model\nachieved considerable improvements compared to state-of-the-art baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1\">Zhenrui Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kratzwald_B/0/1/0/all/0/1\">Bernhard Kratzwald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Model Extraction: Imitation Attack for Black-Box NLP APIs. (arXiv:2108.13873v1 [cs.CR])","link":"http://arxiv.org/abs/2108.13873","description":"<p>Machine-learning-as-a-service (MLaaS) has attracted millions of users to\ntheir outperforming sophisticated models. Although published as black-box APIs,\nthe valuable models behind these services are still vulnerable to imitation\nattacks. Recently, a series of works have demonstrated that attackers manage to\nsteal or extract the victim models. Nonetheless, none of the previous stolen\nmodels can outperform the original black-box APIs. In this work, we take the\nfirst step of showing that attackers could potentially surpass victims via\nunsupervised domain adaptation and multi-victim ensemble. Extensive experiments\non benchmark datasets and real-world APIs validate that the imitators can\nsucceed in outperforming the original black-box models. We consider this as a\nmilestone in the research of imitation attack, especially on NLP APIs, as the\nsuperior performance could influence the defense or even publishing strategy of\nAPI providers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiongkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1\">Lingjuan Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13875","description":"<p>Scenario-based question answering (SQA) requires retrieving and reading\nparagraphs from a large corpus to answer a question which is contextualized by\na long scenario description. Since a scenario contains both keyphrases for\nretrieval and much noise, retrieval for SQA is extremely difficult. Moreover,\nit can hardly be supervised due to the lack of relevance labels of paragraphs\nfor SQA. To meet the challenge, in this paper we propose a joint\nretriever-reader model called JEEVES where the retriever is implicitly\nsupervised only using QA labels via a novel word weighting mechanism. JEEVES\nsignificantly outperforms a variety of strong baselines on multiple-choice\nquestions in three SQA datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zixian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Ao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yulin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1\">Gong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yuzhong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning. (arXiv:2108.13888v1 [cs.CR])","link":"http://arxiv.org/abs/2108.13888","description":"<p>\\textbf{P}re-\\textbf{T}rained \\textbf{M}odel\\textbf{s} have been widely\napplied and recently proved vulnerable under backdoor attacks: the released\npre-trained weights can be maliciously poisoned with certain triggers. When the\ntriggers are activated, even the fine-tuned model will predict pre-defined\nlabels, causing a security threat. These backdoors generated by the poisoning\nmethods can be erased by changing hyper-parameters during fine-tuning or\ndetected by finding the triggers. In this paper, we propose a stronger\nweight-poisoning attack method that introduces a layerwise weight poisoning\nstrategy to plant deeper backdoors; we also introduce a combinatorial trigger\nthat cannot be easily detected. The experiments on text classification tasks\nshow that previous defense methods cannot resist our weight-poisoning method,\nwhich indicates that our method can be widely applied and may provide hints for\nfuture model robustness studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Demin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiehang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Ruotian Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Like Article, Like Audience: Enforcing Multimodal Correlations for Disinformation Detection. (arXiv:2108.13892v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13892","description":"<p>User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Allein_L/0/1/0/all/0/1\">Liesbeth Allein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perrotta_D/0/1/0/all/0/1\">Domenico Perrotta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset. (arXiv:2108.13897v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13897","description":"<p>The MS MARCO ranking dataset has been widely used for training deep learning\nmodels for IR tasks, achieving considerable effectiveness on diverse zero-shot\nscenarios. However, this type of resource is scarce in other languages than\nEnglish. In this work we present mMARCO, a multilingual version of the MS MARCO\npassage ranking dataset comprising 8 languages that was created using machine\ntranslation. We evaluated mMARCO by fine-tuning mono and multilingual\nre-ranking models on it. Experimental results demonstrate that multilingual\nmodels fine-tuned on our translated dataset achieve superior effectiveness than\nmodels fine-tuned on the original English version alone. Also, our distilled\nmultilingual re-ranker is competitive with non-distilled models while having\n5.4 times fewer parameters. The translated datasets as well as fine-tuned\nmodels are available at https://github.com/unicamp-dl/mMARCO.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bonifacio_L/0/1/0/all/0/1\">Luiz Henrique Bonifacio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campiotti_I/0/1/0/all/0/1\">Israel Campiotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotufo_R/0/1/0/all/0/1\">Roberto Lotufo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1\">Rodrigo Nogueira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The emojification of sentiment on social media: Collection and analysis of a longitudinal Twitter sentiment dataset. (arXiv:2108.13898v1 [cs.SI])","link":"http://arxiv.org/abs/2108.13898","description":"<p>Social media, as a means for computer-mediated communication, has been\nextensively used to study the sentiment expressed by users around events or\ntopics. There is however a gap in the longitudinal study of how sentiment\nevolved in social media over the years. To fill this gap, we develop TM-Senti,\na new large-scale, distantly supervised Twitter sentiment dataset with over 184\nmillion tweets and covering a time period of over seven years. We describe and\nassess our methodology to put together a large-scale, emoticon- and emoji-based\nlabelled sentiment analysis dataset, along with an analysis of the resulting\ndataset. Our analysis highlights interesting temporal changes, among others in\nthe increasing use of emojis over emoticons. We publicly release the dataset\nfor further research in tasks including sentiment analysis and text\nclassification of tweets. The dataset can be fully rehydrated including tweet\nmetadata and without missing tweets thanks to the archive of tweets publicly\navailable on the Internet Archive, which the dataset is based on.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhalifa_R/0/1/0/all/0/1\">Rabab Alkhalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Retrieval Augmented Generation for Zero-shot Slot Filling. (arXiv:2108.13934v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13934","description":"<p>Automatically inducing high quality knowledge graphs from a given collection\nof documents still remains a challenging problem in AI. One way to make headway\nfor this problem is through advancements in a related task known as slot\nfilling. In this task, given an entity query in form of [Entity, Slot, ?], a\nsystem is asked to fill the slot by generating or extracting the missing value\nexploiting evidence extracted from relevant passage(s) in the given document\ncollection. The recent works in the field try to solve this task in an\nend-to-end fashion using retrieval-based language models. In this paper, we\npresent a novel approach to zero-shot slot filling that extends dense passage\nretrieval with hard negatives and robust training procedures for retrieval\naugmented generation models. Our model reports large improvements on both T-REx\nand zsRE slot filling datasets, improving both passage retrieval and slot value\ngeneration, and ranking at the top-1 position in the KILT leaderboard.\nMoreover, we demonstrate the robustness of our system showing its domain\nadaptation capability on a new variant of the TACRED dataset for slot filling,\nthrough a combination of zero/few-shot learning. We release the source code and\npre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1\">Michael Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1\">Gaetano Rossiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Md Faisal Mahbub Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1\">Alfio Gliozzo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Thermostat: A Large Collection of NLP Model Explanations and Analysis Tools. (arXiv:2108.13961v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13961","description":"<p>In the language domain, as in other domains, neural explainability takes an\never more important role, with feature attribution methods on the forefront.\nMany such methods require considerable computational resources and expert\nknowledge about implementation details and parameter choices. To facilitate\nresearch, we present Thermostat which consists of a large collection of model\nexplanations and accompanying analysis tools. Thermostat allows easy access to\nover 200k explanations for the decisions of prominent state-of-the-art models\nspanning across different NLP tasks, generated with multiple explainers. The\ndataset took over 10k GPU hours (&gt; one year) to compile; compute time that the\ncommunity now saves. The accompanying software tools allow to analyse\nexplanations instance-wise but also accumulatively on corpus level. Users can\ninvestigate and compare models, datasets and explainers without the need to\norchestrate implementation details. Thermostat is fully open source,\ndemocratizes explainability research in the language domain, circumvents\nredundant computations and increases comparability and replicability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feldhus_N/0/1/0/all/0/1\">Nils Feldhus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwarzenberg_R/0/1/0/all/0/1\">Robert Schwarzenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moller_S/0/1/0/all/0/1\">Sebastian M&#xf6;ller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective Sequence-to-Sequence Dialogue State Tracking. (arXiv:2108.13990v1 [cs.CL])","link":"http://arxiv.org/abs/2108.13990","description":"<p>Sequence-to-sequence models have been applied to a wide variety of NLP tasks,\nbut how to properly use them for dialogue state tracking has not been\nsystematically investigated. In this paper, we study this problem from the\nperspectives of pre-training objectives as well as the formats of context\nrepresentations. We demonstrate that the choice of pre-training objective makes\na significant difference to the state tracking quality. In particular, we find\nthat masked span prediction is more effective than auto-regressive language\nmodeling. We also explore using Pegasus, a span prediction-based pre-training\nobjective for text summarization, for the state tracking model. We found that\npre-training for the seemingly distant summarization task works surprisingly\nwell for dialogue state tracking. In addition, we found that while recurrent\nstate context representation works also reasonably well, the model may have a\nhard time recovering from earlier mistakes. We conducted experiments on the\nMultiWOZ 2.1-2.4 data sets with consistent observations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jeffrey Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahdieh_M/0/1/0/all/0/1\">Mahdis Mahdieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ye Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Generative Approach for Mitigating Structural Biases in Natural Language Inference. (arXiv:2108.14006v1 [cs.CL])","link":"http://arxiv.org/abs/2108.14006","description":"<p>Many natural language inference (NLI) datasets contain biases that allow\nmodels to perform well by only using a biased subset of the input, without\nconsidering the remainder features. For instance, models are able to make a\nclassification decision by only using the hypothesis, without learning the true\nrelationship between it and the premise. These structural biases lead\ndiscriminative models to learn unintended superficial features and to\ngeneralize poorly out of the training distribution. In this work, we\nreformulate the NLI task as a generative task, where a model is conditioned on\nthe biased subset of the input and the label and generates the remaining subset\nof the input. We show that by imposing a uniform prior, we obtain a provably\nunbiased model. Through synthetic experiments, we find that this approach is\nhighly robust to large amounts of bias. We then demonstrate empirically on two\ntypes of natural bias that this approach leads to fully unbiased models in\npractice. However, we find that generative models are difficult to train and\nthey generally perform worse than discriminative baselines. We highlight the\ndifficulty of the generative modeling task in the context of NLI as a cause for\nthis worse performance. Finally, by fine-tuning the generative model with a\ndiscriminative objective, we reduce the performance gap between the generative\nmodel and the discriminative baseline, while allowing for a small amount of\nbias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Asael_D/0/1/0/all/0/1\">Dimion Asael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziegler_Z/0/1/0/all/0/1\">Zachary Ziegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HUMBO: Bridging Response Generation and Facial Expression Synthesis. (arXiv:1905.11240v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1905.11240","description":"<p>Spoken dialogue systems that assist users to solve complex tasks such as\nmovie ticket booking have become an emerging research topic in artificial\nintelligence and natural language processing areas. With a well-designed\ndialogue system as an intelligent personal assistant, people can accomplish\ncertain tasks more easily via natural language interactions. Today there are\nseveral virtual intelligent assistants in the market; however, most systems\nonly focus on textual or vocal interaction. In this paper, we present HUMBO, a\nsystem aiming at generating dialogue responses and simultaneously synthesize\ncorresponding visual expressions on faces for better multimodal interaction.\nHUMBO can (1) let users determine the appearances of virtual assistants by a\nsingle image, and (2) generate coherent emotional utterances and facial\nexpressions on the user-provided image. This is not only a brand new research\ndirection but more importantly, an ultimate step toward more human-like virtual\nassistants.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Shang-Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Po-Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning Visual Dialog with Sparse Graph Learning and Knowledge Transfer. (arXiv:2004.06698v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2004.06698","description":"<p>Visual dialog is a task of answering a sequence of questions grounded in an\nimage using the previous dialog history as context. In this paper, we study how\nto address two fundamental challenges for this task: (1) reasoning over\nunderlying semantic structures among dialog rounds and (2) identifying several\nappropriate answers to the given question. To address these challenges, we\npropose a Sparse Graph Learning (SGL) method to formulate visual dialog as a\ngraph structure learning task. SGL infers inherently sparse dialog structures\nby incorporating binary and score edges and leveraging a new structural loss\nfunction. Next, we introduce a Knowledge Transfer (KT) method that extracts the\nanswer predictions from the teacher model and uses them as pseudo labels. We\npropose KT to remedy the shortcomings of single ground-truth labels, which\nseverely limit the ability of a model to obtain multiple reasonable answers. As\na result, our proposed model significantly improves reasoning capability\ncompared to baseline methods and outperforms the state-of-the-art approaches on\nthe VisDial v1.0 dataset. The source code is available at\nhttps://github.com/gicheonkang/SGLKT-VisDial.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1\">Gi-Cheon Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Junseok Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwaran Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Byoung-Tak Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin-Hwa Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural CRF Model for Sentence Alignment in Text Simplification. (arXiv:2005.02324v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2005.02324","description":"<p>The success of a text simplification system heavily depends on the quality\nand quantity of complex-simple sentence pairs in the training corpus, which are\nextracted by aligning sentences between parallel articles. To evaluate and\nimprove sentence alignment quality, we create two manually annotated\nsentence-aligned datasets from two commonly used text simplification corpora,\nNewsela and Wikipedia. We propose a novel neural CRF alignment model which not\nonly leverages the sequential nature of sentences in parallel documents but\nalso utilizes a neural sentence pair model to capture semantic similarity.\nExperiments demonstrate that our proposed approach outperforms all the previous\nwork on monolingual sentence alignment task by more than 5 points in F1. We\napply our CRF aligner to construct two new text simplification datasets,\nNewsela-Auto and Wiki-Auto, which are much larger and of better quality\ncompared to the existing datasets. A Transformer-based seq2seq model trained on\nour datasets establishes a new state-of-the-art for text simplification in both\nautomatic and human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Chao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddela_M/0/1/0/all/0/1\">Mounica Maddela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1\">Wuwei Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue Response Selection with Hierarchical Curriculum Learning. (arXiv:2012.14756v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.14756","description":"<p>We study the learning of a matching model for dialogue response selection.\nMotivated by the recent finding that models trained with random negative\nsamples are not ideal in real-world scenarios, we propose a hierarchical\ncurriculum learning framework that trains the matching model in an\n\"easy-to-difficult\" scheme. Our learning framework consists of two\ncomplementary curricula: (1) corpus-level curriculum (CC); and (2)\ninstance-level curriculum (IC). In CC, the model gradually increases its\nability in finding the matching clues between the dialogue context and a\nresponse candidate. As for IC, it progressively strengthens the model's ability\nin identifying the mismatching information between the dialogue context and a\nresponse candidate. Empirical studies on three benchmark datasets with three\nstate-of-the-art matching models demonstrate that the proposed learning\nframework significantly improves the model performance across various\nevaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zibo Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baker_S/0/1/0/all/0/1\">Simon Baker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Transformer-Based Generation of Radiology Reports. (arXiv:2102.09777v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.09777","description":"<p>Inspired by Curriculum Learning, we propose a consecutive (i.e.,\nimage-to-text-to-text) generation framework where we divide the problem of\nradiology report generation into two steps. Contrary to generating the full\nradiology report from the image at once, the model generates global concepts\nfrom the image in the first step and then reforms them into finer and coherent\ntexts using a transformer architecture. We follow the transformer-based\nsequence-to-sequence paradigm at each step. We improve upon the\nstate-of-the-art on two benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nooralahzadeh_F/0/1/0/all/0/1\">Farhad Nooralahzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_N/0/1/0/all/0/1\">Nicolas Perez Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frauenfelder_T/0/1/0/all/0/1\">Thomas Frauenfelder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_K/0/1/0/all/0/1\">Koji Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for Unsupervised Sentence Embedding Learning. (arXiv:2104.06979v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06979","description":"<p>Learning sentence embeddings often requires a large amount of labeled data.\nHowever, for most tasks and domains, labeled data is seldom available and\ncreating it is expensive. In this work, we present a new state-of-the-art\nunsupervised method based on pre-trained Transformers and Sequential Denoising\nAuto-Encoder (TSDAE) which outperforms previous approaches by up to 6.4 points.\nIt can achieve up to 93.1% of the performance of in-domain supervised\napproaches. Further, we show that TSDAE is a strong domain adaptation and\npre-training method for sentence embeddings, significantly outperforming other\napproaches like Masked Language Model.\n</p>\n<p>A crucial shortcoming of previous studies is the narrow evaluation: Most work\nmainly evaluates on the single task of Semantic Textual Similarity (STS), which\ndoes not require any domain knowledge. It is unclear if these proposed methods\ngeneralize to other domains and tasks. We fill this gap and evaluate TSDAE and\nother recent approaches on four different datasets from heterogeneous domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kexin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Surface Form Competition: Why the Highest Probability Answer Isn't Always Right. (arXiv:2104.08315v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08315","description":"<p>Large language models have shown promising results in zero-shot settings\n(Brown et al.,2020; Radford et al., 2019). For example, they can perform\nmultiple choice tasks simply by conditioning on a question and selecting the\nanswer with the highest probability.\n</p>\n<p>However, ranking by string probability can be problematic due to surface form\ncompetition-wherein different surface forms compete for probability mass, even\nif they represent the same underlying concept, e.g. \"computer\" and \"PC.\" Since\nprobability mass is finite, this lowers the probability of the correct answer,\ndue to competition from other strings that are valid answers (but not one of\nthe multiple choice options).\n</p>\n<p>We introduce Domain Conditional Pointwise Mutual Information, an alternative\nscoring function that directly compensates for surface form competition by\nsimply reweighing each option according to a term that is proportional to its a\npriori likelihood within the context of the specific zero-shot task. It\nachieves consistent gains in zero-shot performance over both calibrated (Zhao\net al., 2021) and uncalibrated scoring functions on all GPT-2 and GPT-3 models\nover a variety of multiple choice datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1\">Ari Holtzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SimCSE: Simple Contrastive Learning of Sentence Embeddings. (arXiv:2104.08821v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08821","description":"<p>This paper presents SimCSE, a simple contrastive learning framework that\ngreatly advances the state-of-the-art sentence embeddings. We first describe an\nunsupervised approach, which takes an input sentence and predicts itself in a\ncontrastive objective, with only standard dropout used as noise. This simple\nmethod works surprisingly well, performing on par with previous supervised\ncounterparts. We hypothesize that dropout acts as minimal data augmentation and\nremoving it leads to a representation collapse. Then, we incorporate annotated\npairs from natural language inference datasets into our contrastive learning\nframework, by using \"entailment\" pairs as positives and \"contradiction\" pairs\nas hard negatives. We evaluate SimCSE on standard semantic textual similarity\n(STS) tasks, and our unsupervised and supervised models using BERT-base achieve\nan average of 76.3% and 81.6% Spearman's correlation respectively, a 4.2 and\n2.2 points improvement compared to previous best results. We also show -- both\ntheoretically and empirically -- that contrastive learning objective\nregularizes pre-trained embeddings' anisotropic space to be more uniform, and\nit better aligns positive pairs when supervised signals are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xingcheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction. (arXiv:2106.04847v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.04847","description":"<p>Keyphrase Prediction (KP) task aims at predicting several keyphrases that can\nsummarize the main idea of the given document. Mainstream KP methods can be\ncategorized into purely generative approaches and integrated models with\nextraction and generation. However, these methods either ignore the diversity\namong keyphrases or only weakly capture the relation across tasks implicitly.\nIn this paper, we propose UniKeyphrase, a novel end-to-end learning framework\nthat jointly learns to extract and generate keyphrases. In UniKeyphrase,\nstacked relation layer and bag-of-words constraint are proposed to fully\nexploit the latent semantic relation between extraction and generation in the\nview of model structure and training process, respectively. Experiments on KP\nbenchmarks demonstrate that our joint approach outperforms mainstream methods\nby a large margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Huanqin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_D/0/1/0/all/0/1\">Dan Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Feng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.03158","description":"<p>Data augmentation, the artificial creation of training data for machine\nlearning by transformations, is a widely studied research field across machine\nlearning disciplines. While it is useful for increasing the generalization\ncapabilities of a model, it can also address many other challenges and\nproblems, from overcoming a limited amount of training data over regularizing\nthe objective to limiting the amount data used to protect privacy. Based on a\nprecise description of the goals and applications of data augmentation (C1) and\na taxonomy for existing works (C2), this survey is concerned with data\naugmentation methods for textual classification and aims to achieve a concise\nand comprehensive overview for researchers and practitioners (C3). Derived from\nthe taxonomy, we divided more than 100 methods into 12 different groupings and\nprovide state-of-the-art references expounding which methods are highly\npromising (C4). Finally, research perspectives that may constitute a building\nblock for future work are given (C5).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bayer_M/0/1/0/all/0/1\">Markus Bayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufhold_M/0/1/0/all/0/1\">Marc-Andr&#xe9; Kaufhold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuter_C/0/1/0/all/0/1\">Christian Reuter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.12079","description":"<p>Dialogue systems are widely used in AI to support timely and interactive\ncommunication with users. We propose a general-purpose dialogue system\narchitecture that leverages computational argumentation to perform reasoning\nand provide consistent and explainable answers. We illustrate the system using\na COVID-19 vaccine information case study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fazzinga_B/0/1/0/all/0/1\">Bettina Fazzinga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galassi_A/0/1/0/all/0/1\">Andrea Galassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torroni_P/0/1/0/all/0/1\">Paolo Torroni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Goal-Oriented Script Construction. (arXiv:2107.13189v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.13189","description":"<p>The knowledge of scripts, common chains of events in stereotypical scenarios,\nis a valuable asset for task-oriented natural language understanding systems.\nWe propose the Goal-Oriented Script Construction task, where a model produces a\nsequence of steps to accomplish a given goal. We pilot our task on the first\nmultilingual script learning dataset supporting 18 languages collected from\nwikiHow, a website containing half a million how-to articles. For baselines, we\nconsider both a generation-based approach using a language model and a\nretrieval-based approach by first retrieving the relevant steps from a large\ncandidate pool and then ordering them. We show that our task is practical,\nfeasible but challenging for state-of-the-art Transformer models, and that our\nmethods can be readily deployed for various other datasets and domains with\ndecent zero-shot performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1\">Qing Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GENder-IT: An Annotated English-Italian Parallel Challenge Set for Cross-Linguistic Natural Gender Phenomena. (arXiv:2108.02854v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.02854","description":"<p>Languages differ in terms of the absence or presence of gender features, the\nnumber of gender classes and whether and where gender features are explicitly\nmarked. These cross-linguistic differences can lead to ambiguities that are\ndifficult to resolve, especially for sentence-level MT systems. The\nidentification of ambiguity and its subsequent resolution is a challenging task\nfor which currently there aren't any specific resources or challenge sets\navailable. In this paper, we introduce gENder-IT, an English--Italian challenge\nset focusing on the resolution of natural gender phenomena by providing\nword-level gender tags on the English source side and multiple gender\nalternative translations, where needed, on the Italian target side.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vanmassenhove_E/0/1/0/all/0/1\">Eva Vanmassenhove</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_J/0/1/0/all/0/1\">Johanna Monti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hatemoji: A Test Suite and Adversarially-Generated Dataset for Benchmarking and Detecting Emoji-based Hate. (arXiv:2108.05921v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.05921","description":"<p>Detecting online hate is a complex task, and low-performing models have\nharmful consequences when used for sensitive applications such as content\nmoderation. Emoji-based hate is a key emerging challenge for automated\ndetection. We present HatemojiCheck, a test suite of 3,930 short-form\nstatements that allows us to evaluate performance on hateful language expressed\nwith emoji. Using the test suite, we expose weaknesses in existing hate\ndetection models. To address these weaknesses, we create the HatemojiTrain\ndataset using a human-and-model-in-the-loop approach. Models trained on these\n5,912 adversarial examples perform substantially better at detecting\nemoji-based hate, while retaining strong performance on text-only hate. Both\nHatemojiCheck and HatemojiTrain are made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertram Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1\">Paul R&#xf6;ttger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1\">Tristan Thrush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CushLEPOR: Customised hLEPOR Metric Using LABSE Distilled Knowledge Model to Improve Agreement with Human Judgements. (arXiv:2108.09484v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09484","description":"<p>Human evaluation has always been expensive while researchers struggle to\ntrust the automatic metrics. To address this, we propose to customise\ntraditional metrics by taking advantages of the pre-trained language models\n(PLMs) and the limited available human labelled scores. We first re-introduce\nthe hLEPOR metric factors, followed by the Python portable version we developed\nwhich achieved the automatic tuning of the weighting parameters in hLEPOR\nmetric. Then we present the customised hLEPOR (cushLEPOR) which uses LABSE\ndistilled knowledge model to improve the metric agreement with human judgements\nby automatically optimised factor weights regarding the exact MT language pairs\nthat cushLEPOR is deployed to. We also optimise cushLEPOR towards human\nevaluation data based on MQM and pSQM framework on English-German and\nChinese-English language pairs. The experimental investigations show cushLEPOR\nboosts hLEPOR performances towards better agreements to PLMs like LABSE with\nmuch lower cost, and better agreements to human evaluations including MQM and\npSQM scores, and yields much better performances than BLEU (data available at\n\\url{https://github.com/poethan/cushLEPOR}).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorokina_I/0/1/0/all/0/1\">Irina Sorokina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erofeev_G/0/1/0/all/0/1\">Gleb Erofeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gladkoff_S/0/1/0/all/0/1\">Serge Gladkoff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sarcasm Detection in Twitter -- Performance Impact while using Data Augmentation: Word Embeddings. (arXiv:2108.09924v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09924","description":"<p>Sarcasm is the use of words usually used to either mock or annoy someone, or\nfor humorous purposes. Sarcasm is largely used in social networks and\nmicroblogging websites, where people mock or censure in a way that makes it\ndifficult even for humans to tell if what is said is what is meant. Failure to\nidentify sarcastic utterances in Natural Language Processing applications such\nas sentiment analysis and opinion mining will confuse classification algorithms\nand generate false results. Several studies on sarcasm detection have utilized\ndifferent learning algorithms. However, most of these learning models have\nalways focused on the contents of expression only, leaving the contextual\ninformation in isolation. As a result, they failed to capture the contextual\ninformation in the sarcastic expression. Moreover, some datasets used in\nseveral studies have an unbalanced dataset which impacting the model result. In\nthis paper, we propose a contextual model for sarcasm identification in twitter\nusing RoBERTa, and augmenting the dataset by applying Global Vector\nrepresentation (GloVe) for the construction of word embedding and context\nlearning to generate more data and balancing the dataset. The effectiveness of\nthis technique is tested with various datasets and data augmentation settings.\nIn particular, we achieve performance gain by 3.2% in the iSarcasm dataset when\nusing data augmentation to increase 20% of data labeled as sarcastic, resulting\nF-score of 40.4% compared to 37.2% without data augmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Handoyo_A/0/1/0/all/0/1\">Alif Tri Handoyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hidayaturrahman/0/1/0/all/0/1\">Hidayaturrahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhartono_D/0/1/0/all/0/1\">Derwin Suhartono</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query-Focused Extractive Summarisation for Finding Ideal Answers to Biomedical and COVID-19 Questions. (arXiv:2108.12189v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12189","description":"<p>This paper presents Macquarie University's participation to the BioASQ\nSynergy Task, and BioASQ9b Phase B. In each of these tasks, our participation\nfocused on the use of query-focused extractive summarisation to obtain the\nideal answers to medical questions. The Synergy Task is an end-to-end question\nanswering task on COVID-19 where systems are required to return relevant\ndocuments, snippets, and answers to a given question. Given the absence of\ntraining data, we used a query-focused summarisation system that was trained\nwith the BioASQ8b training data set and we experimented with methods to\nretrieve the documents and snippets. Considering the poor quality of the\ndocuments and snippets retrieved by our system, we observed reasonably good\nquality in the answers returned. For phase B of the BioASQ9b task, the relevant\ndocuments and snippets were already included in the test data. Our system split\nthe snippets into candidate sentences and used BERT variants under a sentence\nclassification setup. The system used the question and candidate sentence as\ninput and was trained to predict the likelihood of the candidate sentence being\npart of the ideal answer. The runs obtained either the best or second best\nROUGE-F1 results of all participants to all batches of BioASQ9b. This shows\nthat using BERT in a classification setup is a very strong baseline for the\nidentification of ideal answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Molla_D/0/1/0/all/0/1\">Diego Moll&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khanna_U/0/1/0/all/0/1\">Urvashi Khanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galat_D/0/1/0/all/0/1\">Dima Galat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vincent Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rybinski_M/0/1/0/all/0/1\">Maciej Rybinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Table-to-Text Generation with Prototype Memory. (arXiv:2108.12516v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12516","description":"<p>Neural table-to-text generation models have achieved remarkable progress on\nan array of tasks. However, due to the data-hungry nature of neural models,\ntheir performances strongly rely on large-scale training examples, limiting\ntheir applicability in real-world applications. To address this, we propose a\nnew framework: Prototype-to-Generate (P2G), for table-to-text generation under\nthe few-shot scenario. The proposed framework utilizes the retrieved\nprototypes, which are jointly selected by an IR system and a novel prototype\nselector to help the model bridging the structural gap between tables and\ntexts. Experimental results on three benchmark datasets with three\nstate-of-the-art models demonstrate that the proposed framework significantly\nimproves the model performance across various evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baker_S/0/1/0/all/0/1\">Simon Baker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12582","description":"<p>Despite the remarkable performance of large-scale generative models in\nopen-domain conversation, they are known to be less practical for building\nreal-time conversation systems due to high latency. On the other hand,\nretrieval models could return responses with much lower latency but show\ninferior performance to the large-scale generative models since the\nconversation quality is bounded by the pre-defined response set. To take\nadvantage of both approaches, we propose a new training method called G2R\n(Generative-to-Retrieval distillation) that preserves the efficiency of a\nretrieval model while leveraging the conversational ability of a large-scale\ngenerative model by infusing the knowledge of the generative model into the\nretrieval model. G2R consists of two distinct techniques of distillation: the\ndata-level G2R augments the dialogue dataset with additional responses\ngenerated by the large-scale generative model, and the model-level G2R\ntransfers the response quality score assessed by the generative model to the\nscore of the retrieval model by the knowledge distillation loss. Through\nextensive experiments including human evaluation, we demonstrate that our\nretrieval-based conversation system trained with G2R shows a substantially\nimproved performance compared to the baseline retrieval model while showing\nsignificantly lower inference latency than the large-scale generative models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Seokjun Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Seungju Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdenee_E/0/1/0/all/0/1\">Enkhbayar Erdenee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Buru Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scheduled Sampling Based on Decoding Steps for Neural Machine Translation. (arXiv:2108.12963v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12963","description":"<p>Scheduled sampling is widely used to mitigate the exposure bias problem for\nneural machine translation. Its core motivation is to simulate the inference\nscene during training by replacing ground-truth tokens with predicted tokens,\nthus bridging the gap between training and inference. However, vanilla\nscheduled sampling is merely based on training steps and equally treats all\ndecoding steps. Namely, it simulates an inference scene with uniform error\nrates, which disobeys the real inference scene, where larger decoding steps\nusually have higher error rates due to error accumulations. To alleviate the\nabove discrepancy, we propose scheduled sampling methods based on decoding\nsteps, increasing the selection chance of predicted tokens with the growth of\ndecoding steps. Consequently, we can more realistically simulate the inference\nscene during training, thus better bridging the gap between training and\ninference. Moreover, we investigate scheduled sampling based on both training\nsteps and decoding steps for further improvements. Experimentally, our\napproaches significantly outperform the Transformer baseline and vanilla\nscheduled sampling on three large-scale WMT tasks. Additionally, our approaches\nalso generalize well to the text summarization task on two popular benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13161","description":"<p>Large-scale pre-trained language models have contributed significantly to\nnatural language processing by demonstrating remarkable abilities as few-shot\nlearners. However, their effectiveness depends mainly on scaling the model\nparameters and prompt design, hindering their implementation in most real-world\napplications. This study proposes a novel pluggable, extensible, and efficient\napproach named DifferentiAble pRompT (DART), which can convert small language\nmodels into better few-shot learners without any prompt engineering. The main\nprinciple behind this approach involves reformulating potential natural\nlanguage processing tasks into the task of a pre-trained language model and\ndifferentially optimizing the prompt template as well as the target label with\nbackpropagation. Furthermore, the proposed approach can be: (i) Plugged to any\npre-trained language models; (ii) Extended to widespread classification tasks.\nA comprehensive evaluation of standard NLP tasks demonstrates that the proposed\napproach achieves a better few-shot performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luoqiu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement Types. (arXiv:2108.12971v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2108.12971","description":"<p>A smart contract is a program executed on a blockchain, based on which many\ncryptocurrencies are implemented, and is being used for automating\ntransactions. Due to the large amount of money that smart contracts deal with,\nthere is a surging demand for a method that can statically and formally verify\nthem.\n</p>\n<p>This article describes our type-based static verification tool HELMHOLTZ for\nMichelson, which is a statically typed stack-based language for writing smart\ncontracts that are executed on the blockchain platform Tezos. HELMHOLTZ is\ndesigned on top of our extension of Michelson's type system with refinement\ntypes. HELMHOLTZ takes a Michelson program annotated with a user-defined\nspecification written in the form of a refinement type as input; it then\ntypechecks the program against the specification based on the refinement type\nsystem, discharging the generated verification conditions with the SMT solver\nZ3. We briefly introduce our refinement type system for the core calculus\nMini-Michelson of Michelson, which incorporates the characteristic features\nsuch as compound datatypes (e.g., lists and pairs), higher-order functions, and\ninvocation of another contract. \\HELMHOLTZ{} successfully verifies several\npractical Michelson programs, including one that transfers money to an account\nand that checks a digital signature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nishida_Y/0/1/0/all/0/1\">Yuki Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1\">Hiromasa Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawata_A/0/1/0/all/0/1\">Akira Kawata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuse_J/0/1/0/all/0/1\">Jun Furuse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suenaga_K/0/1/0/all/0/1\">Kohei Suenaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igarashi_A/0/1/0/all/0/1\">Atsushi Igarashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-31T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}