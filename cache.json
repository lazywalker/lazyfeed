{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-06T01:56:40.168498942Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"又见Rust区块链招聘 -_-!, but 这个点进来不后悔^_^","link":"https://rustcc.cn/article?id=640daecb-eec5-4b6d-87a1-02b640bb0433","description":"<p>大家好，我们是Deeper Network, 官网是deeper.network, 一个总部位于硅谷的区块链初创企业,我们跟绝大部分区块链公司不同的是，我们有顶级的产品来支撑我们的业务和发展远景。重要的事情说三遍，有产品，有产品，有产品，而且是业界领先的产品！</p>\n<p>我们的旗舰产品Deeper Connect已经迭代到最新的第四代产品，其中Deeper Connect mini在Indiegogo平台首发，仅预售成绩就超过270万美元，在Indiegogo历史上的一百多万个项目中排名前10。(前十中的绝大部分项目都是Sony, 华为这样级别的公司)</p>\n<p>我们即将发售的最新产品pico的介绍，可以在下面找到：\nhttp://dev.deepernetwork.com:8088/down/tmp/pico.png\n世界上最小，最轻，最薄，功能最强大的网络安全+区块链产品：Deeper Connect Pico</p>\n<p>目前我们在全球150多个国家拥有20，000+的用户，30，000+节点。\n我们于2020年入选了波卡的builders program并且获得了Web 3.0基金会赞助，是波卡生态重要的一员。\n2021年，我们的区块链网络Deeper Chain获得波卡黑客松比赛的社区最佳欢迎奖和亚军。</p>\n<p>Deeper Connect + Deeper Chain是目前世界上唯一的全栈WEB3.0解决方案,包括：web3.0网关，去中心化安全网络，去中心化广告，去中心化视频点播平台，去中心化CDN等等。</p>\n<p>目前公司已经盈利，现金贮备丰厚，正在对接业界最等级的风险投资机构，处于起飞的前夕。</p>\n<p>我们希望您具有以下技能：</p>\n<p>基本要求：</p>\n<p>1、扎实的计算机科学基础知识</p>\n<p>2、动手能力强，有死磕精神</p>\n<p>3、有丰富的 Rust 开发经验</p>\n<p>4、曾经独立完成或者主导完成过具有挑战性的项目</p>\n<p>5、对工作有强大的责任心</p>\n<p>加分项：</p>\n<p>1、区块链相关数据结构与算法</p>\n<p>2、Substrate或其他区块链节点开发经验</p>\n<p>3、跨链、Layer 2 开发经验</p>\n<p>待遇：</p>\n<p>丰厚的薪资待遇：40K~80K/月</p>\n<p>灵活的工作方式：您可以在任何时间，任何地点，只要有网络就行</p>\n<p>表现合格者提供股票/币权的丰厚激励</p>\n<p>表现优异者提供美国/加拿大移民机会（目前闹瘟疫，说实话也没啥好移的）</p>\n<p>有意向的选手，请发个人简历到:jobs@deeper.network, 我们在这里等你！</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 01:21:34","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-05","link":"https://rustcc.cn/article?id=f480ea38-5b5e-423e-9c78-e78bd1344c6e","description":"<h3>rust-tui-template：使用 tui-rs 和 crossterm 引导 Rust TUI 应用程序的模板</h3>\n<p>项目结构如下：</p>\n<pre><code>src/\n├── app.rs     -&gt; holds the states and renders the widgets\n├── event.rs   -&gt; handles the terminal events (key press, mouse click, resize, etc.)\n├── handler.rs -&gt; handles the key press events and updates the application\n├── lib.rs     -&gt; module definitions\n├── main.rs    -&gt; entry-point\n└── tui.rs     -&gt; initializes/exits the terminal interface\n</code></pre>\n<p>按 README 下载执行后效果如下：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/rust-daily-20210905-1.jpg\" alt=\"\"></p>\n<p>GitHub：<a href=\"https://github.com/orhun/rust-tui-template\" rel=\"noopener noreferrer\">orhun/rust-tui-template: A template for bootstrapping a Rust TUI application with tui-rs &amp; crossterm</a></p>\n<h3>perseus：完全支持 SSR 和 SSG 的 Rust 高端前端开发框架</h3>\n<p>Perseus 是一个使用 Rust 构建的极快的前端 Web 开发框架，它支持主要的渲染策略、在没有虚拟 DOM 的情况下具有反应性，并且具有极高的可定制性。它封装了 Sycamore 的底层功能，提供了一个类似 NextJS 的 API！</p>\n<p>✨ 支持静态生成（只提供静态资源）\n✨ 支持服务端渲染（服务动态资源）\n✨ 支持一段时间后重新验证和 / 或使用自定义逻辑（更新已渲染页面）\n✨ 支持增量重建（按需构建）\n✨开放构建矩阵（主要使用任何渲染策略和其他任何东西）\n✨ CLI 工具，让您轻松自信地构建应用程序</p>\n<p>项目的主要目标是：支持每一个主要的渲染策略，并为开发人员提供使用 Rust 高效创建超快速应用程序的能力和炫酷的的开发体验！</p>\n<p>文档：<a href=\"https://arctic-hen7.github.io/perseus/\" rel=\"noopener noreferrer\">Introduction - Perseus Book</a></p>\n<p>GitHub：<a href=\"https://github.com/arctic-hen7/perseus\" rel=\"noopener noreferrer\">arctic-hen7/perseus: A high-level frontend development framework for Rust with full support for SSR and SSG.</a></p>\n<h3>Rust 构建 LC-3 虚拟机</h3>\n<p>Little Computer 3，或 LC-3，是一种计算机教育编程语言，一种汇编语言。它具有相对简单的指令集，但可用于编写中等复杂的汇编程序，是 C 编译器的可行目标。  该语言不如 x86 汇编语言复杂，但具有许多类似于更复杂语言的功能。  这些功能使其对入门教学非常有用，因此它最常用于向计算机科学和计算机工程专业的学生教授编程和计算机体系结构的基础知识。</p>\n<p>教程地址：<a href=\"https://www.rodrigoaraujo.me/posts/lets-build-an-lc-3-virtual-machine/\" rel=\"noopener noreferrer\">Let's build an LC-3 Virtual Machine :: Rodrigo Araujo — Computer Scientist and Software Engineer</a></p>\n<p>另外附上 2 个之前的一个教程：</p>\n<ul>\n<li><a href=\"https://github.com/KuldeepSinh/lc3_vm\" rel=\"noopener noreferrer\">KuldeepSinh/lc3_vm: LC-3 (Little Computer 3) VM implemented in Rust</a></li>\n<li><a href=\"https://github.com/justinmeiners/lc3-vm\" rel=\"noopener noreferrer\">justinmeiners/lc3-vm: Write your own virtual machine for the LC-3 computer!</a></li>\n</ul>\n<h3>RustGameJam 中使用的游戏引擎分布</h3>\n<p>GameJam 是一个游戏开发者的 hackathon，<a href=\"https://itch.io/jam/rusty-jam\" rel=\"noopener noreferrer\">第一届 Rust Game Jam</a> 是于2021年8月22号到8月29号举办，游戏开发者们使用的游戏引擎最多的是 Bevy，其次是 macroquad，当然还有其他引擎，比如：pixels、 RG3D、minifb。想看GameJam的游戏作品，请点击下面链接。</p>\n<ul>\n<li>https://itch.io/jam/rusty-jam</li>\n</ul>\n<h3>memuse 一个分析动态内存使用的库</h3>\n<pre><code>use memuse::DynamicUsage;\n\nassert_eq!(7u64.dynamic_usage(), 0);\nassert_eq(\"I'm simple!\".dynamic_usage(), 0);\nassert_eq(vec![7u64; 2].dynamic_usage(), 16);\n\nlet empty: Vec&lt;u32&gt; = Vec::with_capacity(100);\nassert_eq!(empty.len(), 0);\nassert_eq!(empty.dynamic_usage, 400);\n</code></pre>\n<ul>\n<li>Repo <a href=\"https://crates.io/crates/memuse\" rel=\"noopener noreferrer\">crates.io/crates/memuse</a></li>\n</ul>\n<hr>\n<p>From 日报小组   太子长琴，李冬杰</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rust.cc/\" rel=\"noopener noreferrer\">Rustcc 论坛: 支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f620\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 00:38:06","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust  ffi  link 错误","link":"https://rustcc.cn/article?id=6497a814-b6d9-4b32-9d9d-35cc2fe53845","description":"<p>Clionerror: linking with <code>link.exe</code> failed: exit code: 1112\n|\n= note: \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\n\\Tools\\MSVC\\14.25.28610\\bin\\HostX64\\x64\\link.exe\" \"/NOLOGO\" \"/NXCOMPAT\" \"\n/LIBPATH:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows\n-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\" \"D:\\rust\\test\\test11\\targe\nt\\debug\\deps\\test11.1inhodm0mguvy78p.rcgu.o\" \"D:\\rust\\test\\test11\\target<br>\n\\debug\\deps\\test11.1itxz1f879gxqo0r.rcgu.o\" \"D:\\rust\\test\\test11\\target\\d\nebug\\deps\\test11.1nfdhbezxkijr69v.rcgu.o\" \"D:\\rust\\test\\test11\\target\\deb\nug\\deps\\test11.1okn7si93kck3d1v.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\n\\deps\\test11.1r7eavti91oymq20.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\\ndeps\\test11.24nm5lpcn3t54lyd.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\de\nps\\test11.2hyws9epzawmgilt.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\n\\test11.2old9hh0jdnzckpx.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\\ntest11.3bc649uegqq66vdn.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\te\nst11.3nyjusu4bu7ihnwt.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test\n11.44jxfqx2w1so8gxa.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11\n.47a9u7imyimutge1.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4\n9azsbqjuetnb404.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4bk\nfakiuuxmwqfyp.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4mu1b\nnojyqp0utjl.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4rszv42\nzy3ba1jb2.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4t77rmx77\ntcvwir6.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4tr7ij9mclu\nclpsg.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4xi12smsmm3qs\nmbh.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4yye09rafbxycx8\n1.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.56g0yr2v0k1zblp9.\nrcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.yv2gzy9b0ix4k8o.rcg\nu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.zu1yaj42bq3ogyk.rcgu.o\n\" \"/OUT:D:\\rust\\test\\test11\\target\\debug\\deps\\test11.exe\" \"D:\\rust\\test\n\\test11\\target\\debug\\deps\\test11.sic3ibelt8jd29e.rcgu.o\" \"/OPT:REF,NOICF\" \"\n/DEBUG\" \"/NATVIS:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc\n-windows-msvc\\lib\\rustlib\\etc\\intrinsic.natvis\" \"/NATVIS:C:\\Users\\Administ\nrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\li\nballoc.natvis\" \"/NATVIS:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x8\n6_64-pc-windows-msvc\\lib\\rustlib\\etc\\libcore.natvis\" \"/NATVIS:C:\\Users\\Adm\ninistrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\et\nc\\libstd.natvis\" \"/LIBPATH:D:\\rust\\test\\test11\\target\\debug\\deps\" \"/LIBPA\nTH:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc<br>\n\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\" \"./libs/nav-apps.lib\" \"/WHOLEARCHIVE\n:./libs/nav-apps.lib\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\liblibc-bc05\nadbb061c4c16.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64\n-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libstd-1feb4ba9912f\n83e4.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-wind\nows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libpanic_unwind-10caf631bf1\n7818d.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-win\ndows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_demangle-5f5b841e\n7dcb5069.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-\nwindows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libhashbrown-886e420424\n40a542.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-wi\nndows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_std_workspace_al\nloc-fc3dfd2deda68757.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stabl\ne-x86_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libunwind-4\n765baa3d9fc6a1b.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86\n_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcfg_if-2af04b\n7075550e2b.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-p\nc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\liblibc-9f4eae3434a19\nb51.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windo\nws-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\liballoc-14b08c3097e998dc.rl\nib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msv\nc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_std_workspace_core-9c0450\nbb353ef0cc.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-p\nc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcore-4856f32e5e48b\nded.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windo\nws-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcompiler_builtins-0f66c8d\n6b2ebbbc4.rlib\" \"advapi32.lib\" \"ws2_32.lib\" \"userenv.lib\" \"msvcrt.lib\"\n= note: Non-UTF-8 output: nav-apps.lib(base64.obj) : \\xd5\\xd2\\xb5\\xbd MSIL .ne\ntmodule \\xbb\\xf2\\xca\\xb9\\xd3\\xc3 /GL \\xb1\\xe0\\xd2\\xeb\\xb5\\xc4\\xc4\\xa3\\xbf\\xe9\\xa\n3\\xbb\\xd5\\xfd\\xd4\\xda\\xca\\xb9\\xd3\\xc3 /LTCG \\xd6\\xd8\\xd0\\xc2\\xc6\\xf4\\xb6\\xaf\\xc1\n\\xb4\\xbd\\xd3\\xa3\\xbb\\xbd\\xab /LTCG \\xcc\\xed\\xbc\\xd3\\xb5\\xbd\\xc1\\xb4\\xbd\\xd3\\xc3<br>\nxfc\\xc1\\xee\\xd0\\xd0\\xd2\\xd4\\xb8\\xc4\\xbd\\xf8\\xc1\\xb4\\xbd\\xd3\\xc6\\xf7\\xd0\\xd4\\xc4<br>\nxdc\\r\\ntest11.4mu1bnojyqp0utjl.rcgu.o : error LNK2005: main \\xd2\\xd1\\xbe\\xad\\xd4\n\\xda test11.4mu1bnojyqp0utjl.rcgu.o \\xd6\\xd0\\xb6\\xa8\\xd2\\xe5\\r\\nnav-apps.lib(lib\nmysql32.dll) : fatal error LNK1112: \\xc4\\xa3\\xbf\\xe9\\xbc\\xc6\\xcb\\xe3\\xbb\\xfa\\xc0\n\\xe0\\xd0\\xcd\\xa1\\xb0x86\\xa1\\xb1\\xd3\\xeb\\xc4\\xbf\\xb1\\xea\\xbc\\xc6\\xcb\\xe3\\xbb\\xfa<br>\nxc0\\xe0\\xd0\\xcd\\xa1\\xb0x64\\xa1\\xb1\\xb3\\xe5\\xcd\\xbb\\r\\n</p>\n<p>求大佬给点提示</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-05 12:46:38","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"分享一个命令行文本美化工具库，https://crates.io/crates/colorstyle","link":"https://rustcc.cn/article?id=73d264ed-5f2d-43db-b3ec-12965ccaa550","description":"<p>ColorStyle is a library of styles for command-line text.\nUsed to modify the style of text for standard output to the terminal interface, you can change the foreground colour of the text, the background colour, add underline and bold, etc.</p>\n<p>ColorStyle 是一个用于命令行文本的样式库。\n用于标准输出到终端界面的文本的样式修改，可以修改文本前景色，背景色，增加下划线和加粗显等。</p>\n<p>可以作为一个新手docs.rs 文档编写参考。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-05 09:23:57","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"[已解决]使用rocket框架时sqlite出现的问题","link":"https://rustcc.cn/article?id=089f8f06-780e-409a-952e-fa39c2e79dc6","description":"<p>其实应该是diesel的问题\n之前sqlite缺少lib我是通过这个博客解决了问题\n<a href=\"https://blog.itdevwu.com/post/915/\" rel=\"noopener noreferrer\">解决使用Rust与Sqlite3交互时出现LNK1181错误（Diesel 或 rusqlite）</a>\n但是后面的cargo run 阶段又出现了</p>\n<pre><code>sqlite3.lib : warning LNK4272:库计算机类型“x86”与目标计算机类型“x64”冲突\n          D:\\Project\\Private\\point_plan\\target\\debug\\deps\\point_plan.exe : fatal error LNK1120: 60 个无法解析的外部命令\n</code></pre>\n<p>我明明用的是64位指令编译64位sqlite3.def得到lib的，为啥还会出现这种问题？\n麻烦弄过的这方面的朋友指点下</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-04 15:04:50","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-04","link":"https://rustcc.cn/article?id=e3c58130-184d-482b-b081-168c54694384","description":"<h3>cURL 中的 Rust</h3>\n<p>Allen Wyma 与 cURL 的原作者 Daniel 谈论在 cURL 中使用 Rust。</p>\n<ul>\n<li>cURL 是一个命令行工具和库，用于通过 URL 传输数据。</li>\n<li>cURL 及其数据传输核心 libcurl 都是用 C 编写的，众所周知，这不是内存安全的。</li>\n<li>虽然几乎不可能将其重写为另一种语言，但提供一个用 Rust 编写的第三方库可能会更进一步。</li>\n</ul>\n<p><a href=\"https://rustacean-station.org/episode/035-daniel-stenberg/\" rel=\"noopener noreferrer\">文章链接</a>，https://rustacean-station.org/episode/035-daniel-stenberg/</p>\n<h3>NoProto：灵活、快速和紧凑的序列化和rpc</h3>\n<ul>\n<li>\n<p>轻量</p>\n<ul>\n<li>零依赖</li>\n<li>支持no_std，WASM</li>\n<li>最紧凑的非编译存储格式</li>\n</ul>\n</li>\n<li>\n<p>稳定...</p>\n</li>\n</ul>\n<p><a href=\"https://github.com/only-cliches/NoProto\" rel=\"noopener noreferrer\">Gitlab 链接</a>，https://github.com/only-cliches/NoProto</p>\n<h3>gradient介绍</h3>\n<p>用于玩颜色渐变的命令行工具</p>\n<p>Features:</p>\n<ul>\n<li>许多预设渐变。</li>\n<li>自定义渐变。</li>\n<li>从 SVG 和 GIMP 渐变 (ggr) 文件中读取渐变\n...</li>\n</ul>\n<p><a href=\"https://github.com/mazznoer/gradient-rs\" rel=\"noopener noreferrer\">Gitlab 链接</a>，https://github.com/mazznoer/gradient-rs</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=dd4a77ca-2042-459e-901a-b8f9bfeb7db0\" rel=\"noopener noreferrer\">TOM</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li>[微信公众号：Rust语言中文社区](https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d88</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-04 12:51:53","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"argh：基于  derive 宏且对二进制体积进行优化的命令行解析工具","link":"https://rustcc.cn/article?id=01a3db1f-b567-47d4-9c3b-08142a11cd3e","description":"<blockquote>\n<p>Derive-based argument parsing optimized for code size and conformance to the Fuchsia commandline tools specification.</p>\n<p>基于 derive 宏的参数解析工具，针对代码大小进行了优化，并且遵循 Fuchsia 命令行工具规范。</p>\n</blockquote>\n<p>repo：<a href=\"https://github.com/google/argh\" rel=\"noopener noreferrer\">https://github.com/google/argh</a></p>\n<p>由 Google 开发者编写，但并非 Google 官方支持。</p>\n<p>官方给的基本例子：</p>\n<pre><code>use argh::FromArgs;\n\n#[derive(FromArgs)]\n/// Reach new heights.\nstruct GoUp {\n    /// whether or not to jump\n    #[argh(switch, short = 'j')]\n    jump: bool,\n\n    /// how high to go\n    #[argh(option)]\n    height: usize,\n\n    /// an optional nickname for the pilot\n    #[argh(option)]\n    pilot_nickname: Option&lt;String&gt;,\n}\n\nfn main() {\n    let up: GoUp = argh::from_env();\n}\n</code></pre>\n<pre><code>Usage: cmdname [-j] --height &lt;height&gt; [--pilot-nickname &lt;pilot-nickname&gt;]\n\nReach new heights.\n\nOptions:\n  -j, --jump        whether or not to jump\n  --height          how high to go\n  --pilot-nickname  an optional nickname for the pilot\n  --help            display usage information\n</code></pre>\n<p>过程宏-参数类型：</p>\n<ul>\n<li><code>switch</code>：用在 bool 类型的字段上，表明命令行参数是可选的，而且一旦提供该命令行参数，则给该字段的值赋给 true 。</li>\n<li><code>option</code>：\n<ul>\n<li>用在 <code>Option</code> 类型上，表明命令行参数是可选的。</li>\n<li>用在 <code>Vec</code> 类型上，表明命令行参数可选，而且可以重复出现，即这个参数及其值可以在命令行中出现 0 次或更多次。</li>\n<li>用在非 <code>Option</code> 、非 <code>Vec</code> 类型上，则表示命令行参数必选。</li>\n</ul>\n</li>\n<li><code>positional</code>：位置参数，表明按照结构体声明的字段顺序解析命令行参数，无需 <code>--xx value</code> 的 <code>--xx</code> 。最后一个位置参数可以包含默认值，也可以包装在 Option 或 Vec 中来接收可选（指 0 或 1 个）或重复（指 0 或多个）的位置参数。</li>\n<li><code>subcommand</code>：需定义一个顶层结构体、一个表示子命令的枚举体（这个枚举体列举所有子命令，子命令以结构体形式呈现，子命令结构体还需要 name 设置名称）</li>\n</ul>\n<p>过程宏-其他设置：</p>\n<ul>\n<li><code>short = 'a'</code>：解析 <code>-a</code> 形式的简短参数，只支持 ascii 的 <code>Char</code> 类型，比如大小写、数字。</li>\n<li><code>long = \"xx-xx\"</code>：重新命名这个字段的参数名称，由此可允许参数名称带连字符 <code>--xx-xx</code>。这个设置的默认值为字段名称，只支持 ascii 小写形式的名称，不支持大写和数字。</li>\n<li><code>default = \"default_height()\")</code>、<code>default = \"String::from(\\\"only up\\\")\")</code>：默认值，引号内可以是函数名（带括号）、表达式</li>\n<li><code>from_str_fn(always_five)</code>：针对某个解析的参数进行自定义处理，<code>always_five</code> 的函数签名方式为 <code>fn(&amp;str) -&gt; Result&lt;T, String&gt;</code></li>\n<li><code>description = \"xxxxx\"</code>：给参数添加帮助信息。<code>///</code> 文档注释也可以提供用帮助信息，而 <code>description</code> 的内容在命令行帮助信息里会覆盖掉 <code>///</code> 提供的信息。注意：换行和空换行会在 --help 信息里变成一个空格；描述信息不能过长，否则会出现 <code>error: invalid reference to positional arguments 4 and 5 (there is 1 argument</code> （这个报错信息不准确，我也是排查了很久才发现）。</li>\n</ul>\n<p>trait：</p>\n<ul>\n<li><code>FromArgs</code> trait：用于 argh 命令行解析的所有结构体和枚举体，都必须 derive 这个 trait 。</li>\n<li><code>FromArgValue</code> trait：用于 argh 命令行解析的结构体字段的类型必须实现这个 trait ，argh 已经给所有实现 <code>FromStr</code> trait 的类型实现了这个 trait 。std 的基础类型都实现了 <code>FromStr</code> trait ，所以可以直接使用 std 的基础类型；自定义类型需要实现 <code>FromStr</code> trait 和 <code>FromArgValue</code> trait 。</li>\n</ul>\n<p>优点：</p>\n<ul>\n<li>使用简单而直观，上手快，适用于基础的命令行解析场景</li>\n<li>生成的体积比 clap 小</li>\n<li>依赖少，编译速度快</li>\n<li>支持 unicode</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>终端输出结果非彩色</li>\n<li>默认不支持很长的 help 信息；只支持 <code>--help</code>  不支持 <code>-h</code> （但是也带来优点——可以自定义一个字段，short as <code>-h</code>，从而有一份默认简洁的 help info，又有一份完全自定义的 info，比如 <code>#[argh(option, short = 'h')] description: Vec&lt;String&gt;</code> =&gt; <code>cmd -h arg1 arg2</code> 就可以显示 arg1 和 arg2 的说明）</li>\n<li>只支持 <code>--option value</code> 和 <code>-o value</code>，不支持 <code>--option=value</code> 和 <code>-ovalue</code></li>\n</ul>\n<p>其他 args-parser：</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/blyxxyz/lexopt\" rel=\"noopener noreferrer\">lexopt</a>：零依赖、注重正确性的极简 args-parser 。</li>\n<li><a href=\"https://github.com/clap-rs/clap\" rel=\"noopener noreferrer\"><code>clap</code></a>/<a href=\"https://github.com/TeXitoi/structopt\" rel=\"noopener noreferrer\"><code>structopt</code></a>: very fully-featured. The only other argument parser for Rust I know of that truly handles invalid unicode properly, if used right. Large.</li>\n<li><a href=\"https://github.com/google/argh\" rel=\"noopener noreferrer\"><code>argh</code></a> and <a href=\"https://github.com/murarth/gumdrop\" rel=\"noopener noreferrer\"><code>gumdrop</code></a>: much leaner, yet still convenient and powerful enough for most purposes. Panic on invalid unicode.\n<ul>\n<li><code>argh</code> adheres to the <a href=\"https://fuchsia.dev/fuchsia-src/concepts/api/cli#command_line_arguments\" rel=\"noopener noreferrer\">Fuchsia specification</a> and therefore does <em>not</em> support <code>--option=value</code> and <code>-ovalue</code>, only <code>--option value</code> and <code>-o value</code>.</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/RazrFalcon/pico-args\" rel=\"noopener noreferrer\"><code>pico-args</code></a>: slightly smaller than lexopt and easier to use (but less rigorous).</li>\n<li><a href=\"https://docs.rs/ap\" rel=\"noopener noreferrer\"><code>ap</code></a>: I have not used this, but it seems to support iterative parsing while being less bare-bones than lexopt.</li>\n<li>libc's <a href=\"https://en.wikipedia.org/wiki/Getopt#Examples\" rel=\"noopener noreferrer\"><code>getopt</code></a>.</li>\n</ul>\n<p>src: <a href=\"https://github.com/blyxxyz/lexopt#see-also\" rel=\"noopener noreferrer\">https://github.com/blyxxyz/lexopt#see-also</a></p>\n</blockquote>\n<p>P.S. 不得不说，Rust 利用抽象的类型系统和宏，在 args-parser 方面太棒了。写 Rust 是一种享受。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-03 11:12:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"爱死你了，阿克苏姆","link":"https://rustcc.cn/article?id=628500dc-3232-40ff-98f8-03540eaa5d12","description":"<p>最近花了点时间来学习axum, 并成功将一个用warp写的项目改用axum重写。axum太棒了，充分体现了rust这门语言的表达能力。</p>\n<ol>\n<li>路由设计非常简洁，演示了Rust不用宏，也可以搞DSL的方法。</li>\n<li>Extractor与AddExtension极为灵活，简化了warp通过构建参数获取Request与环境数据的设计。</li>\n<li>借用Tower生态提高了代码利用率。</li>\n</ol>\n<p>axum非常稳定，压力测试中同时开15K并发妥妥的。在axum面世之前，warp是最棒的web框架，现在该是阿克苏姆担当主角了。由于两者都是基于hyper平台，从warp移植到axum也是分分钟的事。\n下面贴出实战项目中两段代码main.rs与servce.rs。main.rs中演示了如何通过命令行参数切换，实现http与https两种服务，还演示了如何调用了静态文件服务功能。service.rs是放api的地方，演示了如何处理get与post请求，如何获取数据库中的数据，如何提供动态下载内容等功能。</p>\n<pre><code>//main.rs\nmod addr;\nmod base16;\nmod bb8_tiberius;\nmod ccb_gwk;\nmod ccb_socket;\nmod config;\nmod context;\nmod database;\nmod json_helper;\nmod json_value;\nmod parse_exp;\nmod parse_param;\nmod service;\nmod service_da;\n\nuse axum::{http::StatusCode, Router};\nuse tower_http::services::ServeDir;\n\nuse std::env::args;\n\nuse chrono::prelude::*;\nuse context::AppContext;\nuse json_helper::JsonHelper;\nuse json_value::JsonValue;\n\nconst VERSION: &amp;str = \"1.3.0\";\n\n#[tokio::main]\nasync fn main() {\n    pretty_env_logger::init_timed();\n\n    let is_https = args().nth(1).unwrap_or(\"http\".into()) == \"https\";\n\n    let context = AppContext::new().await;\n    let ctx = context.clone();\n    let config = &amp;ctx.config;\n    let server_config = &amp;config[\"config\"];\n    let ctx = context.clone();\n    let app = Router::new()\n        .nest(\n            \"/\",\n            axum::service::get(ServeDir::new(\"D:/Js/OnlyOne/public\")).handle_error(\n                |error: std::io::Error| {\n                    Ok::&lt;_, std::convert::Infallible&gt;((\n                        StatusCode::INTERNAL_SERVER_ERROR,\n                        format!(\"Unhandled internal error: {}\", error),\n                    ))\n                },\n            ),\n        )\n        .nest(\"/api\", service::api(ctx));\n\n    let addr = addr::Addr::new(server_config, is_https);\n    let now = Local::now().to_string();\n    let now = &amp;now[0..19];\n    println!(\n        \"{} HTTP{} Server V{} is starting at {:19}, {}\",\n        server_config[\"server_name\"].string(\"W3\"),\n        if is_https { \"S\" } else { \"\" },\n        VERSION,\n        now,\n        addr\n    );\n\n    let addr = addr.to_string_full();\n\n    if is_https {\n        axum_server::bind_rustls(addr)\n            .private_key_file(\"key.pem\")\n            .certificate_file(\"cert.pem\")\n            .serve(app)\n            .await\n            .unwrap();\n    } else {\n        axum_server::bind(addr).serve(app).await.unwrap();\n    }\n}\n</code></pre>\n<pre><code>//service.rs\nuse crate::base16;\nuse crate::ccb_gwk;\nuse crate::database;\nuse crate::parse_param;\nuse crate::service_da::{da_read_about, da_write_about, download_photos, DA_WEBP_DISABLE};\nuse crate::AppContext;\nuse crate::JsonHelper;\nuse crate::JsonValue;\nuse anyhow::{anyhow, Result};\nuse encoding::{all::GB18030, EncoderTrap, Encoding};\nuse serde_json::{json, Value};\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tiberius::ToSql;\nuse tracing::info;\n\nuse axum::{\n    extract::{Extension, Form, Query},\n    response::Json,\n    handler::{get, post},\n    http::header::{HeaderMap, HeaderName, HeaderValue},\n    routing::BoxRoute,\n    AddExtensionLayer, Router,\n};\n\nfn string_to_gb18030bytes(string: &amp;str) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {\n    GB18030\n        .encode(string, EncoderTrap::Strict)\n        .map_err(|e| anyhow!(\"string_to_gb18030bytes failure: {:?}\", e))\n}\n\npub(crate) fn api(ctx: Arc&lt;AppContext&gt;) -&gt; Router&lt;BoxRoute&gt; {\n    Router::new()\n        .route(\"/ask\", get(ask))\n        .route(\"/act\", post(act))\n        .layer(AddExtensionLayer::new(ctx))\n        .boxed()\n}\n\n\npub(crate) async fn ask(\n    Query(qs): Query&lt;HashMap&lt;String, String&gt;&gt;,\n    Extension(context): Extension&lt;Arc&lt;AppContext&gt;&gt;,\n) -&gt; (HeaderMap, Vec&lt;u8&gt;) {\n    let mut headers = HeaderMap::new();\n    //let qs=format!(\"{:?}\",qs);\n    //let bytes=Vec::from(json!({\"ask\":qs}).to_string());\n\n    let empty = String::from(\"\");\n    let dbs = context.dbs.clone();\n    let ask = qs.get(\"ask\").unwrap_or(&amp;empty).clone();\n    let params = base16::base16_decode(qs.get(\"params\").unwrap_or(&amp;empty)).unwrap();\n    let params: Value = serde_json::from_str(&amp;params).unwrap();\n    info!(\"ask={} params={}\", ask, params);\n    //let content_type = \"application/json\";\n    let p1: JsonValue;\n    let p2: JsonValue;\n    let p3: JsonValue;\n    let p4: JsonValue;\n    let p5: JsonValue;\n    let pof = |id| JsonValue::of(&amp;params[id]);\n    let static_path = context.config[\"config\"][\"static_path\"].string(\"wwwroot\");\n    let da_webp_active = context.config[\"config\"][\"da_webp_active\"].bool(false);\n    let accept_webp = params[\"acceptWebp\"].bool(false);\n    let da_webp_quality = if da_webp_active &amp;&amp; accept_webp {\n        context.config[\"config\"][\"da_webp_quality\"].i64(20) as i8\n    } else {\n        DA_WEBP_DISABLE\n    };\n    let mut sql: String = \"\".into();\n    let mut sql_params: Vec&lt;&amp;dyn ToSql&gt; = Vec::new();\n    let mut pending = true;\n    let mut result: String = \"null\".into();\n    let mut about_file: String = \"\".into();\n    let mut voucher_id: &amp;str = &amp;empty;\n    let mut attach: String = \"\".into();\n\n    if ask == \"@login\" {\n        sql = r\"EXEC TM_OnlyOneLogin @P1,@P2\".into();\n        p1 = pof(\"userId\");\n        p2 = pof(\"password\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"workload\" {\n        sql = \"EXEC TM_WorkLoad @P1,@P2,@P3\".into();\n        p1 = pof(\"userName\");\n        p2 = pof(\"year\");\n        let more_where = if params[\"limitMonth\"].bool(false) {\n            let month_from = params[\"monthFrom\"].i64(1);\n            let month_to = params[\"monthTo\"].i64(13);\n            let month_to = if month_to &lt; month_from {\n                month_from\n            } else {\n                month_to\n            };\n            format!(\n                \" AND z.kjqj BETWEEN '{:02}' AND '{:02}'\",\n                month_from, month_to\n            )\n        } else {\n            \"\".to_string()\n        };\n        //println!(\"moreWhere:{}\",more_where);\n        p3 = JsonValue::new(json!(more_where));\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3];\n    } else if ask == \"wujinFH\" {\n        sql = \"EXEC dbo.TM_UpdateOracleWSZZ4WujinFH @P1,@P2\".into();\n        p1 = pof(\"p1\");\n        p2 = pof(\"p2\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"salaryVoucher\" {\n        sql = \"EXEC dbo.TM_MakeSalaryVoucher @P1,@P2\".into();\n        p1 = pof(\"period\");\n        p2 = pof(\"personType\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"salaryVoucherBank\" {\n        sql = \"EXEC dbo.TM_GetSalaryBankDetail @P1,@P2\".into();\n        p1 = pof(\"period\");\n        p2 = pof(\"personType\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"salaryVoucherSheet\" {\n        sql = \"EXEC dbo.TM_GetSalaryVoucher @P1\".into();\n        p1 = pof(\"batch\");\n        sql_params = vec![&amp;p1];\n    } else if ask == \"checkncye\" {\n        sql = \"EXEC dbo.TM_CheckNCYE @P1,@P2\".into();\n        p1 = pof(\"year\");\n        p2 = pof(\"tblname\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"py2code\" {\n        sql = \"EXEC dbo.TM_PY2Code @P1,@P2\".into();\n        p1 = pof(\"type\");\n        p2 = pof(\"code\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"@aboutvoucher\" {\n        sql = \"EXEC dbo.TM_AboutVoucher @P1\".into();\n        p1 = pof(\"pznm\");\n        sql_params = vec![&amp;p1];\n    } else if ask == \"@voucherphotos\" {\n        voucher_id = params[\"voucherId\"].str(\"\");\n        match da_read_about(voucher_id, &amp;static_path, da_webp_quality).await {\n            Ok((about_file_exists, read_result, about_file_name)) =&gt; {\n                about_file = about_file_name;\n                if about_file_exists {\n                    result = format!(\"{{\\\"msg\\\":\\\"ok\\\", \\\"data\\\":{}}}\", read_result);\n                    pending = false;\n                }\n            }\n            Err(e) =&gt; {\n                result = format!(\"{{\\\"msg\\\":\\\"{:?}\\\"}}\", e);\n                pending = false;\n            }\n        }\n        if pending {\n            sql = \"EXEC dbo.TM_VoucherPhotos @P1\".into();\n            p1 = pof(\"voucherId\");\n            sql_params = vec![&amp;p1];\n        }\n    } else if ask == \"@aboutreceipt\" {\n        sql = \"EXEC dbo.TM_AboutReceipt @P1,@P2,@P3,@P4,@P5\".into();\n        p1 = pof(\"id\");\n        p2 = pof(\"checkSum\");\n        p3 = pof(\"datePaid\");\n        p4 = pof(\"amount\");\n        p5 = pof(\"checker\");\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];\n    } else if ask == \"payee\" {\n        sql = \"EXEC dbo.TM_QueryPayee @P1,@P2\".into();\n        p1 = pof(\"bankName\");\n        p2 = pof(\"bankAcct\");\n        sql_params = vec![&amp;p1, &amp;p2];\n    } else if ask == \"ledger\" || ask == \"voucher\" {\n        // CREATE PROCEDURE dbo.TM_QueryLedgerExt\n        // @起始年 INT,@终止年 INT,@查询条件 VARCHAR(4096),@排序 VARCHAR(80)='日期,凭证号,笔号',\n        // @借贷对冲 BIT=0,@隐藏负值 BIT=0,@Select VARCHAR(250)='*'\n        let params = parse_param::params_convert(&amp;context.config, &amp;ask, &amp;params);\n        let pof = |id| JsonValue::of(&amp;params[id]);\n        let only_sum_line = if ask == \"ledger\" { \",1\" } else { \",0\" };\n        sql = \"EXEC dbo.TM_QueryLedgerExt @P1,@P2,@P3,@P4,0,0,@P5\".to_string() + only_sum_line;\n        p1 = pof(\"yearFrom\");\n        p2 = pof(\"yearTo\");\n        p3 = pof(\"filter\");\n        p4 = pof(\"orderby\");\n        p5 = pof(\"select\");\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];\n    } else if ask == \"balance\" {\n        // CREATE PROCEDURE dbo.TM_QueryBalanceExt\n        // @起始年 INT,@终止年 INT,@查询条件 VARCHAR(4096),@期初条件 VARCHAR(4096)=NULL,\n        // @年初条件 VARCHAR(4096)=NULL,@余额条件 VARCHAR(250)=NULL,\n        // @顶层 VARCHAR(10)='科目1级',@底层 VARCHAR(10)='科目4级',\n        // @合并 INT=NULL,@合计 BIT=0,@仅底层 BIT=0,@仅编码 BIT=0,@倍率 INT=1,@查项目余额 BIT=0\n        let params = parse_param::params_convert(&amp;context.config, &amp;ask, &amp;params);\n        let pof = |id| JsonValue::of(&amp;params[id]);\n        sql = format!(\n            \"EXEC dbo.TM_QueryBalanceExt @P1,@P2,@P3,@P4,@P5{}\",\n            params[\"params_in_sql\"].str(\"\")\n        );\n        p1 = pof(\"yearFrom\");\n        p2 = pof(\"yearTo\");\n        p3 = pof(\"filter\");\n        p4 = pof(\"filter_qc\");\n        p5 = pof(\"filter_nc\");\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];\n    }\n    if pending {\n        let result_json = if !sql.is_empty() {\n            let row_is_obj = ask.starts_with('@');\n            let result = database::query(dbs, &amp;sql, &amp;sql_params, row_is_obj).await;\n            match result {\n                Ok(result) =&gt; {\n                    if ask == \"ledger\" {\n                        let params =\n                            parse_param::params_convert(&amp;context.config, \"voucher\", &amp;params);\n                        json!({ \"msg\":\"ok\",\"voucherColDefs\":params[\"select\"], \"data\":result})\n                    } else if ask == \"@voucherphotos\" {\n                        let row_count = result[\"rowCount\"].u64(0);\n                        if row_count &gt; 0 {\n                            let result = download_photos(context, result, da_webp_quality).await;\n                            match da_write_about(&amp;about_file, &amp;result).await {\n                                Ok(_) =&gt; json!({ \"msg\":\"ok\", \"data\":result}),\n                                Err(e) =&gt; json!({ \"msg\": format!(\"{:?}\", e) }),\n                            }\n                        } else {\n                            json!({\n                                \"msg\": format!(\"没有找到凭证{}的影像资料\", voucher_id)\n                            })\n                        }\n                    } else if ask == \"salaryVoucherSheet\" {\n                        let empty_vec: Vec&lt;Value&gt; = Vec::new();\n                        let sheet = result[\"rows\"].as_array().unwrap_or(&amp;empty_vec);\n                        let sheet = sheet\n                            .iter()\n                            .map(|x| x.get(0).unwrap_or(&amp;Value::Null).string(\"\"))\n                            .fold(\"\".to_string(), |lines, line| lines + &amp;line + \"\\r\\n\");\n                        attach = sheet;\n                        json!(\"attachment\")\n                    } else {\n                        json!({ \"msg\":\"ok\", \"data\":result})\n                    }\n                }\n                Err(err) =&gt; {\n                    json!({ \"msg\": format!(\"{:?}\", err) })\n                }\n            }\n        } else if ask == \"checkgwk\" {\n            let check_all = params[\"checkAll\"].bool(false);\n            ccb_gwk::check_gwk(&amp;context.config, check_all)\n                .await\n                .unwrap()\n        } else {\n            json!({ \"msg\": format!(\"unknown ask {} params:{}\", ask, params.to_string()) })\n        };\n        result = format!(\"{}\", result_json);\n    }\n    if ask == \"salaryVoucherSheet\" {\n        let file_name = params[\"fileName\"].str(\"凭证\");\n        let value = format!(\"attachment;filename={}.txt\", file_name);\n        let bytes: Vec&lt;u8&gt; = string_to_gb18030bytes(&amp;attach).unwrap_or_default();\n        //reply::with_header(bytes, \"Content-disposition\", value)\n        headers.insert(\n            HeaderName::from_static(\"content-type\"),\n            HeaderValue::from_static(\"text/plain\"),\n        );\n        headers.insert(\n            HeaderName::from_static(\"content-disposition\"),\n            HeaderValue::from_str(&amp;value).unwrap(),\n        );\n        (headers, bytes)\n    } else {\n        let bytes: Vec&lt;u8&gt; = result.into_bytes();\n        //reply::with_header(bytes, \"content-type\", content_type)\n        headers.insert(\n            HeaderName::from_static(\"content-type\"),\n            HeaderValue::from_static(\"application/json\"),\n        );\n        (headers, bytes)\n    }\n}\n\nasync fn act(\n    Form(qs): Form&lt;HashMap&lt;String, String&gt;&gt;,\n    Extension(context): Extension&lt;Arc&lt;AppContext&gt;&gt;,\n) -&gt; Json&lt;Value&gt; {\n    let empty = String::from(\"\");\n    let dbs = context.dbs.clone();\n    let act = qs.get(\"act\").unwrap_or(&amp;empty).clone();\n    let params = base16::base16_decode(qs.get(\"params\").unwrap_or(&amp;empty)).unwrap();\n    let params: Value = serde_json::from_str(&amp;params).unwrap_or(Value::Null);\n    info!(\"act={} params={}\", act, params);\n    //let content_type = \"application/json\";\n    let sql: String;\n    let p1: JsonValue;\n    let p2: JsonValue;\n    let p3: JsonValue;\n    let p4: JsonValue;\n    let p5: JsonValue;\n    let sql_params: Vec&lt;&amp;dyn ToSql&gt;;\n    let pof = |id| JsonValue::of(&amp;params[id]);\n    if act == \"exam\" {\n        sql = r\"EXEC dbo.TM_Exam @P1,@P2,@P3,@P4\".into();\n        p1 = pof(\"ids\");\n        p2 = pof(\"fhr\");\n        p3 = pof(\"fhrId\");\n        p4 = pof(\"isUndo\");\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4];\n    } else if act == \"changepayee\" {\n        sql = \"EXEC dbo.TM_ChangePayee @P1,@P2,@P3,@P4,@P5\".into();\n        p1 = pof(\"bankName\");\n        p2 = pof(\"bankAcct\");\n        p3 = pof(\"unitCode\");\n        p4 = pof(\"updateDate\");\n        p5 = pof(\"mark\");\n        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];\n    } else if act == \"execsql\" || act == \"@execsql\" {\n        sql = params[\"sql\"].string(\"\");\n        sql_params = Vec::new();\n    } else {\n        sql = \"\".into();\n        sql_params = Vec::new();\n    }\n    let result = if !sql.is_empty() {\n        let row_is_obj = act.starts_with('@');\n        let result = database::query(dbs, &amp;sql, &amp;sql_params, row_is_obj).await;\n        match result {\n            Ok(result) =&gt; {\n                json!({ \"msg\":\"ok\", \"data\":result})\n            }\n            Err(err) =&gt; {\n                json!({ \"msg\": format!(\"{:?}\", err) })\n            }\n        }\n    } else {\n        json!({ \"msg\": format!(\"unknown act {} params:{}\", act, params.to_string()) })\n    };\n    Json(result)\n}\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-03 10:27:07","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-03 Bebop v2.3.0：为 Bebop 序列化添加 Rust 支持","link":"https://rustcc.cn/article?id=99b9fdf0-4026-4753-a07f-b7355caced95","description":"<h4>Bebop v2.3.0：为 Bebop 序列化添加 Rust 支持</h4>\n<p>Bebop 是一种基于模型的二进制序列化技术，类似于 Protocol Buffers 或 MessagePack。特别是，Bebop 试图非常适合需要比 JSON 或 MessagePack 更快、更简洁和类型安全的客户端-服务器或分布式 Web 应用程序。Matthew Conover 2021年8月30日宣布 Bebop 添加了 Rust 的支持</p>\n<ul>\n<li>https://rainway.com/blog/2021/08/30/bebop-rust/</li>\n</ul>\n<h4>将 TensorFlow 模型移植到 Rust 的开发成本</h4>\n<p>通过 CrowdStrike 的可扩展性，可以立即将 TensorFlow 模型成功转换为纯 Rust 代码，文章介绍了通过这一方法的时间和精力成本</p>\n<ul>\n<li>https://www.crowdstrike.com/blog/development-cost-of-porting-tensorflow-models-to-pure-rust/</li>\n</ul>\n<h4>Rust 中的结构更新语法</h4>\n<ul>\n<li>https://www.reddit.com/r/rust/comments/pchp8h/media_struct_update_syntax_in_rust/</li>\n</ul>\n<hr>\n<p>From 日报小组 北纬27度 侯盛鑫</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rust.cc 论坛: 支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-03 08:34:27","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"bytes::ByteMut 无法写入数据","link":"https://rustcc.cn/article?id=1ab18776-e162-4fbc-80b3-d23bb7402cf3","description":"<p>想用 <a href=\"https://docs.rs/bytes/1.1.0/bytes/struct.BytesMut.html\" rel=\"noopener noreferrer\">ByteMut</a> 作缓冲区，从同步io数据源中读取数据，可是无法读取，也没报错。。。</p>\n<pre><code>fn main() -&gt; io::Result&lt;()&gt; {\n    let mut buf = BytesMut::with_capacity(10);\n\n    let mut input: Cursor&lt;Vec&lt;u8&gt;&gt; = Cursor::new({\n        (0..100).collect()\n    });\n\n    loop {\n        match input.read(&amp;mut buf)? {\n            0 =&gt; {\n                println!(\"[READ OVER]\");\n                break;\n            }\n            n =&gt; {\n                println!(\"{:?}\", &amp;buf);\n                println!(\"[READ ONCE]\");\n            }\n        }\n    }\n\n    Ok(())\n}\n</code></pre>\n<p>如果只用普通的数组，是可以读取数据</p>\n<pre><code>let mut buf = [0; 10];\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-03 07:43:46","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"数据表 Timestamp 日期 Serialize","link":"https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0","description":"<p>主要参考：<a href=\"https://github.com/rustcc/forustm\" rel=\"noopener noreferrer\">Rustcc网站源码库</a></p>\n<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，\n查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>\n<h2>1.依赖的库：</h2>\n<pre><code>[dependencies]\n# 日期时间处理 需要开启 serde 特征 支持序列化\nchrono = { version = \"0.4.19\", features = [\"serde\"] }\n\n# 数据库ORM\ndiesel = { version = \"1.4.4\", features = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"] }\ndotenv = \"0.15.0\"\nserde = { version = \"1.0.127\", features = [\"derive\"] }\nserde_json = \"1.0.66\"\nuuid = { version = \"0.8.2\", features = [\"serde\", \"v4\"] }\n</code></pre>\n<h2>2.创建数据表</h2>\n<pre><code>CREATE TABLE characters (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(128) UNIQUE NOT NULL,\n    age INTEGER NOT NULL DEFAULT 0,\n    friends VARCHAR NOT NULL DEFAULT '',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n)\n</code></pre>\n<h2>3.数据表对应的 model</h2>\n<pre><code>use chrono::{NaiveDateTime};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Queryable, Serialize, Deserialize, Debug)]\npub struct Characters {\n    pub id: i32,\n    pub name: String,\n    pub age: i32,\n    pub friends: String,\n    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features\n    pub created_at: NaiveDateTime,\n}\n</code></pre>\n<h2>4.获取数据</h2>\n<pre><code>use db::schema::characters;\nuse db::{get_connection};\nuse db::models::{Characters, NewCharacter};\nuse db::schema::characters::dsl::*;\nuse diesel::QueryDsl;\nuse diesel::prelude::*;\n\nfn main() {\n    let conn = get_connection();\n\n    // 查询年龄大于30的10条数据\n    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))\n        .limit(10)\n        .load::&lt;Characters&gt;(&amp;conn)\n        .expect(\"Loading Error\");\n\n    let date_arr = arr.iter()\n        .map(|item| {\n\t    // 数据格式化\n            let t = item.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n            println!(\"{} {}\", item.name, t);\n            t\n        })\n        .collect::&lt;Vec&lt;String&gt;&gt;();\n}\n</code></pre>\n<p>输出结果类似：</p>\n<pre><code>Box 2021-08-05 09:39:34\nBobe 2021-08-05 09:39:34\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 01:40:35","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Cargo workspace config","link":"https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c","description":"<p><a href=\"https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html\" rel=\"noopener noreferrer\">Workspace 文档链接</a></p>\n<h2>目录结构</h2>\n<pre><code>workspace-test/\n    Cargo.toml\n    db/\n        src/\n            bin/\n                init.rs\n        Cargo.tml\n</code></pre>\n<h2>workspace</h2>\n<p>workspace-test/Cargo.toml</p>\n<pre><code>[workspace]\nmembers = [\"db\"]\ndefault-member = \"db\"\n</code></pre>\n<h2>子项目</h2>\n<p>workspace-test/db/Cargo.toml</p>\n<pre><code>[package]\nname = \"db\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n# 可选的可执行文件配置\n# [[bin]]\n# name = \"init\"\n# path = \"src/bin/init.rs\"\n</code></pre>\n<h2>操作</h2>\n<pre><code># 运行 init\ncargo run --bin init\n# -p 指定项目\ncargo run -p db --bin init\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-04 09:54:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-06T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Challenges in Generalization in Open Domain Question Answering. (arXiv:2109.01156v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01156","description":"<p>Recent work on Open Domain Question Answering has shown that there is a large\ndiscrepancy in model performance between novel test questions and those that\nlargely overlap with training questions. However, it is as of yet unclear which\naspects of novel questions that make them challenging. Drawing upon studies on\nsystematic generalization, we introduce and annotate questions according to\nthree categories that measure different levels and kinds of generalization:\ntraining set overlap, compositional generalization (comp-gen), and novel entity\ngeneralization (novel-entity). When evaluating six popular parametric and\nnon-parametric models, we find that for the established Natural Questions and\nTriviaQA datasets, even the strongest model performance for\ncomp-gen/novel-entity is 13.1/5.4% and 9.6/1.5% lower compared to that for the\nfull test set -- indicating the challenge posed by these types of questions.\nFurthermore, we show that whilst non-parametric models can handle questions\ncontaining novel entities, they struggle with those requiring compositional\ngeneralization. Through thorough analysis we find that key question difficulty\nfactors are: cascading errors from the retrieval component, frequency of\nquestion pattern, and frequency of the entity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_P/0/1/0/all/0/1\">Patrick Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1\">Sebastian Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1\">Pontus Stenetorp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Conformer: Progressive Downsampling and Grouped Attention for Automatic Speech Recognition. (arXiv:2109.01163v1 [eess.AS])","link":"http://arxiv.org/abs/2109.01163","description":"<p>The recently proposed Conformer architecture has shown state-of-the-art\nperformances in Automatic Speech Recognition by combining convolution with\nattention to model both local and global dependencies. In this paper, we study\nhow to reduce the Conformer architecture complexity with a limited computing\nbudget, leading to a more efficient architecture design that we call Efficient\nConformer. We introduce progressive downsampling to the Conformer encoder and\npropose a novel attention mechanism named grouped attention, allowing us to\nreduce attention complexity from $O(n^{2}d)$ to $O(n^{2}d / g)$ for sequence\nlength $n$, hidden dimension $d$ and group size parameter $g$. We also\nexperiment the use of strided multi-head self-attention as a global\ndownsampling operation. Our experiments are performed on the LibriSpeech\ndataset with CTC and RNN-Transducer losses. We show that within the same\ncomputing budget, the proposed architecture achieves better performances with\nfaster training and decoding compared to the Conformer. Our 13M parameters CTC\nmodel achieves competitive WERs of 3.6\\%/9.0\\% without using a language model\nand 2.7\\%/6.7\\% with an external n-gram language model on the\ntest-clean/test-other sets while being 29\\% faster than our CTC Conformer\nbaseline at inference and 36\\% faster to train.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Burchi_M/0/1/0/all/0/1\">Maxime Burchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vielzeuf_V/0/1/0/all/0/1\">Valentin Vielzeuf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ranking Scientific Papers Using Preference Learning. (arXiv:2109.01190v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01190","description":"<p>Peer review is the main quality control mechanism in academia. Quality of\nscientific work has many dimensions; coupled with the subjective nature of the\nreviewing task, this makes final decision making based on the reviews and\nscores therein very difficult and time-consuming. To assist with this important\ntask, we cast it as a paper ranking problem based on peer review texts and\nreviewer scores. We introduce a novel, multi-faceted generic evaluation\nframework for making final decisions based on peer reviews that takes into\naccount effectiveness, efficiency and fairness of the evaluated system. We\npropose a novel approach to paper ranking based on Gaussian Process Preference\nLearning (GPPL) and evaluate it on peer review data from the ACL-2018\nconference. Our experiments demonstrate the superiority of our GPPL-based\napproach over prior work, while highlighting the importance of using both texts\nand review scores for paper ranking during peer review aggregation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dycke_N/0/1/0/all/0/1\">Nils Dycke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simpson_E/0/1/0/all/0/1\">Edwin Simpson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznetsov_I/0/1/0/all/0/1\">Ilia Kuznetsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Establishing Interlingua in Multilingual Language Models. (arXiv:2109.01207v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01207","description":"<p>Large multilingual language models show remarkable zero-shot cross-lingual\ntransfer performance on a range of tasks. Follow-up works hypothesized that\nthese models internally project representations of different languages into a\nshared interlingual space. However, they produced contradictory results. In\nthis paper, we correct %one of the previous works the famous prior work\nclaiming that \"BERT is not an Interlingua\" and show that with the proper choice\nof sentence representation different languages actually do converge to a shared\nspace in such language models. Furthermore, we demonstrate that this\nconvergence pattern is robust across four measures of correlation similarity\nand six mBERT-like models. We then extend our analysis to 28 diverse languages\nand find that the interlingual space exhibits a particular structure similar to\nthe linguistic relatedness of languages. We also highlight a few outlier\nlanguages that seem to fail to converge to the shared space. The code for\nreplicating our results is available at the following URL:\nhttps://github.com/maksym-del/interlingua.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Del_M/0/1/0/all/0/1\">Maksym Del</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fishel_M/0/1/0/all/0/1\">Mark Fishel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying Reproducibility in NLP and ML. (arXiv:2109.01211v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01211","description":"<p>Reproducibility has become an intensely debated topic in NLP and ML over\nrecent years, but no commonly accepted way of assessing reproducibility, let\nalone quantifying it, has so far emerged. The assumption has been that wider\nscientific reproducibility terminology and definitions are not applicable to\nNLP/ML, with the result that many different terms and definitions have been\nproposed, some diametrically opposed. In this paper, we test this assumption,\nby taking the standard terminology and definitions from metrology and applying\nthem directly to NLP/ML. We find that we are able to straightforwardly derive a\npractical framework for assessing reproducibility which has the desirable\nproperty of yielding a quantified degree of reproducibility that is comparable\nacross different reproduction studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01226","description":"<p>More predictable words are easier to process - they are read faster and\nelicit smaller neural signals associated with processing difficulty, most\nnotably, the N400 component of the event-related brain potential. Thus, it has\nbeen argued that prediction of upcoming words is a key component of language\ncomprehension, and that studying the amplitude of the N400 is a valuable way to\ninvestigate the predictions that we make. In this study, we investigate whether\nthe linguistic predictions of computational language models or humans better\nreflect the way in which natural language stimuli modulate the amplitude of the\nN400. One important difference in the linguistic predictions of humans versus\ncomputational language models is that while language models base their\npredictions exclusively on the preceding linguistic context, humans may rely on\nother factors. We find that the predictions of three top-of-the-line\ncontemporary language models - GPT-3, RoBERTa, and ALBERT - match the N400 more\nclosely than human predictions. This suggests that the predictive processes\nunderlying the N400 may be more sensitive to the surface-level statistics of\nlanguage than previously thought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1\">James A. Michaelov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coulson_S/0/1/0/all/0/1\">Seana Coulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Conditionality for Natural Language Generation. (arXiv:2109.01229v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01229","description":"<p>Large scale pretrained language models have demonstrated state-of-the-art\nperformance in language understanding tasks. Their application has recently\nexpanded into multimodality learning, leading to improved representations\ncombining vision and language. However, progress in adapting language models\ntowards conditional Natural Language Generation (NLG) has been limited to a\nsingle modality, generally text. We propose MAnTiS, Multimodal Adaptation for\nText Synthesis, a general approach for multimodal conditionality in\ntransformer-based NLG models. In this method, we pass inputs from each modality\nthrough modality-specific encoders, project to textual token space, and finally\njoin to form a conditionality prefix. We fine-tune the pretrained language\nmodel and encoders with the conditionality prefix guiding the generation. We\napply MAnTiS to the task of product description generation, conditioning a\nnetwork on both product images and titles to generate descriptive text. We\ndemonstrate that MAnTiS outperforms strong baseline approaches on standard NLG\nscoring metrics. Furthermore, qualitative assessments demonstrate that MAnTiS\ncan generate human quality descriptions consistent with given multimodal\ninputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sollami_M/0/1/0/all/0/1\">Michael Sollami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Aashish Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study on Leveraging Position Embeddings for Target-oriented Opinion Words Extraction. (arXiv:2109.01238v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01238","description":"<p>Target-oriented opinion words extraction (TOWE) (Fan et al., 2019b) is a new\nsubtask of target-oriented sentiment analysis that aims to extract opinion\nwords for a given aspect in text. Current state-of-the-art methods leverage\nposition embeddings to capture the relative position of a word to the target.\nHowever, the performance of these methods depends on the ability to incorporate\nthis information into word representations. In this paper, we explore a variety\nof text encoders based on pretrained word embeddings or language models that\nleverage part-of-speech and position embeddings, aiming to examine the actual\ncontribution of each component in TOWE. We also adapt a graph convolutional\nnetwork (GCN) to enhance word representations by incorporating syntactic\ninformation. Our experimental results demonstrate that BiLSTM-based models can\neffectively encode position information into word representations while using a\nGCN only achieves marginal gains. Interestingly, our simple methods outperform\nseveral state-of-the-art complex neural structures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mensah_S/0/1/0/all/0/1\">Samuel Mensah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Kai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity Linking and Discovery via Arborescence-based Supervised Clustering. (arXiv:2109.01242v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01242","description":"<p>Previous work has shown promising results in performing entity linking by\nmeasuring not only the affinities between mentions and entities but also those\namongst mentions. In this paper, we present novel training and inference\nprocedures that fully utilize mention-to-mention affinities by building minimum\narborescences (i.e., directed spanning trees) over mentions and entities across\ndocuments in order to make linking decisions. We also show that this method\ngracefully extends to entity discovery, enabling the clustering of mentions\nthat do not have an associated entity in the knowledge base. We evaluate our\napproach on the Zero-Shot Entity Linking dataset and MedMentions, the largest\npublicly available biomedical dataset, and show significant improvements in\nperformance for both entity linking and discovery compared to identically\nparameterized models. We further show significant efficiency improvements with\nonly a small loss in accuracy over previous work, which use more\ncomputationally expensive models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_D/0/1/0/all/0/1\">Dhruv Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angell_R/0/1/0/all/0/1\">Rico Angell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monath_N/0/1/0/all/0/1\">Nicholas Monath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Prompt-Based Models Really Understand the Meaning of their Prompts?. (arXiv:2109.01247v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01247","description":"<p>Recently, a boom of papers have shown extraordinary progress in few-shot\nlearning with various prompt-based models. Such success can give the impression\nthat prompts help models to learn faster in the same way that humans learn\nfaster when provided with task instructions expressed in natural language. In\nthis study, we experiment with over 30 prompts manually written for natural\nlanguage inference (NLI). We find that models learn just as fast with many\nprompts that are intentionally irrelevant or even pathologically misleading as\nthey do with instructively \"good\" prompts. Additionally, we find that model\nperformance is more dependent on the choice of the LM target words (a.k.a. the\n\"verbalizer\" that converts LM vocabulary prediction to class labels) than on\nthe text of the prompt itself. In sum, we find little evidence that suggests\nexisting prompt-based models truly understand the meaning of their given\nprompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Webson_A/0/1/0/all/0/1\">Albert Webson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Context-Aware Hierarchical BERT Fusion Network for Multi-turn Dialog Act Detection. (arXiv:2109.01267v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01267","description":"<p>The success of interactive dialog systems is usually associated with the\nquality of the spoken language understanding (SLU) task, which mainly\nidentifies the corresponding dialog acts and slot values in each turn. By\ntreating utterances in isolation, most SLU systems often overlook the semantic\ncontext in which a dialog act is expected. The act dependency between turns is\nnon-trivial and yet critical to the identification of the correct semantic\nrepresentations. Previous works with limited context awareness have exposed the\ninadequacy of dealing with complexity in multiproned user intents, which are\nsubject to spontaneous change during turn transitions. In this work, we propose\nto enhance SLU in multi-turn dialogs, employing a context-aware hierarchical\nBERT fusion Network (CaBERT-SLU) to not only discern context information within\na dialog but also jointly identify multiple dialog acts and slots in each\nutterance. Experimental results show that our approach reaches new\nstate-of-the-art (SOTA) performances in two complicated multi-turn dialogue\ndatasets with considerable improvements compared with previous methods, which\nonly consider single utterances for multiple intents and slot filling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Ting-Wei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1\">Ruolin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juang_B/0/1/0/all/0/1\">Biing-Hwang Juang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Open-Source Dataset and A Multi-Task Model for Malay Named Entity Recognition. (arXiv:2109.01293v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01293","description":"<p>Named entity recognition (NER) is a fundamental task of natural language\nprocessing (NLP). However, most state-of-the-art research is mainly oriented to\nhigh-resource languages such as English and has not been widely applied to\nlow-resource languages. In Malay language, relevant NER resources are limited.\nIn this work, we propose a dataset construction framework, which is based on\nlabeled datasets of homologous languages and iterative optimization, to build a\nMalay NER dataset (MYNER) comprising 28,991 sentences (over 384 thousand\ntokens). Additionally, to better integrate boundary information for NER, we\npropose a multi-task (MT) model with a bidirectional revision (Bi-revision)\nmechanism for Malay NER task. Specifically, an auxiliary task, boundary\ndetection, is introduced to improve NER training in both explicit and implicit\nways. Furthermore, a gated ignoring mechanism is proposed to conduct\nconditional label transfer and alleviate error propagation by the auxiliary\ntask. Experimental results demonstrate that our model achieves comparable\nresults over baselines on MYNER. The dataset and the model in this paper would\nbe publicly released as a benchmark dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yingwen Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_N/0/1/0/all/0/1\">Nankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhihe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shengyi Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Information Symmetry Matters: A Modal-Alternating Propagation Network for Few-Shot Learning. (arXiv:2109.01295v1 [cs.CV])","link":"http://arxiv.org/abs/2109.01295","description":"<p>Semantic information provides intra-class consistency and inter-class\ndiscriminability beyond visual concepts, which has been employed in Few-Shot\nLearning (FSL) to achieve further gains. However, semantic information is only\navailable for labeled samples but absent for unlabeled samples, in which the\nembeddings are rectified unilaterally by guiding the few labeled samples with\nsemantics. Therefore, it is inevitable to bring a cross-modal bias between\nsemantic-guided samples and nonsemantic-guided samples, which results in an\ninformation asymmetry problem. To address this problem, we propose a\nModal-Alternating Propagation Network (MAP-Net) to supplement the absent\nsemantic information of unlabeled samples, which builds information symmetry\namong all samples in both visual and semantic modalities. Specifically, the\nMAP-Net transfers the neighbor information by the graph propagation to generate\nthe pseudo-semantics for unlabeled samples guided by the completed visual\nrelationships and rectify the feature embeddings. In addition, due to the large\ndiscrepancy between visual and semantic modalities, we design a Relation\nGuidance (RG) strategy to guide the visual relation vectors via semantics so\nthat the propagated information is more beneficial. Extensive experimental\nresults on three semantic-labeled datasets, i.e., Caltech-UCSD-Birds 200-2011,\nSUN Attribute Database, and Oxford 102 Flower, have demonstrated that our\nproposed method achieves promising performance and outperforms the\nstate-of-the-art approaches, which indicates the necessity of information\nsymmetry.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Zhong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhishen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiyao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1\">Yanwei Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jungong Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Indexing Context-Sensitive Reachability. (arXiv:2109.01321v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01321","description":"<p>Many context-sensitive data flow analyses can be formulated as a variant of\nthe all-pairs Dyck-CFL reachability problem, which, in general, is of sub-cubic\ntime complexity and quadratic space complexity. Such high complexity\nsignificantly limits the scalability of context-sensitive data flow analysis\nand is not affordable for analyzing large-scale software. This paper presents\n\\textsc{Flare}, a reduction from the CFL reachability problem to the\nconventional graph reachability problem for context-sensitive data flow\nanalysis. This reduction allows us to benefit from recent advances in\nreachability indexing schemes, which often consume almost linear space for\nanswering reachability queries in almost constant time. We have applied our\nreduction to a context-sensitive alias analysis and a context-sensitive\ninformation-flow analysis for C/C++ programs. Experimental results on standard\nbenchmarks and open-source software demonstrate that we can achieve orders of\nmagnitude speedup at the cost of only moderate space to store the indexes. The\nimplementation of our approach is publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1\">Qingkai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Charles Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Speaker Personas from Conversational Texts. (arXiv:2109.01330v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01330","description":"<p>Personas are useful for dialogue response prediction. However, the personas\nused in current studies are pre-defined and hard to obtain before a\nconversation. To tackle this issue, we study a new task, named Speaker Persona\nDetection (SPD), which aims to detect speaker personas based on the plain\nconversational text. In this task, a best-matched persona is searched out from\ncandidates given the conversational text. This is a many-to-many semantic\nmatching task because both contexts and personas in SPD are composed of\nmultiple sentences. The long-term dependency and the dynamic redundancy among\nthese sentences increase the difficulty of this task. We build a dataset for\nSPD, dubbed as Persona Match on Persona-Chat (PMPC). Furthermore, we evaluate\nseveral baseline models and propose utterance-to-profile (U2P) matching\nnetworks for this task. The U2P models operate at a fine granularity which\ntreat both contexts and personas as sets of multiple sequences. Then, each\nsequence pair is scored and an interpretable overall score is obtained for a\ncontext-persona pair through aggregation. Evaluation results show that the U2P\nmodels outperform their baseline counterparts significantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhigang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Modeling, Lexical Translation, Reordering: The Training Process of NMT through the Lens of Classical SMT. (arXiv:2109.01396v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01396","description":"<p>Differently from the traditional statistical MT that decomposes the\ntranslation task into distinct separately learned components, neural machine\ntranslation uses a single neural network to model the entire translation\nprocess. Despite neural machine translation being de-facto standard, it is\nstill not clear how NMT models acquire different competences over the course of\ntraining, and how this mirrors the different models in traditional SMT. In this\nwork, we look at the competences related to three core SMT components and find\nthat during training, NMT first focuses on learning target-side language\nmodeling, then improves translation quality approaching word-by-word\ntranslation, and finally learns more complicated reordering patterns. We show\nthat this behavior holds for several models and language pairs. Additionally,\nwe explain how such an understanding of the training process can be useful in\npractice and, as an example, show how it can be used to improve vanilla\nnon-autoregressive neural machine translation by guiding teacher model\nselection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Voita_E/0/1/0/all/0/1\">Elena Voita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Exploratory Study on Utilising the Web of Linked Data for Product Data Mining. (arXiv:2109.01411v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01411","description":"<p>The Linked Open Data practice has led to a significant growth of structured\ndata on the Web in the last decade. Such structured data describe real-world\nentities in a machine-readable way, and have created an unprecedented\nopportunity for research in the field of Natural Language Processing. However,\nthere is a lack of studies on how such data can be used, for what kind of\ntasks, and to what extent they can be useful for these tasks. This work focuses\non the e-commerce domain to explore methods of utilising such structured data\nto create language resources that may be used for product classification and\nlinking. We process billions of structured data points in the form of RDF\nn-quads, to create multi-million words of product-related corpora that are\nlater used in three different ways for creating of language resources: training\nword embedding models, continued pre-training of BERT-like language models, and\ntraining Machine Translation models that are used as a proxy to generate\nproduct-related keywords. Our evaluation on an extensive set of benchmarks\nshows word embeddings to be the most reliable and consistent method to improve\nthe accuracy on both tasks (with up to 6.9 percentage points in macro-average\nF1 on some datasets). The other two methods however, are not as useful. Our\nanalysis shows that this could be due to a number of reasons, including the\nbiased domain representation in the structured data and lack of vocabulary\ncoverage. We share our datasets and discuss how our lessons learned could be\ntaken forward to inform future research in this direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LG4AV: Combining Language Models and Graph Neural Networks for Author Verification. (arXiv:2109.01479v1 [cs.LG])","link":"http://arxiv.org/abs/2109.01479","description":"<p>The automatic verification of document authorships is important in various\nsettings. Researchers are for example judged and compared by the amount and\nimpact of their publications and public figures are confronted by their posts\non social media platforms. Therefore, it is important that authorship\ninformation in frequently used web services and platforms is correct. The\nquestion whether a given document is written by a given author is commonly\nreferred to as authorship verification (AV). While AV is a widely investigated\nproblem in general, only few works consider settings where the documents are\nshort and written in a rather uniform style. This makes most approaches\nunpractical for online databases and knowledge graphs in the scholarly domain.\nHere, authorships of scientific publications have to be verified, often with\njust abstracts and titles available. To this point, we present our novel\napproach LG4AV which combines language models and graph neural networks for\nauthorship verification. By directly feeding the available texts in a\npre-trained transformer architecture, our model does not need any hand-crafted\nstylometric features that are not meaningful in scenarios where the writing\nstyle is, at least to some extent, standardized. By the incorporation of a\ngraph neural network structure, our model can benefit from relations between\nauthors that are meaningful with respect to the verification process. For\nexample, scientific authors are more likely to write about topics that are\naddressed by their co-authors and twitter users tend to post about the same\nsubjects as people they follow. We experimentally evaluate our model and study\nto which extent the inclusion of co-authorships enhances verification decisions\nin bibliometric environments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stubbemann_M/0/1/0/all/0/1\">Maximilian Stubbemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1\">Gerd Stumme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Representation Learning for Exemplar-Guided Paraphrase Generation. (arXiv:2109.01484v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01484","description":"<p>Exemplar-Guided Paraphrase Generation (EGPG) aims to generate a target\nsentence which conforms to the style of the given exemplar while encapsulating\nthe content information of the source sentence. In this paper, we propose a new\nmethod with the goal of learning a better representation of the style andthe\ncontent. This method is mainly motivated by the recent success of contrastive\nlearning which has demonstrated its power in unsupervised feature extraction\ntasks. The idea is to design two contrastive losses with respect to the content\nand the style by considering two problem characteristics during training. One\ncharacteristic is that the target sentence shares the same content with the\nsource sentence, and the second characteristic is that the target sentence\nshares the same style with the exemplar. These two contrastive losses are\nincorporated into the general encoder-decoder paradigm. Experiments on two\ndatasets, namely QQP-Pos and ParaNMT, demonstrate the effectiveness of our\nproposed constrastive losses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haoran Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Piji Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Biomedical Data-to-Text Generation via Fine-Tuning Transformers. (arXiv:2109.01518v1 [cs.LG])","link":"http://arxiv.org/abs/2109.01518","description":"<p>Data-to-text (D2T) generation in the biomedical domain is a promising - yet\nmostly unexplored - field of research. Here, we apply neural models for D2T\ngeneration to a real-world dataset consisting of package leaflets of European\nmedicines. We show that fine-tuned transformers are able to generate realistic,\nmultisentence text from data in the biomedical domain, yet have important\nlimitations. We also release a new dataset (BioLeaflets) for benchmarking D2T\ngeneration models in the biomedical domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yermakov_R/0/1/0/all/0/1\">Ruslan Yermakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drago_N/0/1/0/all/0/1\">Nicholas Drago</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziletti_A/0/1/0/all/0/1\">Angelo Ziletti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Longitudinal Multi-modal Dataset for Dementia Monitoring and Diagnosis. (arXiv:2109.01537v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01537","description":"<p>Dementia is a family of neurogenerative conditions affecting memory and\ncognition in an increasing number of individuals in our globally aging\npopulation. Automated analysis of language, speech and paralinguistic\nindicators have been gaining popularity as potential indicators of cognitive\ndecline. Here we propose a novel longitudinal multi-modal dataset collected\nfrom people with mild dementia and age matched controls over a period of\nseveral months in a natural setting. The multi-modal data consists of spoken\nconversations, a subset of which are transcribed, as well as typed and written\nthoughts and associated extra-linguistic information such as pen strokes and\nkeystrokes. We describe the dataset in detail and proceed to focus on a task\nusing the speech modality. The latter involves distinguishing controls from\npeople with dementia by exploiting the longitudinal nature of the data. Our\nexperiments showed significant differences in how the speech varied from\nsession to session in the control and dementia groups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gkoumas_D/0/1/0/all/0/1\">Dimitris Gkoumas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1\">Adam Tsakalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolters_M/0/1/0/all/0/1\">Maria Wolters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liakata_M/0/1/0/all/0/1\">Maria Liakata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Neural Models for Natural Language Processing in the Face of Distributional Shift. (arXiv:2109.01558v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01558","description":"<p>The dominating NLP paradigm of training a strong neural predictor to perform\none task on a specific dataset has led to state-of-the-art performance in a\nvariety of applications (eg. sentiment classification, span-prediction based\nquestion answering or machine translation). However, it builds upon the\nassumption that the data distribution is stationary, ie. that the data is\nsampled from a fixed distribution both at training and test time. This way of\ntraining is inconsistent with how we as humans are able to learn from and\noperate within a constantly changing stream of information. Moreover, it is\nill-adapted to real-world use cases where the data distribution is expected to\nshift over the course of a model's lifetime.\n</p>\n<p>The first goal of this thesis is to characterize the different forms this\nshift can take in the context of natural language processing, and propose\nbenchmarks and evaluation metrics to measure its effect on current deep\nlearning architectures. We then proceed to take steps to mitigate the effect of\ndistributional shift on NLP models. To this end, we develop methods based on\nparametric reformulations of the distributionally robust optimization\nframework. Empirically, we demonstrate that these approaches yield more robust\nmodels as demonstrated on a selection of realistic problems. In the third and\nfinal part of this thesis, we explore ways of efficiently adapting existing\nmodels to new domains or tasks. Our contribution to this topic takes\ninspiration from information geometry to derive a new gradient update rule\nwhich alleviate catastrophic forgetting issues during adaptation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Michel_P/0/1/0/all/0/1\">Paul Michel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualized Embeddings based Convolutional Neural Networks for Duplicate Question Identification. (arXiv:2109.01560v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01560","description":"<p>Question Paraphrase Identification (QPI) is a critical task for large-scale\nQuestion-Answering forums. The purpose of QPI is to determine whether a given\npair of questions are semantically identical or not. Previous approaches for\nthis task have yielded promising results, but have often relied on complex\nrecurrence mechanisms that are expensive and time-consuming in nature. In this\npaper, we propose a novel architecture combining a Bidirectional Transformer\nEncoder with Convolutional Neural Networks for the QPI task. We produce the\npredictions from the proposed architecture using two different inference\nsetups: Siamese and Matched Aggregation. Experimental results demonstrate that\nour model achieves state-of-the-art performance on the Quora Question Pairs\ndataset. We empirically prove that the addition of convolution layers to the\nmodel architecture improves the results in both inference setups. We also\ninvestigate the impact of partial and complete fine-tuning and analyze the\ntrade-off between computational power and accuracy in the process. Based on the\nobtained results, we conclude that the Matched-Aggregation setup consistently\noutperforms the Siamese setup. Our work provides insights into what\narchitecture combinations and setups are likely to produce better results for\nthe QPI task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakhrani_H/0/1/0/all/0/1\">Harsh Sakhrani</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_S/0/1/0/all/0/1\">Saloni Parekh</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Ratadiya_P/0/1/0/all/0/1\">Pratik Ratadiya</a> (2) ((1) Pune Institute of Computer Technology, Maharashtra, India, (2) vCreaTek Consulting Services Pvt. Ltd., Maharashtra, India)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Multiple Noisy Augmented Data Sets for Better Cross-Lingual Spoken Language Understanding. (arXiv:2109.01583v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01583","description":"<p>Lack of training data presents a grand challenge to scaling out spoken\nlanguage understanding (SLU) to low-resource languages. Although various data\naugmentation approaches have been proposed to synthesize training data in\nlow-resource target languages, the augmented data sets are often noisy, and\nthus impede the performance of SLU models. In this paper we focus on mitigating\nnoise in augmented data. We develop a denoising training approach. Multiple\nmodels are trained with data produced by various augmented methods. Those\nmodels provide supervision signals to each other. The experimental results show\nthat our method outperforms the existing state of the art by 3.05 and 4.24\npercentage points on two benchmark datasets, respectively. The code will be\nmade open sourced on github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yingmei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Linjun Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jian Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingxing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Training with Dense Retrieval for Document Retrieval. (arXiv:2109.01628v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01628","description":"<p>Dense retrieval has shown great success in passage ranking in English.\nHowever, its effectiveness in document retrieval for non-English languages\nremains unexplored due to the limitation in training resources. In this work,\nwe explore different transfer techniques for document ranking from English\nannotations to multiple non-English languages. Our experiments on the test\ncollections in six languages (Chinese, Arabic, French, Hindi, Bengali, Spanish)\nfrom diverse language families reveal that zero-shot model-based transfer using\nmBERT improves the search quality in non-English mono-lingual retrieval. Also,\nwe find that weakly-supervised target language transfer yields competitive\nperformances against the generation-based target language transfer that\nrequires external translators and query generators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Peng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1\">He Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01636","description":"<p>With the fast development of Deep Learning techniques, Named Entity\nRecognition (NER) is becoming more and more important in the information\nextraction task. The greatest difficulty that the NER task faces is to keep the\ndetectability even when types of NE and documents are unfamiliar. Realizing\nthat the specificity information may contain potential meanings of a word and\ngenerate semantic-related features for word embedding, we develop a\ndistribution-aware word embedding and implement three different methods to make\nuse of the distribution information in a NER framework. And the result shows\nthat the performance of NER will be improved if the word specificity is\nincorporated into existing NER methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinyang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Finetuned Language Models Are Zero-Shot Learners. (arXiv:2109.01652v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01652","description":"<p>This paper explores a simple method for improving the zero-shot learning\nabilities of language models. We show that instruction tuning -- finetuning\nlanguage models on a collection of tasks described via instructions --\nsubstantially boosts zero-shot performance on unseen tasks.\n</p>\n<p>We take a 137B parameter pretrained language model and instruction-tune it on\nover 60 NLP tasks verbalized via natural language instruction templates. We\nevaluate this instruction-tuned model, which we call FLAN, on unseen task\ntypes. FLAN substantially improves the performance of its unmodified\ncounterpart and surpasses zero-shot 175B GPT-3 on 19 of 25 tasks that we\nevaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE,\nBoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number\nof tasks and model scale are key components to the success of instruction\ntuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosma_M/0/1/0/all/0/1\">Maarten Bosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_V/0/1/0/all/0/1\">Vincent Y. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guu_K/0/1/0/all/0/1\">Kelvin Guu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Adams Wei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lester_B/0/1/0/all/0/1\">Brian Lester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Nan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew M. Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CREAK: A Dataset for Commonsense Reasoning over Entity Knowledge. (arXiv:2109.01653v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01653","description":"<p>Most benchmark datasets targeting commonsense reasoning focus on everyday\nscenarios: physical knowledge like knowing that you could fill a cup under a\nwaterfall [Talmor et al., 2019], social knowledge like bumping into someone is\nawkward [Sap et al., 2019], and other generic situations. However, there is a\nrich space of commonsense inferences anchored to knowledge about specific\nentities: for example, deciding the truthfulness of a claim \"Harry Potter can\nteach classes on how to fly on a broomstick.\" Can models learn to combine\nentity knowledge with commonsense reasoning in this fashion? We introduce\nCREAK, a testbed for commonsense reasoning about entity knowledge, bridging\nfact-checking about entities (Harry Potter is a wizard and is skilled at riding\na broomstick) with commonsense inferences (if you're good at a skill you can\nteach others how to do it). Our dataset consists of 13k human-authored English\nclaims about entities that are either true or false, in addition to a small\ncontrast set. Crowdworkers can easily come up with these statements and human\nperformance on the dataset is high (high 90s); we argue that models should be\nable to blend entity knowledge and commonsense reasoning to do well here. In\nour experiments, we focus on the closed-book setting and observe that a\nbaseline model finetuned on existing fact verification benchmark struggles on\nCREAK. Training a model on CREAK improves accuracy by a substantial margin, but\nstill falls short of human performance. Our benchmark provides a unique probe\ninto natural language understanding models, testing both its ability to\nretrieve facts (e.g., who teaches at the University of Chicago?) and unstated\ncommonsense knowledge (e.g., butlers do not yell at guests).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1\">Yasumasa Onoe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Michael J.Q. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?. (arXiv:1905.10617v10 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/1905.10617","description":"<p>Exposure bias has been regarded as a central problem for auto-regressive\nlanguage models (LM). It claims that teacher forcing would cause the test-time\ngeneration to be incrementally distorted due to the training-generation\ndiscrepancy. Although a lot of algorithms have been proposed to avoid teacher\nforcing and therefore alleviate exposure bias, there is little work showing how\nserious the exposure bias problem actually is. In this work, we focus on the\ntask of open-ended language generation, propose metrics to quantify the impact\nof exposure bias in the aspects of quality, diversity, and consistency. Our key\nintuition is that if we feed ground-truth data prefixes (instead of prefixes\ngenerated by the model itself) into the model and ask it to continue the\ngeneration, the performance should become much better because the\ntraining-generation discrepancy in the prefix is removed. Both automatic and\nhuman evaluations are conducted in our experiments. On the contrary to the\npopular belief in exposure bias, we find that the the distortion induced by the\nprefix discrepancy is limited, and does not seem to be incremental during the\ngeneration. Moreover, our analysis reveals an interesting self-recovery ability\nof the LM, which we hypothesize to be countering the harmful effects from\nexposure bias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhiming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey on Publicly Available Sinhala Natural Language Processing Tools and Research. (arXiv:1906.02358v10 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1906.02358","description":"<p>Sinhala is the native language of the Sinhalese people who make up the\nlargest ethnic group of Sri Lanka. The language belongs to the globe-spanning\nlanguage tree, Indo-European. However, due to poverty in both linguistic and\neconomic capital, Sinhala, in the perspective of Natural Language Processing\ntools and research, remains a resource-poor language which has neither the\neconomic drive its cousin English has nor the sheer push of the law of numbers\na language such as Chinese has. A number of research groups from Sri Lanka have\nnoticed this dearth and the resultant dire need for proper tools and research\nfor Sinhala natural language processing. However, due to various reasons, these\nattempts seem to lack coordination and awareness of each other. The objective\nof this paper is to fill that gap of a comprehensive literature survey of the\npublicly available Sinhala natural language tools and research so that the\nresearchers working in this field can better utilize contributions of their\npeers. As such, we shall be uploading this paper to arXiv and perpetually\nupdate it periodically to reflect the advances made in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1\">Nisansa de Silva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adjusting for Confounders with Text: Challenges and an Empirical Evaluation Framework for Causal Inference. (arXiv:2009.09961v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.09961","description":"<p>Leveraging text, such as social media posts, for causal inferences requires\nthe use of NLP models to 'learn' and adjust for confounders, which could\notherwise impart bias. However, evaluating such models is challenging, as\nground truth is almost never available. We demonstrate the need for empirical\nevaluation frameworks for causal inference in natural language by showing that\nexisting, commonly used models regularly disagree with one another on real\nworld tasks. We contribute the first such framework, generalizing several\nchallenges across these real world tasks. Using this framework, we evaluate a\nlarge set of commonly used causal inference models based on propensity scores\nand identify their strengths and weaknesses to inform future improvements. We\nmake all tasks, data, and models public to inform applications and encourage\nadditional research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weld_G/0/1/0/all/0/1\">Galen Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glenski_M/0/1/0/all/0/1\">Maria Glenski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arbour_D/0/1/0/all/0/1\">David Arbour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Althoff_T/0/1/0/all/0/1\">Tim Althoff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CR-Walker: Tree-Structured Graph Reasoning and Dialog Acts for Conversational Recommendation. (arXiv:2010.10333v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.10333","description":"<p>Growing interests have been attracted in Conversational Recommender Systems\n(CRS), which explore user preference through conversational interactions in\norder to make appropriate recommendation. However, there is still a lack of\nability in existing CRS to (1) traverse multiple reasoning paths over\nbackground knowledge to introduce relevant items and attributes, and (2)\narrange selected entities appropriately under current system intents to control\nresponse generation. To address these issues, we propose CR-Walker in this\npaper, a model that performs tree-structured reasoning on a knowledge graph,\nand generates informative dialog acts to guide language generation. The unique\nscheme of tree-structured reasoning views the traversed entity at each hop as\npart of dialog acts to facilitate language generation, which links how entities\nare selected and expressed. Automatic and human evaluations show that CR-Walker\ncan arrive at more accurate recommendation, and generate more informative and\nengaging responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenchang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1\">Ryuichi Takanobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Where Are You? Localization from Embodied Dialog. (arXiv:2011.08277v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2011.08277","description":"<p>We present Where Are You? (WAY), a dataset of ~6k dialogs in which two humans\n-- an Observer and a Locator -- complete a cooperative localization task. The\nObserver is spawned at random in a 3D environment and can navigate from\nfirst-person views while answering questions from the Locator. The Locator must\nlocalize the Observer in a detailed top-down map by asking questions and giving\ninstructions. Based on this dataset, we define three challenging tasks:\nLocalization from Embodied Dialog or LED (localizing the Observer from dialog\nhistory), Embodied Visual Dialog (modeling the Observer), and Cooperative\nLocalization (modeling both agents). In this paper, we focus on the LED task --\nproviding a strong baseline model with detailed ablations characterizing both\ndataset biases and the importance of various modeling choices. Our best model\nachieves 32.7% success at identifying the Observer's location within 3m in\nunseen buildings, vs. 70.4% for human Locators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hahn_M/0/1/0/all/0/1\">Meera Hahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krantz_J/0/1/0/all/0/1\">Jacob Krantz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1\">Dhruv Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stefan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anderson_P/0/1/0/all/0/1\">Peter Anderson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CascadeBERT: Accelerating Inference of Pre-trained Language Models via Calibrated Complete Models Cascade. (arXiv:2012.14682v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.14682","description":"<p>Dynamic early exiting aims to accelerate the inference of pre-trained\nlanguage models (PLMs) by emitting predictions in internal layers without\npassing through the entire model. In this paper, we empirically analyze the\nworking mechanism of dynamic early exiting and find that it faces a performance\nbottleneck under high speed-up ratios. On one hand, the PLMs' representations\nin shallow layers lack high-level semantic information and thus are not\nsufficient for accurate predictions. On the other hand, the exiting decisions\nmade by internal classifiers are unreliable, leading to wrongly emitted early\npredictions. We instead propose a new framework for accelerating the inference\nof PLMs, CascadeBERT, which dynamically selects proper-sized and complete\nmodels in a cascading manner, providing comprehensive representations for\npredictions. We further devise a difficulty-aware objective, encouraging the\nmodel to output the class probability that reflects the real difficulty of each\ninstance for a more reliable cascading mechanism. Experimental results show\nthat CascadeBERT can achieve an overall 15\\% improvement under 4$\\times$\nspeed-up compared with existing dynamic early exiting methods on six\nclassification tasks, yielding more calibrated and accurate predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deli Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Which Linguist Invented the Lightbulb? Presupposition Verification for Question-Answering. (arXiv:2101.00391v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00391","description":"<p>Many Question-Answering (QA) datasets contain unanswerable questions, but\ntheir treatment in QA systems remains primitive. Our analysis of the Natural\nQuestions (Kwiatkowski et al. 2019) dataset reveals that a substantial portion\nof unanswerable questions ($\\sim$21%) can be explained based on the presence of\nunverifiable presuppositions. We discuss the shortcomings of current models in\nhandling such questions, and describe how an improved system could handle them.\nThrough a user preference study, we demonstrate that the oracle behavior of our\nproposed system that provides responses based on presupposition failure is\npreferred over the oracle behavior of existing QA systems. Then we discuss how\nour proposed system could be implemented, presenting a novel framework that\nbreaks down the problem into three steps: presupposition generation,\npresupposition verification and explanation generation. We report our progress\nin tackling each subproblem, and present a preliminary approach to integrating\nthese steps into an existing QA system. We find that adding presuppositions and\ntheir verifiability to an existing model yields modest gains in downstream\nperformance and unanswerability detection. The biggest bottleneck is the\nverification component, which needs to be substantially improved for the\nintegrated system to approach ideal behavior -- even transfer from the best\nentailment models currently falls short.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayan_B/0/1/0/all/0/1\">Burcu Karagol Ayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_D/0/1/0/all/0/1\">Deepak Ramachandran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CDLM: Cross-Document Language Modeling. (arXiv:2101.00406v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00406","description":"<p>We introduce a new pretraining approach geared for multi-document language\nmodeling, incorporating two key ideas into the masked language modeling\nself-supervised objective. First, instead of considering documents in\nisolation, we pretrain over sets of multiple related documents, encouraging the\nmodel to learn cross-document relationships. Second, we improve over recent\nlong-range transformers by introducing dynamic global attention that has access\nto the entire input to predict masked tokens. We release CDLM (Cross-Document\nLanguage Model), a new general language model for multi-document setting that\ncan be easily applied to downstream tasks. Our extensive analysis shows that\nboth ideas are essential for the success of CDLM, and work in synergy to set\nnew state-of-the-art results for several multi-text tasks. Code and models are\navailable at https://github.com/aviclu/CDLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_M/0/1/0/all/0/1\">Matthew E. Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections. (arXiv:2104.04670v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.04670","description":"<p>Large pre-trained language models (LMs) such as GPT-3 have acquired a\nsurprising ability to perform zero-shot learning. For example, to classify\nsentiment without any training examples, we can \"prompt\" the LM with the review\nand the label description \"Does the user like this movie?\", and ask whether the\nnext word is \"yes\" or \"no\". However, the next word prediction training\nobjective is still misaligned with the target zero-shot learning objective. To\naddress this weakness, we propose meta-tuning, which directly optimizes the\nzero-shot learning objective by fine-tuning pre-trained language models on a\ncollection of datasets. We focus on classification tasks, and construct the\nmeta-dataset by aggregating 43 existing datasets and annotating 441 label\ndescriptions in a question-answering (QA) format. When evaluated on unseen\ntasks, meta-tuned models outperform a same-sized QA model and the previous SOTA\nzero-shot learning system based on natural language inference. Additionally,\nincreasing parameter count from 220M to 770M improves AUC-ROC scores by 6.3%,\nand we forecast that even larger models would perform better. Therefore,\nmeasuring zero-shot learning performance on language models out-of-the-box\nmight underestimate their true potential, and community-wide efforts on\naggregating datasets and unifying their formats can help build models that\nanswer prompts better.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kristy Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07650","description":"<p>Recently, prompt-tuning has achieved promising results on some few-shot\nclassification tasks. The core idea of prompt-tuning is to insert text pieces,\ni.e., templates, into the input and transform a classification task into a\nmasked language modeling problem. However, as for relation extraction,\ndetermining the appropriate prompt template requires domain expertise. Single\nlabel word handcrafted or auto-searched is cumbersome and time-consuming to\nverify their effectiveness in non-few-shot scenarios. Further, there exist\nabundant semantic knowledge among the entities and relation labels which cannot\nbe ignored. To this end, we focus on incorporating knowledge into prompt-tuning\nfor relation extraction and propose a knowledge-aware prompt-tuning with\nsynergistic optimization (KnowPrompt) approach. Specifically, we inject entity\nand relation knowledge into prompt construction with learnable virtual template\nwords and answer words and jointly optimize their representation with knowledge\nconstraints. Extensive experimental results on five datasets with standard and\nlow-resource settings demonstrate the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sublanguage: A Serious Issue Affects Pretrained Models in Legal Domain. (arXiv:2104.07782v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07782","description":"<p>Legal English is a sublanguage that is important for everyone but not for\neveryone to understand. Pretrained models have become best practices among\ncurrent deep learning approaches for different problems. It would be a waste or\neven a danger if these models were applied in practice without knowledge of the\nsublanguage of the law. In this paper, we raise the issue and propose a trivial\nsolution by introducing BERTLaw a legal sublanguage pretrained model. The\npaper's experiments demonstrate the superior effectiveness of the method\ncompared to the baseline pretrained model\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Le-Minh Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KI-BERT: Infusing Knowledge Context for Better Language and Domain Understanding. (arXiv:2104.08145v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08145","description":"<p>Contextualized entity representations learned by state-of-the-art\ntransformer-based language models (TLMs) like BERT, GPT, T5, etc., leverage the\nattention mechanism to learn the data context from training data corpus.\nHowever, these models do not use the knowledge context. Knowledge context can\nbe understood as semantics about entities and their relationship with\nneighboring entities in knowledge graphs. We propose a novel and effective\ntechnique to infuse knowledge context from multiple knowledge graphs for\nconceptual and ambiguous entities into TLMs during fine-tuning. It projects\nknowledge graph embeddings in the homogeneous vector-space, introduces new\ntoken-types for entities, aligns entity position ids, and a selective attention\nmechanism. We take BERT as a baseline model and implement the\n\"Knowledge-Infused BERT\" by infusing knowledge context from ConceptNet and\nWordNet, which significantly outperforms BERT and other recent knowledge-aware\nBERT variants like ERNIE, SenseBERT, and BERT_CS over eight different subtasks\nof GLUE benchmark. The KI-BERT-base model even significantly outperforms\nBERT-large for domain-specific tasks like SciTail and academic subsets of QQP,\nQNLI, and MNLI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faldu_K/0/1/0/all/0/1\">Keyur Faldu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kikani_P/0/1/0/all/0/1\">Prashant Kikani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbari_H/0/1/0/all/0/1\">Hemang Akbari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extract, Denoise and Enforce: Evaluating and Improving Concept Preservation for Text-to-Text Generation. (arXiv:2104.08724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08724","description":"<p>Prior studies on text-to-text generation typically assume that the model\ncould figure out what to attend to in the input and what to include in the\noutput via seq2seq learning, with only the parallel training data and no\nadditional guidance. However, it remains unclear whether current models can\npreserve important concepts in the source input, as seq2seq learning does not\nhave explicit focus on the concepts and commonly used evaluation metrics also\ntreat concepts equally important as other tokens. In this paper, we present a\nsystematic analysis that studies whether current seq2seq models, especially\npre-trained language models, are good enough for preserving important input\nconcepts and to what extent explicitly guiding generation with the concepts as\nlexical constraints is beneficial. We answer the above questions by conducting\nextensive analytical experiments on four representative text-to-text generation\ntasks. Based on the observations, we then propose a simple yet effective\nframework to automatically extract, denoise, and enforce important input\nconcepts as lexical constraints. This new method performs comparably or better\nthan its unconstrained counterpart on automatic metrics, demonstrates higher\ncoverage for concept preservation, and receives better ratings in the human\nevaluation. Our code is available at https://github.com/morningmoni/EDE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wenchang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_D/0/1/0/all/0/1\">Deren Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Verdi: Quality Estimation and Error Detection for Bilingual Corpora. (arXiv:2105.14878v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.14878","description":"<p>Translation Quality Estimation is critical to reducing post-editing efforts\nin machine translation and to cross-lingual corpus cleaning. As a research\nproblem, quality estimation (QE) aims to directly estimate the quality of\ntranslation in a given pair of source and target sentences, and highlight the\nwords that need corrections, without referencing to golden translations. In\nthis paper, we propose Verdi, a novel framework for word-level and\nsentence-level post-editing effort estimation for bilingual corpora. Verdi\nadopts two word predictors to enable diverse features to be extracted from a\npair of sentences for subsequent quality estimation, including a\ntransformer-based neural machine translation (NMT) model and a pre-trained\ncross-lingual language model (XLM). We exploit the symmetric nature of\nbilingual corpora and apply model-level dual learning in the NMT predictor,\nwhich handles a primal task and a dual task simultaneously with weight sharing,\nleading to stronger context prediction ability than single-direction NMT\nmodels. By taking advantage of the dual learning scheme, we further design a\nnovel feature to directly encode the translated target information without\nrelying on the source context. Extensive experiments conducted on WMT20 QE\ntasks demonstrate that our method beats the winner of the competition and\noutperforms other baseline methods by a great margin. We further use the\nsentence-level scores provided by Verdi to clean a parallel corpus and observe\nbenefits on both model performance and training efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mingjun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haijiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_D/0/1/0/all/0/1\">Di Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoli Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Coreference Resolution with Harmonized Annotations. (arXiv:2107.12088v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.12088","description":"<p>In this paper, we present coreference resolution experiments with a newly\ncreated multilingual corpus CorefUD. We focus on the following languages:\nCzech, Russian, Polish, German, Spanish, and Catalan. In addition to\nmonolingual experiments, we combine the training data in multilingual\nexperiments and train two joined models -- for Slavic languages and for all the\nlanguages together. We rely on an end-to-end deep learning model that we\nslightly adapted for the CorefUD corpus. Our results show that we can profit\nfrom harmonized annotations, and using joined models helps significantly for\nthe languages with smaller training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prazak_O/0/1/0/all/0/1\">Ond&#x159;ej Pra&#x17e;&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konopik_M/0/1/0/all/0/1\">Miloslav Konop&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sido_J/0/1/0/all/0/1\">Jakub Sido</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Dataset for Answering Time-Sensitive Questions. (arXiv:2108.06314v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.06314","description":"<p>Time is an important dimension in our physical world. Lots of facts can\nevolve with respect to time. For example, the U.S. President might change every\nfour years. Therefore, it is important to consider the time dimension and\nempower the existing QA models to reason over time. However, the existing QA\ndatasets contain rather few time-sensitive questions, hence not suitable for\ndiagnosing or benchmarking the model's temporal reasoning capability. In order\nto promote research in this direction, we propose to construct a time-sensitive\nQA dataset. The dataset is constructed by 1) mining time-evolving facts from\nWikiData and align them to their corresponding Wikipedia page, 2) employing\ncrowd workers to verify and calibrate these noisy facts, 3) generating\nquestion-answer pairs based on the annotated time-sensitive facts. Our dataset\nposes challenges in the aspect of both temporal understanding and temporal\nreasoning. We evaluate different SoTA long-document QA systems like BigBird and\nFiD on our dataset. The best-performing model FiD can only achieve 46\\%\naccuracy, still far behind the human performance of 87\\%. We demonstrate that\nthese models are still lacking the ability to perform consistent temporal\nreasoning. Therefore, we believe that our dataset could serve as a benchmark to\ndevelop NLP models more sensitive to temporal shift. The dataset and code are\nreleased in~\\url{https://github.com/wenhuchen/Time-Sensitive-QA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Affective Decoding for Empathetic Response Generation. (arXiv:2108.08102v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08102","description":"<p>Understanding speaker's feelings and producing appropriate responses with\nemotion connection is a key communicative skill for empathetic dialogue\nsystems. In this paper, we propose a simple technique called Affective Decoding\nfor empathetic response generation. Our method can effectively incorporate\nemotion signals during each decoding step, and can additionally be augmented\nwith an auxiliary dual emotion encoder, which learns separate embeddings for\nthe speaker and listener given the emotion base of the dialogue. Extensive\nempirical studies show that our models are perceived to be more empathetic by\nhuman evaluations, in comparison to several strong mainstream methods for\nempathetic responding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chengkun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruizhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhigang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12202","description":"<p>In joint entity and relation extraction, existing work either sequentially\nencode task-specific features, leading to an imbalance in inter-task feature\ninteraction where features extracted later have no direct contact with those\nthat come first. Or they encode entity features and relation features in a\nparallel manner, meaning that feature representation learning for each task is\nlargely independent of each other except for input sharing. We propose a\npartition filter network to model two-way interaction between tasks properly,\nwhere feature encoding is decomposed into two steps: partition and filter. In\nour encoder, we leverage two gates: entity and relation gate, to segment\nneurons into two task partitions and one shared partition. The shared partition\nrepresents inter-task information valuable to both tasks and is evenly shared\nacross two tasks to ensure proper two-way interaction. The task partitions\nrepresent intra-task information and are formed through concerted efforts of\nboth gates, making sure that encoding of task-specific features is dependent\nupon each other. Experiment results on five public datasets show that our model\nperforms significantly better than previous approaches. In addition, contrary\nto what previous work claims, our auxiliary experiments suggest that relation\nprediction is contributory to named entity prediction in a non-negligible way.\nThe source code can be found at https://github.com/Coopercoppers/PFN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12229","description":"<p>The ability to detect Out-of-Domain (OOD) inputs has been a critical\nrequirement in many real-world NLP applications since the inclusion of\nunsupported OOD inputs may lead to catastrophic failure of systems. However, it\nremains an empirical question whether current algorithms can tackle such\nproblem reliably in a realistic scenario where zero OOD training data is\navailable. In this study, we propose ProtoInfoMax, a new architecture that\nextends Prototypical Networks to simultaneously process In-Domain (ID) and OOD\nsentences via Mutual Information Maximization (InfoMax) objective. Experimental\nresults show that our proposed method can substantially improve performance up\nto 20% for OOD detection in low resource settings of text classification. We\nalso show that ProtoInfoMax is less prone to typical over-confidence Error of\nNeural Networks, leading to more reliable ID and OOD prediction outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nimah_I/0/1/0/all/0/1\">Iftitahu Ni&#x27;mah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1\">Vlado Menkovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NEREL: A Russian Dataset with Nested Named Entities, Relations and Events. (arXiv:2108.13112v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13112","description":"<p>In this paper, we present NEREL, a Russian dataset for named entity\nrecognition and relation extraction. NEREL is significantly larger than\nexisting Russian datasets: to date it contains 56K annotated named entities and\n39K annotated relations. Its important difference from previous datasets is\nannotation of nested named entities, as well as relations within nested\nentities and at the discourse level. NEREL can facilitate development of novel\nmodels that can extract relations between nested named entities, as well as\nrelations on both sentence and document levels. NEREL also contains the\nannotation of events involving named entities and their roles in the events.\nThe NEREL collection is available via https://github.com/nerel-ds/NEREL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loukachevitch_N/0/1/0/all/0/1\">Natalia Loukachevitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1\">Ekaterina Artemova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1\">Tatiana Batura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braslavski_P/0/1/0/all/0/1\">Pavel Braslavski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denisov_I/0/1/0/all/0/1\">Ilia Denisov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_V/0/1/0/all/0/1\">Vladimir Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manandhar_S/0/1/0/all/0/1\">Suresh Manandhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pugachev_A/0/1/0/all/0/1\">Alexander Pugachev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutubalina_E/0/1/0/all/0/1\">Elena Tutubalina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition. (arXiv:2109.00627v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00627","description":"<p>Contextual knowledge is important for real-world automatic speech recognition\n(ASR) applications. In this paper, a novel tree-constrained pointer generator\n(TCPGen) component is proposed that incorporates such knowledge as a list of\nbiasing words into both attention-based encoder-decoder and transducer\nend-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing\nwords into an efficient prefix tree to serve as its symbolic input and creates\na neural shortcut between the tree and the final ASR output distribution to\nfacilitate recognising biasing words during decoding. Systems were trained and\nevaluated on the Librispeech corpus where biasing words were extracted at the\nscales of an utterance, a chapter, or a book to simulate different application\nscenarios. Experimental results showed that TCPGen consistently improved word\nerror rates (WERs) compared to the baselines, and in particular, achieved\nsignificant WER reductions on the biasing words. TCPGen is highly efficient: it\ncan handle 5,000 biasing words and distractors and only add a small overhead to\nmemory use and computation cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Guangzhi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1\">Philip C. Woodland</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language Model Pre-Training. (arXiv:2109.00993v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00993","description":"<p>Large Transformer-based language models such as BERT have led to broad\nperformance improvements on many NLP tasks. Domain-specific variants of these\nmodels have demonstrated excellent performance on a variety of specialised\ntasks. In legal NLP, BERT-based models have led to new state-of-the-art results\non multiple tasks. The exploration of these models has demonstrated the\nimportance of capturing the specificity of the legal language and its\nvocabulary. However, such approaches suffer from high computational costs,\nleading to a higher ecological impact and lower accessibility. Our findings,\nfocusing on English language legal text, show that lightweight LSTM-based\nLanguage Models are able to capture enough information from a small legal text\npretraining corpus and achieve excellent performance on short legal text\nclassification tasks. This is achieved with a significantly reduced\ncomputational overhead compared to BERT-based models. However, our method also\nshows degraded performance on a more complex task, multi-label classification\nof longer documents, highlighting the limitations of this lightweight approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Clavie_B/0/1/0/all/0/1\">Benjamin Clavi&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gheewala_A/0/1/0/all/0/1\">Akshita Gheewala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briton_P/0/1/0/all/0/1\">Paul Briton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alphonsus_M/0/1/0/all/0/1\">Marc Alphonsus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laabiyad_R/0/1/0/all/0/1\">Rym Laabiyad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccoli_F/0/1/0/all/0/1\">Francesco Piccoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-05T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/"}}]}]}