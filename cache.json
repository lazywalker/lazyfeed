{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-14T04:21:09.755367936Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【招聘｜北京/上海/成都/深圳/美国加州】Rust开发工程师（30k-60k+）","link":"https://rustcc.cn/article?id=ab239e8d-3a99-4b85-930f-a3e57d5fb63f","description":"<p>现阶段，非凸科技正在寻找行业内优秀的Rust开发工程师，薪资福利超级优厚。关键是团队有很好的Rust开发氛围，Rust大神手把手辅导，助你从Rust新人不断升级。欢迎加入我们。</p>\n<p>岗位职责：\n1.设计并开发基于RUST的高性能，低时延算法交易系统；\n2.设计并开发数据处理平台，监控运维平台；\n3.设计并开发面向客户的高可用交易工具等；\n4.设计并开发策略相关的回测平台。</p>\n<p>岗位要求：\n1.本科及以上学历（985优先）。编程基础扎实，具有良好的计算机理论基础；\n2.熟练掌握Linux操作，性能分析，具备Rust/C++/Java/Go丰富开发经验，熟悉常用的设计模式，有分布式相关经验加分；\n3.有研发高性能，低时延系统经验加分；\n4.对技术充满热情，思考深入。自我驱动，能快速学习新鲜事物。</p>\n<p>公司福利\n1.提供租房补贴；\n2.日常不间断网红零食、饮料、茶水供给；\n3.不定期组织各部门技术交流学习研讨会，分享心得，互相成长；\n4.团建活动丰富多彩，放松心情缓解疲劳。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 14:39:59","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-13 Rust 在 linux 内核中的最新进展","link":"https://rustcc.cn/article?id=1c26513e-c4c2-4d52-becf-8c39379474e9","description":"<h1>Rust 在 linux 内核中的最新进展</h1>\n<p>虽然Rust编程语言在内核中使用的支持还没有登陆到本周末结束的 <code>Linux 5.15</code> 合并窗口，但这项工作仍在进行中。本周，关于Rust在Linux内核中的使用的最新进展被分享了出来。</p>\n<p>作为Rust for Linux项目的主要开发人员之一，Miguel Ojeda在本周的Linaro Connect虚拟会议上介绍了该项目，他目前正在为谷歌的合同工作。</p>\n<p>对周五的演讲感兴趣的人可以查看下面的 Presentation。</p>\n<p><a href=\"https://bigthinkbuzz.com/the-latest-progress-on-rust-for-the-linux-kernel/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<p><a href=\"https://static.linaro.org/connect/lvc21f/presentations/LVC21F-317.pdf\" rel=\"noopener noreferrer\">Presentation地址</a></p>\n<h1>Matchbox: Rust wasm 中的 p2p 网络解决方案</h1>\n<p>Matchbox 的诞生是因为作者在<code>rust</code> 中制作了一款多人网页游戏，遇到了以下问题:</p>\n<p>如何使用不可靠的、无序的 p2p connection 连接 N 个web浏览器?</p>\n<p><a href=\"https://johanhelsing.studio/posts/introducing-matchbox\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>Learn Wgpu 更新了</h1>\n<p><code>wgrpu</code> 是 <code>WebGPU API spec</code> 的 Rust 实现, 目前这个教程已经更新到了 0.10 版本, 有大量的原理和代码示例讲解.</p>\n<p><a href=\"https://sotrh.github.io/learn-wgpu/beginner/tutorial2-surface/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>Sycamore: v0.6.0 版本发布了</h1>\n<p>Sycamore是一个用 Rust 和 WebAssembly 构建同构web应用程序的库. 目前发布了 0.6.0 版本了.</p>\n<ul>\n<li>静态生成</li>\n<li>服务端渲染</li>\n<li>重验证</li>\n<li>增量构建</li>\n<li>开放构建矩阵</li>\n<li>CLI利用，让您轻松和自信地构建应用程序</li>\n<li>充分利用 Fluent 开箱即用的 i18n 支持</li>\n</ul>\n<p><a href=\"https://sycamore-rs.netlify.app/news/announcing-v0.6.0\" rel=\"noopener noreferrer\">原文链接</a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 13:10:04","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【成都】招聘Rust开发工程师","link":"https://rustcc.cn/article?id=ed86a028-a5b8-41e6-9849-e43a55ff7faf","description":"<h2>Rust开发工程师招聘</h2>\n<h3>岗位职责：</h3>\n<ul>\n<li>1、负责电商产品后端功能接口的开发；</li>\n<li>2、负责电商产品业务功能开发、迭代和维护，对业务数据进行处理和分析；</li>\n<li>3、配合前端开发完成功能的前后台功能联调；</li>\n<li>4、配合完成产品测试，BUG修改。</li>\n</ul>\n<h3>任职要求：</h3>\n<ul>\n<li>1、后端开发语言基础扎实，有电商产品后端开发经验；</li>\n<li>2、熟练使用使用Mysql关系型数据库；</li>\n<li>3、至少了解并使用过RocketMQ、RabbitMQ、Kafka中的一种；</li>\n<li>4、有Rust语言的基础，或者愿意转Rust开发；</li>\n<li>5、三年以上的互联网开发工作经验；</li>\n<li>6、熟习微服务或ServicesMesh架构者优先；</li>\n</ul>\n<p>工作地点四川成都环球时代中心\n有意者请发邮件至：shaipe@sina.com 或直接添加微信号：shaipe</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 10:59:47","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"read_dir 返回的 io::Result<DirEntry> 会在什么情况下返回 Error 呢？","link":"https://rustcc.cn/article?id=c1f3f464-9146-4b43-8467-7eacc8f53bf8","description":"<p><code>read_dir</code> 迭代的时候给到的是一个 <code>io::Result&lt;DirEntry&gt;</code>，文档里面只是简单说了 <strong>New errors may be encountered after an iterator is initially constructed.</strong></p>\n<p>但是具体这个 New errors 到底是什么？</p>\n<p>我试过了在迭代的时候对文件夹或者里面的文件作删除、重命名、改变权限，都没有返回 error；\n（测试平台包括 Mac 和 Linux，没有 windows 暂时没测）。</p>\n<p><img src=\"https://i.loli.net/2021/09/13/AbE9KdTL1sSxWJg.png\" alt=\"screenshot-20210913-174925.png\"></p>\n<pre><code>/// Iterator over the entries in a directory.\n///\n/// This iterator is returned from the [`read_dir`] function of this module and\n/// will yield instances of [`io::Result`]`&lt;`[`DirEntry`]`&gt;`. Through a [`DirEntry`]\n/// information like the entry's path and possibly other metadata can be\n/// learned.\n///\n/// The order in which this iterator returns entries is platform and filesystem\n/// dependent.\n///\n/// # Errors\n///\n/// This [`io::Result`] will be an [`Err`] if there's some sort of intermittent\n/// IO error during iteration.\n#[stable(feature = \"rust1\", since = \"1.0.0\")]\n#[derive(Debug)]\npub struct ReadDir(fs_imp::ReadDir);\n</code></pre>\n<p>This [<code>io::Result</code>] will be an [<code>Err</code>] if there's some sort of intermittent IO error during iteration.</p>\n<p>看起来一定要是比较罕见的 IO 错误？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 09:45:42","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"关于我前些天，在 GitHub 上 Rust 的 repo 的那些事","link":"https://rustcc.cn/article?id=111d596f-f53f-44dc-9a59-69ccf2ff7563","description":"<p>上周我在 GitHub 上整理的 <a href=\"https://github.com/0voice/Understanding_in_Rust\" rel=\"noopener noreferrer\">《 Rust 工程师枕边资料》</a> ,涉及了侵权行为。在这里向大家赔礼道歉。并且在第一时间，处理了相关内容。\n我在整理的之前的初衷只是单纯为了给大家提供更好、更多、更全、更专业地的 Rust 学习资料。并没有丝毫的商业化手段。\n我收集的内容全部来源于互联网，由于我的疏忽没有注明文章出处链接，确实是不应该的。</p>\n<p>再一次，给作品的作者道歉。</p>\n<p>我将在以后 repo 里将不会出现类似的错误事件，同时也希望广大开发者们监督。如果有任何问题，可以邮箱至：wchao_isvip@163.com ，我会在第一时间处理的。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 08:11:56","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"filecoin项目RUST大牛招聘","link":"https://rustcc.cn/article?id=3a173b77-c75e-4cbb-a8c9-8c0496b17619","description":"<p>该岗位薪资面谈\n岗位职责：\n1.参与区块链项目开发，以C++/rust为主；\n2.理解业务逻辑与对后端服务的需求，能够分析需求并产生合理技术方案；\n3.负责平台对外接口，相关数据服务的设计与实现；\n4.根据技术需求部署Filecoin环境，编写脚本，对环境进行测试部署；\n5.参与公司项目专利的编写；\n岗位要求：\n1.大专以上学历，计算机或者相关专业，精通rust语言；\n2.至少熟悉两种其他开发语言，如C++、go、Python等；\n3.2年以上后端开发工作经验，做过区块链项目开发经验的可优先考虑；\n4.熟悉Ethereum、EOS、Bitcoin、Filecoin中至少两个项目的基本原理和设计；\n5.熟悉区块链项目中常见的共识机制、加密算法、P2P网络等；\n6.思路清晰，具备良好的沟通能力、团队合作意识，能抗压，能主动承担，乐于分享。</p>\n<p>详情可联系yhcaozyyz@qq.com or 18109055866</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-13 06:45:02","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【招聘  杭州，上海】Rust开发工程师（30K-50K）","link":"https://rustcc.cn/article?id=4f8da484-d0fc-4f56-88ca-c19e7ea32b5a","description":"<p>【岗位职责】</p>\n<ol>\n<li>负责分布式计算及存储系统的高可扩展后端系统，服务和API；</li>\n<li>设计高性能、高可靠性的服务，建立快速、稳定、安全的后端代码&nbsp;；</li>\n<li>为其他开发人员提供指导，参与算法设计和实现。</li>\n<li>负责设计和优化协议、弱网通信、存储、网络并发、并行计算、加密以及安全等；</li>\n<li>保证工程质量和开发效率。</li>\n<li>设计和维护性能测试用例；</li>\n</ol>\n<p>【岗位要求】</p>\n<ol>\n<li>计算机或者相关专业本科以上学历，两年以上相关工作经验</li>\n<li>技术扎实，熟悉Rust语言编程</li>\n<li>理解ownership, trait, async等语言机制。</li>\n<li>熟练使用tokio。熟练使用rust常用库</li>\n<li>有丰富的多线程应用和平台构建经验，可熟练构建稳定、高效率和安全的代码&nbsp;；</li>\n<li>有强烈的上进心和求知欲，善于学习和运用新知识，善于沟通和逻辑表达，有强烈的团队意识和执行力。</li>\n<li>熟悉Linux下多线程/多进程编程模型，进程间通讯，消息事件通知，同步/异步。</li>\n<li>熟悉Linux下内存管理机制，低延迟、高并发无锁化编程。</li>\n</ol>\n<p>【特别备注】</p>\n<ol>\n<li>了解安全加密相关算法者优先&nbsp;；</li>\n<li>有丰富的c++、python编程经验者优先</li>\n<li>参与大型系统的开发，并成功部署、广泛应用者优先；</li>\n<li>熟悉大数据、机器学习框架，如:spark，flink, tensorflow者优先。</li>\n</ol>\n<p>【工作地点】\nbase1: 杭州市西湖区中电万谷园区\nbase2: 上海市浦东新区前滩东方广场一期\n杭州上海均有岗位。</p>\n<p>联系方式：朝歌13732914991（微信同号） 邮箱：zhaoge@fudata.cn</p>\n<p>【公司介绍】\n上海富数科技有限公司 简称“富数科技”，是国内领先的金融AI和安全计算技术领跑者，核心团队来自CapitalOne，Alibaba和IBM，公司自2016年成立以来受国内顶级风投青睐，已完成C轮融资。富数科技坚持以“以数据安全驱动人工智能”，依托于安全计算和机器学习AI技术，助力金融和各行业机构组织提高智能风控、营销和运营的效率，实现数据合规安全地融合计算和价值流通。</p>\n<p>富数科技是中国通信标准化协会会员、工信部信通院大数据安全及流通标准组成员、安全多方计算标准参与方，为行业规范标准制定贡献创新技术成果。富数科技结合最新密码学和区块链技术研发创新，其安全计算和联邦学习开创性地采用“松弛迭代法”，在智能合约、ML算法优化、代码编译和计算硬件芯片融合方面改善性能，在同等条件下实现了收敛速度的大幅提升，精度和准确度损失低于1%，速度较行业水平提高了3倍。</p>\n<p>富数科技致力于驱动安全可信的人工智能科技与各行业场景的深度融合赋能，在兼顾隐私保护下发挥大数据的商业价值。富数科技自2017年投入数据安全计算领域研发创新，拥有多项专利发明和软著，并与国内外金融机构和科研机构（上海交大等）联合研发和推动工程化商业化落地。富数科技安全计算解决方案已经落地在智能风控、智能营销、监管和科研统计分析、异业或同业数据安全融合计算等场景，目前已在银行、持牌消金、政务、医疗、运营商等领域积累上百案例，在安全的机器学习领域具有突出的领先优势。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-12 15:57:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-09-12 Rust 的 Logging 推荐","link":"https://rustcc.cn/article?id=91b91a60-cbe9-4f8a-a5ec-8825da34457b","description":"<h3>Rust 的 Logging 推荐</h3>\n<p>内容整理自 Reddit 的讨论：<a href=\"https://www.reddit.com/r/rust/comments/pmdh6a/what_is_the_current_recommendation_for_logging_in/\" rel=\"noopener noreferrer\">What is the current recommendation for logging in Rust? : rust</a>。</p>\n<p>问题简述：除了标准的 <code>log</code>，还有不少选择：<code>env_logger</code>，<code>tracing</code>，<code>slog</code>，<code>simplelog</code> 等等，最佳实践是什么？</p>\n<p>来自 <a href=\"https://www.reddit.com/user/Koxiaet/\" rel=\"noopener noreferrer\">Koxiaet</a> 的答复：通常有两类与日志相关的 crate：日志接口和日志消费者。接口提供了想要记录某些东西时调用的函数，消费者处理将结构化日志数据格式化到某个地方（stderr 或文件）。两个主要的接口是 <code>log</code> 和 <code>tracing</code>，后者功能更强大因为它支持结构化日志记录，但前者更普遍。还有另一个结构化日志接口 slog，比 <code>tracing</code> 更古老但用的较少。每个日志接口都有自己生态系统，可以根据自己的需要选择。如果在写一个库，<code>log</code> 是个不错的选择，因为所有的日志记录接口都与它兼容。但如果你确实需要结构化日志记录，则可以改用 <code>tracing</code>，这取决于你的需求，比如你是需要写到文件还是只是终端。</p>\n<p>其他网友的推荐：</p>\n<ul>\n<li>File Logging：<a href=\"https://github.com/emabee/flexi_logger\" rel=\"noopener noreferrer\">emabee/flexi_logger: A flexible logger for rust programs that can write to stderr or to log files</a>。（来自 cfsamson）</li>\n<li><code>tracing</code> 的接口：<a href=\"https://docs.rs/tracing-log/0.1.2/tracing_log/\" rel=\"noopener noreferrer\">tracing_log - Rust</a>，有多个同时操作交错日志消息时特别方便，可以按某些属性对它们进行分组并单独查看它们。（来自 class_two_perversion）</li>\n<li><a href=\"https://github.com/estk/log4rs\" rel=\"noopener noreferrer\">estk/log4rs: A highly configurable logging framework for Rust</a>，log4rs 是一个高度可配置的日志框架，以 Java 的 Logback 和 log4j 库为模型。通过 Yaml 配置，到 sdout 和文件，带有文件大小限制选项，还可以配置不同级别的日志。（来自 tms102）</li>\n<li><a href=\"https://crates.io/crates/tracing-appender\" rel=\"noopener noreferrer\">tracing-appender - crates.io: Rust Package Registry</a>，推荐者所知道的唯一线程外日志记录解决方案，不仅适用于异步应用程序。（来自 Pand9）</li>\n<li><a href=\"https://github.com/daboross/fern\" rel=\"noopener noreferrer\">daboross/fern: Simple, efficient logging for Rust</a>，像 Python 的 <code>logging</code> 和 JS 的 <code>Winston</code>。（来自 RapBeautician）</li>\n</ul>\n<h3>Rust 全栈</h3>\n<p>本文是一篇博客翻译，来自：<a href=\"https://www.justinm.one/blog/2021/09/11/fullstackrust/\" rel=\"noopener noreferrer\">Full Stack Rust - Blog</a>。</p>\n<p>一年前，我的首选语言如下：</p>\n<ul>\n<li>Python 用于高级代码快速原型设计，或用于需要第三方功能的代码</li>\n<li>C/C++ 用于长期的 low-level 项目</li>\n</ul>\n<p>当时只听过 Rust 并简单使用过，我的经验来自用 Rust 写了一个处理大文件（&gt;4GB）的事务并从中挖掘一些统计信息的小工具。我用了一个库将文件映射到内存，缤瑞按照顺序对其进行分析。有一些很酷的概念，比如编译器静态地强制内存映射在它被取消映射后无法访问——如果你不小心，C++ 中可能就会发生这种错误。</p>\n<p>不过当时并没有真正吸引我，因为那只是一个小新奇。当我向 <a href=\"https://github.com/DrChat/pdblister\" rel=\"noopener noreferrer\">pdblister</a> 添加新功能以并行获取数千个 PDB 文件时诀窍来了。由于 GIL，在 CPython 中几乎不可能，而在 C/C++ 中做到不面临并行错误是极其困难的。然而 Rust 让这变得容易。我添加了 tokio 驱动的异步，使用 <code>tokio::spawn</code> 生成新任务来下载 PDB，并修复了编译器报的错误，它可以正常工作了。Rust 编译器输出一个二进制文件，它可以在任何地方运行，没有运行时依赖。</p>\n<p><strong>取代 Python</strong></p>\n<p>这是第一点，Rust 是 Python 作为中长期工具语言的绝佳替代品。Python 的好处是庞大的库和生态系统，通过 pip 可以直接拿到，想要快速制作与 API 交互的原型，可以使用 <code>requests</code>，只要 <code>import requests</code> 就可以使用了。Rust 的 <code>reqwest\t</code> 也是如此，只要输入 <code>cargo add reqwest</code> 就可以在代码中使用它。</p>\n<p>然而当进入更长期的生命周期时，Python 就显示出劣势，<code>requests</code> 是程序的依赖，用户需要后去后才能使用。此外，由于弱类型和错误处理能力（与 Rust 比），Python 变得更加劣势。这一点上，我可以使用 Rust 比使用 Python 更快地编写原型工具，并且我可以自信地知道我的工具比等效的 Python 更易于维护且寿命更长。但是，对于短期工具，Python 可能仍然更好，因为它不需要启动项目即可在 VSCode 中获得智能感知支持。 Rust 的 cargo-script 接近将 Rust 推入脚本语言的领域，但不幸的是，我还没有在 VSCode 中找到与之集成的插件。</p>\n<p><strong>取代 C</strong></p>\n<p>Rust 也是 C 的直接替代品，它在各方面都更好，并且可以与遗留 C 代码原生互操作以进行增量替换。Rust 最大的改进是生态系统：如上所述，利用 Rust 生态中已有的库是很容易的。如果你从未使用过 C，那很幸运，实际上 C 中使用高级功能的最佳方法是自己写。</p>\n<p>C 生态系统是支离破碎的，而且很脆弱。ABI 或构建系统没有一致的标准：</p>\n<ul>\n<li>由于缺乏 ABI 一致性，你不能跨平台或操作系统使用相同的二进制文件。  所以你必须从源代码构建。</li>\n<li>由于缺乏一致的构建系统，你不能简单地和应用程序一起构建 C 库，必须修补或重写要使其与你的库兼容的库的构建系统。</li>\n<li>C 库很少跨平台兼容，因为它们缺乏可以依赖的共享抽象。</li>\n</ul>\n<p>然后还有 Rust 最特色的安全改进——我就不展开了。但根据我的经验 - 安全性在很大程度上是一种工具，可以让第三方库开发人员更容易强迫我正确使用他们的库，这是 C 库不能做的事情。</p>\n<p><strong>全栈 Rust</strong></p>\n<p>总而言之，在过去的一年中，我一直在堆栈的所有部分使用 Rust，而我之前使用过其他语言。我已经使用 Rust 来实现引导加载程序：<a href=\"https://github.com/xenia-project/xell-rs\" rel=\"noopener noreferrer\">xenia-project/xell-rs: Xell Bootloader, rewritten in Rust because ¯_(ツ)_/¯，</a>我已经使用它通过 <a href=\"https://github.com/DrChat/pdblister\" rel=\"noopener noreferrer\">pdblister</a> 和 <a href=\"https://github.com/panamax-rs/panamax\" rel=\"noopener noreferrer\">panamax</a> 中的高级 HTTP/HTTPS 和其他技术来镜像文件。我利用并贡献了优秀的 <a href=\"https://github.com/DrChat/gdbstub\" rel=\"noopener noreferrer\">gdbstub</a> 库，用于控制由自定义 VMM 运行的 VM。这些项目都是在堆栈的不同级别完成的，而 Rust 非常适合所有级别。  我已经开始在我的个人项目中专门使用 Rust，并在适合的时候推动它在我的工作中使用。</p>\n<h3>tagged_cell：快速、可初始化和线程安全的静态变量</h3>\n<p>通过 <code>TaggedCell</code> 和 <code>Tag</code> 类型实现，为了安全操作，<code>TaggedCell</code> 的每个实例都必须是唯一的。然后必须通过 <code>TaggedCell::init ()</code> 初始化 <code>TaggedCell</code>，它使用用户提供的函数或闭包初始化底层数据，然后返回一个特殊的零大小的 <code>Init&lt;Tag&gt;</code> 用于访问 Cell 的数据。为了确保每个单元格使用唯一的标签类型，<code>tagged_cell!</code> 提供宏。该宏根据变量的名称创建一个新的标记类型，并将其应用到声明中。</p>\n<pre><code>use tagged_cell::tagged_cell;\ntagged_cell!{\n   static BAR: TaggedCell&lt;Vec&lt;usize&gt;, _&gt; = TaggedCell::new();\n}\n\nlet tag = BAR.init(|| vec![0, 10, 20]);\nlet vec = BAR.get(tag);\n\nassert_eq!(vec[2], 20);\n</code></pre>\n<p>为了允许跨线程使用，只有第一次调用 <code>TaggedCell::init</code> 才会初始化 Cell 的数据。所有未来的 <code>TaggedCell::init</code> 调用都将返回一个新标签。未确定哪个线程将初始化 Cell 的数据。</p>\n<pre><code>use std::thread;\nuse tagged_cell::tagged_cell;\n\ntagged_cell!{\n    static TABLE: TaggedCell&lt;Vec&lt;usize&gt;, _&gt; = TaggedCell::new();\n}\n\nthread::spawn(move || {\n    let tag = TABLE.init(|| vec![0, 10, 20]);\n    let table = TABLE.get(tag);\n    assert_eq!(table[2], 20);\n});\n\nthread::spawn(move || {\n    let tag = TABLE.init(|| vec![0, 10, 20]);\n    let table = TABLE.get(tag);\n    assert_eq!(table[1], 10);\n});\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/Dasch0/tagged_cell\" rel=\"noopener noreferrer\">Dasch0/tagged_cell: Fast, initializable, and thread safe static variables</a></p>\n<h3>ukanren-rs：µKanren 的 Rust 实现</h3>\n<p>µKanren 是一种轻量级关系编程语言</p>\n<ul>\n<li>原始的 Schema 实现在这里：<a href=\"https://github.com/jasonhemann/microKanren\" rel=\"noopener noreferrer\">jasonhemann/microKanren: The implementation of microKanren, a featherweight relational programming language</a></li>\n<li>相关参考：<a href=\"http://minikanren.org/\" rel=\"noopener noreferrer\">miniKanren.org</a></li>\n</ul>\n<pre><code>use ukanren::*;\n\nfn appendo(first: Value, second: Value, out: Value) -&gt; BoxedGoal&lt;impl Iterator&lt;Item = State&gt;&gt; {\n    eq(&amp;first, &amp;())\n        .and(eq(&amp;second, &amp;out))\n        .or(fresh(move |a: Value, d: Value, res: Value| {\n            eq(&amp;(a.clone(), d.clone()), &amp;first)\n                .and(eq(&amp;(a.clone(), res.clone()), &amp;out))\n                .and(appendo(d.clone(), second.clone(), res))\n        }))\n        .boxed()\n}\n\nlet goal = fresh(|x, y| appendo(x, y, [1, 2, 3, 4, 5].to_value()));\nassert_eq!(\n    goal.run(2).collect::&lt;Vec&lt;_&gt;&gt;(),\n    vec![\n        state![(), [1, 2, 3, 4, 5]],\n        state![[1], [2, 3, 4, 5]],\n        state![[1, 2], [3, 4, 5]],\n        state![[1, 2, 3], [4, 5]],\n        state![[1, 2, 3, 4], [5]],\n        state![[1, 2, 3, 4, 5], ()],\n    ],\n);\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/ekzhang/ukanren-rs\" rel=\"noopener noreferrer\">ekzhang/ukanren-rs: Rust implementation of µKanren, a featherweight relational programming language.</a></p>\n<h3>rust-counter-strings：快速定位字符串位置</h3>\n<p>字符串中的每个星号都出现在由紧接前面的数字指定的位置。因此，29 后面的星号是该字符串中的第 29 个字符。可以在任何地方砍掉字符串的末尾，并且确切地知道它在哪里被剪掉了。比如不用数就知道字符串 <code>2*4*6*8*11*14*17*2</code> 正好有 18 个字符。当处理 50 万个字符时会比较省事。</p>\n<pre><code>$ ./rust-counter-strings 50\n# 2*4*6*8*11*14*17*20*23*26*29*32*35*38*41*44*47*50*\n</code></pre>\n<p>这就是个小工具，代码也只有几十行。</p>\n<p>GitHub：<a href=\"https://github.com/thomaschaplin/rust-counter-strings\" rel=\"noopener noreferrer\">thomaschaplin/rust-counter-strings: 🧵 Generate self-describing strings of a given length to help aid software testing</a></p>\n<hr>\n<p>From 日报小组 长琴</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc 论坛：支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-12 14:30:38","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-11 Tabled 发布v0.3, bma-benchmark, ferros, Veloren发布v0.11","link":"https://rustcc.cn/article?id=db077b1a-5af6-4fb2-b065-ff8be974fd62","description":"<h3>Tabled 发布v0.3</h3>\n<p>Tabled 是一个易于使用的库，用于美化 Rust 结构和枚举的输出。</p>\n<p>Github<a href=\"https://github.com/zhiburt/tabled\" rel=\"noopener noreferrer\">链接</a>，https://github.com/zhiburt/tabled</p>\n<h3>bma-benchmark 一个友好的基准测试工具</h3>\n<p>使用 <code>bma_benchmark</code></p>\n<pre><code>#[macro_use]\nextern crate bma_benchmark;\n\nuse std::sync::Mutex;\n\nlet n = 100_000_000;\nlet mutex = Mutex::new(0);\nbenchmark_start!();\nfor _ in 0..n {\n    let _a = mutex.lock().unwrap();\n}\nbenchmark_print!(n);\n</code></pre>\n<p>使用宏 <code>benchmark!</code></p>\n<pre><code>#[macro_use]\nextern crate bma_benchmark;\n\nuse std::sync::Mutex;\n\nlet mutex = Mutex::new(0);\nbenchmark!(100_000_000, {\n    let _a = mutex.lock().unwrap();\n    });\n</code></pre>\n<p><img src=\"https://raw.githubusercontent.com/alttch/bma-benchmark/main/simple.png\" alt=\"结果\"></p>\n<p>Crate <a href=\"https://crates.io/crates/bma-benchmark\" rel=\"noopener noreferrer\">链接</a>，https://crates.io/crates/bma-benchmark</p>\n<h3>ferros</h3>\n<p>seL4 是一个用于构建操作系统和嵌入式程序的工具包，这个开源项目是使 Rust 中的 seL4 编程变得更好。</p>\n<p>以下代码演练假定使用示例 sel4_start 库执行 selfe，并介绍了 ferros 的某些方面。</p>\n<pre><code>use selfe_sys;\nuse ferros::alloc::{self, micro_alloc, smart_alloc};\nuse ferros::userland::{root_cnode, BootInfo};\n\n// The raw boot info is provided by the sel4_start library\nlet raw_boot_info: &amp;'static selfe_sys::seL4_BootInfo = unsafe { &amp;*sel4_start::BOOTINFO };\n\n\n// Utility for finding and claiming `Untyped` instances supplied by the boot info.\nlet mut allocator = micro_alloc::Allocator::bootstrap(&amp;raw_boot_info)?;\nlet initial_untyped = allocator\n    .get_untyped::&lt;U20&gt;() // The size of the Untyped instance, as bits\n    .expect(\"Couldn't find an untyped instance of the desired size\");\n\n// Create the top-level CNode wrapper with type-level-tracked remaining slot capacity\nlet (root_cnode, local_slots) = root_cnode(&amp;raw_boot_info);\n\n// Once we have an initial Untyped instance, memory distribution from it\n// can be tracked with compile-time checks. The smart_alloc macro synthesizes\n// the allocation code, and the capacity bounds are statically verified by\n// the type checker. The effect is that you can write 'slots' in the macro body \n// anywhere you need some slots, and you'll get the right number allocated\n// with type inference. A reference to 'ut' does the same for untyped memory. \nsmart_alloc!(|slots from local_slots, ut from uts| {\n\n    // Create a page table seL4 kernel object and return a capability pointer to it.\n    // Here we use a variable binding type annotation and Rust's type system can figure out\n    // if it can allocate a large enough Untyped instance and enough cnode slots\n    // to represent this particular kernel object.\n    let example_page_table: LocalCap&lt;UnmappedPageTable&gt; = retype(ut, slots)?;\n\n    // Create a resource-tracking wrapper around the raw boot info to assist in\n    // virtual memory related operations.\n    let boot_info  = BootInfo::wrap(raw_boot_info, ut, slots);\n    let (root_page_table, boot_info) = boot_info.map_page_table(root_page_table)?;\n});\n\n</code></pre>\n<p>Github<a href=\"https://github.com/auxoncorp/ferros\" rel=\"noopener noreferrer\">链接</a>，https://github.com/auxoncorp/ferros</p>\n<h3>Veloren发布v0.11</h3>\n<p>今天，Veloren 发布了 0.11。 这个版本已经制作了 3 个月，其一大重点是让世界各地的战斗更具活力。这是以新的地点系统的形式出现，以及 NPC 和生物如何与世界互动。</p>\n<p>要了解还有哪些新功能！请继续阅读 V0.11 变更日志<a href=\"https://veloren.net/release-0-11/\" rel=\"noopener noreferrer\">链接</a>，https://veloren.net/release-0-11/</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929\" rel=\"noopener noreferrer\">洋芋</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-11 15:33:08","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"cargo fix 如何自动修复warning？","link":"https://rustcc.cn/article?id=0d747849-2064-4ba2-a725-2fe64f6ab556","description":"<p>代码中有些外面copy过来的enum，导致很多的“should have an upper camel case name”warning。就是编码风格的问题，可是<code>cargo fix</code>没有办法按照rust给的建议自动帮我改掉。。。。</p>\n<p>有办法吗？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-11 14:31:22","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 培养提高计划 Vol. 7 - 8 | Rust 项目工程来了","link":"https://rustcc.cn/article?id=9dec6eeb-38d8-4ec4-b75e-783bd11bf24b","description":"<p>我们的 Rust 公开课进行了 6 期了，带大家了解了 ：</p>\n<ol>\n<li>认识面向基础架构语言</li>\n<li>理解 Rust 所有权</li>\n<li>通过实战理解 Rust 宏</li>\n<li>通过 Datafuse 理解全链路跟踪</li>\n<li>Rust 异步编程入门 Future Part 1</li>\n<li>Rust 异步编程入门 Future Part 2</li>\n</ol>\n<p>目前视频回放传到 B 站收获许多好评，赞，也给我们很大的鼓励。希望我们的 Rust 培养提高计划 | Datafuse 可以帮助更多的朋友快速的使用上 Rust 。\n本周给大家排两个公开课：周四晚上，周日晚上。我们 Rust 培养提高计划邀请到第二位分享嘉宾 董泽润老师， 另外 Rust 培养提高计划 的内容上也做了一些调整。</p>\n<hr>\n<p>分享主题：《深入了解rust 闭包》 | Vol. 7</p>\n<p>分享时间： 周四晚上2021-09-09 20:00-21:00</p>\n<p>分享讲师： 董泽润</p>\n<p>内容介绍： 深入浅出了解 rust 闭包工作原理，让大家了解底层实现\n讲师介绍：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/07-%E8%91%A3%E6%B3%BD%E6%B6%A6.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<hr>\n<p>分享主题：《利用 Tokio 实现一个高性能 Mini Http server》 | Vol. 8</p>\n<p>分享时间：  周日晚上2021-09-12 20:00-21:00</p>\n<p>分享讲师： 苏林</p>\n<p>首先感谢苏林老师的坚持付出， 带我们学习 Rust 的重点知识。 经过和苏琳老师沟通，我们后续的课程，会更加往实战方向转变。接下是一个系列的内容：</p>\n<ol>\n<li>利用 Tokio 实现一个 Mini Http server</li>\n<li>基于 Http server提供内容动态的 API 网关</li>\n<li>利用 Redis 实现对 API 网关加速</li>\n<li>学习 Rust RPC 调用，实现微服务调用</li>\n</ol>\n<p>这个内容可能需要4次左右的公开课，目的是带着大家做一些小项目，带大家熟悉一下 Rust 工程，让大家可以快速把 Rust 用到后端开发中。</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<p>Rust 异步编程入门 Future Part 1   | Vol. 5\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<p>Rust 异步编程入门 Future Part 2  | Vol. 6\nhttps://www.bilibili.com/video/bv1oy4y1G7jC</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-07 02:23:16","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust 学习随笔","link":"https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8","description":"<h1>切换镜像源</h1>\n<p>crm =&gt; https://github.com/wtklbm/crm</p>\n<p>常用命令就是 <code>crm best</code></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 14:35:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"pretree 补全文档发布了,再次谢谢大神的指点终于入门了。","link":"https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827","description":"<h1>Pretree</h1>\n<p>pretree is a package for storing and querying routing rules with prefix tree .</p>\n<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>\n<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>\n<p>Inspired by <a href=\"https://github.com/obity/pretree\" rel=\"noopener noreferrer\">obity/pretree</a> (golang)</p>\n<h1>Doc</h1>\n<p>See this document at <a href=\"https://docs.rs/pretree\" rel=\"noopener noreferrer\">API documentation</a></p>\n<h1>Install</h1>\n<p>Add the following line to your Cargo.toml file:</p>\n<pre><code>pretree = \"1.0.0\"\n</code></pre>\n<h1>Example</h1>\n<pre><code>use pretree::Pretree;\nlet mut p = Pretree::new();\np.store(\"GET\",\"account/{id}/info/:name\");\np.store(\"GET\",\"account/:id/login\");\np.store(\"GET\",\"account/{id}\");\np.store(\"GET\",\"bacteria/count_number_by_month\");\nlet (ok,rule,vars) = p.query(\"GET\",\"account/929239\");\nprintln!(\"ok:{} rule:{} vars:{:#?}\",ok,rule,vars);\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 09:37:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-14T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Reference-Centric Models for Grounded Collaborative Dialogue. (arXiv:2109.05042v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05042","description":"<p>We present a grounded neural dialogue model that successfully collaborates\nwith people in a partially-observable reference game. We focus on a setting\nwhere two agents each observe an overlapping part of a world context and need\nto identify and agree on some object they share. Therefore, the agents should\npool their information and communicate pragmatically to solve the task. Our\ndialogue agent accurately grounds referents from the partner's utterances using\na structured reference resolver, conditions on these referents using a\nrecurrent memory, and uses a pragmatic generation procedure to ensure the\npartner can resolve the references the agent produces. We evaluate on the\nOneCommon spatial grounding dialogue task (Udagawa and Aizawa 2019), involving\na number of dots arranged on a board with continuously varying positions,\nsizes, and shades. Our agent substantially outperforms the previous state of\nthe art for the task, obtaining a 20% relative improvement in successful task\ncompletion in self-play evaluations and a 50% relative improvement in success\nin human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Justin T. Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity-Based Knowledge Conflicts in Question Answering. (arXiv:2109.05052v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05052","description":"<p>Knowledge-dependent tasks typically use two sources of knowledge: parametric,\nlearned at training time, and contextual, given as a passage at inference time.\nTo understand how models use these sources together, we formalize the problem\nof knowledge conflicts, where the contextual information contradicts the\nlearned information. Analyzing the behaviour of popular models, we measure\ntheir over-reliance on memorized information (the cause of hallucinations), and\nuncover important factors that exacerbate this behaviour. Lastly, we propose a\nsimple method to mitigate over-reliance on parametric knowledge, which\nminimizes hallucination, and improves out-of-distribution generalization by\n4%-7%. Our findings demonstrate the importance for practitioners to evaluate\nmodel tendency to hallucinate rather than read, and show that our mitigation\nstrategy encourages generalization to evolving information (i.e.,\ntime-dependent queries). To encourage these practices, we have released our\nframework for generating knowledge conflicts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perisetla_K/0/1/0/all/0/1\">Kartik Perisetla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_N/0/1/0/all/0/1\">Nikhil Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DuBois_C/0/1/0/all/0/1\">Chris DuBois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaker Turn Modeling for Dialogue Act Classification. (arXiv:2109.05056v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05056","description":"<p>Dialogue Act (DA) classification is the task of classifying utterances with\nrespect to the function they serve in a dialogue. Existing approaches to DA\nclassification model utterances without incorporating the turn changes among\nspeakers throughout the dialogue, therefore treating it no different than\nnon-interactive written text. In this paper, we propose to integrate the turn\nchanges in conversations among speakers when modeling DAs. Specifically, we\nlearn conversation-invariant speaker turn embeddings to represent the speaker\nturns in a conversation; the learned speaker turn embeddings are then merged\nwith the utterance embeddings for the downstream task of DA classification.\nWith this simple yet effective mechanism, our model is able to capture the\nsemantics from the dialogue content while accounting for different speaker\nturns in a conversation. Validation on three benchmark public datasets\ndemonstrates superior performance of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zihao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavabi_L/0/1/0/all/0/1\">Leili Tavabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_K/0/1/0/all/0/1\">Kristina Lerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soleymani_M/0/1/0/all/0/1\">Mohammad Soleymani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FBERT: A Neural Transformer for Identifying Offensive Content. (arXiv:2109.05074v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05074","description":"<p>Transformer-based models such as BERT, XLNET, and XLM-R have achieved\nstate-of-the-art performance across various NLP tasks including the\nidentification of offensive language and hate speech, an important problem in\nsocial media. In this paper, we present fBERT, a BERT model retrained on SOLID,\nthe largest English offensive language identification corpus available with\nover $1.4$ million offensive instances. We evaluate fBERT's performance on\nidentifying offensive content on multiple English datasets and we test several\nthresholds for selecting instances from SOLID. The fBERT model will be made\nfreely available to the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_D/0/1/0/all/0/1\">Diptanu Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1\">Alexander Ororbia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Self-Disclosure In Neural Dialog Models By Candidate Re-ranking. (arXiv:2109.05090v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05090","description":"<p>Neural language modelling has progressed the state-of-the-art in different\ndownstream Natural Language Processing (NLP) tasks. One such area is of\nopen-domain dialog modelling, neural dialog models based on GPT-2 such as\nDialoGPT have shown promising performance in single-turn conversation. However,\nsuch (neural) dialog models have been criticized for generating responses which\nalthough may have relevance to the previous human response, tend to quickly\ndissipate human interest and descend into trivial conversation. One reason for\nsuch performance is the lack of explicit conversation strategy being employed\nin human-machine conversation. Humans employ a range of conversation strategies\nwhile engaging in a conversation, one such key social strategies is\nSelf-disclosure(SD). A phenomenon of revealing information about one-self to\nothers. Social penetration theory (SPT) proposes that communication between two\npeople moves from shallow to deeper levels as the relationship progresses\nprimarily through self-disclosure. Disclosure helps in creating rapport among\nthe participants engaged in a conversation. In this paper, Self-disclosure\nenhancement architecture (SDEA) is introduced utilizing Self-disclosure Topic\nModel (SDTM) during inference stage of a neural dialog model to re-rank\nresponse candidates to enhance self-disclosure in single-turn responses from\nfrom the model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soni_M/0/1/0/all/0/1\">Mayank Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cowan_B/0/1/0/all/0/1\">Benjamin Cowan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wade_V/0/1/0/all/0/1\">Vincent Wade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models. (arXiv:2109.05093v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05093","description":"<p>Large pre-trained language models for textual data have an unconstrained\noutput space; at each decoding step, they can produce any of 10,000s of\nsub-word tokens. When fine-tuned to target constrained formal languages like\nSQL, these models often generate invalid code, rendering it unusable. We\npropose PICARD (code and trained models available at\nhttps://github.com/ElementAI/picard), a method for constraining auto-regressive\ndecoders of language models through incremental parsing. PICARD helps to find\nvalid output sequences by rejecting inadmissible tokens at each decoding step.\nOn the challenging Spider and CoSQL text-to-SQL translation tasks, we show that\nPICARD transforms fine-tuned T5 models with passable performance into\nstate-of-the-art solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scholak_T/0/1/0/all/0/1\">Torsten Scholak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schucher_N/0/1/0/all/0/1\">Nathan Schucher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahdanau_D/0/1/0/all/0/1\">Dzmitry Bahdanau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HypoGen: Hyperbole Generation with Commonsense and Counterfactual Knowledge. (arXiv:2109.05097v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05097","description":"<p>A hyperbole is an intentional and creative exaggeration not to be taken\nliterally. Despite its ubiquity in daily life, the computational explorations\nof hyperboles are scarce. In this paper, we tackle the under-explored and\nchallenging task: sentence-level hyperbole generation. We start with a\nrepresentative syntactic pattern for intensification and systematically study\nthe semantic (commonsense and counterfactual) relationships between each\ncomponent in such hyperboles. Next, we leverage the COMeT and reverse COMeT\nmodels to do commonsense and counterfactual inference. We then generate\nmultiple hyperbole candidates based on our findings from the pattern, and train\nneural classifiers to rank and select high-quality hyperboles. Automatic and\nhuman evaluations show that our generation method is able to generate\nhyperboles creatively with high success rate and intensity scores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yufei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Arvind krishna Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Zero-shot Commonsense Reasoning with Self-supervised Refinement of Language Models. (arXiv:2109.05105v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05105","description":"<p>Can we get existing language models and refine them for zero-shot commonsense\nreasoning? This paper presents an initial study exploring the feasibility of\nzero-shot commonsense reasoning for the Winograd Schema Challenge by\nformulating the task as self-supervised refinement of a pre-trained language\nmodel. In contrast to previous studies that rely on fine-tuning annotated\ndatasets, we seek to boost conceptualization via loss landscape refinement. To\nthis end, we propose a novel self-supervised learning approach that refines the\nlanguage model utilizing a set of linguistic perturbations of similar concept\nrelationships. Empirical analysis of our conceptually simple framework\ndemonstrates the viability of zero-shot commonsense reasoning on multiple\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klein_T/0/1/0/all/0/1\">Tassilo Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1\">Moin Nabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attention-based Contrastive Learning for Winograd Schemas. (arXiv:2109.05108v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05108","description":"<p>Self-supervised learning has recently attracted considerable attention in the\nNLP community for its ability to learn discriminative features using a\ncontrastive objective. This paper investigates whether contrastive learning can\nbe extended to Transfomer attention to tackling the Winograd Schema Challenge.\nTo this end, we propose a novel self-supervised framework, leveraging a\ncontrastive loss directly at the level of self-attention. Experimental analysis\nof our attention-based models on multiple datasets demonstrates superior\ncommonsense reasoning capabilities. The proposed approach outperforms all\ncomparable unsupervised approaches while occasionally surpassing supervised\nones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klein_T/0/1/0/all/0/1\">Tassilo Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1\">Moin Nabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Latent Tree Induction with Distant Supervision via Span Constraints. (arXiv:2109.05112v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05112","description":"<p>For over thirty years, researchers have developed and analyzed methods for\nlatent tree induction as an approach for unsupervised syntactic parsing.\nNonetheless, modern systems still do not perform well enough compared to their\nsupervised counterparts to have any practical use as structural annotation of\ntext. In this work, we present a technique that uses distant supervision in the\nform of span constraints (i.e. phrase bracketing) to improve performance in\nunsupervised constituency parsing. Using a relatively small number of span\nconstraints we can substantially improve the output from DIORA, an already\ncompetitive unsupervised parsing system. Compared with full parse tree\nannotation, span constraints can be acquired with minimal effort, such as with\na lexicon derived from Wikipedia, to find exact text matches. Our experiments\nshow span constraints based on entities improves constituency parsing on\nEnglish WSJ Penn Treebank by more than 5 F1. Furthermore, our method extends to\nany domain where span constraints are easily attainable, and as a case study we\ndemonstrate its effectiveness by parsing biomedical text from the CRAFT\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drozdov_A/0/1/0/all/0/1\">Andrew Drozdov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jay Yoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OGorman_T/0/1/0/all/0/1\">Tim O&#x27;Gorman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rongali_S/0/1/0/all/0/1\">Subendhu Rongali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finkbeiner_D/0/1/0/all/0/1\">Dylan Finkbeiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Shilpa Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Partially-supervised novel object captioning leveraging context from paired data. (arXiv:2109.05115v1 [cs.CV])","link":"http://arxiv.org/abs/2109.05115","description":"<p>In this paper, we propose an approach to improve image captioning solutions\nfor images with novel objects that do not have caption labels in the training\ndataset. Our approach is agnostic to model architecture, and primarily focuses\non training technique that uses existing fully paired image-caption data and\nthe images with only the novel object detection labels (partially paired data).\nWe create synthetic paired captioning data for these novel objects by\nleveraging context from existing image-caption pairs. We further re-use these\npartially paired images with novel objects to create pseudo-label captions that\nare used to fine-tune the captioning model. Using a popular captioning model\n(Up-Down) as baseline, our approach achieves state-of-the-art results on\nheld-out MS COCO out-of-domain test split, and improves F1 metric and CIDEr for\nnovel object images by 75.8 and 26.6 points respectively, compared to baseline\nmodel that does not use partially paired images during training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1\">Shashank Bujimalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1\">Mahesh Subedar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1\">Omesh Tickoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MURAL: Multimodal, Multitask Retrieval Across Languages. (arXiv:2109.05125v1 [cs.IR])","link":"http://arxiv.org/abs/2109.05125","description":"<p>Both image-caption pairs and translation pairs provide the means to learn\ndeep representations of and connections between languages. We use both types of\npairs in MURAL (MUltimodal, MUltitask Representations Across Languages), a dual\nencoder that solves two tasks: 1) image-text matching and 2) translation pair\nmatching. By incorporating billions of translation pairs, MURAL extends ALIGN\n(Jia et al. PMLR'21)--a state-of-the-art dual encoder learned from 1.8 billion\nnoisy image-text pairs. When using the same encoders, MURAL's performance\nmatches or exceeds ALIGN's cross-modal retrieval performance on well-resourced\nlanguages across several datasets. More importantly, it considerably improves\nperformance on under-resourced languages, showing that text-text learning can\novercome a paucity of image-caption examples for these languages. On the\nWikipedia Image-Text dataset, for example, MURAL-base improves zero-shot mean\nrecall by 8.1% on average for eight under-resourced languages and by 6.8% on\naverage when fine-tuning. We additionally show that MURAL's text\nrepresentations cluster not only with respect to genealogical connections but\nalso based on areal linguistics, such as the Balkan Sprachbund.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Aashi Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Mandy Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_K/0/1/0/all/0/1\">Krishna Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kudugunta_S/0/1/0/all/0/1\">Sneha Kudugunta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yinfei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1\">Jason Baldridge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"D-REX: Dialogue Relation Extraction with Explanations. (arXiv:2109.05126v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05126","description":"<p>Existing research studies on cross-sentence relation extraction in long-form\nmulti-party conversations aim to improve relation extraction without\nconsidering the explainability of such methods. This work addresses that gap by\nfocusing on extracting explanations that indicate that a relation exists while\nusing only partially labeled data. We propose our model-agnostic framework,\nD-REX, a policy-guided semi-supervised algorithm that explains and ranks\nrelations. We frame relation extraction as a re-ranking task and include\nrelation- and entity-specific explanations as an intermediate step of the\ninference process. We find that about 90% of the time, human annotators prefer\nD-REX's explanations over a strong BERT-based joint relation extraction and\nexplanation model. Finally, our evaluations on a dialogue relation extraction\ndataset show that our method is simple yet effective and achieves a\nstate-of-the-art F1 score on relation extraction, improving upon existing\nmethods by 13.5%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Embar_V/0/1/0/all/0/1\">Varun Embar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1\">Yi-Lin Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1\">Lise Getoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Refocusing on Relevance: Personalization in NLG. (arXiv:2109.05140v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05140","description":"<p>Many NLG tasks such as summarization, dialogue response, or open domain\nquestion answering focus primarily on a source text in order to generate a\ntarget response. This standard approach falls short, however, when a user's\nintent or context of work is not easily recoverable based solely on that source\ntext -- a scenario that we argue is more of the rule than the exception. In\nthis work, we argue that NLG systems in general should place a much higher\nlevel of emphasis on making use of additional context, and suggest that\nrelevance (as used in Information Retrieval) be thought of as a crucial tool\nfor designing user-oriented text-generating tasks. We further discuss possible\nharms and hazards around such personalization, and argue that value-sensitive\ndesign represents a crucial path forward through these challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dudy_S/0/1/0/all/0/1\">Shiran Dudy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedrick_S/0/1/0/all/0/1\">Steven Bedrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webber_B/0/1/0/all/0/1\">Bonnie Webber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension. (arXiv:2109.05149v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05149","description":"<p>In this paper, we present a new verification style reading comprehension\ndataset named VGaokao from Chinese Language tests of Gaokao. Different from\nexisting efforts, the new dataset is originally designed for native speakers'\nevaluation, thus requiring more advanced language understanding skills. To\naddress the challenges in VGaokao, we propose a novel Extract-Integrate-Compete\napproach, which iteratively selects complementary evidence with a novel query\nupdating mechanism and adaptively distills supportive evidence, followed by a\npairwise competition to push models to learn the subtle difference among\nsimilar text pieces. Experiments show that our methods outperform various\nbaselines on VGaokao with retrieved complementary evidence, while having the\nmerits of efficiency and explainability. Our dataset and code are released for\nfurther research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Yuxuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yansong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural SQL: Making SQL Easier to Infer from Natural Language Specifications. (arXiv:2109.05153v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05153","description":"<p>Addressing the mismatch between natural language descriptions and the\ncorresponding SQL queries is a key challenge for text-to-SQL translation. To\nbridge this gap, we propose an SQL intermediate representation (IR) called\nNatural SQL (NatSQL). Specifically, NatSQL preserves the core functionalities\nof SQL, while it simplifies the queries as follows: (1) dispensing with\noperators and keywords such as GROUP BY, HAVING, FROM, JOIN ON, which are\nusually hard to find counterparts for in the text descriptions; (2) removing\nthe need for nested subqueries and set operators; and (3) making schema linking\neasier by reducing the required number of schema items. On Spider, a\nchallenging text-to-SQL benchmark that contains complex and nested SQL queries,\nwe demonstrate that NatSQL outperforms other IRs, and significantly improves\nthe performance of several previous SOTA models. Furthermore, for existing\nmodels that do not support executable SQL generation, NatSQL easily enables\nthem to generate executable SQL queries, and achieves the new state-of-the-art\nexecution accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yujian Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jinxia Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodward_J/0/1/0/all/0/1\">John R. Woodward</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drake_J/0/1/0/all/0/1\">John Drake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiaofu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization. (arXiv:2109.05157v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05157","description":"<p>Recently, there has been significant progress in studying neural networks for\ntranslating text descriptions into SQL queries under the zero-shot cross-domain\nsetting. Despite achieving good performance on some public benchmarks, we\nobserve that existing text-to-SQL models do not generalize when facing domain\nknowledge that does not frequently appear in the training data, which may\nrender the worse prediction performance for unseen domains. In this work, we\ninvestigate the robustness of text-to-SQL models when the questions require\nrarely observed domain knowledge. In particular, we define five types of domain\nknowledge and introduce Spider-DK (DK is the abbreviation of domain knowledge),\na human-curated dataset based on the Spider benchmark for text-to-SQL\ntranslation. NL questions in Spider-DK are selected from Spider, and we modify\nsome samples by adding domain knowledge that reflects real-world question\nparaphrases. We demonstrate that the prediction accuracy dramatically drops on\nsamples that require such domain knowledge, even if the domain knowledge\nappears in the training set, and the model provides the correct predictions for\nrelated training samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yujian Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StreamHover: Livestream Transcript Summarization and Annotation. (arXiv:2109.05160v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05160","description":"<p>With the explosive growth of livestream broadcasting, there is an urgent need\nfor new summarization technology that enables us to create a preview of\nstreamed content and tap into this wealth of knowledge. However, the problem is\nnontrivial due to the informal nature of spoken language. Further, there has\nbeen a shortage of annotated datasets that are necessary for transcript\nsummarization. In this paper, we present StreamHover, a framework for\nannotating and summarizing livestream transcripts. With a total of over 500\nhours of videos annotated with both extractive and abstractive summaries, our\nbenchmark dataset is significantly larger than currently existing annotated\ncorpora. We explore a neural extractive summarization model that leverages\nvector-quantized variational autoencoder to learn latent vector representations\nof spoken utterances and identify salient utterances from the transcripts to\nform summaries. We show that our model generalizes better and improves\nperformance over strong baselines. The results of this study provide an avenue\nfor future research to improve summarization solutions for efficient browsing\nof livestreams.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sangwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganter_T/0/1/0/all/0/1\">Tim Ganter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Trung Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_W/0/1/0/all/0/1\">Walter Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hailin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandt_J/0/1/0/all/0/1\">Jonathan Brandt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroosh_H/0/1/0/all/0/1\">Hassan Foroosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Categorization of Social Knowledge for Commonsense Question Answering. (arXiv:2109.05168v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05168","description":"<p>Large pre-trained language models (PLMs) have led to great success on various\ncommonsense question answering (QA) tasks in an end-to-end fashion. However,\nlittle attention has been paid to what commonsense knowledge is needed to\ndeeply characterize these QA tasks. In this work, we proposed to categorize the\nsemantics needed for these tasks using the SocialIQA as an example. Building\nupon our labeled social knowledge categories dataset on top of SocialIQA, we\nfurther train neural QA models to incorporate such social knowledge categories\nand relation information from a knowledge base. Unlike previous work, we\nobserve our models with semantic categorizations of social knowledge can\nachieve comparable performance with a relatively simple model and smaller size\ncompared to other complex approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_X/0/1/0/all/0/1\">Xiaochen Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"College Student Retention Risk Analysis From Educational Database using Multi-Task Multi-Modal Neural Fusion. (arXiv:2109.05178v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05178","description":"<p>We develop a Multimodal Spatiotemporal Neural Fusion network for Multi-Task\nLearning (MSNF-MTCL) to predict 5 important students' retention risks: future\ndropout, next semester dropout, type of dropout, duration of dropout and cause\nof dropout. First, we develop a general purpose multi-modal neural fusion\nnetwork model MSNF for learning students' academic information representation\nby fusing spatial and temporal unstructured advising notes with spatiotemporal\nstructured data. MSNF combines a Bidirectional Encoder Representations from\nTransformers (BERT)-based document embedding framework to represent each\nadvising note, Long-Short Term Memory (LSTM) network to model temporal advising\nnote embeddings, LSTM network to model students' temporal performance variables\nand students' static demographics altogether. The final fused representation\nfrom MSNF has been utilized on a Multi-Task Cascade Learning (MTCL) model\ntowards building MSNF-MTCL for predicting 5 student retention risks. We\nevaluate MSNFMTCL on a large educational database consists of 36,445 college\nstudents over 18 years period of time that provides promising performances\ncomparing with the nearest state-of-art models. Additionally, we test the\nfairness of such model given the existence of biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mohammad Arif Ul Alam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Asking Questions Like Educational Experts: Automatically Generating Question-Answer Pairs on Real-World Examination Data. (arXiv:2109.05179v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05179","description":"<p>Generating high quality question-answer pairs is a hard but meaningful task.\nAlthough previous works have achieved great results on answer-aware question\ngeneration, it is difficult to apply them into practical application in the\neducation field. This paper for the first time addresses the question-answer\npair generation task on the real-world examination data, and proposes a new\nunified framework on RACE. To capture the important information of the input\npassage we first automatically generate(rather than extracting) keyphrases,\nthus this task is reduced to keyphrase-question-answer triplet joint\ngeneration. Accordingly, we propose a multi-agent communication model to\ngenerate and optimize the question and keyphrases iteratively, and then apply\nthe generated question and keyphrases to guide the generation of answers. To\nestablish a solid benchmark, we build our model on the strong generative\npre-training model. Experimental results show that our model makes great\nbreakthroughs in the question-answer pair generation task. Moreover, we make a\ncomprehensive analysis on our model, suggesting new directions for this\nchallenging task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qu_F/0/1/0/all/0/1\">Fanyi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunfang Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaker-Oriented Latent Structures for Dialogue-Based Relation Extraction. (arXiv:2109.05182v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05182","description":"<p>Dialogue-based relation extraction (DiaRE) aims to detect the structural\ninformation from unstructured utterances in dialogues. Existing relation\nextraction models may be unsatisfactory under such a conversational setting,\ndue to the entangled logic and information sparsity issues in utterances\ninvolving multiple speakers. To this end, we introduce SOLS, a novel model\nwhich can explicitly induce speaker-oriented latent structures for better\nDiaRE. Specifically, we learn latent structures to capture the relationships\namong tokens beyond the utterance boundaries, alleviating the entangled logic\nissue. During the learning process, our speaker-specific regularization method\nprogressively highlights speaker-related key clues and erases the irrelevant\nones, alleviating the information sparsity issue. Experiments on three public\ndatasets demonstrate the effectiveness of our proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1\">Guoshun Nan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1\">Guoqing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1\">Sicong Leng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets. (arXiv:2109.05184v1 [cs.MM])","link":"http://arxiv.org/abs/2109.05184","description":"<p>Internet memes have become powerful means to transmit political,\npsychological, and socio-cultural ideas. Although memes are typically humorous,\nrecent days have witnessed an escalation of harmful memes used for trolling,\ncyberbullying, and abusing social entities. Detecting such harmful memes is\nchallenging as they can be highly satirical and cryptic. Moreover, while\nprevious work has focused on specific aspects of memes such as hate speech and\npropaganda, there has been little work on harm in general, and only one\nspecialized dataset for it. Here, we focus on bridging this gap. In particular,\nwe aim to solve two novel tasks: detecting harmful memes and identifying the\nsocial entities they target. We further extend the recently released HarMeme\ndataset to generalize on two prevalent topics - COVID-19 and US politics and\nname the two datasets as Harm-C and Harm-P, respectively. We then propose\nMOMENTA (MultimOdal framework for detecting harmful MemEs aNd Their tArgets), a\nnovel multimodal (text + image) deep neural model, which uses global and local\nperspectives to detect harmful memes. MOMENTA identifies the object proposals\nand attributes and uses a multimodal model to perceive the comprehensive\ncontext in which the objects and the entities are portrayed in a given meme.\nMOMENTA is interpretable and generalizable, and it outperforms numerous\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pramanick_S/0/1/0/all/0/1\">Shraman Pramanick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Dimitar Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Total Recall: a Customized Continual Learning Method for Neural Semantic Parsers. (arXiv:2109.05186v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05186","description":"<p>This paper investigates continual learning for semantic parsing. In this\nsetting, a neural semantic parser learns tasks sequentially without accessing\nfull training data from previous tasks. Direct application of the SOTA\ncontinual learning algorithms to this problem fails to achieve comparable\nperformance with re-training models with all seen tasks because they have not\nconsidered the special properties of structured outputs yielded by semantic\nparsers. Therefore, we propose TotalRecall, a continual learning method\ndesigned for neural semantic parsers from two aspects: i) a sampling method for\nmemory replay that diversifies logical form templates and balances\ndistributions of parse actions in a memory; ii) a two-stage training method\nthat significantly improves generalization capability of the parsers across\ntasks. We conduct extensive experiments to study the research problems involved\nin continual semantic parsing and demonstrate that a neural semantic parser\ntrained with TotalRecall achieves superior performance than the one trained\ndirectly with the SOTA continual learning algorithms and achieve a 3-6 times\nspeedup compared to re-training from scratch. Code and datasets are available\nat: https://github.com/zhuang-li/cl_nsp.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TopicRefine: Joint Topic Prediction and Dialogue Response Generation for Multi-turn End-to-End Dialogue System. (arXiv:2109.05187v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05187","description":"<p>A multi-turn dialogue always follows a specific topic thread, and topic shift\nat the discourse level occurs naturally as the conversation progresses,\nnecessitating the model's ability to capture different topics and generate\ntopic-aware responses. Previous research has either predicted the topic first\nand then generated the relevant response, or simply applied the attention\nmechanism to all topics, ignoring the joint distribution of the topic\nprediction and response generation models and resulting in uncontrollable and\nunrelated responses. In this paper, we propose a joint framework with a topic\nrefinement mechanism to learn these two tasks simultaneously. Specifically, we\ndesign a three-pass iteration mechanism to generate coarse response first, then\npredict corresponding topics, and finally generate refined response conditioned\non predicted topics. Moreover, we utilize GPT2DoubleHeads and BERT for the\ntopic prediction task respectively, aiming to investigate the effects of joint\nlearning and the understanding ability of GPT model. Experimental results\ndemonstrate that our proposed framework achieves new state-of-the-art\nperformance at response generation task and the great potential understanding\ncapability of GPT model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1\">Mingyu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zimo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_G/0/1/0/all/0/1\">Gabriel Pui Cheong Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Eliciting Knowledge from Language Models for Event Extraction. (arXiv:2109.05190v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05190","description":"<p>Eliciting knowledge contained in language models via prompt-based learning\nhas shown great potential in many natural language processing tasks, such as\ntext classification and generation. Whereas, the applications for more complex\ntasks such as event extraction are less studied, since the design of prompt is\nnot straightforward due to the complicated types and arguments. In this paper,\nwe explore to elicit the knowledge from pre-trained language models for event\ntrigger detection and argument extraction. Specifically, we present various\njoint trigger/argument prompt methods, which can elicit more complementary\nknowledge by modeling the interactions between different triggers or arguments.\nThe experimental results on the benchmark dataset, namely ACE2005, show the\ngreat advantages of our proposed approach. In particular, our approach is\nsuperior to the recent advanced methods in the few-shot scenario where only a\nfew samples are used for training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jiaju Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_J/0/1/0/all/0/1\">Jin Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Multi-modal Summarization. (arXiv:2109.05199v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05199","description":"<p>The new era of technology has brought us to the point where it is convenient\nfor people to share their opinions over an abundance of platforms. These\nplatforms have a provision for the users to express themselves in multiple\nforms of representations, including text, images, videos, and audio. This,\nhowever, makes it difficult for users to obtain all the key information about a\ntopic, making the task of automatic multi-modal summarization (MMS) essential.\nIn this paper, we present a comprehensive survey of the existing research in\nthe area of MMS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jangra_A/0/1/0/all/0/1\">Anubhav Jangra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jatowt_A/0/1/0/all/0/1\">Adam Jatowt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Sriparna Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasanuzzaman_M/0/1/0/all/0/1\">Mohammad Hasanuzzaman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncovering Main Causalities for Long-tailed Information Extraction. (arXiv:2109.05213v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05213","description":"<p>Information Extraction (IE) aims to extract structural information from\nunstructured texts. In practice, long-tailed distributions caused by the\nselection bias of a dataset, may lead to incorrect correlations, also known as\nspurious correlations, between entities and labels in the conventional\nlikelihood models. This motivates us to propose counterfactual IE (CFIE), a\nnovel framework that aims to uncover the main causalities behind data in the\nview of causal inference. Specifically, 1) we first introduce a unified\nstructural causal model (SCM) for various IE tasks, describing the\nrelationships among variables; 2) with our SCM, we then generate\ncounterfactuals based on an explicit language structure to better calculate the\ndirect causal effect during the inference stage; 3) we further propose a novel\ndebiasing approach to yield more robust predictions. Experiments on three IE\ntasks across five public datasets show the effectiveness of our CFIE model in\nmitigating the spurious correlation issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1\">Guoshun Nan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiaqi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1\">Rui Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empirical Analysis of Training Strategies of Transformer-based Japanese Chit-chat Systems. (arXiv:2109.05217v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05217","description":"<p>In recent years, several high-performance conversational systems have been\nproposed based on the Transformer encoder-decoder model. Although previous\nstudies analyzed the effects of the model parameters and the decoding method on\nsubjective dialogue evaluations with overall metrics, they did not analyze how\nthe differences of fine-tuning datasets affect on user's detailed impression.\nIn addition, the Transformer-based approach has only been verified for English,\nnot for such languages with large inter-language distances as Japanese. In this\nstudy, we develop large-scale Transformer-based Japanese dialogue models and\nJapanese chit-chat datasets to examine the effectiveness of the\nTransformer-based approach for building chit-chat dialogue systems. We\nevaluated and analyzed the impressions of human dialogues in different\nfine-tuning datasets, model parameters, and the use of additional information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_H/0/1/0/all/0/1\">Hiroaki Sugiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizukami_M/0/1/0/all/0/1\">Masahiro Mizukami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arimoto_T/0/1/0/all/0/1\">Tsunehiro Arimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narimatsu_H/0/1/0/all/0/1\">Hiromi Narimatsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiba_Y/0/1/0/all/0/1\">Yuya Chiba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakajima_H/0/1/0/all/0/1\">Hideharu Nakajima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meguro_T/0/1/0/all/0/1\">Toyomi Meguro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with Incomplete Annotations. (arXiv:2109.05233v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05233","description":"<p>State-of-the-art Named Entity Recognition(NER) models rely heavily on large\namountsof fully annotated training data. However, ac-cessible data are often\nincompletely annotatedsince the annotators usually lack comprehen-sive\nknowledge in the target domain. Normallythe unannotated tokens are regarded as\nnon-entities by default, while we underline thatthese tokens could either be\nnon-entities orpart of any entity. Here, we study NER mod-eling with incomplete\nannotated data whereonly a fraction of the named entities are la-beled, and the\nunlabeled tokens are equiva-lently multi-labeled by every possible label.Taking\nmulti-labeled tokens into account, thenumerous possible paths can distract the\ntrain-ing model from the gold path (ground truthlabel sequence), and thus\nhinders the learn-ing ability. In this paper, we propose AdaK-NER, named the\nadaptive top-Kapproach, tohelp the model focus on a smaller feasible re-gion\nwhere the gold path is more likely to belocated. We demonstrate the superiority\nofour approach through extensive experimentson both English and Chinese\ndatasets, aver-agely improving 2% in F-score on the CoNLL-2003 and over 10% on\ntwo Chinese datasetscompared with the prior state-of-the-art works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_H/0/1/0/all/0/1\">Hongtao Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Liying Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Peixian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prior Omission of Dissimilar Source Domain(s) for Cost-Effective Few-Shot Learning. (arXiv:2109.05234v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05234","description":"<p>Few-shot slot tagging is an emerging research topic in the field of Natural\nLanguage Understanding (NLU). With sufficient annotated data from source\ndomains, the key challenge is how to train and adapt the model to another\ntarget domain which only has few labels. Conventional few-shot approaches use\nall the data from the source domains without considering inter-domain relations\nand implicitly assume each sample in the domain contributes equally. However,\nour experiments show that the data distribution bias among different domains\nwill significantly affect the adaption performance. Moreover, transferring\nknowledge from dissimilar domains will even introduce some extra noises so that\naffect the performance of models. To tackle this problem, we propose an\neffective similarity-based method to select data from the source domains. In\naddition, we propose a Shared-Private Network (SP-Net) for the few-shot slot\ntagging task. The words from the same class would have some shared features. We\nextract those shared features from the limited annotated data on the target\ndomain and merge them together as the label embedding to help us predict other\nunlabelled data on the target domain. The experiment shows that our method\noutperforms the state-of-the-art approaches with fewer source data. The result\nalso proves that some training data from dissimilar sources are redundant and\neven negative for the adaption.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zezhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_K/0/1/0/all/0/1\">Kwan Wai Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jia Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_G/0/1/0/all/0/1\">Gabriel Pui Cheong Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy. (arXiv:2109.05238v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05238","description":"<p>Simultaneous machine translation (SiMT) generates translation before reading\nthe entire source sentence and hence it has to trade off between translation\nquality and latency. To fulfill the requirements of different translation\nquality and latency in practical applications, the previous methods usually\nneed to train multiple SiMT models for different latency levels, resulting in\nlarge computational costs. In this paper, we propose a universal SiMT model\nwith Mixture-of-Experts Wait-k Policy to achieve the best translation quality\nunder arbitrary latency with only one trained model. Specifically, our method\nemploys multi-head attention to accomplish the mixture of experts where each\nhead is treated as a wait-k expert with its own waiting words number, and given\na test latency and source inputs, the weights of the experts are accordingly\nadjusted to produce the best translation. Experiments on three datasets show\nthat our method outperforms all the strong baselines under different latency,\nincluding the state-of-the-art adaptive policy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model. (arXiv:2109.05244v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05244","description":"<p>Cross-attention is an important component of neural machine translation\n(NMT), which is always realized by dot-product attention in previous methods.\nHowever, dot-product attention only considers the pair-wise correlation between\nwords, resulting in dispersion when dealing with long sentences and neglect of\nsource neighboring relationships. Inspired by linguistics, the above issues are\ncaused by ignoring a type of cross-attention, called concentrated attention,\nwhich focuses on several central words and then spreads around them. In this\nwork, we apply Gaussian Mixture Model (GMM) to model the concentrated attention\nin cross-attention. Experiments and analyses we conducted on three datasets\nshow that the proposed method outperforms the baseline and has significant\nimprovement on alignment quality, N-gram accuracy, and long sentence\ntranslation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qualitative and Quantitative Analysis of Diversity in Cross-document Coreference Resolution Datasets. (arXiv:2109.05250v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05250","description":"<p>Cross-document coreference resolution (CDCR) datasets, such as ECB+, contain\nmanually annotated event-centric mentions of events and entities that form\ncoreference chains with identity relations. ECB+ is a state-of-the-art CDCR\ndataset that focuses on the resolution of events and their descriptive\nattributes, i.e., actors, location, and date-time. NewsWCL50 is a dataset that\nannotates coreference chains of both events and entities with a strong variance\nof word choice and more loosely-related coreference anaphora, e.g., bridging or\nnear-identity relations. In this paper, we qualitatively and quantitatively\ncompare annotation schemes of ECB+ and NewsWCL50 with multiple criteria. We\npropose a phrasing diversity metric (PD) that compares lexical diversity within\ncoreference chains on a more detailed level than previously proposed metric,\ne.g., a number of unique lemmas. We discuss the different tasks that both CDCR\ndatasets create, i.e., lexical disambiguation and lexical diversity challenges,\nand propose a direction for further CDCR evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1\">Anastasia Zhukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1\">Felix Hamborg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XCoref: Cross-document Coreference Resolution in the Wild. (arXiv:2109.05252v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05252","description":"<p>Datasets and methods for cross-document coreference resolution (CDCR) focus\non events or entities with strict coreference relations. They lack, however,\nannotating and resolving coreference mentions with more abstract or loose\nrelations that may occur when news articles report about controversial and\npolarized events. Bridging and loose coreference relations trigger associations\nthat may lead to exposing news readers to bias by word choice and labeling. For\nexample, coreferential mentions of \"direct talks between U.S. President Donald\nTrump and Kim\" such as \"an extraordinary meeting following months of heated\nrhetoric\" or \"great chance to solve a world problem\" form a more positive\nperception of this event. A step towards bringing awareness of bias by word\nchoice and labeling is the reliable resolution of coreferences with high\nlexical diversity. We propose an unsupervised method named XCoref, which is a\nCDCR method that capably resolves not only previously prevalent entities, such\nas persons, e.g., \"Donald Trump,\" but also abstractly defined concepts, such as\ngroups of persons, \"caravan of immigrants,\" events and actions, e.g., \"marching\nto the U.S. border.\" In an extensive evaluation, we compare the proposed XCoref\nto a state-of-the-art CDCR method and a previous method TCA that resolves such\ncomplex coreference relations and find that XCoref outperforms these methods.\nOutperforming an established CDCR model shows that the new CDCR models need to\nbe evaluated on semantically complex mentions with more loose coreference\nrelations to indicate their applicability of models to resolve mentions in the\n\"wild\" of political news articles.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1\">Anastasia Zhukova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1\">Felix Hamborg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donnay_K/0/1/0/all/0/1\">Karsten Donnay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Translation via Grafting Pre-trained Language Models. (arXiv:2109.05256v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05256","description":"<p>Can pre-trained BERT for one language and GPT for another be glued together\nto translate texts? Self-supervised training using only monolingual data has\nled to the success of pre-trained (masked) language models in many NLP tasks.\nHowever, directly connecting BERT as an encoder and GPT as a decoder can be\nchallenging in machine translation, for GPT-like models lack a cross-attention\ncomponent that is needed in seq2seq decoders. In this paper, we propose\nGraformer to graft separately pre-trained (masked) language models for machine\ntranslation. With monolingual data for pre-training and parallel data for\ngrafting training, we maximally take advantage of the usage of both types of\ndata. Experiments on 60 directions show that our method achieves average\nimprovements of 5.8 BLEU in x2en and 2.9 BLEU in en2x directions comparing with\nthe multilingual Transformer of the same size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zewei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COSMic: A Coherence-Aware Generation Metric for Image Descriptions. (arXiv:2109.05281v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05281","description":"<p>Developers of text generation models rely on automated evaluation metrics as\na stand-in for slow and expensive manual evaluations. However, image captioning\nmetrics have struggled to give accurate learned estimates of the semantic and\npragmatic success of output text. We address this weakness by introducing the\nfirst discourse-aware learned generation metric for evaluating image\ndescriptions. Our approach is inspired by computational theories of discourse\nfor capturing information goals using coherence. We present a dataset of\nimage$\\unicode{x2013}$description pairs annotated with coherence relations. We\nthen train a coherence-aware metric on a subset of the Conceptual Captions\ndataset and measure its effectiveness$\\unicode{x2014}$its ability to predict\nhuman ratings of output captions$\\unicode{x2014}$on a test set composed of\nout-of-domain images. We demonstrate a higher Kendall Correlation Coefficient\nfor our proposed metric with the human judgments for the results of a number of\nstate-of-the-art coherence-aware caption generation models when compared to\nseveral other metrics including recently proposed learned metrics such as\nBLEURT and BERTScore.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inan_M/0/1/0/all/0/1\">Mert &#x130;nan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_B/0/1/0/all/0/1\">Baber Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_M/0/1/0/all/0/1\">Matthew Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1\">Malihe Alikhani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What's in a Name? Answer Equivalence For Open-Domain Question Answering. (arXiv:2109.05289v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05289","description":"<p>A flaw in QA evaluation is that annotations often only provide one gold\nanswer. Thus, model predictions semantically equivalent to the answer but\nsuperficially different are considered incorrect. This work explores mining\nalias entities from knowledge bases and using them as additional gold answers\n(i.e., equivalent answers). We incorporate answers for two settings: evaluation\nwith additional answers and model training with equivalent answers. We analyse\nthree QA benchmarks: Natural Questions, TriviaQA, and SQuAD. Answer expansion\nincreases the exact match score on all datasets for evaluation, while\nincorporating it helps model training over real-world datasets. We ensure the\nadditional answers are valid through a human post hoc evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Looking for Confirmations: An Effective and Human-Like Visual Dialogue Strategy. (arXiv:2109.05312v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05312","description":"<p>Generating goal-oriented questions in Visual Dialogue tasks is a challenging\nand long-standing problem. State-Of-The-Art systems are shown to generate\nquestions that, although grammatically correct, often lack an effective\nstrategy and sound unnatural to humans. Inspired by the cognitive literature on\ninformation search and cross-situational word learning, we design Confirm-it, a\nmodel based on a beam search re-ranking algorithm that guides an effective\ngoal-oriented strategy by asking questions that confirm the model's conjecture\nabout the referent. We take the GuessWhat?! game as a case-study. We show that\ndialogues generated by Confirm-it are more natural and effective than beam\nsearch decoding without re-ranking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Testoni_A/0/1/0/all/0/1\">Alberto Testoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernardi_R/0/1/0/all/0/1\">Raffaella Bernardi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bayesian Topic Regression for Causal Inference. (arXiv:2109.05317v1 [stat.ML])","link":"http://arxiv.org/abs/2109.05317","description":"<p>Causal inference using observational text data is becoming increasingly\npopular in many research areas. This paper presents the Bayesian Topic\nRegression (BTR) model that uses both text and numerical information to model\nan outcome variable. It allows estimation of both discrete and continuous\ntreatment effects. Furthermore, it allows for the inclusion of additional\nnumerical confounding factors next to text data. To this end, we combine a\nsupervised Bayesian topic model with a Bayesian regression framework and\nperform supervised representation learning for the text features jointly with\nthe regression parameter training, respecting the Frisch-Waugh-Lovell theorem.\nOur paper makes two main contributions. First, we provide a regression\nframework that allows causal inference in settings when both text and numerical\nconfounders are of relevance. We show with synthetic and semi-synthetic\ndatasets that our joint approach recovers ground truth with lower bias than any\nbenchmark model, when text and numerical features are correlated. Second,\nexperiments on two real-world datasets demonstrate that a joint and supervised\nlearning strategy also yields superior prediction results compared to\nstrategies that estimate regression weights for text and non-text features\nseparately, being even competitive with more complex deep neural networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Ahrens_M/0/1/0/all/0/1\">Maximilian Ahrens</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ashwin_J/0/1/0/all/0/1\">Julian Ashwin</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Calliess_J/0/1/0/all/0/1\">Jan-Peter Calliess</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1\">Vu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Latent Hatred: A Benchmark for Understanding Implicit Hate Speech. (arXiv:2109.05322v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05322","description":"<p>Hate speech has grown significantly on social media, causing serious\nconsequences for victims of all demographics. Despite much attention being paid\nto characterize and detect discriminatory speech, most work has focused on\nexplicit or overt hate speech, failing to address a more pervasive form based\non coded or indirect language. To fill this gap, this work introduces a\ntheoretically-justified taxonomy of implicit hate speech and a benchmark corpus\nwith fine-grained labels for each message and its implication. We present\nsystematic analyses of our dataset using contemporary baselines to detect and\nexplain implicit hate speech, and we discuss key features that challenge\nexisting models. This dataset will continue to serve as a useful benchmark for\nunderstanding this multifaceted issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1\">Mai ElSherief</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziems_C/0/1/0/all/0/1\">Caleb Ziems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muchlinski_D/0/1/0/all/0/1\">David Muchlinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anupindi_V/0/1/0/all/0/1\">Vaishnavi Anupindi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seybolt_J/0/1/0/all/0/1\">Jordyn Seybolt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Munmun De Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To Protect and To Serve? Analyzing Entity-Centric Framing of Police Violence. (arXiv:2109.05325v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05325","description":"<p>Framing has significant but subtle effects on public opinion and policy. We\npropose an NLP framework to measure entity-centric frames. We use it to\nunderstand media coverage on police violence in the United States in a new\nPolice Violence Frames Corpus of 82k news articles spanning 7k police killings.\nOur work uncovers more than a dozen framing devices and reveals significant\ndifferences in the way liberal and conservative news sources frame both the\nissue of police violence and the entities involved. Conservative sources\nemphasize when the victim is armed or attacking an officer and are more likely\nto mention the victim's criminal record. Liberal sources focus more on the\nunderlying systemic injustice, highlighting the victim's race and that they\nwere unarmed. We discover temporary spikes in these injustice frames near\nhigh-profile shooting events, and finally, we show protest volume correlates\nwith and precedes media framing decisions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ziems_C/0/1/0/all/0/1\">Caleb Ziems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Objective Metric for Explainable AI: How and Why to Estimate the Degree of Explainability. (arXiv:2109.05327v1 [cs.AI])","link":"http://arxiv.org/abs/2109.05327","description":"<p>Numerous government initiatives (e.g. the EU with GDPR) are coming to the\nconclusion that the increasing complexity of modern software systems must be\ncontrasted with some Rights to Explanation and metrics for the Impact\nAssessment of these tools, that allow humans to understand and oversee the\noutput of Automated Decision Making systems. Explainable AI was born as a\npathway to allow humans to explore and understand the inner working of complex\nsystems. But establishing what is an explanation and objectively evaluating\nexplainability, are not trivial tasks. With this paper, we present a new\nmodel-agnostic metric to measure the Degree of eXplainability of correct\ninformation in an objective way, exploiting a specific model from Ordinary\nLanguage Philosophy called the Achinstein's Theory of Explanations. In order to\nunderstand whether this metric is actually behaving as explainability is\nexpected to, we designed a few experiments and a user-study on two realistic\nAI-based systems for healthcare and finance, involving famous AI technology\nincluding Artificial Neural Networks and TreeSHAP. The results we obtained are\nvery encouraging, suggesting that our proposed metric for measuring the Degree\nof eXplainability is robust on several scenarios and it can be eventually\nexploited for a lawful Impact Assessment of an Automated Decision Making\nsystem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sovrano_F/0/1/0/all/0/1\">Francesco Sovrano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vitali_F/0/1/0/all/0/1\">Fabio Vitali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling and Acceleration of Three-dimensional Structure Determination for Single-Particle Imaging Experiments with SpiniFEL. (arXiv:2109.05339v1 [physics.comp-ph])","link":"http://arxiv.org/abs/2109.05339","description":"<p>The Linac Coherent Light Source (LCLS) is an X- ray free electron laser\n(XFEL) facility enabling the study of the structure and dynamics of single\nmacromolecules. A major upgrade will bring the repetition rate of the X-ray\nsource from 120 to 1 million pulses per second. Exascale high performance\ncomputing (HPC) capabilities will be required to process the corresponding data\nrates. We present SpiniFEL, an application used for structure determination of\nproteins from single-particle imaging (SPI) experiments. An emerging technique\nfor imaging individual proteins and other large molecular complexes by\noutrunning radiation damage, SPI breaks free from the need for crystallization\n(which is difficult for some proteins) and allows for imaging molecular\ndynamics at near ambient conditions. SpiniFEL is being developed to run on\nsupercomputers in near real-time while an experiment is taking place, so that\nthe feedback about the data can guide the data collection strategy. We describe\nhere how we reformulated the mathematical framework for parallelizable\nimplementation and accelerated the most compute intensive parts of the\napplication. We also describe the use of Pygion, a Python interface for the\nLegion task-based programming model and compare to our existing MPI+GPU\nimplementation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Chang_H/0/1/0/all/0/1\">Hsing-Yin Chang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Slaughter_E/0/1/0/all/0/1\">Elliott Slaughter</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Mirchandaney_S/0/1/0/all/0/1\">Seema Mirchandaney</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Donatelli_J/0/1/0/all/0/1\">Jeffrey Donatelli</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Yoon_C/0/1/0/all/0/1\">Chun Hong Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HYDRA -- Hyper Dependency Representation Attentions. (arXiv:2109.05349v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05349","description":"<p>Attention is all we need as long as we have enough data. Even so, it is\nsometimes not easy to determine how much data is enough while the models are\nbecoming larger and larger. In this paper, we propose HYDRA heads, lightweight\npretrained linguistic self-attention heads to inject knowledge into transformer\nmodels without pretraining them again. Our approach is a balanced paradigm\nbetween leaving the models to learn unsupervised and forcing them to conform to\nlinguistic knowledge rigidly as suggested in previous studies. Our experiment\nproves that the approach is not only the boost performance of the model but\nalso lightweight and architecture friendly. We empirically verify our framework\non benchmark datasets to show the contribution of linguistic knowledge to a\ntransformer model. This is a promising result for a new approach to\ntransferring knowledge from linguistic resources into transformer-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tran-Binh Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1\">Minh-Quan Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh-Phuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Le-Minh Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Language Description: Low-shot Named Entity Recognition via Decomposed Framework. (arXiv:2109.05357v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05357","description":"<p>In this work, we study the problem of named entity recognition (NER) in a low\nresource scenario, focusing on few-shot and zero-shot settings. Built upon\nlarge-scale pre-trained language models, we propose a novel NER framework,\nnamely SpanNER, which learns from natural language supervision and enables the\nidentification of never-seen entity classes without using in-domain labeled\ndata. We perform extensive experiments on 5 benchmark datasets and evaluate the\nproposed method in the few-shot learning, domain transfer and zero-shot\nlearning settings. The experimental results show that the proposed method can\nbring 10%, 23% and 26% improvements in average over the best baselines in\nfew-shot learning, domain transfer and zero-shot learning settings\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1\">Haoda Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Implicit Premise Generation with Discourse-aware Commonsense Knowledge Models. (arXiv:2109.05358v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05358","description":"<p>Enthymemes are defined as arguments where a premise or conclusion is left\nimplicit. We tackle the task of generating the implicit premise in an\nenthymeme, which requires not only an understanding of the stated conclusion\nand premise but also additional inferences that could depend on commonsense\nknowledge. The largest available dataset for enthymemes (Habernal et al., 2018)\nconsists of 1.7k samples, which is not large enough to train a neural text\ngeneration model. To address this issue, we take advantage of a similar task\nand dataset: Abductive reasoning in narrative text (Bhagavatula et al., 2020).\nHowever, we show that simply using a state-of-the-art seq2seq model fine-tuned\non this data might not generate meaningful implicit premises associated with\nthe given enthymemes. We demonstrate that encoding discourse-aware commonsense\nduring fine-tuning improves the quality of the generated implicit premises and\noutperforms all other baselines both in automatic and human evaluations on\nthree different datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1\">Tuhin Chakrabarty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Aadit Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COMBO: State-of-the-Art Morphosyntactic Analysis. (arXiv:2109.05361v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05361","description":"<p>We introduce COMBO - a fully neural NLP system for accurate part-of-speech\ntagging, morphological analysis, lemmatisation, and (enhanced) dependency\nparsing. It predicts categorical morphosyntactic features whilst also exposes\ntheir vector representations, extracted from hidden layers. COMBO is an easy to\ninstall Python package with automatically downloadable pre-trained models for\nover 40 languages. It maintains a balance between efficiency and quality. As it\nis an end-to-end system and its modules are jointly trained, its training is\ncompetitively fast. As its models are optimised for accuracy, they achieve\noften better prediction quality than SOTA. The COMBO library is available at:\nhttps://gitlab.clarin-pl.eu/syntactic-tools/combo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klimaszewski_M/0/1/0/all/0/1\">Mateusz Klimaszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wroblewska_A/0/1/0/all/0/1\">Alina Wr&#xf3;blewska</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modular Self-Supervision for Document-Level Relation Extraction. (arXiv:2109.05362v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05362","description":"<p>Extracting relations across large text spans has been relatively\nunderexplored in NLP, but it is particularly important for high-value domains\nsuch as biomedicine, where obtaining high recall of the latest findings is\ncrucial for practical applications. Compared to conventional information\nextraction confined to short text spans, document-level relation extraction\nfaces additional challenges in both inference and learning. Given longer text\nspans, state-of-the-art neural architectures are less effective and\ntask-specific self-supervision such as distant supervision becomes very noisy.\nIn this paper, we propose decomposing document-level relation extraction into\nrelation detection and argument resolution, taking inspiration from Davidsonian\nsemantics. This enables us to incorporate explicit discourse modeling and\nleverage modular self-supervision for each sub-problem, which is less\nnoise-prone and can be further refined end-to-end via variational EM. We\nconduct a thorough evaluation in biomedical machine reading for precision\noncology, where cross-paragraph relation mentions are prevalent. Our method\noutperforms prior state of the art, such as multi-scale learning and graph\nneural networks, by over 20 absolute F1 points. The gain is particularly\npronounced among the most challenging relation instances whose arguments never\nco-occur in a paragraph.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1\">Cliff Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Sarthak Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Impact of Positional Encodings on Multilingual Compression. (arXiv:2109.05388v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05388","description":"<p>In order to preserve word-order information in a non-autoregressive setting,\ntransformer architectures tend to include positional knowledge, by (for\ninstance) adding positional encodings to token embeddings. Several\nmodifications have been proposed over the sinusoidal positional encodings used\nin the original transformer architecture; these include, for instance,\nseparating position encodings and token embeddings, or directly modifying\nattention weights based on the distance between word pairs. We first show that\nsurprisingly, while these modifications tend to improve monolingual language\nmodels, none of them result in better multilingual language models. We then\nanswer why that is: Sinusoidal encodings were explicitly designed to facilitate\ncompositionality by allowing linear projections over arbitrary time steps.\nHigher variances in multilingual training distributions requires higher\ncompression, in which case, compositionality becomes indispensable. Learned\nabsolute positional encodings (e.g., in mBERT) tend to approximate sinusoidal\nembeddings in multilingual settings, but more complex positional encoding\narchitectures lack the inductive bias to effectively learn compositionality and\ncross-lingual alignment. In other words, while sinusoidal positional encodings\nwere originally designed for monolingual applications, they are particularly\nuseful in multilingual language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravishankar_V/0/1/0/all/0/1\">Vinit Ravishankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Table Content for Zero-shot Text-to-SQL with Meta-Learning. (arXiv:2109.05395v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05395","description":"<p>Single-table text-to-SQL aims to transform a natural language question into a\nSQL query according to one single table. Recent work has made promising\nprogress on this task by pre-trained language models and a multi-submodule\nframework. However, zero-shot table, that is, the invisible table in the\ntraining set, is currently the most critical bottleneck restricting the\napplication of existing approaches to real-world scenarios. Although some work\nhas utilized auxiliary tasks to help handle zero-shot tables, expensive extra\nmanual annotation limits their practicality. In this paper, we propose a new\napproach for the zero-shot text-to-SQL task which does not rely on any\nadditional manual annotations. Our approach consists of two parts. First, we\npropose a new model that leverages the abundant information of table content to\nhelp establish the mapping between questions and zero-shot tables. Further, we\npropose a simple but efficient meta-learning strategy to train our model. The\nstrategy utilizes the two-step gradient update to force the model to learn a\ngeneralization ability towards zero-shot tables. We conduct extensive\nexperiments on a public open-domain text-to-SQL dataset WikiSQL and a\ndomain-specific dataset ESQL. Compared to existing approaches using the same\npre-trained model, our approach achieves significant improvements on both\ndatasets. Compared to the larger pre-trained model and the tabular-specific\npre-trained model, our approach is still competitive. More importantly, on the\nzero-shot subsets of both the datasets, our approach further increases the\nimprovements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xinnan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaojie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jian Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guilin Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huiying Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guiding Topic Flows in the Generative Chatbot by Enhancing the ConceptNet with the Conversation Corpora. (arXiv:2109.05406v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05406","description":"<p>Human conversations consist of reasonable and natural topic flows, which are\nobserved as the shifts of the mentioned concepts across utterances. Previous\nchatbots that incorporate the external commonsense knowledge graph prove that\nmodeling the concept shifts can effectively alleviate the dull and\nuninformative response dilemma. However, there still exists a gap between the\nconcept relations in the natural conversation and those in the external\ncommonsense knowledge graph, which is an issue to solve. Specifically, the\nconcept relations in the external commonsense knowledge graph are not\nintuitively built from the conversational scenario but the world knowledge,\nwhich makes them insufficient for the chatbot construction. To bridge the above\ngap, we propose the method to supply more concept relations extracted from the\nconversational corpora and reconstruct an enhanced concept graph for the\nchatbot construction. In addition, we present a novel, powerful, and fast graph\nencoding architecture named the Edge-Transformer to replace the traditional GNN\narchitecture. Experimental results on the Reddit conversation dataset indicate\nour proposed method significantly outperforms strong baseline systems and\nachieves new SOTA results. Further analysis individually proves the\neffectiveness of the enhanced concept graph and the Edge-Transformer\narchitecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_P/0/1/0/all/0/1\">Pengda Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pairwise Supervised Contrastive Learning of Sentence Representations. (arXiv:2109.05424v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05424","description":"<p>Many recent successes in sentence representation learning have been achieved\nby simply fine-tuning on the Natural Language Inference (NLI) datasets with\ntriplet loss or siamese loss. Nevertheless, they share a common weakness:\nsentences in a contradiction pair are not necessarily from different semantic\ncategories. Therefore, optimizing the semantic entailment and contradiction\nreasoning objective alone is inadequate to capture the high-level semantic\nstructure. The drawback is compounded by the fact that the vanilla siamese or\ntriplet losses only learn from individual sentence pairs or triplets, which\noften suffer from bad local optima. In this paper, we propose PairSupCon, an\ninstance discrimination based approach aiming to bridge semantic entailment and\ncontradiction understanding with high-level categorical concept encoding. We\nevaluate PairSupCon on various downstream tasks that involve understanding\nsentence semantics at different granularities. We outperform the previous\nstate-of-the-art method with $10\\%$--$13\\%$ averaged improvement on eight\nclustering tasks, and $5\\%$--$6\\%$ averaged improvement on seven semantic\ntextual similarity (STS) tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dejiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1\">Wei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Henghui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallapati_R/0/1/0/all/0/1\">Ramesh Nallapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnold_A/0/1/0/all/0/1\">Andrew O. Arnold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not All Negatives are Equal: Label-Aware Contrastive Loss for Fine-grained Text Classification. (arXiv:2109.05427v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05427","description":"<p>Fine-grained classification involves dealing with datasets with larger number\nof classes with subtle differences between them. Guiding the model to focus on\ndifferentiating dimensions between these commonly confusable classes is key to\nimproving performance on fine-grained tasks. In this work, we analyse the\ncontrastive fine-tuning of pre-trained language models on two fine-grained text\nclassification tasks, emotion classification and sentiment analysis. We\nadaptively embed class relationships into a contrastive objective function to\nhelp differently weigh the positives and negatives, and in particular,\nweighting closely confusable negatives more than less similar negative\nexamples. We find that Label-aware Contrastive Loss outperforms previous\ncontrastive methods, in the presence of larger number and/or more confusable\nclasses, and helps models to produce output distributions that are more\ndifferentiated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_V/0/1/0/all/0/1\">Varsha Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_D/0/1/0/all/0/1\">Desmond C. Ong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Gender-Neutral Queries Really Gender-Neutral? Mitigating Gender Bias in Image Search. (arXiv:2109.05433v1 [cs.CV])","link":"http://arxiv.org/abs/2109.05433","description":"<p>Internet search affects people's cognition of the world, so mitigating biases\nin search results and learning fair models is imperative for social good. We\nstudy a unique gender bias in image search in this work: the search images are\noften gender-imbalanced for gender-neutral natural language queries. We\ndiagnose two typical image search models, the specialized model trained on\nin-domain datasets and the generalized representation model pre-trained on\nmassive image and text data across the internet. Both models suffer from severe\ngender bias. Therefore, we introduce two novel debiasing approaches: an\nin-processing fair sampling method to address the gender imbalance issue for\ntraining models, and a post-processing feature clipping method base on mutual\ninformation to debias multimodal representations of pre-trained models.\nExtensive experiments on MS-COCO and Flickr30K benchmarks show that our methods\nsignificantly reduce the gender bias in image search models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jialu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Let Your Characters Tell Their Story\": A Dataset for Character-Centric Narrative Understanding. (arXiv:2109.05438v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05438","description":"<p>When reading a literary piece, readers often make inferences about various\ncharacters' roles, personalities, relationships, intents, actions, etc. While\nhumans can readily draw upon their past experiences to build such a\ncharacter-centric view of the narrative, understanding characters in narratives\ncan be a challenging task for machines. To encourage research in this field of\ncharacter-centric narrative understanding, we present LiSCU -- a new dataset of\nliterary pieces and their summaries paired with descriptions of characters that\nappear in them. We also introduce two new tasks on LiSCU: Character\nIdentification and Character Description Generation. Our experiments with\nseveral pre-trained language models adapted for these tasks demonstrate that\nthere is a need for better models of narrative comprehension.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Meng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tafjord_O/0/1/0/all/0/1\">Oyvind Tafjord</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaturvedi_S/0/1/0/all/0/1\">Snigdha Chaturvedi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Conversational Search for Online Shopping with Utterance Transfer. (arXiv:2109.05460v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05460","description":"<p>Successful conversational search systems can present natural, adaptive and\ninteractive shopping experience for online shopping customers. However,\nbuilding such systems from scratch faces real word challenges from both\nimperfect product schema/knowledge and lack of training dialog data.In this\nwork we first propose ConvSearch, an end-to-end conversational search system\nthat deeply combines the dialog system with search. It leverages the text\nprofile to retrieve products, which is more robust against imperfect product\nschema/knowledge compared with using product attributes alone. We then address\nthe lack of data challenges by proposing an utterance transfer approach that\ngenerates dialogue utterances by using existing dialog from other domains, and\nleveraging the search behavior data from e-commerce retailer. With utterance\ntransfer, we introduce a new conversational search dataset for online shopping.\nExperiments show that our utterance transfer method can significantly improve\nthe availability of training dialogue data without crowd-sourcing, and the\nconversational search system significantly outperformed the best tested\nbaseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Liqiang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma2_J/0/1/0/all/0/1\">Jun Ma2</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xin Luna Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_Gomez_P/0/1/0/all/0/1\">Pascual Martinez-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1\">Nasser Zalmout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaohui Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Logic Traps in Evaluating Post-hoc Interpretations. (arXiv:2109.05463v1 [cs.LG])","link":"http://arxiv.org/abs/2109.05463","description":"<p>Post-hoc interpretation aims to explain a trained model and reveal how the\nmodel arrives at a decision. Though research on post-hoc interpretations has\ndeveloped rapidly, one growing pain in this field is the difficulty in\nevaluating interpretations. There are some crucial logic traps behind existing\nevaluation methods, which are ignored by most works. In this opinion piece, we\nsummarize four kinds evaluation methods and point out the corresponding logic\ntraps behind them. We argue that we should be clear about these traps rather\nthan ignore them and draw conclusions assertively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ju_Y/0/1/0/all/0/1\">Yiming Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhongtao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Task Difficulty for Few-Shot Relation Extraction. (arXiv:2109.05473v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05473","description":"<p>Few-shot relation extraction (FSRE) focuses on recognizing novel relations by\nlearning with merely a handful of annotated instances. Meta-learning has been\nwidely adopted for such a task, which trains on randomly generated few-shot\ntasks to learn generic data representations. Despite impressive results\nachieved, existing models still perform suboptimally when handling hard FSRE\ntasks, where the relations are fine-grained and similar to each other. We argue\nthis is largely because existing models do not distinguish hard tasks from easy\nones in the learning process. In this paper, we introduce a novel approach\nbased on contrastive learning that learns better representations by exploiting\nrelation label information. We further design a method that allows the model to\nadaptively learn how to focus on hard tasks. Experiments on two standard\ndatasets demonstrate the effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiale Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stylistic Retrieval-based Dialogue System with Unparallel Training Data. (arXiv:2109.05477v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05477","description":"<p>The ability of a dialog system to express consistent language style during\nconversations has a direct, positive impact on its usability and on user\nsatisfaction. Although previous studies have demonstrated that style transfer\nis feasible with a large amount of parallel data, it is often impossible to\ncollect such data for different styles. In this paper, instead of manually\nconstructing conversation data with a certain style, we propose a flexible\nframework that adapts a generic retrieval-based dialogue system to mimic the\nlanguage style of a specified persona without any parallel data. Our approach\nis based on automatic generation of stylized data by learning the usage of\njargon, and then rewriting the generic conversations to a stylized one by\nincorporating the jargon. In experiments we implemented dialogue systems with\nfive distinct language styles, and the result shows our framework significantly\noutperforms baselines in terms of the average score of responses' relevance and\nstyle degree, and content diversity. A/B testing on a commercial chatbot shows\nthat users are more satisfied with our system. This study demonstrates the\nfeasibility of building stylistic dialogue systems by simple data augmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Hao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Ruihua Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tianran Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jianyun Nie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Enhanced Fine-Tuning for Better Handling Unseen Entities in Dialogue Generation. (arXiv:2109.05487v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05487","description":"<p>Although pre-training models have achieved great success in dialogue\ngeneration, their performance drops dramatically when the input contains an\nentity that does not appear in pre-training and fine-tuning datasets (unseen\nentity). To address this issue, existing methods leverage an external knowledge\nbase to generate appropriate responses. In real-world scenario, the entity may\nnot be included by the knowledge base or suffer from the precision of knowledge\nretrieval. To deal with this problem, instead of introducing knowledge base as\nthe input, we force the model to learn a better semantic representation by\npredicting the information in the knowledge base, only based on the input\ncontext. Specifically, with the help of a knowledge base, we introduce two\nauxiliary training objectives: 1) Interpret Masked Word, which conjectures the\nmeaning of the masked entity given the context; 2) Hypernym Generation, which\npredicts the hypernym of the entity based on the context. Experiment results on\ntwo dialogue corpus verify the effectiveness of our methods under both\nknowledge available and unavailable settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Domain Adaptation Schemes for Building ASR in Low-resource Languages. (arXiv:2109.05494v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05494","description":"<p>Building an automatic speech recognition (ASR) system from scratch requires a\nlarge amount of annotated speech data, which is difficult to collect in many\nlanguages. However, there are cases where the low-resource language shares a\ncommon acoustic space with a high-resource language having enough annotated\ndata to build an ASR. In such cases, we show that the domain-independent\nacoustic models learned from the high-resource language through unsupervised\ndomain adaptation (UDA) schemes can enhance the performance of the ASR in the\nlow-resource language. We use the specific example of Hindi in the source\ndomain and Sanskrit in the target domain. We explore two architectures: i)\ndomain adversarial training using gradient reversal layer (GRL) and ii) domain\nseparation networks (DSN). The GRL and DSN architectures give absolute\nimprovements of 6.71% and 7.32%, respectively, in word error rate over the\nbaseline deep neural network model when trained on just 5.5 hours of data in\nthe target domain. We also show that choosing a proper language (Telugu) in the\nsource domain can bring further improvement. The results suggest that UDA\nschemes can be helpful in the development of ASR systems for low-resource\nlanguages, mitigating the hassle of collecting large amounts of annotated\nspeech data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+S_A/0/1/0/all/0/1\">Anoop C S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+P_P/0/1/0/all/0/1\">Prathosh A P</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_A/0/1/0/all/0/1\">A G Ramakrishnan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TEASEL: A Transformer-Based Speech-Prefixed Language Model. (arXiv:2109.05522v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05522","description":"<p>Multimodal language analysis is a burgeoning field of NLP that aims to\nsimultaneously model a speaker's words, acoustical annotations, and facial\nexpressions. In this area, lexicon features usually outperform other modalities\nbecause they are pre-trained on large corpora via Transformer-based models.\nDespite their strong performance, training a new self-supervised learning (SSL)\nTransformer on any modality is not usually attainable due to insufficient data,\nwhich is the case in multimodal language learning. This work proposes a\nTransformer-Based Speech-Prefixed Language Model called TEASEL to approach the\nmentioned constraints without training a complete Transformer model. TEASEL\nmodel includes speech modality as a dynamic prefix besides the textual modality\ncompared to a conventional language model. This method exploits a conventional\npre-trained language model as a cross-modal Transformer model. We evaluated\nTEASEL for the multimodal sentiment analysis task defined by CMU-MOSI dataset.\nExtensive experiments show that our model outperforms unimodal baseline\nlanguage models by 4% and outperforms the current multimodal state-of-the-art\n(SoTA) model by 1% in F1-score. Additionally, our proposed method is 72%\nsmaller than the SoTA model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arjmand_M/0/1/0/all/0/1\">Mehdi Arjmand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dousti_M/0/1/0/all/0/1\">Mohammad Javad Dousti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moradi_H/0/1/0/all/0/1\">Hadi Moradi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constructing Phrase-level Semantic Labels to Form Multi-Grained Supervision for Image-Text Retrieval. (arXiv:2109.05523v1 [cs.CV])","link":"http://arxiv.org/abs/2109.05523","description":"<p>Existing research for image text retrieval mainly relies on sentence-level\nsupervision to distinguish matched and mismatched sentences for a query image.\nHowever, semantic mismatch between an image and sentences usually happens in\nfiner grain, i.e., phrase level. In this paper, we explore to introduce\nadditional phrase-level supervision for the better identification of mismatched\nunits in the text. In practice, multi-grained semantic labels are automatically\nconstructed for a query image in both sentence-level and phrase-level. We\nconstruct text scene graphs for the matched sentences and extract entities and\ntriples as the phrase-level labels. In order to integrate both supervision of\nsentence-level and phrase-level, we propose Semantic Structure Aware Multimodal\nTransformer (SSAMT) for multi-modal representation learning. Inside the SSAMT,\nwe utilize different kinds of attention mechanisms to enforce interactions of\nmulti-grain semantic units in both sides of vision and language. For the\ntraining, we propose multi-scale matching losses from both global and local\nperspectives, and penalize mismatched phrases. Experimental results on MS-COCO\nand Flickr30K show the effectiveness of our approach compared to some\nstate-of-the-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhihao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zejun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Haijun Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Jianqing Fan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting Event Temporal Relations via Hyperbolic Geometry. (arXiv:2109.05527v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05527","description":"<p>Detecting events and their evolution through time is a crucial task in\nnatural language understanding. Recent neural approaches to event temporal\nrelation extraction typically map events to embeddings in the Euclidean space\nand train a classifier to detect temporal relations between event pairs.\nHowever, embeddings in the Euclidean space cannot capture richer asymmetric\nrelations such as event temporal relations. We thus propose to embed events\ninto hyperbolic spaces, which are intrinsically oriented at modeling\nhierarchical structures. We introduce two approaches to encode events and their\ntemporal relations in hyperbolic spaces. One approach leverages hyperbolic\nembeddings to directly infer event relations through simple geometrical\noperations. In the second one, we devise an end-to-end architecture composed of\nhyperbolic neural units tailored for the temporal relation extraction task.\nThorough experimental assessments on widely used datasets have shown the\nbenefits of revisiting the tasks on a different geometrical space, resulting in\nstate-of-the-art performance on several standard metrics. Finally, the ablation\nstudy and several qualitative analyses highlighted the rich event semantics\nimplicitly encoded into hyperbolic spaces.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xingwei Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1\">Gabriele Pergola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Good-Enough Example Extrapolation. (arXiv:2109.05602v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05602","description":"<p>This paper asks whether extrapolating the hidden space distribution of text\nexamples from one class onto another is a valid inductive bias for data\naugmentation. To operationalize this question, I propose a simple data\naugmentation protocol called \"good-enough example extrapolation\" (GE3). GE3 is\nlightweight and has no hyperparameters. Applied to three text classification\ndatasets for various data imbalance scenarios, GE3 improves performance more\nthan upsampling and other hidden-space data augmentation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jason Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Levenshtein Training for Word-level Quality Estimation. (arXiv:2109.05611v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05611","description":"<p>We propose a novel scheme to use the Levenshtein Transformer to perform the\ntask of word-level quality estimation. A Levenshtein Transformer is a natural\nfit for this task: trained to perform decoding in an iterative manner, a\nLevenshtein Transformer can learn to post-edit without explicit supervision. To\nfurther minimize the mismatch between the translation task and the word-level\nQE task, we propose a two-stage transfer learning procedure on both augmented\ndata and human post-editing data. We also propose heuristics to construct\nreference labels that are compatible with subword-level finetuning and\ninference. Results on WMT 2020 QE shared task dataset show that our proposed\nmethod has superior data efficiency under the data-constrained setting and\ncompetitive performance under the unconstrained setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Shuoyang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junczys_Dowmunt_M/0/1/0/all/0/1\">Marcin Junczys-Dowmunt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RockNER: A Simple Method to Create Adversarial Examples for Evaluating the Robustness of Named Entity Recognition Models. (arXiv:2109.05620v1 [cs.CL])","link":"http://arxiv.org/abs/2109.05620","description":"<p>To audit the robustness of named entity recognition (NER) models, we propose\nRockNER, a simple yet effective method to create natural adversarial examples.\nSpecifically, at the entity level, we replace target entities with other\nentities of the same semantic class in Wikidata; at the context level, we use\npre-trained language models (e.g., BERT) to generate word substitutions.\nTogether, the two levels of attack produce natural adversarial examples that\nresult in a shifted distribution from the training data on which our target\nmodels have been trained. We apply the proposed method to the OntoNotes dataset\nand create a new benchmark named OntoRock for evaluating the robustness of\nexisting NER models via a systematic evaluation protocol. Our experiments and\nanalysis reveal that even the best model has a significant performance drop,\nand these models seem to memorize in-domain entity patterns instead of\nreasoning from the context. Our work also studies the effects of a few simple\ndata augmentation methods to improve the robustness of NER models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wenyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_R/0/1/0/all/0/1\">Ryan Moreno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialBERT: A Hierarchical Pre-Trained Model for Conversation Disentanglement. (arXiv:2004.03760v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.03760","description":"<p>Disentanglement is a problem in which multiple conversations occur in the\nsame channel simultaneously, and the listener should decide which utterance is\npart of the conversation he will respond to. We propose a new model, named\nDialogue BERT (DialBERT), which integrates local and global semantics in a\nsingle stream of messages to disentangle the conversations that mixed together.\nWe employ BERT to capture the matching information in each utterance pair at\nthe utterance-level, and use a BiLSTM to aggregate and incorporate the\ncontext-level information. With only a 3% increase in parameters, a 12%\nimprovement has been attained in comparison to BERT, based on the F1-Score. The\nmodel achieves a state-of-the-art result on the a new dataset proposed by IBM\nand surpasses previous work by a substantial margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianda Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhiming Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Si Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fighting the COVID-19 Infodemic: Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society. (arXiv:2005.00033v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2005.00033","description":"<p>With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic has been\ndeclared one of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Ad-dressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nTo address this gap, we release a large dataset of 16K manually annotated\ntweets for fine-grained disinformation analysis that (i) focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society, and (iii) covers Arabic,\nBulgarian, Dutch, and English. Finally, we show strong evaluation results using\npretrained Transformers, thus con-firming the practical utility of the dataset\nin monolingual vs. multilingual, and single task vs. multitask settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1\">Shaden Shaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1\">Alex Nikolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mubarak_H/0/1/0/all/0/1\">Hamdy Mubarak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_G/0/1/0/all/0/1\">Giovanni Da San Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelali_A/0/1/0/all/0/1\">Ahmed Abdelali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darwish_K/0/1/0/all/0/1\">Kareem Darwish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedLatinEpi and MedLatinLit: Two Datasets for the Computational Authorship Analysis of Medieval Latin Texts. (arXiv:2006.12289v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2006.12289","description":"<p>We present and make available MedLatinEpi and MedLatinLit, two datasets of\nmedieval Latin texts to be used in research on computational authorship\nanalysis. MedLatinEpi and MedLatinLit consist of 294 and 30 curated texts,\nrespectively, labelled by author; MedLatinEpi texts are of epistolary nature,\nwhile MedLatinLit texts consist of literary comments and treatises about\nvarious subjects. As such, these two datasets lend themselves to supporting\nresearch in authorship analysis tasks, such as authorship attribution,\nauthorship verification, or same-author verification. Along with the datasets\nwe provide experimental results, obtained on these datasets, for the authorship\nverification task, i.e., the task of predicting whether a text of unknown\nauthorship was written by a candidate author or not. We also make available the\nsource code of the authorship verification system we have used, thus allowing\nour experiments to be reproduced, and to be used as baselines, by other\nresearchers. We also describe the application of the above authorship\nverification system, using these datasets as training data, for investigating\nthe authorship of two medieval epistles whose authorship has been disputed by\nscholars.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Corbara_S/0/1/0/all/0/1\">Silvia Corbara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1\">Alejandro Moreo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1\">Fabrizio Sebastiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavoni_M/0/1/0/all/0/1\">Mirko Tavoni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OSCaR: Orthogonal Subspace Correction and Rectification of Biases in Word Embeddings. (arXiv:2007.00049v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2007.00049","description":"<p>Language representations are known to carry stereotypical biases and, as a\nresult, lead to biased predictions in downstream tasks. While existing methods\nare effective at mitigating biases by linear projection, such methods are too\naggressive: they not only remove bias, but also erase valuable information from\nword embeddings. We develop new measures for evaluating specific information\nretention that demonstrate the tradeoff between bias removal and information\nretention. To address this challenge, we propose OSCaR (Orthogonal Subspace\nCorrection and Rectification), a bias-mitigating method that focuses on\ndisentangling biased associations between concepts instead of removing concepts\nwholesale. Our experiments on gender biases show that OSCaR is a well-balanced\napproach that ensures that semantic information is retained in the embeddings\nand bias is also effectively mitigated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1\">Sunipa Dev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1\">Jeff M Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Robustness and Bias Analysis of BERT-based Relation Extraction. (arXiv:2009.06206v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.06206","description":"<p>Fine-tuning pre-trained models have achieved impressive performance on\nstandard natural language processing benchmarks. However, the resultant model\ngeneralizability remains poorly understood. We do not know, for example, how\nexcellent performance can lead to the perfection of generalization models. In\nthis study, we analyze a fine-tuned BERT model from different perspectives\nusing relation extraction. We also characterize the differences in\ngeneralization techniques according to our proposed improvements. From\nempirical experimentation, we find that BERT suffers a bottleneck in terms of\nrobustness by way of randomizations, adversarial and counterfactual tests, and\nbiases (i.e., selection and semantic). These findings highlight opportunities\nfor future improvements. Our open-sourced testbed DiagnoseRE is available in\n\\url{https://github.com/zjunlp/DiagnoseRE}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luoqiu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphCodeBERT: Pre-training Code Representations with Data Flow. (arXiv:2009.08366v4 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2009.08366","description":"<p>Pre-trained models for programming language have achieved dramatic empirical\nimprovements on a variety of code-related tasks such as code search, code\ncompletion, code summarization, etc. However, existing pre-trained models\nregard a code snippet as a sequence of tokens, while ignoring the inherent\nstructure of code, which provides crucial code semantics and would enhance the\ncode understanding process. We present GraphCodeBERT, a pre-trained model for\nprogramming language that considers the inherent structure of code. Instead of\ntaking syntactic-level structure of code like abstract syntax tree (AST), we\nuse data flow in the pre-training stage, which is a semantic-level structure of\ncode that encodes the relation of \"where-the-value-comes-from\" between\nvariables. Such a semantic-level structure is neat and does not bring an\nunnecessarily deep hierarchy of AST, the property of which makes the model more\nefficient. We develop GraphCodeBERT based on Transformer. In addition to using\nthe task of masked language modeling, we introduce two structure-aware\npre-training tasks. One is to predict code structure edges, and the other is to\nalign representations between source code and code structure. We implement the\nmodel in an efficient way with a graph-guided masked attention function to\nincorporate the code structure. We evaluate our model on four tasks, including\ncode search, clone detection, code translation, and code refinement. Results\nshow that code structure and newly introduced pre-training tasks can improve\nGraphCodeBERT and achieves state-of-the-art performance on the four downstream\ntasks. We further show that the model prefers structure-level attentions over\ntoken-level attentions in the task of code search.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Daya Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuo Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shuai Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhangyin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1\">Duyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1\">Alexey Svyatkovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Shengyu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tufano_M/0/1/0/all/0/1\">Michele Tufano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shao Kun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clement_C/0/1/0/all/0/1\">Colin Clement</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drain_D/0/1/0/all/0/1\">Dawn Drain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jian Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Program Enhanced Fact Verification with Verbalization and Graph Attention Network. (arXiv:2010.03084v6 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2010.03084","description":"<p>Performing fact verification based on structured data is important for many\nreal-life applications and is a challenging research problem, particularly when\nit involves both symbolic operations and informal inference based on language\nunderstanding. In this paper, we present a Program-enhanced Verbalization and\nGraph Attention Network (ProgVGAT) to integrate programs and execution into\ntextual inference models. Specifically, a verbalization with program execution\nmodel is proposed to accumulate evidences that are embedded in operations over\nthe tables. Built on that, we construct the graph attention verification\nnetworks, which are designed to fuse different sources of evidences from\nverbalized program execution, program structures, and the original statements\nand tables, to make the final verification decision. To support the above\nframework, we propose a program selection module optimized with a new training\nstrategy based on margin loss, to produce more accurate programs, which is\nshown to be effective in enhancing the final verification results. Experimental\nresults show that the proposed framework achieves the new state-of-the-art\nperformance, a 74.4% accuracy, on the benchmark dataset TABFACT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1\">Feng Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yufei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhigang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DuoRAT: Towards Simpler Text-to-SQL Models. (arXiv:2010.11119v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.11119","description":"<p>Recent neural text-to-SQL models can effectively translate natural language\nquestions to corresponding SQL queries on unseen databases. Working mostly on\nthe Spider dataset, researchers have proposed increasingly sophisticated\nsolutions to the problem. Contrary to this trend, in this paper we focus on\nsimplifications. We begin by building DuoRAT, a re-implementation of the\nstate-of-the-art RAT-SQL model that unlike RAT-SQL is using only relation-aware\nor vanilla transformers as the building blocks. We perform several ablation\nexperiments using DuoRAT as the baseline model. Our experiments confirm the\nusefulness of some techniques and point out the redundancy of others, including\nstructural SQL features and features that link the question with the schema.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scholak_T/0/1/0/all/0/1\">Torsten Scholak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Raymond Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahdanau_D/0/1/0/all/0/1\">Dzmitry Bahdanau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_H/0/1/0/all/0/1\">Harm de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Chris Pal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Paraphrasing with Pretrained Language Models. (arXiv:2010.12885v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.12885","description":"<p>Paraphrase generation has benefited extensively from recent progress in the\ndesigning of training objectives and model architectures. However, previous\nexplorations have largely focused on supervised methods, which require a large\namount of labeled data that is costly to collect. To address this drawback, we\nadopt a transfer learning approach and propose a training pipeline that enables\npre-trained language models to generate high-quality paraphrases in an\nunsupervised setting. Our recipe consists of task-adaptation, self-supervision,\nand a novel decoding algorithm named Dynamic Blocking (DB). To enforce a\nsurface form dissimilar from the input, whenever the language model emits a\ntoken contained in the source sequence, DB prevents the model from outputting\nthe subsequent source token for the next generation step. We show with\nautomatic and human evaluations that our approach achieves state-of-the-art\nperformance on both the Quora Question Pair (QQP) and the ParaNMT datasets and\nis robust to domain shift between the two datasets of distinct distributions.\nWe also demonstrate that our model transfers to paraphrasing in other languages\nwithout any additional finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1\">Tong Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keskar_N/0/1/0/all/0/1\">Nitish Shirish Keskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-task Language Modeling for Improving Speech Recognition of Rare Words. (arXiv:2011.11715v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2011.11715","description":"<p>End-to-end automatic speech recognition (ASR) systems are increasingly\npopular due to their relative architectural simplicity and competitive\nperformance. However, even though the average accuracy of these systems may be\nhigh, the performance on rare content words often lags behind hybrid ASR\nsystems. To address this problem, second-pass rescoring is often applied\nleveraging upon language modeling. In this paper, we propose a second-pass\nsystem with multi-task learning, utilizing semantic targets (such as intent and\nslot prediction) to improve speech recognition performance. We show that our\nrescoring model trained with these additional tasks outperforms the baseline\nrescoring model, trained with only the language modeling task, by 1.4% on a\ngeneral test and by 2.6% on a rare word test set in terms of word-error-rate\nrelative (WERR). Our best ASR system with multi-task LM shows 4.6% WERR\ndeduction compared with RNN Transducer only ASR baseline for rare words\nrecognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linda Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhe_A/0/1/0/all/0/1\">Ankur Gandhe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yile Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raju_A/0/1/0/all/0/1\">Anirudh Raju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filimonov_D/0/1/0/all/0/1\">Denis Filimonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1\">Ivan Bulyko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Guided Image Captioning Performance across Domains. (arXiv:2012.02339v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2012.02339","description":"<p>Image captioning models generally lack the capability to take into account\nuser interest, and usually default to global descriptions that try to balance\nreadability, informativeness, and information overload. On the other hand, VQA\nmodels generally lack the ability to provide long descriptive answers, while\nexpecting the textual question to be quite precise. We present a method to\ncontrol the concepts that an image caption should focus on, using an additional\ninput called the guiding text that refers to either groundable or ungroundable\nconcepts in the image. Our model consists of a Transformer-based multimodal\nencoder that uses the guiding text together with global and object-level image\nfeatures to derive early-fusion representations used to generate the guided\ncaption. While models trained on Visual Genome data have an in-domain advantage\nof fitting well when guided with automatic object labels, we find that guided\ncaptioning models trained on Conceptual Captions generalize better on\nout-of-domain images and guiding texts. Our human-evaluation results indicate\nthat attempting in-the-wild guided image captioning requires access to large,\nunrestricted-domain training datasets, and that increased style diversity (even\nwithout increasing the number of unique tokens) is a key factor for improved\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ng_E/0/1/0/all/0/1\">Edwin G. Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Sense Language Modelling. (arXiv:2012.05776v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.05776","description":"<p>The effectiveness of a language model is influenced by its token\nrepresentations, which must encode contextual information and handle the same\nword form having a plurality of meanings (polysemy). Currently, none of the\ncommon language modelling architectures explicitly model polysemy. We propose a\nlanguage model which not only predicts the next word, but also its sense in\ncontext. We argue that this higher prediction granularity may be useful for end\ntasks such as assistive writing, and allow for more a precise linking of\nlanguage models with knowledge bases. We find that multi-sense language\nmodelling requires architectures that go beyond standard language models, and\nhere propose a structured prediction framework that decomposes the task into a\nword followed by a sense prediction task. To aid sense prediction, we utilise a\nGraph Attention Network, which encodes definitions and example uses of word\nsenses. Overall, we find that multi-sense language modelling is a highly\nchallenging task, and suggest that future work focus on the creation of more\nannotated training datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lekkas_A/0/1/0/all/0/1\">Andrea Lekkas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_Kamp_P/0/1/0/all/0/1\">Peter Schneider-Kamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YASO: A Targeted Sentiment Analysis Evaluation Dataset for Open-Domain Reviews. (arXiv:2012.14541v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.14541","description":"<p>Current TSA evaluation in a cross-domain setup is restricted to the small set\nof review domains available in existing datasets. Such an evaluation is\nlimited, and may not reflect true performance on sites like Amazon or Yelp that\nhost diverse reviews from many domains. To address this gap, we present YASO -\na new TSA evaluation dataset of open-domain user reviews. YASO contains 2,215\nEnglish sentences from dozens of review domains, annotated with target terms\nand their sentiment. Our analysis verifies the reliability of these\nannotations, and explores the characteristics of the collected data. Benchmark\nresults using five contemporary TSA systems show there is ample room for\nimprovement on this challenging new dataset. YASO is available at\nhttps://github.com/IBM/yaso-tsa.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Orbach_M/0/1/0/all/0/1\">Matan Orbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toledo_Ronen_O/0/1/0/all/0/1\">Orith Toledo-Ronen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spector_A/0/1/0/all/0/1\">Artem Spector</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharonov_R/0/1/0/all/0/1\">Ranit Aharonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning. (arXiv:2012.15283v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.15283","description":"<p>While pre-trained language models (PTLMs) have achieved noticeable success on\nmany NLP tasks, they still struggle for tasks that require event temporal\nreasoning, which is essential for event-centric applications. We present a\ncontinual pre-training approach that equips PTLMs with targeted knowledge about\nevent temporal relations. We design self-supervised learning objectives to\nrecover masked-out event and temporal indicators and to discriminate sentences\nfrom their corrupted counterparts (where event or temporal indicators got\nreplaced). By further pre-training a PTLM with these objectives jointly, we\nreinforce its attention to event and temporal information, yielding enhanced\ncapability on event temporal reasoning. This effective continual pre-training\nframework for event temporal reasoning (ECONET) improves the PTLMs' fine-tuning\nperformances across five relation extraction and question answering tasks and\nachieves new or on-par state-of-the-art performances in most of our downstream\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1\">Rujun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From How Human Correct For Data-Centric Deep Learning. (arXiv:2102.00225v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.00225","description":"<p>In industry NLP application, our manually labeled data has a certain number\nof noisy data. We present a simple method to find the noisy data and relabel\nthem manually, meanwhile we collect the correction information. Then we present\nnovel method to incorporate the human correction information into deep learning\nmodel. Human know how to correct noisy data. So the correction information can\nbe inject into deep learning model. We do the experiment on our own text\nclassification dataset, which is manually labeled, because we relabel the noisy\ndata in our dataset for our industry application. The experiment result shows\nthat our method improve the classification accuracy from 91.7% to 92.5%. The\n91.7% baseline is based on BERT training on the corrected dataset, which is\nhard to surpass.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Transformer Modifications Transfer Across Implementations and Applications?. (arXiv:2102.11972v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2102.11972","description":"<p>The research community has proposed copious modifications to the Transformer\narchitecture since it was introduced over three years ago, relatively few of\nwhich have seen widespread adoption. In this paper, we comprehensively evaluate\nmany of these modifications in a shared experimental setting that covers most\nof the common uses of the Transformer in natural language processing.\nSurprisingly, we find that most modifications do not meaningfully improve\nperformance. Furthermore, most of the Transformer variants we found beneficial\nwere either developed in the same codebase that we used or are relatively minor\nchanges. We conjecture that performance improvements may strongly depend on\nimplementation details and correspondingly make some recommendations for\nimproving the generality of experimental results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hyung Won Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fedus_W/0/1/0/all/0/1\">William Fedus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fevry_T/0/1/0/all/0/1\">Thibault Fevry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matena_M/0/1/0/all/0/1\">Michael Matena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malkan_K/0/1/0/all/0/1\">Karishma Malkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiedel_N/0/1/0/all/0/1\">Noah Fiedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shazeer_N/0/1/0/all/0/1\">Noam Shazeer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanqi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marcus_J/0/1/0/all/0/1\">Jake Marcus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging pre-trained representations to improve access to untranscribed speech from endangered languages. (arXiv:2103.14583v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.14583","description":"<p>Pre-trained speech representations like wav2vec 2.0 are a powerful tool for\nautomatic speech recognition (ASR). Yet many endangered languages lack\nsufficient data for pre-training such models, or are predominantly oral\nvernaculars without a standardised writing system, precluding fine-tuning.\nQuery-by-example spoken term detection (QbE-STD) offers an alternative for\niteratively indexing untranscribed speech corpora by locating spoken query\nterms. Using data from 7 Australian Aboriginal languages and a regional variety\nof Dutch, all of which are endangered or vulnerable, we show that QbE-STD can\nbe improved by leveraging representations developed for ASR (wav2vec 2.0: the\nEnglish monolingual model and XLSR53 multilingual model). Surprisingly, the\nEnglish model outperformed the multilingual model on 4 Australian language\ndatasets, raising questions around how to optimally leverage self-supervised\nspeech representations for QbE-STD. Nevertheless, we find that wav2vec 2.0\nrepresentations (either English or XLSR53) offer large improvements (56-86%\nrelative) over state-of-the-art approaches on our endangered language datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+San_N/0/1/0/all/0/1\">Nay San</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartelds_M/0/1/0/all/0/1\">Martijn Bartelds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Browne_M/0/1/0/all/0/1\">Mitchell Browne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifford_L/0/1/0/all/0/1\">Lily Clifford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibson_F/0/1/0/all/0/1\">Fiona Gibson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansfield_J/0/1/0/all/0/1\">John Mansfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nash_D/0/1/0/all/0/1\">David Nash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simpson_J/0/1/0/all/0/1\">Jane Simpson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turpin_M/0/1/0/all/0/1\">Myfany Turpin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vollmer_M/0/1/0/all/0/1\">Maria Vollmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilmoth_S/0/1/0/all/0/1\">Sasha Wilmoth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Convex Aggregation for Opinion Summarization. (arXiv:2104.01371v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.01371","description":"<p>Recent advances in text autoencoders have significantly improved the quality\nof the latent space, which enables models to generate grammatical and\nconsistent text from aggregated latent vectors. As a successful application of\nthis property, unsupervised opinion summarization models generate a summary by\ndecoding the aggregated latent vectors of inputs. More specifically, they\nperform the aggregation via simple average. However, little is known about how\nthe vector aggregation step affects the generation quality. In this study, we\nrevisit the commonly used simple average approach by examining the latent space\nand generated summaries. We found that text autoencoders tend to generate\noverly generic summaries from simply averaged latent vectors due to an\nunexpected $L_2$-norm shrinkage in the aggregated latent vectors, which we\nrefer to as summary vector degeneration. To overcome this issue, we develop a\nframework Coop, which searches input combinations for the latent vector\naggregation using input-output word overlap. Experimental results show that\nCoop successfully alleviates the summary vector degeneration issue and\nestablishes new state-of-the-art performance on two opinion summarization\nbenchmarks. Code is available at \\url{https://github.com/megagonlabs/coop}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iso_H/0/1/0/all/0/1\">Hayate Iso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhara_Y/0/1/0/all/0/1\">Yoshihiko Suhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angelidis_S/0/1/0/all/0/1\">Stefanos Angelidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Wang-Chiew Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Role of BERT Token Representations to Explain Sentence Probing Results. (arXiv:2104.01477v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.01477","description":"<p>Several studies have been carried out on revealing linguistic features\ncaptured by BERT. This is usually achieved by training a diagnostic classifier\non the representations obtained from different layers of BERT. The subsequent\nclassification accuracy is then interpreted as the ability of the model in\nencoding the corresponding linguistic property. Despite providing insights,\nthese studies have left out the potential role of token representations. In\nthis paper, we provide a more in-depth analysis on the representation space of\nBERT in search for distinct and meaningful subspaces that can explain the\nreasons behind these probing results. Based on a set of probing tasks and with\nthe help of attribution methods we show that BERT tends to encode meaningful\nknowledge in specific token representations (which are often ignored in\nstandard classification setups), allowing the model to detect syntactic and\nsemantic abnormalities, and to distinctively separate grammatical number and\ntense subspaces.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohebbi_H/0/1/0/all/0/1\">Hosein Mohebbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modarressi_A/0/1/0/all/0/1\">Ali Modarressi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilehvar_M/0/1/0/all/0/1\">Mohammad Taher Pilehvar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pushing the Limits of Non-Autoregressive Speech Recognition. (arXiv:2104.03416v4 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2104.03416","description":"<p>We combine recent advancements in end-to-end speech recognition to\nnon-autoregressive automatic speech recognition. We push the limits of\nnon-autoregressive state-of-the-art results for multiple datasets: LibriSpeech,\nFisher+Switchboard and Wall Street Journal. Key to our recipe, we leverage CTC\non giant Conformer neural network architectures with SpecAugment and wav2vec2\npre-training. We achieve 1.8%/3.6% WER on LibriSpeech test/test-other sets,\n5.1%/9.8% WER on Switchboard, and 3.4% on the Wall Street Journal, all without\na language model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Ng_E/0/1/0/all/0/1\">Edwin G. Ng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiu_C/0/1/0/all/0/1\">Chung-Cheng Chiu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_W/0/1/0/all/0/1\">William Chan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reducing Discontinuous to Continuous Parsing with Pointer Network Reordering. (arXiv:2104.06239v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06239","description":"<p>Discontinuous constituent parsers have always lagged behind continuous\napproaches in terms of accuracy and speed, as the presence of constituents with\ndiscontinuous yield introduces extra complexity to the task. However, a\ndiscontinuous tree can be converted into a continuous variant by reordering\ntokens. Based on that, we propose to reduce discontinuous parsing to a\ncontinuous problem, which can then be directly solved by any off-the-shelf\ncontinuous parser. To that end, we develop a Pointer Network capable of\naccurately generating the continuous token arrangement for a given input\nsentence and define a bijective function to recover the original order.\nExperiments on the main benchmarks with two continuous parsers prove that our\napproach is on par in accuracy with purely discontinuous state-of-the-art\nalgorithms, but considerably faster.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_Gonzalez_D/0/1/0/all/0/1\">Daniel Fern&#xe1;ndez-Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez-Rodr&#xed;guez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Interpretable Clauses Semantically using Pretrained Word Representation. (arXiv:2104.06901v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06901","description":"<p>Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based\non propositional logic, which has demonstrated competitive performance in many\nNatural Language Processing (NLP) tasks, including sentiment analysis, text\nclassification, and Word Sense Disambiguation. To obtain human-level\ninterpretability, legacy TM employs Boolean input features such as bag-of-words\n(BOW). However, the BOW representation makes it difficult to use any\npre-trained information, for instance, word2vec and GloVe word representations.\nThis restriction has constrained the performance of TM compared to deep neural\nnetworks (DNNs) in NLP. To reduce the performance gap, in this paper, we\npropose a novel way of using pre-trained word representations for TM. The\napproach significantly enhances the performance and interpretability of TM. We\nachieve this by extracting semantically related words from pre-trained word\nrepresentations as input features to the TM. Our experiments show that the\naccuracy of the proposed approach is significantly higher than the previous\nBOW-based TM, reaching the level of DNN-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_R/0/1/0/all/0/1\">Rohan Kumar Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1\">Lei Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1\">Morten Goodwin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Disentangling Representations of Text by Masking Transformers. (arXiv:2104.07155v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07155","description":"<p>Representations from large pretrained models such as BERT encode a range of\nfeatures into monolithic vectors, affording strong predictive accuracy across a\nmultitude of downstream tasks. In this paper we explore whether it is possible\nto learn disentangled representations by identifying existing subnetworks\nwithin pretrained models that encode distinct, complementary aspect\nrepresentations. Concretely, we learn binary masks over transformer weights or\nhidden units to uncover subsets of features that correlate with a specific\nfactor of variation; this eliminates the need to train a disentangled model\nfrom scratch for a particular task. We evaluate this method with respect to its\nability to disentangle representations of sentiment from genre in movie\nreviews, \"toxicity\" from dialect in Tweets, and syntax from semantics.\n</p>\n<p>By combining masking with magnitude pruning we find that we can identify\nsparse subnetworks within BERT that strongly encode particular aspects (e.g.,\ntoxicity) while only weakly encoding others (e.g., race). Moreover, despite\nonly learning masks, we find that disentanglement-via-masking performs as well\nas -- and often better than -- previously proposed methods based on variational\nautoencoders and adversarial training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiongyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meent_J/0/1/0/all/0/1\">Jan-Willem van de Meent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Domain Label-Adaptive Stance Detection. (arXiv:2104.07467v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07467","description":"<p>Stance detection concerns the classification of a writer's viewpoint towards\na target. There are different task variants, e.g., stance of a tweet vs. a full\narticle, or stance with respect to a claim vs. an (implicit) topic. Moreover,\ntask definitions vary, which includes the label inventory, the data collection,\nand the annotation protocol. All these aspects hinder cross-domain studies, as\nthey require changes to standard domain adaptation approaches. In this paper,\nwe perform an in-depth analysis of 16 stance detection datasets, and we explore\nthe possibility for cross-domain learning from them. Moreover, we propose an\nend-to-end unsupervised framework for out-of-domain prediction of unseen,\nuser-defined labels. In particular, we combine domain adaptation techniques\nsuch as mixture of experts and domain-adversarial training with label\nembeddings, and we demonstrate sizable performance gains over strong baselines,\nboth (i) in-domain, i.e., for seen targets, and (ii) out-of-domain, i.e., for\nunseen targets. Finally, we perform an exhaustive analysis of the cross-domain\nresults, and we highlight the important factors influencing the model\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hardalov_M/0/1/0/all/0/1\">Momchil Hardalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Arnav Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Deconfounding the Influence of Entity Demographics for Question Answering Accuracy. (arXiv:2104.07571v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07571","description":"<p>The goal of question answering (QA) is to answer any question. However, major\nQA datasets have skewed distributions over gender, profession, and nationality.\nDespite that skew, model accuracy analysis reveals little evidence that\naccuracy is lower for people based on gender or nationality; instead, there is\nmore variation on professions (question topic). But QA's lack of representation\ncould itself hide evidence of bias, necessitating QA datasets that better\nrepresent global diversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gor_M/0/1/0/all/0/1\">Maharshi Gor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webster_K/0/1/0/all/0/1\">Kellie Webster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Polarized Topics Using Partisanship-aware Contextualized Topic Embeddings. (arXiv:2104.07814v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07814","description":"<p>Growing polarization of the news media has been blamed for fanning\ndisagreement, controversy and even violence. Early identification of polarized\ntopics is thus an urgent matter that can help mitigate conflict. However,\naccurate measurement of topic-wise polarization is still an open research\nchallenge. To address this gap, we propose Partisanship-aware Contextualized\nTopic Embeddings (PaCTE), a method to automatically detect polarized topics\nfrom partisan news sources. Specifically, utilizing a language model that has\nbeen finetuned on recognizing partisanship of the news articles, we represent\nthe ideology of a news corpus on a topic by corpus-contextualized topic\nembedding and measure the polarization using cosine distance. We apply our\nmethod to a dataset of news articles about the COVID-19 pandemic. Extensive\nexperiments on different news sources and topics demonstrate the efficacy of\nour method to capture topical polarization, as indicated by its effectiveness\nof retrieving the most polarized topics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zihao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mokhberian_N/0/1/0/all/0/1\">Negar Mokhberian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camara_A/0/1/0/all/0/1\">Antonio Camara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abeliuk_A/0/1/0/all/0/1\">Andres Abeliuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_K/0/1/0/all/0/1\">Kristina Lerman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Matching-oriented Product Quantization For Ad-hoc Retrieval. (arXiv:2104.07858v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07858","description":"<p>Product quantization (PQ) is a widely used technique for ad-hoc retrieval.\nRecent studies propose supervised PQ, where the embedding and quantization\nmodels can be jointly trained with supervised learning. However, there is a\nlack of appropriate formulation of the joint training objective; thus, the\nimprovements over previous non-supervised baselines are limited in reality. In\nthis work, we propose the Matching-oriented Product Quantization (MoPQ), where\na novel objective Multinoulli Contrastive Loss (MCL) is formulated. With the\nminimization of MCL, we are able to maximize the matching probability of query\nand ground-truth key, which contributes to the optimal retrieval accuracy.\nGiven that the exact computation of MCL is intractable due to the demand of\nvast contrastive samples, we further propose the Differentiable Cross-device\nSampling (DCS), which significantly augments the contrastive samples for\nprecise approximation of MCL. We conduct extensive experimental studies on four\nreal-world datasets, whose results verify the effectiveness of MoPQ. The code\nis available at https://github.com/microsoft/MoPQ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shitao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1\">Defu Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counter-Interference Adapter for Multilingual Machine Translation. (arXiv:2104.08154v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08154","description":"<p>Developing a unified multilingual model has long been a pursuit for machine\ntranslation. However, existing approaches suffer from performance degradation\n-- a single multilingual model is inferior to separately trained bilingual ones\non rich-resource languages. We conjecture that such a phenomenon is due to\ninterference caused by joint training with multiple languages. To accommodate\nthe issue, we propose CIAT, an adapted Transformer model with a small parameter\noverhead for multilingual machine translation. We evaluate CIAT on multiple\nbenchmark datasets, including IWSLT, OPUS-100, and WMT. Experiments show that\nCIAT consistently outperforms strong multilingual baselines on 64 of total 66\nlanguage directions, 42 of which see above 0.5 BLEU improvement. Our code is\navailable at \\url{https://github.com/Yaoming95/CIAT}~.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chengqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESTER: A Machine Reading Comprehension Dataset for Event Semantic Relation Reasoning. (arXiv:2104.08350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08350","description":"<p>Understanding how events are semantically related to each other is the\nessence of reading comprehension. Recent event-centric reading comprehension\ndatasets focus mostly on event arguments or temporal relations. While these\ntasks partially evaluate machines' ability of narrative understanding,\nhuman-like reading comprehension requires the capability to process event-based\ninformation beyond arguments and temporal reasoning. For example, to understand\ncausality between events, we need to infer motivation or purpose; to establish\nevent hierarchy, we need to understand the composition of events. To facilitate\nthese tasks, we introduce ESTER, a comprehensive machine reading comprehension\n(MRC) dataset for Event Semantic Relation Reasoning. The dataset leverages\nnatural language queries to reason about the five most common event semantic\nrelations, provides more than 6K questions and captures 10.1K event relation\npairs. Experimental results show that the current SOTA systems achieve 22.1%,\n63.3%, and 83.5% for token-based exact-match, F1, and event-based HIT@1 scores,\nwhich are all significantly below human performances (36.0%, 79.6%, 100%\nrespectively), highlighting our dataset as a challenging benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1\">Rujun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_I/0/1/0/all/0/1\">I-Hung Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baylon_J/0/1/0/all/0/1\">Julia Baylon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Q/0/1/0/all/0/1\">Qiang Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MT6: Multilingual Pretrained Text-to-Text Transformer with Translation Pairs. (arXiv:2104.08692v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08692","description":"<p>Multilingual T5 (mT5) pretrains a sequence-to-sequence model on massive\nmonolingual texts, which has shown promising results on many cross-lingual\ntasks. In this paper, we improve multilingual text-to-text transfer Transformer\nwith translation pairs (mT6). Specifically, we explore three cross-lingual\ntext-to-text pre-training tasks, namely, machine translation, translation pair\nspan corruption, and translation span corruption. In addition, we propose a\npartially non-autoregressive objective for text-to-text pre-training. We\nevaluate the methods on eight multilingual benchmark datasets, including\nsentence classification, named entity recognition, question answering, and\nabstractive summarization. Experimental results show that the proposed mT6\nimproves cross-lingual transferability over mT5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shaohan Huang Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GooAQ: Open Question Answering with Diverse Answer Types. (arXiv:2104.08727v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08727","description":"<p>While day-to-day questions come with a variety of answer types, the current\nquestion-answering (QA) literature has failed to adequately address the answer\ndiversity of questions. To this end, we present GooAQ, a large-scale dataset\nwith a variety of answer types. This dataset contains over 5 million questions\nand 3 million answers collected from Google. GooAQ questions are collected\nsemi-automatically from the Google search engine using its autocomplete\nfeature. This results in naturalistic questions of practical interest that are\nnonetheless short and expressed using simple language. GooAQ answers are mined\nfrom Google's responses to our collected questions, specifically from the\nanswer boxes in the search results. This yields a rich space of answer types,\ncontaining both textual answers (short and long) as well as more structured\nones such as collections. We benchmarkT5 models on GooAQ and observe that: (a)\nin line with recent work, LM's strong performance on GooAQ's short-answer\nquestions heavily benefit from annotated data; however, (b) their quality in\ngenerating coherent and accurate responses for questions requiring long\nresponses (such as 'how' and 'why' questions) is less reliant on observing\nannotated data and mainly supported by their pre-training. We release GooAQ to\nfacilitate further research on improving QA with diverse response types.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1\">Amos Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can NLI Models Verify QA Systems' Predictions?. (arXiv:2104.08731v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08731","description":"<p>To build robust question answering systems, we need the ability to verify\nwhether answers to questions are truly correct, not just \"good enough\" in the\ncontext of imperfect QA datasets. We explore the use of natural language\ninference (NLI) as a way to achieve this goal, as NLI inherently requires the\npremise (document context) to contain all necessary information to support the\nhypothesis (proposed answer to the question). We leverage large pre-trained\nmodels and recent prior datasets to construct powerful question converter and\ndecontextualization modules, which can reformulate QA instances as\npremise-hypothesis pairs with very high reliability. Then, by combining\nstandard NLI datasets with NLI examples automatically derived from QA training\ndata, we can train NLI models to judge the correctness of QA models' proposed\nanswers. We show that our NLI approach can generally improve the confidence\nestimation of a QA model across different domains, evaluated in a selective QA\nsetting. Careful manual analysis over the predictions of our NLI model shows\nthat it can further identify cases where the QA model produces the right answer\nfor the wrong reason, or where the answer cannot be verified as addressing all\naspects of the question.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling End-to-End Models for Large-Scale Multilingual ASR. (arXiv:2104.14830v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.14830","description":"<p>Building ASR models across many languages is a challenging multi-task\nlearning problem due to large variations and heavily unbalanced data. Existing\nwork has shown positive transfer from high resource to low resource languages.\nHowever, degradations on high resource languages are commonly observed due to\ninterference from the heterogeneous multilingual data and reduction in\nper-language capacity. We conduct a capacity study on a 15-language task, with\nthe amount of data per language varying from 7.6K to 53.5K hours. We adopt\nGShard [1] to efficiently scale up to 10B parameters. Empirically, we find that\n(1) scaling the number of model parameters is an effective way to solve the\ncapacity bottleneck - our 500M-param model already outperforms monolingual\nbaselines and scaling it to 1B and 10B brought further quality gains; (2)\nlarger models are not only more data efficient, but also more efficient in\nterms of training cost as measured in TPU days - the 1B-param model reaches the\nsame accuracy at 34% of training time as the 500M-param model; (3) given a\nfixed capacity budget, adding depth works better than width and large encoders\ndo better than large decoders; (4) with continuous training, they can be\nadapted to new languages and domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Ruoming Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulati_A/0/1/0/all/0/1\">Anmol Gulati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">James Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghani_P/0/1/0/all/0/1\">Parisa Haghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Min Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Junwen Bai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Classifying Continuous Constraint Satisfaction problems. (arXiv:2106.02397v2 [cs.CC] UPDATED)","link":"http://arxiv.org/abs/2106.02397","description":"<p>A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with a domain $U \\subset \\mathbb{R}$. We engage in a\nsystematic study to classify CCSPs that are complete of the Existential Theory\nof the Reals, i.e., ER-complete. To define this class, we first consider the\nproblem ETR, which also stands for Existential Theory of the Reals. In an\ninstance of this problem we are given some sentence of the form $\\exists x_1,\n\\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where $\\Phi$ is a\nwell-formed quantifier-free formula consisting of the symbols $\\{0, 1, +,\n\\cdot, \\geq, &gt;, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n</p>\n<p>We restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n</p>\n<p>We apply our findings to geometric packing and answer an open question by\nAbrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing\nconvex pieces into a square container under rotations and translations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1\">Tillmann Miltzow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmiermann_R/0/1/0/all/0/1\">Reinier F. Schmiermann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment. (arXiv:2106.06381v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.06381","description":"<p>The cross-lingual language models are typically pretrained with masked\nlanguage modeling on multilingual text or parallel sentences. In this paper, we\nintroduce denoising word alignment as a new cross-lingual pre-training task.\nSpecifically, the model first self-labels word alignments for parallel\nsentences. Then we randomly mask tokens in a bitext pair. Given a masked token,\nthe model uses a pointer network to predict the aligned token in the other\nlanguage. We alternately perform the above two steps in an\nexpectation-maximization manner. Experimental results show that our method\nimproves cross-lingual transferability on various datasets, especially on the\ntoken-level tasks, such as question answering, and structured prediction.\nMoreover, the model can serve as a pretrained word aligner, which achieves\nreasonably low error rates on the alignment benchmarks. The code and pretrained\nparameters are available at https://github.com/CZWin32768/XLM-Align.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Bo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WeChat Neural Machine Translation Systems for WMT21. (arXiv:2108.02401v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.02401","description":"<p>This paper introduces WeChat AI's participation in WMT 2021 shared news\ntranslation task on English-&gt;Chinese, English-&gt;Japanese, Japanese-&gt;English and\nEnglish-&gt;German. Our systems are based on the Transformer (Vaswani et al.,\n2017) with several novel and effective variants. In our experiments, we employ\ndata filtering, large-scale synthetic data generation (i.e., back-translation,\nknowledge distillation, forward-translation, iterative in-domain knowledge\ntransfer), advanced finetuning approaches, and boosted Self-BLEU based model\nensemble. Our constrained systems achieve 36.9, 46.9, 27.8 and 31.3\ncase-sensitive BLEU scores on English-&gt;Chinese, English-&gt;Japanese,\nJapanese-&gt;English and English-&gt;German, respectively. The BLEU scores of\nEnglish-&gt;Chinese, English-&gt;Japanese and Japanese-&gt;English are the highest among\nall submissions, and that of English-&gt;German is the highest among all\nconstrained submissions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xianfeng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1\">Ernan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ran_Q/0/1/0/all/0/1\">Qiu Ran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Element Identification in Complaint Text of Internet Fraud. (arXiv:2108.08676v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08676","description":"<p>Existing system dealing with online complaint provides a final decision\nwithout explanations. We propose to analyse the complaint text of internet\nfraud in a fine-grained manner. Considering the complaint text includes\nmultiple clauses with various functions, we propose to identify the role of\neach clause and classify them into different types of fraud element. We\nconstruct a large labeled dataset originated from a real finance service\nplatform. We build an element identification model on top of BERT and propose\nadditional two modules to utilize the context of complaint text for better\nelement label classification, namely, global context encoder and label refiner.\nExperimental results show the effectiveness of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jingchao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Heng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liaosa Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_W/0/1/0/all/0/1\">Weiqiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Just Say No: Analyzing the Stance of Neural Dialogue Generation in Offensive Contexts. (arXiv:2108.11830v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11830","description":"<p>Dialogue models trained on human conversations inadvertently learn to\ngenerate toxic responses. In addition to producing explicitly offensive\nutterances, these models can also implicitly insult a group or individual by\naligning themselves with an offensive statement. To better understand the\ndynamics of contextually offensive language, we investigate the stance of\ndialogue model responses in offensive Reddit conversations. Specifically, we\ncreate ToxiChat, a crowd-annotated dataset of 2,000 Reddit threads and model\nresponses labeled with offensive language and stance. Our analysis reveals that\n42% of human responses agree with toxic comments, whereas only 13% agree with\nsafe comments. This undesirable behavior is learned by neural dialogue models,\nsuch as DialoGPT, which we show are two times more likely to agree with\noffensive comments. To enable automatic detection of offensive language, we\nfine-tuned transformer-based classifiers on ToxiChat that achieve 0.71 F1 for\noffensive labels and 0.53 Macro-F1 for stance labels. Finally, we quantify the\neffectiveness of controllable text generation (CTG) methods to mitigate the\ntendency of neural dialogue models to agree with offensive comments. Compared\nto the baseline, our best CTG model achieves a 19% reduction in agreement with\noffensive comments and produces 29% fewer offensive replies. Our work\nhighlights the need for further efforts to characterize and analyze\ninappropriate behavior in dialogue models, in order to help make them safer.\nOur code and corpus are available at https://github.com/abaheti95/ToxiChat .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baheti_A/0/1/0/all/0/1\">Ashutosh Baheti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1\">Mark Riedl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. (arXiv:2108.12084v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12084","description":"<p>Gender is widely discussed in the context of language tasks and when\nexamining the stereotypes propagated by language models. However, current\ndiscussions primarily treat gender as binary, which can perpetuate harms such\nas the cyclical erasure of non-binary gender identities. These harms are driven\nby model and dataset biases, which are consequences of the non-recognition and\nlack of understanding of non-binary genders in society. In this paper, we\nexplain the complexity of gender and language around it, and survey non-binary\npersons to understand harms associated with the treatment of gender as binary\nin English language technologies. We also detail how current language\nrepresentations (e.g., GloVe, BERT) capture and perpetuate these harms and\nrelated challenges that need to be acknowledged and addressed for\nrepresentations to equitably encode gender information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1\">Sunipa Dev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monajatipoor_M/0/1/0/all/0/1\">Masoud Monajatipoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1\">Anaelia Ovalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramonian_A/0/1/0/all/0/1\">Arjun Subramonian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1\">Jeff M Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v8 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12202","description":"<p>In joint entity and relation extraction, existing work either sequentially\nencode task-specific features, leading to an imbalance in inter-task feature\ninteraction where features extracted later have no direct contact with those\nthat come first. Or they encode entity features and relation features in a\nparallel manner, meaning that feature representation learning for each task is\nlargely independent of each other except for input sharing. We propose a\npartition filter network to model two-way interaction between tasks properly,\nwhere feature encoding is decomposed into two steps: partition and filter. In\nour encoder, we leverage two gates: entity and relation gate, to segment\nneurons into two task partitions and one shared partition. The shared partition\nrepresents inter-task information valuable to both tasks and is evenly shared\nacross two tasks to ensure proper two-way interaction. The task partitions\nrepresent intra-task information and are formed through concerted efforts of\nboth gates, making sure that encoding of task-specific features is dependent\nupon each other. Experiment results on six public datasets show that our model\nperforms significantly better than previous approaches. In addition, contrary\nto what previous work has claimed, our auxiliary experiments suggest that\nrelation prediction is contributory to named entity prediction in a\nnon-negligible way. The source code can be found at\nhttps://github.com/Coopercoppers/PFN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentence Bottleneck Autoencoders from Transformer Language Models. (arXiv:2109.00055v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00055","description":"<p>Representation learning for text via pretraining a language model on a large\ncorpus has become a standard starting point for building NLP systems. This\napproach stands in contrast to autoencoders, also trained on raw text, but with\nthe objective of learning to encode each input as a vector that allows full\nreconstruction. Autoencoders are attractive because of their latent space\nstructure and generative properties. We therefore explore the construction of a\nsentence-level autoencoder from a pretrained, frozen transformer language\nmodel. We adapt the masked language modeling objective as a generative,\ndenoising one, while only training a sentence bottleneck and a single-layer\nmodified transformer decoder. We demonstrate that the sentence representations\ndiscovered by our model achieve better quality than previous methods that\nextract representations from pretrained transformers on text similarity tasks,\nstyle transfer (an example of controlled generation), and single-sentence\nclassification tasks in the GLUE benchmark, while using fewer parameters than\nlarge pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Montero_I/0/1/0/all/0/1\">Ivan Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_N/0/1/0/all/0/1\">Nikolaos Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Improving Adversarial Training of NLP Models. (arXiv:2109.00544v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00544","description":"<p>Adversarial training, a method for learning robust deep neural networks,\nconstructs adversarial examples during training. However, recent methods for\ngenerating NLP adversarial examples involve combinatorial search and expensive\nsentence encoders for constraining the generated instances. As a result, it\nremains challenging to use vanilla adversarial training to improve NLP models'\nperformance, and the benefits are mainly uninvestigated. This paper proposes a\nsimple and improved vanilla adversarial training process for NLP models, which\nwe name Attacking to Training (A2T). The core part of A2T is a new and cheaper\nword substitution attack optimized for vanilla adversarial training. We use A2T\nto train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI\ndatasets. Our results empirically show that it is possible to train robust NLP\nmodels using a much cheaper adversary. We demonstrate that vanilla adversarial\ntraining with A2T can improve an NLP model's robustness to the attack it was\noriginally trained with and also defend the model against other types of word\nsubstitution attacks. Furthermore, we show that A2T can improve NLP models'\nstandard accuracy, cross-domain generalization, and interpretability. Code is\navailable at https://github.com/QData/Textattack-A2T .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jin Yong Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yanjun Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models. (arXiv:2109.01951v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.01951","description":"<p>The task of learning from only a few examples (called a few-shot setting) is\nof key importance and relevance to a real-world setting. For question answering\n(QA), the current state-of-the-art pre-trained models typically need\nfine-tuning on tens of thousands of examples to obtain good results. Their\nperformance degrades significantly in a few-shot setting (&lt; 100 examples). To\naddress this, we propose a simple fine-tuning framework that leverages\npre-trained text-to-text models and is directly aligned with their pre-training\nframework. Specifically, we construct the input as a concatenation of the\nquestion, a mask token representing the answer span and a context. Given this\ninput, the model is fine-tuned using the same objective as that of its\npre-training objective. Through experimental studies on various few-shot\nconfigurations, we show that this formulation leads to significant gains on\nmultiple QA benchmarks (an absolute gain of 34.2 F1 points on average when\nthere are only 16 training examples). The gains extend further when used with\nlarger models (Eg:- 72.3 F1 on SQuAD using BART-large with only 32 examples)\nand translate well to a multilingual setting . On the multilingual TydiQA\nbenchmark, our model outperforms the XLM-Roberta-large by an absolute margin of\nupto 40 F1 points and an average of 33 F1 points in a few-shot setting (&lt;= 64\ntraining examples). We conduct detailed ablation studies to analyze factors\ncontributing to these gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chada_R/0/1/0/all/0/1\">Rakesh Chada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Pradeep Natarajan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Autoregressive Language Models Complex Tasks By Demonstration. (arXiv:2109.02102v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.02102","description":"<p>This paper demonstrates that by fine-tuning an autoregressive language model\n(GPT-Neo) on appropriately structured step-by-step demonstrations, it is\npossible to teach it to execute a mathematical task that has previously proved\ndifficult for Transformers - longhand modulo operations - with a relatively\nsmall number of examples. Specifically, we fine-tune GPT-Neo to solve the\nnumbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et\nal. (<a href=\"/abs/1904.01557\">arXiv:1904.01557</a>) reported below 40% accuracy on this task with 2 million\ntraining examples. We show that after fine-tuning on 200 appropriately\nstructured demonstrations of solving long division problems and reporting the\nremainders, the smallest available GPT-Neo model achieves over 80% accuracy.\nThis is achieved by constructing an appropriate dataset for fine-tuning, with\nno changes to the learning algorithm. These results suggest that fine-tuning\nautoregressive language models on small sets of well-crafted demonstrations may\nbe a useful paradigm for enabling individuals without training in machine\nlearning to coax such models to perform some kinds of complex multi-step tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Recchia_G/0/1/0/all/0/1\">Gabriel Recchia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source Pretraining. (arXiv:2109.04080v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04080","description":"<p>With the rapid increase in the volume of dialogue data from daily life, there\nis a growing demand for dialogue summarization. Unfortunately, training a large\nsummarization model is generally infeasible due to the inadequacy of dialogue\ndata with annotated summaries. Most existing works for low-resource dialogue\nsummarization directly pretrain models in other domains, e.g., the news domain,\nbut they generally neglect the huge difference between dialogues and\nconventional articles. To bridge the gap between out-of-domain pretraining and\nin-domain fine-tuning, in this work, we propose a multi-source pretraining\nparadigm to better leverage the external summary data. Specifically, we exploit\nlarge-scale in-domain non-summary data to separately pretrain the dialogue\nencoder and the summary decoder. The combined encoder-decoder model is then\npretrained on the out-of-domain summary data using adversarial critics, aiming\nto facilitate domain-agnostic summarization. The experimental results on two\npublic datasets show that with only limited training data, our approach\nachieves competitive performance and generalizes well in different dialogue\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yicheng Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bolin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xingwu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lexico-semantic and affective modelling of Spanish poetry: A semi-supervised learning approach. (arXiv:2109.04152v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2109.04152","description":"<p>Text classification tasks have improved substantially during the last years\nby the usage of transformers. However, the majority of researches focus on\nprose texts, with poetry receiving less attention, specially for Spanish\nlanguage. In this paper, we propose a semi-supervised learning approach for\ninferring 21 psychological categories evoked by a corpus of 4572 sonnets, along\nwith 10 affective and lexico-semantic multiclass ones. The subset of poems used\nfor training an evaluation includes 270 sonnets. With our approach, we achieve\nan AUC beyond 0.7 for 76% of the psychological categories, and an AUC over 0.65\nfor 60% on the multiclass ones. The sonnets are modelled using transformers,\nthrough sentence embeddings, along with lexico-semantic and affective features,\nobtained by using external lexicons. Consequently, we see that this approach\nprovides an AUC increase of up to 0.12, as opposed to using transformers alone.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barbado_A/0/1/0/all/0/1\">Alberto Barbado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_M/0/1/0/all/0/1\">Mar&#xed;a Dolores Gonz&#xe1;lez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carrera_D/0/1/0/all/0/1\">D&#xe9;bora Carrera</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning with Different Amounts of Annotation: From Zero to Many Labels. (arXiv:2109.04408v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.04408","description":"<p>Training NLP systems typically assumes access to annotated data that has a\nsingle human label per example. Given imperfect labeling from annotators and\ninherent ambiguity of language, we hypothesize that single label is not\nsufficient to learn the spectrum of language interpretation. We explore new\nannotation distribution schemes, assigning multiple labels per example for a\nsmall subset of training examples. Introducing such multi label examples at the\ncost of annotating fewer examples brings clear gains on natural language\ninference task and entity typing task, even when we simply first train with a\nsingle label data and then fine tune with multi label examples. Extending a\nMixUp data augmentation framework, we propose a learning algorithm that can\nlearn from training examples with different amount of annotation (with zero,\none, or multiple labels). This algorithm efficiently combines signals from\nuneven training data and brings additional gains in low annotation budget and\ncross domain settings. Together, our method achieves consistent gains in two\ntasks, suggesting distributing labels unevenly among training examples can be\nbeneficial for many NLP tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shujian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1\">Chengyue Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-13T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}