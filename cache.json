{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-07T01:49:01.662660085Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"【Rust日报】2021-09-06 加快 Rust 的编译","link":"https://rustcc.cn/article?id=28141388-ce4a-4421-95b4-e2059e3b2347","description":"<h1>加快 Rust 的编译</h1>\n<p>众所周知，Rust代码编译起来很慢。但我有一种强烈的直觉，大多数Rust代码的编译速度比它本可以的要慢得多。</p>\n<p>例如, Rust 的 <code>rust-analyzer</code> CI 在 GitHub 上操作需要8分钟。这是一个相当大和复杂的项目，有20万行自己的代码和100万行依赖。</p>\n<p>跟随作者, 让我们进一步了解如何使编译时间保持在合理的范围内!</p>\n<p><a href=\"https://matklad.github.io/2021/09/04/fast-rust-builds.html\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>async 的另外一个语法方案</h1>\n<p>作者对于 <code>async</code>的语法方案提出了完整的自己的解决方案, 非常有趣.</p>\n<p><a href=\"https://ibraheem.ca/writings/an-alternative-async-fn-syntax/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>Rust 插件</h1>\n<p>这是作者的第二篇关于 Rust插件的文章!\n在这里，作者将尝试编写一些 PDK (Plugin Development Kit, 插件开发工具包) 可能是什么样子的简单代码，并对在编写过程中出现的问题做一些研究。</p>\n<p><a href=\"https://nullderef.com/blog/plugin-start/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>sentinel-rust: Rust 版本的 sentinel</h1>\n<p><code>Sentinel</code> 是一个面向分布式服务架构的高可用流量控制组件. 现在 Rust 版本已加入</p>\n<p><a href=\"https://github.com/sentinel-group/sentinel-rust\" rel=\"noopener noreferrer\">github 地址</a></p>\n<h1><code>&lt;&lt;Programming Rust&gt;&gt;</code> 第二版电子书已上架</h1>\n<p><code>&lt;&lt;Programming Rust&gt;&gt;</code> 第二版的在线电子书现已上架.</p>\n<p><a href=\"https://www.lunaticai.com/2021/09/programming-rust-2nd-edition-pdf-github.html\" rel=\"noopener noreferrer\">原文链接</a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 12:00:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust ffi 调用C++函数,C++函数返回 之指向智能对象的指针","link":"https://rustcc.cn/article?id=6060f204-1000-4bc2-a492-1e452c7ae9ef","description":"<p>\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcompiler_builtins-0f3806ca1d72c7be.rlib\" \"kernel32.lib\" \"ws2_32.lib\" \"advapi32.lib\" \"userenv.lib\" \"kernel32.lib\" \"msvcrt.lib\" \"/NXCOMPAT\" \"/LIBPATH:C:\\Users\\xiake\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\" \"/OUT:D:\\other\\github\\rust_nav\\testffi\\target\\debug\\deps\\testffi.exe\" \"/OPT:REF,NOICF\" \"/DEBUG\" \"/NATVIS:C:\\Users\\xiake\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\intrinsic.natvis\" \"/NATVIS:C:\\Users\\xiake\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\liballoc.natvis\" \"/NATVIS:C:\\Users\\xiake\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\libcore.natvis\" \"/NATVIS:C:\\Users\\xiake\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\libstd.natvis\"\n= note: navapp.lib(pch.obj) : MSIL .netmodule or module compiled with /GL found; restarting link with /LTCG; add /LTCG to the link command line to improve linker performance\nCreating library D:\\other\\github\\rust_nav\\testffi\\target\\debug\\deps\\testffi.lib and object D:\\other\\github\\rust_nav\\testffi\\target\\debug\\deps\\testffi.exp\nnavapp.lib(navapp.obj) : error LNK2001: unresolved external symbol \"public: class KBEngine::SmartPointer __cdecl KBEngine::Navigation::findNavigation(class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;)\" (?findNavigation@Navigation@KBEngine@@QEAA?AV?$SmartPointer@VNavigationHandle@KBEngine@@@2@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)\nnavapp.lib(navapp.obj) : error LNK2001: unresolved external symbol \"public: class KBEngine::SmartPointer <em><em>cdecl KBEngine::Navigation::loadNavigation(class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;,class std::map&lt;int,class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;,struct std::less,class std::allocator&lt;struct std::pair&lt;int const ,class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt; &gt; &gt; &gt; const &amp;)\" (?loadNavigation@Navigation@KBEngine@@QEAA?AV?$SmartPointer@VNavigationHandle@KBEngine@@@2@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV?$map@HV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@H@2@V?$allocator@U?$pair@$$CBHV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@5@@Z)\nnavapp.lib(navapp.obj) : error LNK2001: unresolved external symbol \"protected: static class KBEngine::Navigation * KBEngine::Singleton::singleton</em>\" (?singleton</em>@?$Singleton@VNavigation@KBEngine@@@KBEngine@@1PEAVNavigation@2@EA)\nD:\\other\\github\\rust_nav\\testffi\\target\\debug\\deps\\testffi.exe : fatal error LNK1120: 3 unresolved externals</p>\n<p>C++部分</p>\n<p>DLLEXPORT KBEngine::NavigationHandlePtr* get_nav_handle(char* resPath_);</p>\n<p>typedef SmartPointer NavigationHandlePtr;</p>\n<p>template \nclass SmartPointer : public ConstSmartPointer\n{\npublic:\ntypedef ConstSmartPointer ConstProxy;</p>\n<pre><code>SmartPointer(T* obj = 0, typename ConstProxy::REF_TAG tag = ConstProxy::NEW_REF):\nConstProxy(obj, tag)\n{\n}\n\nSmartPointer( const SmartPointer&lt;T&gt;&amp; P ) : ConstProxy( P ) { }\n\ntemplate&lt;class DerivedType&gt;\nSmartPointer( ConstSmartPointer&lt;DerivedType&gt;&amp; dt ) :\n\tConstProxy( dt.get() )\n{\n}\n</code></pre>\n<p>代码太长省略</p>\n<p>求大佬给点提示  实在找不到原因</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 07:05:51","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"有没有方法将一个usize的值转成i32的-1","link":"https://rustcc.cn/article?id=7f247165-5483-4b7e-b39b-7f2db042e5df","description":"<p>今天写leetcode的每日一题的时候突发奇想</p>\n<pre><code>impl Solution {\n    pub fn search(nums: Vec&lt;i32&gt;, target: i32) -&gt; i32 {\n        nums.binary_search(&amp;target).unwrap_or_default() as i32\n    }\n}\n</code></pre>\n<p>像这里能不能用一个unwrap_or(x) 然后转成失败返回-1</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 03:45:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"又见Rust区块链招聘 -_-!, but 这个点进来不后悔^_^","link":"https://rustcc.cn/article?id=640daecb-eec5-4b6d-87a1-02b640bb0433","description":"<p>大家好，我们是Deeper Network, 官网是deeper.network, 一个总部位于硅谷的区块链初创企业,我们跟绝大部分区块链公司不同的是，我们有顶级的产品来支撑我们的业务和发展愿景。重要的事情说三遍，有产品，有产品，有产品，而且是业界领先的产品！</p>\n<p>我们的旗舰产品Deeper Connect已经迭代到最新的第四代产品，其中Deeper Connect mini在Indiegogo平台首发，仅预售成绩就超过270万美元，在Indiegogo历史上的一百多万个项目中排名前10。(前十中的绝大部分项目都是Sony, 华为这样级别的公司)</p>\n<p>我们即将发售的最新产品pico的介绍，可以在下面找到：</p>\n<p>http://dev.deepernetwork.com:8088/down/tmp/pico.png</p>\n<p>世界上最小，最轻，最薄，功能最强大的网络安全+区块链产品：Deeper Connect Pico</p>\n<p>目前我们在全球150多个国家拥有20，000+的用户，30，000+节点。</p>\n<p>我们于2020年入选了波卡的builders program并且获得了Web 3.0基金会赞助，是波卡生态重要的一员。</p>\n<p>2021年，我们的区块链网络Deeper Chain获得波卡第一届黑客松比赛的社区最受欢迎奖和决赛亚军。</p>\n<p>Deeper Connect + Deeper Chain是目前世界上唯一的全栈WEB3.0解决方案,包括：web3.0网关，去中心化安全网络，去中心化广告，去中心化视频点播平台，去中心化CDN等等。</p>\n<p>目前公司已经盈利，现金贮备丰厚，正在对接业界最等级的风险投资机构，处于起飞的前夕。</p>\n<p>我们希望您具有以下技能：</p>\n<p>基本要求：</p>\n<p>1、扎实的计算机科学基础知识</p>\n<p>2、动手能力强，有死磕精神</p>\n<p>3、有丰富的 Rust 开发经验</p>\n<p>4、曾经独立完成或者主导完成过具有挑战性的项目</p>\n<p>5、对工作有高度的责任心</p>\n<p>加分项：</p>\n<p>1、区块链相关数据结构与算法</p>\n<p>2、Substrate或其他区块链节点开发经验</p>\n<p>3、跨链、Layer 2 开发经验</p>\n<p>待遇：</p>\n<p>丰厚的薪资待遇：40K~80K/月</p>\n<p>灵活的工作方式：您可以在任何时间，任何地点，只要有网络就行</p>\n<p>表现合格者提供股票/币权的丰厚激励</p>\n<p>表现优异者提供美国/加拿大移民机会（目前闹瘟疫，说实话也没啥好移的）</p>\n<p>有意向的选手，请发个人简历到:jobs@deeper.network, 我们在这里等你！</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 01:21:34","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-05","link":"https://rustcc.cn/article?id=f480ea38-5b5e-423e-9c78-e78bd1344c6e","description":"<h3>rust-tui-template：使用 tui-rs 和 crossterm 引导 Rust TUI 应用程序的模板</h3>\n<p>项目结构如下：</p>\n<pre><code>src/\n├── app.rs     -&gt; holds the states and renders the widgets\n├── event.rs   -&gt; handles the terminal events (key press, mouse click, resize, etc.)\n├── handler.rs -&gt; handles the key press events and updates the application\n├── lib.rs     -&gt; module definitions\n├── main.rs    -&gt; entry-point\n└── tui.rs     -&gt; initializes/exits the terminal interface\n</code></pre>\n<p>按 README 下载执行后效果如下：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/rust-daily-20210905-1.jpg\" alt=\"\"></p>\n<p>GitHub：<a href=\"https://github.com/orhun/rust-tui-template\" rel=\"noopener noreferrer\">orhun/rust-tui-template: A template for bootstrapping a Rust TUI application with tui-rs &amp; crossterm</a></p>\n<h3>perseus：完全支持 SSR 和 SSG 的 Rust 高端前端开发框架</h3>\n<p>Perseus 是一个使用 Rust 构建的极快的前端 Web 开发框架，它支持主要的渲染策略、在没有虚拟 DOM 的情况下具有反应性，并且具有极高的可定制性。它封装了 Sycamore 的底层功能，提供了一个类似 NextJS 的 API！</p>\n<p>✨ 支持静态生成（只提供静态资源）\n✨ 支持服务端渲染（服务动态资源）\n✨ 支持一段时间后重新验证和 / 或使用自定义逻辑（更新已渲染页面）\n✨ 支持增量重建（按需构建）\n✨开放构建矩阵（主要使用任何渲染策略和其他任何东西）\n✨ CLI 工具，让您轻松自信地构建应用程序</p>\n<p>项目的主要目标是：支持每一个主要的渲染策略，并为开发人员提供使用 Rust 高效创建超快速应用程序的能力和炫酷的的开发体验！</p>\n<p>文档：<a href=\"https://arctic-hen7.github.io/perseus/\" rel=\"noopener noreferrer\">Introduction - Perseus Book</a></p>\n<p>GitHub：<a href=\"https://github.com/arctic-hen7/perseus\" rel=\"noopener noreferrer\">arctic-hen7/perseus: A high-level frontend development framework for Rust with full support for SSR and SSG.</a></p>\n<h3>Rust 构建 LC-3 虚拟机</h3>\n<p>Little Computer 3，或 LC-3，是一种计算机教育编程语言，一种汇编语言。它具有相对简单的指令集，但可用于编写中等复杂的汇编程序，是 C 编译器的可行目标。  该语言不如 x86 汇编语言复杂，但具有许多类似于更复杂语言的功能。  这些功能使其对入门教学非常有用，因此它最常用于向计算机科学和计算机工程专业的学生教授编程和计算机体系结构的基础知识。</p>\n<p>教程地址：<a href=\"https://www.rodrigoaraujo.me/posts/lets-build-an-lc-3-virtual-machine/\" rel=\"noopener noreferrer\">Let's build an LC-3 Virtual Machine :: Rodrigo Araujo — Computer Scientist and Software Engineer</a></p>\n<p>另外附上 2 个之前的一个教程：</p>\n<ul>\n<li><a href=\"https://github.com/KuldeepSinh/lc3_vm\" rel=\"noopener noreferrer\">KuldeepSinh/lc3_vm: LC-3 (Little Computer 3) VM implemented in Rust</a></li>\n<li><a href=\"https://github.com/justinmeiners/lc3-vm\" rel=\"noopener noreferrer\">justinmeiners/lc3-vm: Write your own virtual machine for the LC-3 computer!</a></li>\n</ul>\n<h3>RustGameJam 中使用的游戏引擎分布</h3>\n<p>GameJam 是一个游戏开发者的 hackathon，<a href=\"https://itch.io/jam/rusty-jam\" rel=\"noopener noreferrer\">第一届 Rust Game Jam</a> 是于2021年8月22号到8月29号举办，游戏开发者们使用的游戏引擎最多的是 Bevy，其次是 macroquad，当然还有其他引擎，比如：pixels、 RG3D、minifb。想看GameJam的游戏作品，请点击下面链接。</p>\n<ul>\n<li>https://itch.io/jam/rusty-jam</li>\n</ul>\n<h3>memuse 一个分析动态内存使用的库</h3>\n<pre><code>use memuse::DynamicUsage;\n\nassert_eq!(7u64.dynamic_usage(), 0);\nassert_eq(\"I'm simple!\".dynamic_usage(), 0);\nassert_eq(vec![7u64; 2].dynamic_usage(), 16);\n\nlet empty: Vec&lt;u32&gt; = Vec::with_capacity(100);\nassert_eq!(empty.len(), 0);\nassert_eq!(empty.dynamic_usage, 400);\n</code></pre>\n<ul>\n<li>Repo <a href=\"https://crates.io/crates/memuse\" rel=\"noopener noreferrer\">crates.io/crates/memuse</a></li>\n</ul>\n<hr>\n<p>From 日报小组   太子长琴，李冬杰</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rust.cc/\" rel=\"noopener noreferrer\">Rustcc 论坛: 支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f620\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 00:38:06","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust  ffi  link 错误","link":"https://rustcc.cn/article?id=6497a814-b6d9-4b32-9d9d-35cc2fe53845","description":"<p>Clionerror: linking with <code>link.exe</code> failed: exit code: 1112\n|\n= note: \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\n\\Tools\\MSVC\\14.25.28610\\bin\\HostX64\\x64\\link.exe\" \"/NOLOGO\" \"/NXCOMPAT\" \"\n/LIBPATH:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows\n-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\" \"D:\\rust\\test\\test11\\targe\nt\\debug\\deps\\test11.1inhodm0mguvy78p.rcgu.o\" \"D:\\rust\\test\\test11\\target<br>\n\\debug\\deps\\test11.1itxz1f879gxqo0r.rcgu.o\" \"D:\\rust\\test\\test11\\target\\d\nebug\\deps\\test11.1nfdhbezxkijr69v.rcgu.o\" \"D:\\rust\\test\\test11\\target\\deb\nug\\deps\\test11.1okn7si93kck3d1v.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\n\\deps\\test11.1r7eavti91oymq20.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\\ndeps\\test11.24nm5lpcn3t54lyd.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\de\nps\\test11.2hyws9epzawmgilt.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\n\\test11.2old9hh0jdnzckpx.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\\ntest11.3bc649uegqq66vdn.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\te\nst11.3nyjusu4bu7ihnwt.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test\n11.44jxfqx2w1so8gxa.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11\n.47a9u7imyimutge1.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4\n9azsbqjuetnb404.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4bk\nfakiuuxmwqfyp.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4mu1b\nnojyqp0utjl.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4rszv42\nzy3ba1jb2.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4t77rmx77\ntcvwir6.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4tr7ij9mclu\nclpsg.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4xi12smsmm3qs\nmbh.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.4yye09rafbxycx8\n1.rcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.56g0yr2v0k1zblp9.\nrcgu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.yv2gzy9b0ix4k8o.rcg\nu.o\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\test11.zu1yaj42bq3ogyk.rcgu.o\n\" \"/OUT:D:\\rust\\test\\test11\\target\\debug\\deps\\test11.exe\" \"D:\\rust\\test\n\\test11\\target\\debug\\deps\\test11.sic3ibelt8jd29e.rcgu.o\" \"/OPT:REF,NOICF\" \"\n/DEBUG\" \"/NATVIS:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc\n-windows-msvc\\lib\\rustlib\\etc\\intrinsic.natvis\" \"/NATVIS:C:\\Users\\Administ\nrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\etc\\li\nballoc.natvis\" \"/NATVIS:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x8\n6_64-pc-windows-msvc\\lib\\rustlib\\etc\\libcore.natvis\" \"/NATVIS:C:\\Users\\Adm\ninistrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\\lib\\rustlib\\et\nc\\libstd.natvis\" \"/LIBPATH:D:\\rust\\test\\test11\\target\\debug\\deps\" \"/LIBPA\nTH:C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc<br>\n\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\" \"./libs/nav-apps.lib\" \"/WHOLEARCHIVE\n:./libs/nav-apps.lib\" \"D:\\rust\\test\\test11\\target\\debug\\deps\\liblibc-bc05\nadbb061c4c16.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64\n-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libstd-1feb4ba9912f\n83e4.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-wind\nows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libpanic_unwind-10caf631bf1\n7818d.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-win\ndows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_demangle-5f5b841e\n7dcb5069.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-\nwindows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libhashbrown-886e420424\n40a542.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-wi\nndows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_std_workspace_al\nloc-fc3dfd2deda68757.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stabl\ne-x86_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libunwind-4\n765baa3d9fc6a1b.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86\n_64-pc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcfg_if-2af04b\n7075550e2b.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-p\nc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\liblibc-9f4eae3434a19\nb51.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windo\nws-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\liballoc-14b08c3097e998dc.rl\nib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windows-msv\nc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\librustc_std_workspace_core-9c0450\nbb353ef0cc.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-p\nc-windows-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcore-4856f32e5e48b\nded.rlib\" \"C:\\Users\\Administrator\\.rustup\\toolchains\\stable-x86_64-pc-windo\nws-msvc\\lib\\rustlib\\x86_64-pc-windows-msvc\\lib\\libcompiler_builtins-0f66c8d\n6b2ebbbc4.rlib\" \"advapi32.lib\" \"ws2_32.lib\" \"userenv.lib\" \"msvcrt.lib\"\n= note: Non-UTF-8 output: nav-apps.lib(base64.obj) : \\xd5\\xd2\\xb5\\xbd MSIL .ne\ntmodule \\xbb\\xf2\\xca\\xb9\\xd3\\xc3 /GL \\xb1\\xe0\\xd2\\xeb\\xb5\\xc4\\xc4\\xa3\\xbf\\xe9\\xa\n3\\xbb\\xd5\\xfd\\xd4\\xda\\xca\\xb9\\xd3\\xc3 /LTCG \\xd6\\xd8\\xd0\\xc2\\xc6\\xf4\\xb6\\xaf\\xc1\n\\xb4\\xbd\\xd3\\xa3\\xbb\\xbd\\xab /LTCG \\xcc\\xed\\xbc\\xd3\\xb5\\xbd\\xc1\\xb4\\xbd\\xd3\\xc3<br>\nxfc\\xc1\\xee\\xd0\\xd0\\xd2\\xd4\\xb8\\xc4\\xbd\\xf8\\xc1\\xb4\\xbd\\xd3\\xc6\\xf7\\xd0\\xd4\\xc4<br>\nxdc\\r\\ntest11.4mu1bnojyqp0utjl.rcgu.o : error LNK2005: main \\xd2\\xd1\\xbe\\xad\\xd4\n\\xda test11.4mu1bnojyqp0utjl.rcgu.o \\xd6\\xd0\\xb6\\xa8\\xd2\\xe5\\r\\nnav-apps.lib(lib\nmysql32.dll) : fatal error LNK1112: \\xc4\\xa3\\xbf\\xe9\\xbc\\xc6\\xcb\\xe3\\xbb\\xfa\\xc0\n\\xe0\\xd0\\xcd\\xa1\\xb0x86\\xa1\\xb1\\xd3\\xeb\\xc4\\xbf\\xb1\\xea\\xbc\\xc6\\xcb\\xe3\\xbb\\xfa<br>\nxc0\\xe0\\xd0\\xcd\\xa1\\xb0x64\\xa1\\xb1\\xb3\\xe5\\xcd\\xbb\\r\\n</p>\n<p>求大佬给点提示</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-05 12:46:38","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"分享一个命令行文本美化工具库，https://crates.io/crates/colorstyle","link":"https://rustcc.cn/article?id=73d264ed-5f2d-43db-b3ec-12965ccaa550","description":"<p>ColorStyle is a library of styles for command-line text.\nUsed to modify the style of text for standard output to the terminal interface, you can change the foreground colour of the text, the background colour, add underline and bold, etc.</p>\n<p>ColorStyle 是一个用于命令行文本的样式库。\n用于标准输出到终端界面的文本的样式修改，可以修改文本前景色，背景色，增加下划线和加粗显等。</p>\n<p>可以作为一个新手docs.rs 文档编写参考。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-05 09:23:57","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"[已解决]使用rocket框架时sqlite出现的问题","link":"https://rustcc.cn/article?id=089f8f06-780e-409a-952e-fa39c2e79dc6","description":"<p>其实应该是diesel的问题\n之前sqlite缺少lib我是通过这个博客解决了问题\n<a href=\"https://blog.itdevwu.com/post/915/\" rel=\"noopener noreferrer\">解决使用Rust与Sqlite3交互时出现LNK1181错误（Diesel 或 rusqlite）</a>\n但是后面的cargo run 阶段又出现了</p>\n<pre><code>sqlite3.lib : warning LNK4272:库计算机类型“x86”与目标计算机类型“x64”冲突\n          D:\\Project\\Private\\point_plan\\target\\debug\\deps\\point_plan.exe : fatal error LNK1120: 60 个无法解析的外部命令\n</code></pre>\n<p>我明明用的是64位指令编译64位sqlite3.def得到lib的，为啥还会出现这种问题？\n麻烦弄过的这方面的朋友指点下</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-04 15:04:50","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-04","link":"https://rustcc.cn/article?id=e3c58130-184d-482b-b081-168c54694384","description":"<h3>cURL 中的 Rust</h3>\n<p>Allen Wyma 与 cURL 的原作者 Daniel 谈论在 cURL 中使用 Rust。</p>\n<ul>\n<li>cURL 是一个命令行工具和库，用于通过 URL 传输数据。</li>\n<li>cURL 及其数据传输核心 libcurl 都是用 C 编写的，众所周知，这不是内存安全的。</li>\n<li>虽然几乎不可能将其重写为另一种语言，但提供一个用 Rust 编写的第三方库可能会更进一步。</li>\n</ul>\n<p><a href=\"https://rustacean-station.org/episode/035-daniel-stenberg/\" rel=\"noopener noreferrer\">文章链接</a>，https://rustacean-station.org/episode/035-daniel-stenberg/</p>\n<h3>NoProto：灵活、快速和紧凑的序列化和rpc</h3>\n<ul>\n<li>\n<p>轻量</p>\n<ul>\n<li>零依赖</li>\n<li>支持no_std，WASM</li>\n<li>最紧凑的非编译存储格式</li>\n</ul>\n</li>\n<li>\n<p>稳定...</p>\n</li>\n</ul>\n<p><a href=\"https://github.com/only-cliches/NoProto\" rel=\"noopener noreferrer\">Gitlab 链接</a>，https://github.com/only-cliches/NoProto</p>\n<h3>gradient介绍</h3>\n<p>用于玩颜色渐变的命令行工具</p>\n<p>Features:</p>\n<ul>\n<li>许多预设渐变。</li>\n<li>自定义渐变。</li>\n<li>从 SVG 和 GIMP 渐变 (ggr) 文件中读取渐变\n...</li>\n</ul>\n<p><a href=\"https://github.com/mazznoer/gradient-rs\" rel=\"noopener noreferrer\">Gitlab 链接</a>，https://github.com/mazznoer/gradient-rs</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=dd4a77ca-2042-459e-901a-b8f9bfeb7db0\" rel=\"noopener noreferrer\">TOM</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li>[微信公众号：Rust语言中文社区](https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d88</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-04 12:51:53","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"argh：基于  derive 宏且对二进制体积进行优化的命令行解析工具","link":"https://rustcc.cn/article?id=01a3db1f-b567-47d4-9c3b-08142a11cd3e","description":"<blockquote>\n<p>Derive-based argument parsing optimized for code size and conformance to the Fuchsia commandline tools specification.</p>\n<p>基于 derive 宏的参数解析工具，针对代码大小进行了优化，并且遵循 Fuchsia 命令行工具规范。</p>\n</blockquote>\n<p>repo：<a href=\"https://github.com/google/argh\" rel=\"noopener noreferrer\">https://github.com/google/argh</a></p>\n<p>由 Google 开发者编写，但并非 Google 官方支持。</p>\n<p>官方给的基本例子：</p>\n<pre><code>use argh::FromArgs;\n\n#[derive(FromArgs)]\n/// Reach new heights.\nstruct GoUp {\n    /// whether or not to jump\n    #[argh(switch, short = 'j')]\n    jump: bool,\n\n    /// how high to go\n    #[argh(option)]\n    height: usize,\n\n    /// an optional nickname for the pilot\n    #[argh(option)]\n    pilot_nickname: Option&lt;String&gt;,\n}\n\nfn main() {\n    let up: GoUp = argh::from_env();\n}\n</code></pre>\n<pre><code>Usage: cmdname [-j] --height &lt;height&gt; [--pilot-nickname &lt;pilot-nickname&gt;]\n\nReach new heights.\n\nOptions:\n  -j, --jump        whether or not to jump\n  --height          how high to go\n  --pilot-nickname  an optional nickname for the pilot\n  --help            display usage information\n</code></pre>\n<p>过程宏-参数类型：</p>\n<ul>\n<li><code>switch</code>：用在 bool 类型的字段上，表明命令行参数是可选的，而且一旦提供该命令行参数，则给该字段的值赋给 true 。</li>\n<li><code>option</code>：\n<ul>\n<li>用在 <code>Option</code> 类型上，表明命令行参数是可选的。</li>\n<li>用在 <code>Vec</code> 类型上，表明命令行参数可选，而且可以重复出现，即这个参数及其值可以在命令行中出现 0 次或更多次。</li>\n<li>用在非 <code>Option</code> 、非 <code>Vec</code> 类型上，则表示命令行参数必选。</li>\n</ul>\n</li>\n<li><code>positional</code>：位置参数，表明按照结构体声明的字段顺序解析命令行参数，无需 <code>--xx value</code> 的 <code>--xx</code> 。最后一个位置参数可以包含默认值，也可以包装在 Option 或 Vec 中来接收可选（指 0 或 1 个）或重复（指 0 或多个）的位置参数。</li>\n<li><code>subcommand</code>：需定义一个顶层结构体、一个表示子命令的枚举体（这个枚举体列举所有子命令，子命令以结构体形式呈现，子命令结构体还需要 name 设置名称）</li>\n</ul>\n<p>过程宏-其他设置：</p>\n<ul>\n<li><code>short = 'a'</code>：解析 <code>-a</code> 形式的简短参数，只支持 ascii 的 <code>Char</code> 类型，比如大小写、数字。</li>\n<li><code>long = \"xx-xx\"</code>：重新命名这个字段的参数名称，由此可允许参数名称带连字符 <code>--xx-xx</code>。这个设置的默认值为字段名称，只支持 ascii 小写形式的名称，不支持大写和数字。</li>\n<li><code>default = \"default_height()\")</code>、<code>default = \"String::from(\\\"only up\\\")\")</code>：默认值，引号内可以是函数名（带括号）、表达式</li>\n<li><code>from_str_fn(always_five)</code>：针对某个解析的参数进行自定义处理，<code>always_five</code> 的函数签名方式为 <code>fn(&amp;str) -&gt; Result&lt;T, String&gt;</code></li>\n<li><code>description = \"xxxxx\"</code>：给参数添加帮助信息。<code>///</code> 文档注释也可以提供用帮助信息，而 <code>description</code> 的内容在命令行帮助信息里会覆盖掉 <code>///</code> 提供的信息。注意：换行和空换行会在 --help 信息里变成一个空格；描述信息不能过长，否则会出现 <code>error: invalid reference to positional arguments 4 and 5 (there is 1 argument</code> （这个报错信息不准确，我也是排查了很久才发现）。</li>\n</ul>\n<p>trait：</p>\n<ul>\n<li><code>FromArgs</code> trait：用于 argh 命令行解析的所有结构体和枚举体，都必须 derive 这个 trait 。</li>\n<li><code>FromArgValue</code> trait：用于 argh 命令行解析的结构体字段的类型必须实现这个 trait ，argh 已经给所有实现 <code>FromStr</code> trait 的类型实现了这个 trait 。std 的基础类型都实现了 <code>FromStr</code> trait ，所以可以直接使用 std 的基础类型；自定义类型需要实现 <code>FromStr</code> trait 和 <code>FromArgValue</code> trait 。</li>\n</ul>\n<p>优点：</p>\n<ul>\n<li>使用简单而直观，上手快，适用于基础的命令行解析场景</li>\n<li>生成的体积比 clap 小</li>\n<li>依赖少，编译速度快</li>\n<li>支持 unicode</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>终端输出结果非彩色</li>\n<li>默认不支持很长的 help 信息；只支持 <code>--help</code>  不支持 <code>-h</code> （但是也带来优点——可以自定义一个字段，short as <code>-h</code>，从而有一份默认简洁的 help info，又有一份完全自定义的 info，比如 <code>#[argh(option, short = 'h')] description: Vec&lt;String&gt;</code> =&gt; <code>cmd -h arg1 arg2</code> 就可以显示 arg1 和 arg2 的说明）</li>\n<li>只支持 <code>--option value</code> 和 <code>-o value</code>，不支持 <code>--option=value</code> 和 <code>-ovalue</code></li>\n</ul>\n<p>其他 args-parser：</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/blyxxyz/lexopt\" rel=\"noopener noreferrer\">lexopt</a>：零依赖、注重正确性的极简 args-parser 。</li>\n<li><a href=\"https://github.com/clap-rs/clap\" rel=\"noopener noreferrer\"><code>clap</code></a>/<a href=\"https://github.com/TeXitoi/structopt\" rel=\"noopener noreferrer\"><code>structopt</code></a>: very fully-featured. The only other argument parser for Rust I know of that truly handles invalid unicode properly, if used right. Large.</li>\n<li><a href=\"https://github.com/google/argh\" rel=\"noopener noreferrer\"><code>argh</code></a> and <a href=\"https://github.com/murarth/gumdrop\" rel=\"noopener noreferrer\"><code>gumdrop</code></a>: much leaner, yet still convenient and powerful enough for most purposes. Panic on invalid unicode.\n<ul>\n<li><code>argh</code> adheres to the <a href=\"https://fuchsia.dev/fuchsia-src/concepts/api/cli#command_line_arguments\" rel=\"noopener noreferrer\">Fuchsia specification</a> and therefore does <em>not</em> support <code>--option=value</code> and <code>-ovalue</code>, only <code>--option value</code> and <code>-o value</code>.</li>\n</ul>\n</li>\n<li><a href=\"https://github.com/RazrFalcon/pico-args\" rel=\"noopener noreferrer\"><code>pico-args</code></a>: slightly smaller than lexopt and easier to use (but less rigorous).</li>\n<li><a href=\"https://docs.rs/ap\" rel=\"noopener noreferrer\"><code>ap</code></a>: I have not used this, but it seems to support iterative parsing while being less bare-bones than lexopt.</li>\n<li>libc's <a href=\"https://en.wikipedia.org/wiki/Getopt#Examples\" rel=\"noopener noreferrer\"><code>getopt</code></a>.</li>\n</ul>\n<p>src: <a href=\"https://github.com/blyxxyz/lexopt#see-also\" rel=\"noopener noreferrer\">https://github.com/blyxxyz/lexopt#see-also</a></p>\n</blockquote>\n<p>P.S. 不得不说，Rust 利用抽象的类型系统和宏，在 args-parser 方面太棒了。写 Rust 是一种享受。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-03 11:12:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust 学习随笔","link":"https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8","description":"<h1>切换镜像源</h1>\n<p>crm =&gt; https://github.com/wtklbm/crm</p>\n<p>常用命令就是 <code>crm best</code></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 14:35:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"pretree 补全文档发布了,再次谢谢大神的指点终于入门了。","link":"https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827","description":"<h1>Pretree</h1>\n<p>pretree is a package for storing and querying routing rules with prefix tree .</p>\n<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>\n<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>\n<p>Inspired by <a href=\"https://github.com/obity/pretree\" rel=\"noopener noreferrer\">obity/pretree</a> (golang)</p>\n<h1>Doc</h1>\n<p>See this document at <a href=\"https://docs.rs/pretree\" rel=\"noopener noreferrer\">API documentation</a></p>\n<h1>Install</h1>\n<p>Add the following line to your Cargo.toml file:</p>\n<pre><code>pretree = \"1.0.0\"\n</code></pre>\n<h1>Example</h1>\n<pre><code>use pretree::Pretree;\nlet mut p = Pretree::new();\np.store(\"GET\",\"account/{id}/info/:name\");\np.store(\"GET\",\"account/:id/login\");\np.store(\"GET\",\"account/{id}\");\np.store(\"GET\",\"bacteria/count_number_by_month\");\nlet (ok,rule,vars) = p.query(\"GET\",\"account/929239\");\nprintln!(\"ok:{} rule:{} vars:{:#?}\",ok,rule,vars);\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 09:37:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-07T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"ALLWAS: Active Learning on Language models in WASserstein space. (arXiv:2109.01691v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01691","description":"<p>Active learning has emerged as a standard paradigm in areas with scarcity of\nlabeled training data, such as in the medical domain. Language models have\nemerged as the prevalent choice of several natural language tasks due to the\nperformance boost offered by these models. However, in several domains, such as\nmedicine, the scarcity of labeled training data is a common issue. Also, these\nmodels may not work well in cases where class imbalance is prevalent. Active\nlearning may prove helpful in these cases to boost the performance with a\nlimited label budget. To this end, we propose a novel method using sampling\ntechniques based on submodular optimization and optimal transport for active\nlearning in language models, dubbed ALLWAS. We construct a sampling strategy\nbased on submodular optimization of the designed objective in the gradient\ndomain. Furthermore, to enable learning from few samples, we propose a novel\nstrategy for sampling from the Wasserstein barycenters. Our empirical\nevaluations on standard benchmark datasets for text classification show that\nour methods perform significantly better (&gt;20% relative increase in some cases)\nthan existing approaches for active learning on language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1\">Anson Bastos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaul_M/0/1/0/all/0/1\">Manohar Kaul</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Error Detection in Large-Scale Natural Language Understanding Systems Using Transformer Models. (arXiv:2109.01754v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01754","description":"<p>Large-scale conversational assistants like Alexa, Siri, Cortana and Google\nAssistant process every utterance using multiple models for domain, intent and\nnamed entity recognition. Given the decoupled nature of model development and\nlarge traffic volumes, it is extremely difficult to identify utterances\nprocessed erroneously by such systems. We address this challenge to detect\ndomain classification errors using offline Transformer models. We combine\nutterance encodings from a RoBERTa model with the Nbest hypothesis produced by\nthe production system. We then fine-tune end-to-end in a multitask setting\nusing a small dataset of humanannotated utterances with domain classification\nerrors. We tested our approach for detecting misclassifications from one domain\nthat accounts for &lt;0.5% of the traffic in a large-scale conversational AI\nsystem. Our approach achieves an F1 score of 30% outperforming a bi- LSTM\nbaseline by 16.9% and a standalone RoBERTa model by 4.8%. We improve this\nfurther by 2.2% to 32.2% by ensembling multiple models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chada_R/0/1/0/all/0/1\">Rakesh Chada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Pradeep Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fofadiya_D/0/1/0/all/0/1\">Darshan Fofadiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandra_P/0/1/0/all/0/1\">Prathap Ramachandra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation for Cross-Domain Named Entity Recognition. (arXiv:2109.01758v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01758","description":"<p>Current work in named entity recognition (NER) shows that data augmentation\ntechniques can produce more robust models. However, most existing techniques\nfocus on augmenting in-domain data in low-resource scenarios where annotated\ndata is quite limited. In contrast, we study cross-domain data augmentation for\nthe NER task. We investigate the possibility of leveraging data from\nhigh-resource domains by projecting it into the low-resource domains.\nSpecifically, we propose a novel neural architecture to transform the data\nrepresentation from a high-resource to a low-resource domain by learning the\npatterns (e.g. style, noise, abbreviations, etc.) in the text that\ndifferentiate them and a shared feature space where both domains are aligned.\nWe experiment with diverse datasets and show that transforming the data to the\nlow-resource domain representation achieves significant improvements over only\nusing data from high-resource domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuguang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aguilar_G/0/1/0/all/0/1\">Gustavo Aguilar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neves_L/0/1/0/all/0/1\">Leonardo Neves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solorio_T/0/1/0/all/0/1\">Thamar Solorio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representation Learning for Efficient and Effective Similarity Search and Recommendation. (arXiv:2109.01815v1 [cs.IR])","link":"http://arxiv.org/abs/2109.01815","description":"<p>How data is represented and operationalized is critical for building\ncomputational solutions that are both effective and efficient. A common\napproach is to represent data objects as binary vectors, denoted \\textit{hash\ncodes}, which require little storage and enable efficient similarity search\nthrough direct indexing into a hash table or through similarity computations in\nan appropriate space. Due to the limited expressibility of hash codes, compared\nto real-valued representations, a core open challenge is how to generate hash\ncodes that well capture semantic content or latent properties using a small\nnumber of bits, while ensuring that the hash codes are distributed in a way\nthat does not reduce their search efficiency. State of the art methods use\nrepresentation learning for generating such hash codes, focusing on neural\nautoencoder architectures where semantics are encoded into the hash codes by\nlearning to reconstruct the original inputs of the hash codes. This thesis\naddresses the above challenge and makes a number of contributions to\nrepresentation learning that (i) improve effectiveness of hash codes through\nmore expressive representations and a more effective similarity measure than\nthe current state of the art, namely the Hamming distance, and (ii) improve\nefficiency of hash codes by learning representations that are especially suited\nto the choice of search method. The contributions are empirically validated on\nseveral tasks related to similarity search and recommendation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hansen_C/0/1/0/all/0/1\">Casper Hansen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Frustratingly Simple Pretraining Alternatives to Masked Language Modeling. (arXiv:2109.01819v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01819","description":"<p>Masked language modeling (MLM), a self-supervised pretraining objective, is\nwidely used in natural language processing for learning text representations.\nMLM trains a model to predict a random sample of input tokens that have been\nreplaced by a [MASK] placeholder in a multi-class setting over the entire\nvocabulary. When pretraining, it is common to use alongside MLM other auxiliary\nobjectives on the token or sequence level to improve downstream performance\n(e.g. next sentence prediction). However, no previous work so far has attempted\nin examining whether other simpler linguistically intuitive or not objectives\ncan be used standalone as main pretraining objectives. In this paper, we\nexplore five simple pretraining objectives based on token-level classification\ntasks as replacements of MLM. Empirical results on GLUE and SQuAD show that our\nproposed methods achieve comparable or better performance to MLM using a\nBERT-BASE architecture. We further validate our methods using smaller models,\nshowing that pretraining a model with 41% of the BERT-BASE's parameters,\nBERT-MEDIUM results in only a 1% drop in GLUE scores with our best objective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamaguchi_A/0/1/0/all/0/1\">Atsuki Yamaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chrysostomou_G/0/1/0/all/0/1\">George Chrysostomou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Margatina_K/0/1/0/all/0/1\">Katerina Margatina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Expressive Communication with Internet Memes: A New Multimodal Conversation Dataset and Benchmark. (arXiv:2109.01839v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01839","description":"<p>As a kind of new expression elements, Internet memes are popular and\nextensively used in online chatting scenarios since they manage to make\ndialogues vivid, moving, and interesting. However, most current dialogue\nresearches focus on text-only dialogue tasks. In this paper, we propose a new\ntask named as \\textbf{M}eme incorporated \\textbf{O}pen-domain \\textbf{D}ialogue\n(MOD). Compared to previous dialogue tasks, MOD is much more challenging since\nit requires the model to understand the multimodal elements as well as the\nemotions behind them. To facilitate the MOD research, we construct a\nlarge-scale open-domain multimodal dialogue dataset incorporating abundant\nInternet memes into utterances. The dataset consists of $\\sim$45K Chinese\nconversations with $\\sim$606K utterances. Each conversation contains about $13$\nutterances with about $4$ Internet memes on average and each utterance equipped\nwith an Internet meme is annotated with the corresponding emotion. In addition,\nwe present a simple and effective method, which utilizes a unified generation\nnetwork to solve the MOD task. Experimental results demonstrate that our method\ntrained on the proposed corpus is able to achieve expressive communication\nincluding texts and memes. The corpus and models have been publicly available\nat https://github.com/lizekang/DSTC10-MOD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supervised Contrastive Learning for Multimodal Unreliable News Detection in COVID-19 Pandemic. (arXiv:2109.01850v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01850","description":"<p>As the digital news industry becomes the main channel of information\ndissemination, the adverse impact of fake news is explosively magnified. The\ncredibility of a news report should not be considered in isolation. Rather,\npreviously published news articles on the similar event could be used to assess\nthe credibility of a news report. Inspired by this, we propose a BERT-based\nmultimodal unreliable news detection framework, which captures both textual and\nvisual information from unreliable articles utilising the contrastive learning\nstrategy. The contrastive learner interacts with the unreliable news classifier\nto push similar credible news (or similar unreliable news) closer while moving\nnews articles with similar content but opposite credibility labels away from\neach other in the multimodal embedding space. Experimental results on a\nCOVID-19 related dataset, ReCOVery, show that our model outperforms a number of\ncompetitive baseline in unreliable news detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pushing Paraphrase Away from Original Sentence: A Multi-Round Paraphrase Generation Approach. (arXiv:2109.01862v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01862","description":"<p>In recent years, neural paraphrase generation based on Seq2Seq has achieved\nsuperior performance, however, the generated paraphrase still has the problem\nof lack of diversity. In this paper, we focus on improving the diversity\nbetween the generated paraphrase and the original sentence, i.e., making\ngenerated paraphrase different from the original sentence as much as possible.\nWe propose BTmPG (Back-Translation guided multi-round Paraphrase Generation),\nwhich leverages multi-round paraphrase generation to improve diversity and\nemploys back-translation to preserve semantic information. We evaluate BTmPG on\ntwo benchmark datasets. Both automatic and human evaluation show BTmPG can\nimprove the diversity of paraphrase while preserving the semantics of the\noriginal sentence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhe Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncovering the Limits of Text-based Emotion Detection. (arXiv:2109.01900v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01900","description":"<p>Identifying emotions from text is crucial for a variety of real world tasks.\nWe consider the two largest now-available corpora for emotion classification:\nGoEmotions, with 58k messages labelled by readers, and Vent, with 33M\nwriter-labelled messages. We design a benchmark and evaluate several feature\nspaces and learning algorithms, including two simple yet novel models on top of\nBERT that outperform previous strong baselines on GoEmotions. Through an\nexperiment with human participants, we also analyze the differences between how\nwriters express emotions and how readers perceive them. Our results suggest\nthat emotions expressed by writers are harder to identify than emotions that\nreaders perceive. We share a public web interface for researchers to explore\nour models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_Gonzalez_N/0/1/0/all/0/1\">Nurudin Alvarez-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaltenbrunner_A/0/1/0/all/0/1\">Andreas Kaltenbrunner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_V/0/1/0/all/0/1\">Vicen&#xe7; G&#xf3;mez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Neural Network-Based Linguistic Similarity Measure for Entrainment in Conversations. (arXiv:2109.01924v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01924","description":"<p>Linguistic entrainment is a phenomenon where people tend to mimic each other\nin conversation. The core instrument to quantify entrainment is a linguistic\nsimilarity measure between conversational partners. Most of the current\nsimilarity measures are based on bag-of-words approaches that rely on\nlinguistic markers, ignoring the overall language structure and dialogue\ncontext. To address this issue, we propose to use a neural network model to\nperform the similarity measure for entrainment. Our model is context-aware, and\nit further leverages a novel component to learn the shared high-level\nlinguistic features across dialogues. We first investigate the effectiveness of\nour novel component. Then we use the model to perform similarity measure in a\ncorpus-based entrainment analysis. We observe promising results for both\nevaluation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mingzhi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litman_D/0/1/0/all/0/1\">Diane Litman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weakly Supervised Relative Spatial Reasoning for Visual Question Answering. (arXiv:2109.01934v1 [cs.CV])","link":"http://arxiv.org/abs/2109.01934","description":"<p>Vision-and-language (V\\&amp;L) reasoning necessitates perception of visual\nconcepts such as objects and actions, understanding semantics and language\ngrounding, and reasoning about the interplay between the two modalities. One\ncrucial aspect of visual reasoning is spatial understanding, which involves\nunderstanding relative locations of objects, i.e.\\ implicitly learning the\ngeometry of the scene. In this work, we evaluate the faithfulness of V\\&amp;L\nmodels to such geometric understanding, by formulating the prediction of\npair-wise relative locations of objects as a classification as well as a\nregression task. Our findings suggest that state-of-the-art transformer-based\nV\\&amp;L models lack sufficient abilities to excel at this task. Motivated by this,\nwe design two objectives as proxies for 3D spatial reasoning (SR) -- object\ncentroid estimation, and relative position estimation, and train V\\&amp;L with weak\nsupervision from off-the-shelf depth estimators. This leads to considerable\nimprovements in accuracy for the \"GQA\" visual question answering challenge (in\nfully supervised, few-shot, and O.O.D settings) as well as improvements in\nrelative spatial reasoning. Code and data will be released\n\\href{https://github.com/pratyay-banerjee/weak_sup_vqa}{here}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1\">Pratyay Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Supervised Detection of Contextual Synonyms in a Multi-Class Setting: Phenotype Annotation Use Case. (arXiv:2109.01935v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01935","description":"<p>Contextualised word embeddings is a powerful tool to detect contextual\nsynonyms. However, most of the current state-of-the-art (SOTA) deep learning\nconcept extraction methods remain supervised and underexploit the potential of\nthe context. In this paper, we propose a self-supervised pre-training approach\nwhich is able to detect contextual synonyms of concepts being training on the\ndata created by shallow matching. We apply our methodology in the sparse\nmulti-class setting (over 15,000 concepts) to extract phenotype information\nfrom electronic health records. We further investigate data augmentation\ntechniques to address the problem of the class sparsity. Our approach achieves\na new SOTA for the unsupervised phenotype concept annotation on clinical text\non F1 and Recall outperforming the previous SOTA with a gain of up to 4.5 and\n4.0 absolute points, respectively. After fine-tuning with as little as 20\\% of\nthe labelled data, we also outperform BioBERT and ClinicalBERT. The extrinsic\nevaluation on three ICU benchmarks also shows the benefit of using the\nphenotypes annotated by our model as features.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolanos_L/0/1/0/all/0/1\">Luis Bolanos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanwar_A/0/1/0/all/0/1\">Ashwani Tanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freire_G/0/1/0/all/0/1\">Guilherme Freire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ive_J/0/1/0/all/0/1\">Julia Ive</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vibhor Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the ability of monolingual models to learn language-agnostic representations. (arXiv:2109.01942v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01942","description":"<p>Pretrained multilingual models have become a de facto default approach for\nzero-shot cross-lingual transfer. Previous work has shown that these models are\nable to achieve cross-lingual representations when pretrained on two or more\nlanguages with shared parameters. In this work, we provide evidence that a\nmodel can achieve language-agnostic representations even when pretrained on a\nsingle language. That is, we find that monolingual models pretrained and\nfinetuned on different languages achieve competitive performance compared to\nthe ones that use the same target language. Surprisingly, the models show a\nsimilar performance on a same task regardless of the pretraining language. For\nexample, models pretrained on distant languages such as German and Portuguese\nperform similarly on English tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Souza_L/0/1/0/all/0/1\">Leandro Rodrigues de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1\">Rodrigo Nogueira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotufo_R/0/1/0/all/0/1\">Roberto Lotufo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Joint Learning of Chest X-Ray and Radiology Report by Word Region Alignment. (arXiv:2109.01949v1 [cs.LG])","link":"http://arxiv.org/abs/2109.01949","description":"<p>Self-supervised learning provides an opportunity to explore unlabeled chest\nX-rays and their associated free-text reports accumulated in clinical routine\nwithout manual supervision. This paper proposes a Joint Image Text\nRepresentation Learning Network (JoImTeRNet) for pre-training on chest X-ray\nimages and their radiology reports. The model was pre-trained on both the\nglobal image-sentence level and the local image region-word level for\nvisual-textual matching. Both are bidirectionally constrained on Cross-Entropy\nbased and ranking-based Triplet Matching Losses. The region-word matching is\ncalculated using the attention mechanism without direct supervision about their\nmapping. The pre-trained multi-modal representation learning paves the way for\ndownstream tasks concerning image and/or text encoding. We demonstrate the\nrepresentation learning quality by cross-modality retrievals and multi-label\nclassifications on two datasets: OpenI-IU and MIMIC-CXR\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Zhanghexuan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_M/0/1/0/all/0/1\">Mohammad Abuzar Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moukheiber_D/0/1/0/all/0/1\">Dana Moukheiber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srihari_S/0/1/0/all/0/1\">Sargur Srihari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Mingchen Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models. (arXiv:2109.01951v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01951","description":"<p>The task of learning from only a few examples (called a few-shot setting) is\nof key importance and relevance to a real-world setting. For question answering\n(QA), the current state-of-the-art pre-trained models typically need\nfine-tuning on tens of thousands of examples to obtain good results. Their\nperformance degrades significantly in a few-shot setting (&lt; 100 examples). To\naddress this, we propose a simple fine-tuning framework that leverages\npre-trained text-to-text models and is directly aligned with their pre-training\nframework. Specifically, we construct the input as a concatenation of the\nquestion, a mask token representing the answer span and a context. Given this\ninput, the model is fine-tuned using the same objective as that of its\npre-training objective. Through experimental studies on various few-shot\nconfigurations, we show that this formulation leads to significant gains on\nmultiple QA benchmarks (an absolute gain of 34.2 F1 points on average when\nthere are only 16 training examples). The gains extend further when used with\nlarger models (Eg:- 72.3 F1 on SQuAD using BART-large with only 32 examples)\nand translate well to a multilingual setting . On the multilingual TydiQA\nbenchmark, our model outperforms the XLM-Roberta-large by an absolute margin of\nupto 40 F1 points and an average of 33 F1 points in a few-shot setting (&lt;= 64\ntraining examples). We conduct detailed ablation studies to analyze factors\ncontributing to these gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chada_R/0/1/0/all/0/1\">Rakesh Chada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1\">Pradeep Natarajan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SideControl: Controlled Open-domain Dialogue Generation via Additive Side Networks. (arXiv:2109.01958v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01958","description":"<p>Transformer-based pre-trained language models boost the performance of\nopen-domain dialogue systems. Prior works leverage Transformer-based\npre-trained language models to generate texts with desired attributes in two\ngeneral approaches: (1) gradient-based methods: updating all latent\nrepresentations of pre-trained models with gradients from attribute models; (2)\nweighted-decoding methods: re-ranking beam candidates from pre-trained models\nwith attribute functions. However, gradient-based methods lead to high\ncomputation cost and can easily get overfitted on small training sets, while\nweighted-decoding methods are inherently constrained by the low-variance\nhigh-bias pre-trained model. In this work, we propose a novel approach to\ncontrol the generation of Transformer-based pre-trained language models: the\nSideControl framework, which leverages a novel control attributes loss to\nincorporate useful control signals, and is shown to perform well with very\nlimited training samples. We evaluate our proposed method on two benchmark\nopen-domain dialogue datasets, and results show that the SideControl framework\nhas better controllability, higher generation quality and better\nsample-efficiency than existing gradient-based and weighted-decoding baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_W/0/1/0/all/0/1\">Wanyu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yangfeng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counterfactual Evaluation for Explainable AI. (arXiv:2109.01962v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01962","description":"<p>While recent years have witnessed the emergence of various explainable\nmethods in machine learning, to what degree the explanations really represent\nthe reasoning process behind the model prediction -- namely, the faithfulness\nof explanation -- is still an open problem. One commonly used way to measure\nfaithfulness is \\textit{erasure-based} criteria. Though conceptually simple,\nerasure-based criterion could inevitably introduce biases and artifacts. We\npropose a new methodology to evaluate the faithfulness of explanations from the\n\\textit{counterfactual reasoning} perspective: the model should produce\nsubstantially different outputs for the original input and its corresponding\ncounterfactual edited on a faithful feature. Specially, we introduce two\nalgorithms to find the proper counterfactuals in both discrete and continuous\nscenarios and then use the acquired counterfactuals to measure faithfulness.\nEmpirical results on several datasets show that compared with existing metrics,\nour proposed counterfactual evaluation method can achieve top correlation with\nthe ground truth under diffe\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zelong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Shijie Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Hierarchical Structures with Differentiable Nondeterministic Stacks. (arXiv:2109.01982v1 [cs.CL])","link":"http://arxiv.org/abs/2109.01982","description":"<p>Learning hierarchical structures in sequential data -- from simple\nalgorithmic patterns to natural language -- in a reliable, generalizable way\nremains a challenging problem for neural language models. Past work has shown\nthat recurrent neural networks (RNNs) struggle to generalize on held-out\nalgorithmic or syntactic patterns without supervision or some inductive bias.\nTo remedy this, many papers have explored augmenting RNNs with various\ndifferentiable stacks, by analogy with finite automata and pushdown automata.\nIn this paper, we present a stack RNN model based on the recently proposed\nNondeterministic Stack RNN (NS-RNN) that achieves lower cross-entropy than all\nprevious stack RNNs on five context-free language modeling tasks (within 0.05\nnats of the information-theoretic lower bound), including a task in which the\nNS-RNN previously failed to outperform a deterministic stack RNN baseline. Our\nmodel assigns arbitrary positive weights instead of probabilities to stack\nactions, and we provide an analysis of why this improves training. We also\npropose a restricted version of the NS-RNN that makes it practical to use for\nlanguage modeling on natural language and present results on the Penn Treebank\ncorpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DuSell_B/0/1/0/all/0/1\">Brian DuSell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1\">David Chiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Re-entry Prediction for Online Conversations via Self-Supervised Learning. (arXiv:2109.02020v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02020","description":"<p>In recent years, world business in online discussions and opinion sharing on\nsocial media is booming. Re-entry prediction task is thus proposed to help\npeople keep track of the discussions which they wish to continue. Nevertheless,\nexisting works only focus on exploiting chatting history and context\ninformation, and ignore the potential useful learning signals underlying\nconversation data, such as conversation thread patterns and repeated engagement\nof target users, which help better understand the behavior of target users in\nconversations. In this paper, we propose three interesting and well-founded\nauxiliary tasks, namely, Spread Pattern, Repeated Target user, and Turn\nAuthorship, as the self-supervised signals for re-entry prediction. These\nauxiliary tasks are trained together with the main task in a multi-task manner.\nExperimental results on two datasets newly collected from Twitter and Reddit\nshow that our method outperforms the previous state-of-the-arts with fewer\nparameters and faster convergence. Extensive experiments and analysis show the\neffectiveness of our proposed models and also point out some key ideas in\ndesigning self-supervised tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lingzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Huang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Efficient Masked Language Modeling for Vision and Language. (arXiv:2109.02040v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02040","description":"<p>Masked language modeling (MLM) is one of the key sub-tasks in vision-language\npretraining. In the cross-modal setting, tokens in the sentence are masked at\nrandom, and the model predicts the masked tokens given the image and the text.\nIn this paper, we observe several key disadvantages of MLM in this setting.\nFirst, as captions tend to be short, in a third of the sentences no token is\nsampled. Second, the majority of masked tokens are stop-words and punctuation,\nleading to under-utilization of the image. We investigate a range of\nalternative masking strategies specific to the cross-modal setting that address\nthese shortcomings, aiming for better fusion of text and image in the learned\nrepresentation. When pre-training the LXMERT model, our alternative masking\nstrategies consistently improve over the original masking strategy on three\ndownstream tasks, especially in low resource settings. Further, our\npre-training approach substantially outperforms the baseline model on a\nprompt-based probing task designed to elicit image objects. These results and\nour analysis indicate that our method allows for better utilization of the\ntraining data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_M/0/1/0/all/0/1\">Michael Elhadad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1\">Roy Schwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Attention Branch Network with Combined Loss Function for Automatic Speaker Verification Spoof Detection. (arXiv:2109.02051v1 [cs.SD])","link":"http://arxiv.org/abs/2109.02051","description":"<p>Many endeavors have sought to develop countermeasure techniques as\nenhancements on Automatic Speaker Verification (ASV) systems, in order to make\nthem more robust against spoof attacks. As evidenced by the latest ASVspoof\n2019 countermeasure challenge, models currently deployed for the task of ASV\nare, at their best, devoid of suitable degrees of generalization to unseen\nattacks. Upon further investigation of the proposed methods, it appears that a\nbroader three-tiered view of the proposed systems. comprised of the classifier,\nfeature extraction phase, and model loss function, may to some extent lessen\nthe problem. Accordingly, the present study proposes the Efficient Attention\nBranch Network (EABN) modular architecture with a combined loss function to\naddress the generalization problem...\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rostami_A/0/1/0/all/0/1\">Amir Mohammad Rostami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Homayounpour_M/0/1/0/all/0/1\">Mohammad Mehdi Homayounpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nickabadi_A/0/1/0/all/0/1\">Ahmad Nickabadi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Self-Debiasing Framework for Robust NLU Training. (arXiv:2109.02071v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02071","description":"<p>Existing Natural Language Understanding (NLU) models have been shown to\nincorporate dataset biases leading to strong performance on in-distribution\n(ID) test sets but poor performance on out-of-distribution (OOD) ones. We\nintroduce a simple yet effective debiasing framework whereby the shallow\nrepresentations of the main model are used to derive a bias model and both\nmodels are trained simultaneously. We demonstrate on three well studied NLU\ntasks that despite its simplicity, our method leads to competitive OOD results.\nIt significantly outperforms other debiasing approaches on two tasks, while\nstill delivering high in-distribution performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghaddar_A/0/1/0/all/0/1\">Abbas Ghaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1\">Philippe Langlais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_A/0/1/0/all/0/1\">Ahmad Rashid</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowing False Negatives: An Adversarial Training Method for Distantly Supervised Relation Extraction. (arXiv:2109.02099v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02099","description":"<p>Distantly supervised relation extraction (RE) automatically aligns\nunstructured text with relation instances in a knowledge base (KB). Due to the\nincompleteness of current KBs, sentences implying certain relations may be\nannotated as N/A instances, which causes the so-called false negative (FN)\nproblem. Current RE methods usually overlook this problem, inducing improper\nbiases in both training and testing procedures. To address this issue, we\npropose a two-stage approach. First, it finds out possible FN samples by\nheuristically leveraging the memory mechanism of deep neural networks. Then, it\naligns those unlabeled data with the training data into a unified feature space\nby adversarial training to assign pseudo labels and further utilize the\ninformation contained in them. Experiments on two wildly-used benchmark\ndatasets demonstrate the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_K/0/1/0/all/0/1\">Kailong Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Botao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Autoregressive Language Models Complex Tasks By Demonstration. (arXiv:2109.02102v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02102","description":"<p>This paper demonstrates that by fine-tuning an autoregressive language model\n(GPT-Neo) on appropriately structured step-by-step demonstrations, it is\npossible to teach it to execute a mathematical task that has previously proved\ndifficult for Transformers - longhand modulo operations - with a relatively\nsmall number of examples. Specifically, we fine-tune GPT-Neo to solve the\nnumbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et\nal. (<a href=\"/abs/1904.01557\">arXiv:1904.01557</a>) reported below 40% accuracy on this task with 2 million\ntraining examples. We show that after fine-tuning on 200 appropriately\nstructured demonstrations of solving long division problems and reporting the\nremainders, the smallest available GPT-Neo model achieves over 80% accuracy.\nThis is achieved by constructing an appropriate dataset for fine-tuning, with\nno changes to the learning algorithm. These results suggest that fine-tuning\nautoregressive language models on small sets of well-crafted demonstrations may\nbe a useful paradigm for enabling individuals without training in machine\nlearning to coax such models to perform some kinds of complex multi-step tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Recchia_G/0/1/0/all/0/1\">Gabriel Recchia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer Models for Text Coherence Assessment. (arXiv:2109.02176v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02176","description":"<p>Coherence is an important aspect of text quality and is crucial for ensuring\nits readability. It is essential desirable for outputs from text generation\nsystems like summarization, question answering, machine translation, question\ngeneration, table-to-text, etc. An automated coherence scoring model is also\nhelpful in essay scoring or providing writing feedback. A large body of\nprevious work has leveraged entity-based methods, syntactic patterns, discourse\nrelations, and more recently traditional deep learning architectures for text\ncoherence assessment. Previous work suffers from drawbacks like the inability\nto handle long-range dependencies, out-of-vocabulary words, or model sequence\ninformation. We hypothesize that coherence assessment is a cognitively complex\ntask that requires deeper models and can benefit from other related tasks.\nAccordingly, in this paper, we propose four different Transformer-based\narchitectures for the task: vanilla Transformer, hierarchical Transformer,\nmulti-task learning-based model, and a model with fact-based input\nrepresentation. Our experiments with popular benchmark datasets across multiple\ndomains on four different coherence assessment tasks demonstrate that our\nmodels achieve state-of-the-art results outperforming existing models by a good\nmargin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abhishek_T/0/1/0/all/0/1\">Tushar Abhishek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawat_D/0/1/0/all/0/1\">Daksh Rawat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varma_V/0/1/0/all/0/1\">Vasudeva Varma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nearest Neighbour Few-Shot Learning for Cross-lingual Classification. (arXiv:2109.02221v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02221","description":"<p>Even though large pre-trained multilingual models (e.g. mBERT, XLM-R) have\nled to significant performance gains on a wide range of cross-lingual NLP\ntasks, success on many downstream tasks still relies on the availability of\nsufficient annotated data. Traditional fine-tuning of pre-trained models using\nonly a few target samples can cause over-fitting. This can be quite limiting as\nmost languages in the world are under-resourced. In this work, we investigate\ncross-lingual adaptation using a simple nearest neighbor few-shot (&lt;15 samples)\ninference technique for classification tasks. We experiment using a total of 16\ndistinct languages across two NLP tasks- XNLI and PAWS-X. Our approach\nconsistently improves traditional fine-tuning using only a handful of labeled\nsamples in target locales. We also demonstrate its generalization capability\nacross tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haider_B/0/1/0/all/0/1\">Batool Haider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack. (arXiv:2109.02229v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02229","description":"<p>Over the past few years, various word-level textual attack approaches have\nbeen proposed to reveal the vulnerability of deep neural networks used in\nnatural language processing. Typically, these approaches involve an important\noptimization step to determine which substitute to be used for each word in the\noriginal input. However, current research on this step is still rather limited,\nfrom the perspectives of both problem-understanding and problem-solving. In\nthis paper, we address these issues by uncovering the theoretical properties of\nthe problem and proposing an efficient local search algorithm (LS) to solve it.\nWe establish the first provable approximation guarantee on solving the problem\nin general cases. Notably, for adversarial textual attack, it is even better\nthan the previous bound which only holds in special case. Extensive experiments\ninvolving five NLP tasks, six datasets and eleven NLP models show that LS can\nlargely reduce the number of queries usually by an order of magnitude to\nachieve high attack success rates. Further experiments show that the\nadversarial examples crafted by LS usually have higher quality, exhibit better\ntransferability, and can bring more robustness improvement to victim models by\nadversarial training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengcai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1\">Ning Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Ke Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERT might be Overkill: A Tiny but Effective Biomedical Entity Linker based on Residual Convolutional Neural Networks. (arXiv:2109.02237v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02237","description":"<p>Biomedical entity linking is the task of linking entity mentions in a\nbiomedical document to referent entities in a knowledge base. Recently, many\nBERT-based models have been introduced for the task. While these models have\nachieved competitive results on many datasets, they are computationally\nexpensive and contain about 110M parameters. Little is known about the factors\ncontributing to their impressive performance and whether the\nover-parameterization is needed. In this work, we shed some light on the inner\nworking mechanisms of these large BERT-based models. Through a set of probing\nexperiments, we have found that the entity linking performance only changes\nslightly when the input word order is shuffled or when the attention scope is\nlimited to a fixed window size. From these observations, we propose an\nefficient convolutional neural network with residual connections for biomedical\nentity linking. Because of the sparse connectivity and weight sharing\nproperties, our model has a small number of parameters and is highly efficient.\nOn five public datasets, our model achieves comparable or even better linking\naccuracy than the state-of-the-art BERT-based models while having about 60\ntimes fewer parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1\">Tuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"STaCK: Sentence Ordering with Temporal Commonsense Knowledge. (arXiv:2109.02247v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02247","description":"<p>Sentence order prediction is the task of finding the correct order of\nsentences in a randomly ordered document. Correctly ordering the sentences\nrequires an understanding of coherence with respect to the chronological\nsequence of events described in the text. Document-level contextual\nunderstanding and commonsense knowledge centered around these events are often\nessential in uncovering this coherence and predicting the exact chronological\norder. In this paper, we introduce STaCK -- a framework based on graph neural\nnetworks and temporal commonsense knowledge to model global information and\npredict the relative order of sentences. Our graph network accumulates temporal\nevidence using knowledge of `past' and `future' and formulates sentence\nordering as a constrained edge classification problem. We report results on\nfive different datasets, and empirically show that the proposed method is\nnaturally suitable for order prediction. The implementation of this work is\npublicly available at: https://github.com/declare-lab/sentence-ordering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_D/0/1/0/all/0/1\">Deepanway Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1\">Navonil Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations. (arXiv:2109.02254v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02254","description":"<p>The rapid growth in published clinical trials makes it difficult to maintain\nup-to-date systematic reviews, which requires finding all relevant trials. This\nleads to policy and practice decisions based on out-of-date, incomplete, and\nbiased subsets of available clinical evidence. Extracting and then normalising\nPopulation, Intervention, Comparator, and Outcome (PICO) information from\nclinical trial articles may be an effective way to automatically assign trials\nto systematic reviews and avoid searching and screening - the two most\ntime-consuming systematic review processes. We propose and test a novel\napproach to PICO span detection. The major difference between our proposed\nmethod and previous approaches comes from detecting spans without needing\nannotated span data and using only crowdsourced sentence-level annotations.\nExperiments on two datasets show that PICO span detection results achieve much\nhigher results for recall when compared to fully supervised methods with PICO\nsentence detection at least as good as human annotations. By removing the\nreliance on expert annotations for span detection, this work could be used in\nhuman-machine pipeline for turning low-quality crowdsourced, and sentence-level\nPICO annotations into structured information that can be used to quickly assign\ntrials to relevant systematic reviews.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yifang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bourgeois_F/0/1/0/all/0/1\">Florence T. Bourgeois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunn_A/0/1/0/all/0/1\">Adam G. Dunn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncertainty-Aware Balancing for Multilingual and Multi-Domain Neural Machine Translation Training. (arXiv:2109.02284v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02284","description":"<p>Learning multilingual and multi-domain translation model is challenging as\nthe heterogeneous and imbalanced data make the model converge inconsistently\nover different corpora in real world. One common practice is to adjust the\nshare of each corpus in the training, so that the learning process is balanced\nand low-resource cases can benefit from the high resource ones. However,\nautomatic balancing methods usually depend on the intra- and inter-dataset\ncharacteristics, which is usually agnostic or requires human priors. In this\nwork, we propose an approach, MultiUAT, that dynamically adjusts the training\ndata usage based on the model's uncertainty on a small set of trusted clean\ndata for multi-corpus machine translation. We experiments with two classes of\nuncertainty measures on multilingual (16 languages with 4 settings) and\nmulti-domain settings (4 for in-domain and 2 for out-of-domain on\nEnglish-German translation) and demonstrate our approach MultiUAT substantially\noutperforms its baselines, including both static and dynamic strategies. We\nanalyze the cross-domain transfer and show the deficiency of static and\nsimilarity based methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Minghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yitong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangyou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Numerical Reasoning Skills in the Modular Approach for Complex Question Answering on Text. (arXiv:2109.02289v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02289","description":"<p>Numerical reasoning skills are essential for complex question answering (CQA)\nover text. It requires opertaions including counting, comparison, addition and\nsubtraction. A successful approach to CQA on text, Neural Module Networks\n(NMNs), follows the programmer-interpreter paradigm and leverages specialised\nmodules to perform compositional reasoning. However, the NMNs framework does\nnot consider the relationship between numbers and entities in both questions\nand paragraphs. We propose effective techniques to improve NMNs' numerical\nreasoning capabilities by making the interpreter question-aware and capturing\nthe relationship between entities and numbers. On the same subset of the DROP\ndataset for CQA on text, experimental results show that our additions\noutperform the original NMNs by 3.0 points for the overall F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiao-Yu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan-Fang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Visual Dialog Questioner with Entity-based Strategy Learning and Augmented Guesser. (arXiv:2109.02297v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02297","description":"<p>Considering the importance of building a good Visual Dialog (VD) Questioner,\nmany researchers study the topic under a Q-Bot-A-Bot image-guessing game\nsetting, where the Questioner needs to raise a series of questions to collect\ninformation of an undisclosed image. Despite progress has been made in\nSupervised Learning (SL) and Reinforcement Learning (RL), issues still exist.\nFirstly, previous methods do not provide explicit and effective guidance for\nQuestioner to generate visually related and informative questions. Secondly,\nthe effect of RL is hampered by an incompetent component, i.e., the Guesser,\nwho makes image predictions based on the generated dialogs and assigns rewards\naccordingly. To enhance VD Questioner: 1) we propose a Related entity enhanced\nQuestioner (ReeQ) that generates questions under the guidance of related\nentities and learns entity-based questioning strategy from human dialogs; 2) we\npropose an Augmented Guesser (AugG) that is strong and is optimized for the VD\nsetting especially. Experimental results on the VisDial v1.0 dataset show that\nour approach achieves state-of-theart performance on both image-guessing task\nand question diversity. Human study further proves that our model generates\nmore visually related, informative and coherent questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1\">Duo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zipeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaojie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LightTag: Text Annotation Platform. (arXiv:2109.02320v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02320","description":"<p>Text annotation tools assume that their user's goal is to create a labeled\ncorpus. However, users view annotation as a necessary evil on the way to\ndeliver business value through NLP. Thus an annotation tool should optimize for\nthe throughput of the global NLP process, not only the productivity of\nindividual annotators. LightTag is a text annotation tool designed and built on\nthat principle. This paper shares our design rationale, data modeling choices,\nand user interface decisions then illustrates how those choices serve the full\nNLP lifecycle.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perry_T/0/1/0/all/0/1\">Tal Perry</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hocalarim: Mining Turkish Student Reviews. (arXiv:2109.02325v1 [cs.CL])","link":"http://arxiv.org/abs/2109.02325","description":"<p>We introduce Hocalarim (MyProfessors), the largest student review dataset\navailable for the Turkish language. It consists of over 5000 professor reviews\nleft online by students, with different aspects of education rated on a scale\nof 1 to 5 stars. We investigate the properties of the dataset and present its\nstatistics. We examine the impact of students' institution type on their\nratings and the correlation of students' bias to give positive or negative\nfeedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1\">Ibrahim Faruk Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calik_N/0/1/0/all/0/1\">Necmettin Bera Calik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yapucuoglu_M/0/1/0/all/0/1\">Mert Yapucuoglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1\">Ahmet Yavuz Uluslu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Putting a Spin on Language: A Quantum Interpretation of Unary Connectives for Linguistic Applications. (arXiv:2004.04128v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.04128","description":"<p>Extended versions of the Lambek Calculus currently used in computational\nlinguistics rely on unary modalities to allow for the controlled application of\nstructural rules affecting word order and phrase structure. These controlled\nstructural operations give rise to derivational ambiguities that are missed by\nthe original Lambek Calculus or its pregroup simplification. Proposals for\ncompositional interpretation of extended Lambek Calculus in the compact closed\ncategory of FVect and linear maps have been made, but in these proposals the\nsyntax-semantics mapping ignores the control modalities, effectively\nrestricting their role to the syntax. Our aim is to turn the modalities into\nfirst-class citizens of the vectorial interpretation. Building on the\ndirectional density matrix semantics, we extend the interpretation of the type\nsystem with an extra spin density matrix space. The interpretation of proofs\nthen results in ambiguous derivations being tensored with orthogonal spin\nstates. Our method introduces a way of simultaneously representing co-existing\ninterpretations of ambiguous utterances, and provides a uniform framework for\nthe integration of lexical and derivational ambiguity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Correia_A/0/1/0/all/0/1\">Adriana D. Correia</a> (Utrecht University), <a href=\"http://arxiv.org/find/cs/1/au:+Stoof_H/0/1/0/all/0/1\">Henk T. C. Stoof</a> (Utrecht University), <a href=\"http://arxiv.org/find/cs/1/au:+Moortgat_M/0/1/0/all/0/1\">Michael Moortgat</a> (Utrecht University)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantum Natural Language Processing on Near-Term Quantum Computers. (arXiv:2005.04147v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2005.04147","description":"<p>In this work, we describe a full-stack pipeline for natural language\nprocessing on near-term quantum computers, aka QNLP. The language-modelling\nframework we employ is that of compositional distributional semantics\n(DisCoCat), which extends and complements the compositional structure of\npregroup grammars. Within this model, the grammatical reduction of a sentence\nis interpreted as a diagram, encoding a specific interaction of words according\nto the grammar. It is this interaction which, together with a specific choice\nof word embedding, realises the meaning (or \"semantics\") of a sentence.\nBuilding on the formal quantum-like nature of such interactions, we present a\nmethod for mapping DisCoCat diagrams to quantum circuits. Our methodology is\ncompatible both with NISQ devices and with established Quantum Machine Learning\ntechniques, paving the way to near-term applications of quantum technology to\nnatural language processing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meichanetzidis_K/0/1/0/all/0/1\">Konstantinos Meichanetzidis</a> (University of Oxford and Cambridge Quantum Computing Ltd.), <a href=\"http://arxiv.org/find/cs/1/au:+Gogioso_S/0/1/0/all/0/1\">Stefano Gogioso</a> (Hashberg), <a href=\"http://arxiv.org/find/cs/1/au:+Felice_G/0/1/0/all/0/1\">Giovanni de Felice</a> (University of Oxford and Cambridge Quantum Computing Ltd.), <a href=\"http://arxiv.org/find/cs/1/au:+Chiappori_N/0/1/0/all/0/1\">Nicol&#xf2; Chiappori</a> (Hashberg), <a href=\"http://arxiv.org/find/cs/1/au:+Toumi_A/0/1/0/all/0/1\">Alexis Toumi</a> (University of Oxford and Cambridge Quantum Computing Ltd.), <a href=\"http://arxiv.org/find/cs/1/au:+Coecke_B/0/1/0/all/0/1\">Bob Coecke</a> (University of Oxford and Cambridge Quantum Computing Ltd.)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Impact and dynamics of hate and counter speech online. (arXiv:2009.08392v3 [cs.SI] UPDATED)","link":"http://arxiv.org/abs/2009.08392","description":"<p>Citizen-generated counter speech is a promising way to fight hate speech and\npromote peaceful, non-polarized discourse. However, there is a lack of\nlarge-scale longitudinal studies of its effectiveness for reducing hate speech.\nTo this end, we perform an exploratory analysis of the effectiveness of counter\nspeech using several different macro- and micro-level measures to analyze\n180,000 political conversations that took place on German Twitter over four\nyears. We report on the dynamic interactions of hate and counter speech over\ntime and provide insights into whether, as in `classic' bullying situations,\norganized efforts are more effective than independent individuals in steering\nonline discourse. Taken together, our results build a multifaceted picture of\nthe dynamics of hate and counter speech online. While we make no causal claims\ndue to the complexity of discourse dynamics, our findings suggest that\norganized hate speech is associated with changes in public discourse and that\ncounter speech -- especially when organized -- may help curb hateful rhetoric\nin online discourse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garland_J/0/1/0/all/0/1\">Joshua Garland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazi_Zahedi_K/0/1/0/all/0/1\">Keyan Ghazi-Zahedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_J/0/1/0/all/0/1\">Jean-Gabriel Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hebert_Dufresne_L/0/1/0/all/0/1\">Laurent H&#xe9;bert-Dufresne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galesic_M/0/1/0/all/0/1\">Mirta Galesic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic with Natural Language Processing (NLP). (arXiv:2010.16413v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.16413","description":"<p>The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leaman_R/0/1/0/all/0/1\">Robert Leaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allot_A/0/1/0/all/0/1\">Alexis Allot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Ling Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chih-Hsuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shankai Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference. (arXiv:2011.14203v5 [cs.AR] UPDATED)","link":"http://arxiv.org/abs/2011.14203","description":"<p>Transformer-based language models such as BERT provide significant accuracy\nimprovement for a multitude of natural language processing (NLP) tasks.\nHowever, their hefty computational and memory demands make them challenging to\ndeploy to resource-constrained edge platforms with strict latency requirements.\nWe present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware\nenergy optimization for multi-task NLP. EdgeBERT employs entropy-based early\nexit predication in order to perform dynamic voltage-frequency scaling (DVFS),\nat a sentence granularity, for minimal energy consumption while adhering to a\nprescribed target latency. Computation and memory footprint overheads are\nfurther alleviated by employing a calibrated combination of adaptive attention\nspan, selective network pruning, and floating-point quantization. Furthermore,\nin order to maximize the synergistic benefits of these algorithms in always-on\nand intermediate edge computing settings, we specialize a 12nm scalable\nhardware accelerator system, integrating a fast-switching low-dropout voltage\nregulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,\nhigh-density embedded non-volatile memories (eNVMs) wherein the sparse\nfloating-point bit encodings of the shared multi-task parameters are carefully\nstored. Altogether, latency-aware multi-task NLP inference acceleration on the\nEdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy\ncompared to the conventional inference without early stopping, the\nlatency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson\nTegra X2 mobile GPU, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tambe_T/0/1/0/all/0/1\">Thierry Tambe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooper_C/0/1/0/all/0/1\">Coleman Hooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pentecost_L/0/1/0/all/0/1\">Lillian Pentecost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_T/0/1/0/all/0/1\">Tianyu Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">En-Yu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donato_M/0/1/0/all/0/1\">Marco Donato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanh_V/0/1/0/all/0/1\">Victor Sanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whatmough_P/0/1/0/all/0/1\">Paul N. Whatmough</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brooks_D/0/1/0/all/0/1\">David Brooks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Gu-Yeon Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer Feed-Forward Layers Are Key-Value Memories. (arXiv:2012.14913v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2012.14913","description":"<p>Feed-forward layers constitute two-thirds of a transformer model's\nparameters, yet their role in the network remains under-explored. We show that\nfeed-forward layers in transformer-based language models operate as key-value\nmemories, where each key correlates with textual patterns in the training\nexamples, and each value induces a distribution over the output vocabulary. Our\nexperiments show that the learned patterns are human-interpretable, and that\nlower layers tend to capture shallow patterns, while upper layers learn more\nsemantic ones. The values complement the keys' input patterns by inducing\noutput distributions that concentrate probability mass on tokens likely to\nappear immediately after each pattern, particularly in the upper layers.\nFinally, we demonstrate that the output of a feed-forward layer is a\ncomposition of its memories, which is subsequently refined throughout the\nmodel's layers via residual connections to produce the final output\ndistribution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_R/0/1/0/all/0/1\">Roei Schuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.01345","description":"<p>Emotion dynamics is a framework for measuring how an individual's emotions\nchange over time. It is a powerful tool for understanding how we behave and\ninteract with the world. In this paper, we introduce a framework to track\nemotion dynamics through one's utterances. Specifically we introduce a number\nof utterance emotion dynamics (UED) metrics inspired by work in Psychology. We\nuse this approach to trace emotional arcs of movie characters. We analyze\nthousands of such character arcs to test hypotheses that inform our broader\nunderstanding of stories. Notably, we show that there is a tendency for\ncharacters to use increasingly more negative words and become increasingly\nemotionally discordant with each other until about 90 percent of the narrative\nlength. UED also has applications in behavior studies, social sciences, and\npublic health.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hipson_W/0/1/0/all/0/1\">Will E. Hipson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Interplay of Variant, Size, and Task Type in Arabic Pre-trained Language Models. (arXiv:2103.06678v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.06678","description":"<p>In this paper, we explore the effects of language variants, data sizes, and\nfine-tuning task types in Arabic pre-trained language models. To do so, we\nbuild three pre-trained language models across three variants of Arabic: Modern\nStandard Arabic (MSA), dialectal Arabic, and classical Arabic, in addition to a\nfourth language model which is pre-trained on a mix of the three. We also\nexamine the importance of pre-training data size by building additional models\nthat are pre-trained on a scaled-down set of the MSA variant. We compare our\ndifferent models to each other, as well as to eight publicly available models\nby fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest\nthat the variant proximity of pre-training data to fine-tuning data is more\nimportant than the pre-training data size. We exploit this insight in defining\nan optimized system selection model for the studied tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_G/0/1/0/all/0/1\">Go Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alhafni_B/0/1/0/all/0/1\">Bashar Alhafni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baimukan_N/0/1/0/all/0/1\">Nurpeiis Baimukan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouamor_H/0/1/0/all/0/1\">Houda Bouamor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habash_N/0/1/0/all/0/1\">Nizar Habash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constructive and Toxic Speech Detection for Open-domain Social Media Comments in Vietnamese. (arXiv:2103.10069v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.10069","description":"<p>The rise of social media has led to the increasing of comments on online\nforums. However, there still exists invalid comments which are not informative\nfor users. Moreover, those comments are also quite toxic and harmful to people.\nIn this paper, we create a dataset for constructive and toxic speech detection,\nnamed UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset)\nwith 10,000 human-annotated comments. For these tasks, we propose a system for\nconstructive and toxic speech detection with the state-of-the-art transfer\nlearning model in Vietnamese NLP as PhoBERT. With this system, we obtain\nF1-scores of 78.59% and 59.40% for classifying constructive and toxic comments,\nrespectively. Besides, we implement various baseline models as traditional\nMachine Learning and Deep Neural Network-Based models to evaluate the dataset.\nWith the results, we can solve several tasks on the online discussions and\ndevelop the framework for identifying constructiveness and toxicity of\nVietnamese social media comments automatically.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Luan Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What's in your Head? Emergent Behaviour in Multi-Task Transformer Models. (arXiv:2104.06129v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06129","description":"<p>The primary paradigm for multi-task training in natural language processing\nis to represent the input with a shared pre-trained language model, and add a\nsmall, thin network (head) per task. Given an input, a target head is the head\nthat is selected for outputting the final prediction. In this work, we examine\nthe behaviour of non-target heads, that is, the output of heads when given\ninput that belongs to a different task than the one they were trained for. We\nfind that non-target heads exhibit emergent behaviour, which may either explain\nthe target task, or generalize beyond their original task. For example, in a\nnumerical reasoning task, a span extraction head extracts from the input the\narguments to a computation that results in a number generated by a target\ngenerative head. In addition, a summarization head that is trained with a\ntarget question answering head, outputs query-based summaries when given a\nquestion and a context from which the answer is to be extracted. This emergent\nbehaviour suggests that multi-task training leads to non-trivial extrapolation\nof skills, which can be harnessed for interpretability and generalization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_U/0/1/0/all/0/1\">Uri Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_Arie_A/0/1/0/all/0/1\">Aviv Ben-Arie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Planning with Learned Entity Prompts for Abstractive Summarization. (arXiv:2104.07606v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07606","description":"<p>We introduce a simple but flexible mechanism to learn an intermediate plan to\nground the generation of abstractive summaries. Specifically, we prepend (or\nprompt) target summaries with entity chains -- ordered sequences of entities\nmentioned in the summary. Transformer-based sequence-to-sequence models are\nthen trained to generate the entity chain and then continue generating the\nsummary conditioned on the entity chain and the input. We experimented with\nboth pretraining and finetuning with this content planning objective. When\nevaluated on CNN/DailyMail, XSum, SAMSum and BillSum, we demonstrate\nempirically that the grounded generation with the planning objective improves\nentity specificity and planning in summaries for all datasets, and achieves\nstate-of-the-art performance on XSum and SAMSum in terms of Rouge. Moreover, we\ndemonstrate empirically that planning with entity chains provides a mechanism\nto control hallucinations in abstractive summaries. By prompting the decoder\nwith a modified content plan that drops hallucinated entities, we outperform\nstate-of-the-art approaches for faithfulness when evaluated automatically and\nby humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simoes_G/0/1/0/all/0/1\">Gon&#xe7;alo Simoes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_V/0/1/0/all/0/1\">Vitaly Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_R/0/1/0/all/0/1\">Ryan McDonald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Masked Segmental Language Model for Unsupervised Natural Language Segmentation. (arXiv:2104.07829v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07829","description":"<p>Segmentation remains an important preprocessing step both in languages where\n\"words\" or other important syntactic/semantic units (like morphemes) are not\nclearly delineated by white space, as well as when dealing with continuous\nspeech data, where there is often no meaningful pause between words.\nNear-perfect supervised methods have been developed for use in resource-rich\nlanguages such as Chinese, but many of the world's languages are both\nmorphologically complex, and have no large dataset of \"gold\" segmentations into\nmeaningful units. To solve this problem, we propose a new type of Segmental\nLanguage Model (Sun and Deng, 2018; Kawakami et al., 2019; Wang et al., 2021)\nfor use in both unsupervised and lightly supervised segmentation tasks. We\nintroduce a Masked Segmental Language Model (MSLM) built on a span-masking\ntransformer architecture, harnessing the power of a bi-directional masked\nmodeling context and attention. In a series of experiments, our model\nconsistently outperforms Recurrent SLMs on Chinese (PKU Corpus) in segmentation\nquality, and performs similarly to the Recurrent model on English (PTB). We\nconclude by discussing the different challenges posed in segmenting\nphonemic-type writing systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Downey_C/0/1/0/all/0/1\">C.M. Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levow_G/0/1/0/all/0/1\">Gina-Anne Levow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinert_Threlkeld_S/0/1/0/all/0/1\">Shane Steinert-Threlkeld</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Matching-oriented Product Quantization For Ad-hoc Retrieval. (arXiv:2104.07858v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07858","description":"<p>Product quantization (PQ) is a widely used technique for ad-hoc retrieval.\nRecent studies propose supervised PQ, where the embedding and quantization\nmodels can be jointly trained with supervised learning. However, there is a\nlack of appropriate formulation of the joint training objective; thus, the\nimprovements over previous non-supervised baselines are limited in reality. In\nthis work, we propose the Matching-oriented Product Quantization (MoPQ), where\na novel objective Multinoulli Contrastive Loss (MCL) is formulated. With the\nminimization of MCL, we are able to maximize the matching probability of query\nand ground-truth key, which contributes to the optimal retrieval accuracy.\nGiven that the exact computation of MCL is intractable due to the demand of\nvast contrastive samples, we further propose the Differentiable Cross-device\nSampling (DCS), which significantly augments the contrastive samples for\nprecise approximation of MCL. We conduct extensive experimental studies on four\nreal-world datasets, whose results verify the effectiveness of MoPQ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1\">Shitao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yingxia Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1\">Defu Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08773","description":"<p>Humans (e.g., crowdworkers) have a remarkable ability in solving different\ntasks, by simply reading textual instructions that define them and looking at a\nfew examples. NLP models built with the conventional paradigm, however, often\nstruggle with generalization across tasks (e.g., a question-answering system\ncannot solve classification tasks). A long-standing challenge in AI is to build\na model that is equipped with the understanding of human-readable instructions\nthat define the tasks, and can generalize to new tasks. To study this, we\nintroduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their\nhuman-authored instructions and 193k task instances. The instructions are\nobtained from crowdsourcing instructions used to collect existing NLP datasets\nand mapped to a unified schema. We adopt generative pre-trained language models\nto encode task-specific instructions along with input and generate task output.\nOur results indicate that models can benefit from instructions to generalize\nacross tasks. These models, however, are far behind supervised task-specific\nmodels, indicating significant room for more progress in this direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An automated domain-independent text reading, interpreting and extracting approach for reviewing the scientific literature. (arXiv:2107.14638v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.14638","description":"<p>It is presented here a machine learning-based (ML) natural language\nprocessing (NLP) approach capable to automatically recognize and extract\ncategorical and numerical parameters from a corpus of articles. The approach\n(named a.RIX) operates with a concomitant/interchangeable use of ML models such\nas neuron networks (NNs), latent semantic analysis (LSA), naive-Bayes\nclassifiers (NBC), and a pattern recognition model using regular expression\n(REGEX). A corpus of 7,873 scientific articles dealing with natural products\n(NPs) was used to demonstrate the efficiency of the a.RIX engine. The engine\nautomatically extracts categorical and numerical parameters such as (i) the\nplant species from which active molecules are extracted, (ii) the\nmicroorganisms species for which active molecules can act against, and (iii)\nthe values of minimum inhibitory concentration (MIC) against these\nmicroorganisms. The parameters are extracted without part-of-speech tagging\n(POS) and named entity recognition (NER) approaches (i.e. without the need of\ntext annotation), and the models training is performed with unsupervised\napproaches. In this way, a.RIX can be essentially used on articles from any\nscientific field. Finally, it can potentially make obsolete the current article\nreviewing process in some areas, especially those in which machine learning\nmodels capture texts structure, text semantics, and latent knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paula_A/0/1/0/all/0/1\">Amauri J Paula</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opinion Prediction with User Fingerprinting. (arXiv:2108.00270v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.00270","description":"<p>Opinion prediction is an emerging research area with diverse real-world\napplications, such as market research and situational awareness. We identify\ntwo lines of approaches to the problem of opinion prediction. One uses\ntopic-based sentiment analysis with time-series modeling, while the other uses\nstatic embedding of text. The latter approaches seek user-specific solutions by\ngenerating user fingerprints. Such approaches are useful in predicting user's\nreactions to unseen content. In this work, we propose a novel dynamic\nfingerprinting method that leverages contextual embedding of user's comments\nconditioned on relevant user's reading history. We integrate BERT variants with\na recurrent neural network to generate predictions. The results show up to 13\\%\nimprovement in micro F1-score compared to previous approaches. Experimental\nresults show novel insights that were previously unknown such as better\npredictions for an increase in dynamic history length, the impact of the nature\nof the article on performance, thereby laying the foundation for further\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tumarada_K/0/1/0/all/0/1\">Kishore Tumarada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dr. Yifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dr. Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dragut_D/0/1/0/all/0/1\">Dr. Eduard Dragut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gnawali_D/0/1/0/all/0/1\">Dr. Omprakash Gnawali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_D/0/1/0/all/0/1\">Dr. Arjun Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating harm in language models with conditional-likelihood filtration. (arXiv:2108.07790v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.07790","description":"<p>Language models trained on large-scale unfiltered datasets curated from the\nopen web acquire systemic biases, prejudices, and harmful views from their\ntraining data. We present a methodology for programmatically identifying and\nremoving harmful text from web-scale datasets. A pretrained language model is\nused to calculate the log-likelihood of researcher-written trigger phrases\nconditioned on a specific document, which is used to identify and filter\ndocuments from the dataset. We demonstrate that models trained on this filtered\ndataset exhibit lower propensity to generate harmful text, with a marginal\ndecrease in performance on standard language modeling benchmarks compared to\nunfiltered baselines. We provide a partial explanation for this performance gap\nby surfacing examples of hate speech and other undesirable content from\nstandard language modeling benchmarks. Finally, we discuss the generalization\nof this method and how trigger phrases which reflect specific values can be\nused by researchers to build language models which are more closely aligned\nwith their values.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ngo_H/0/1/0/all/0/1\">Helen Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raterink_C/0/1/0/all/0/1\">Cooper Raterink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araujo_J/0/1/0/all/0/1\">Jo&#xe3;o G.M. Ara&#xfa;jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_I/0/1/0/all/0/1\">Ivan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Carol Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morisot_A/0/1/0/all/0/1\">Adrien Morisot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frosst_N/0/1/0/all/0/1\">Nicholas Frosst</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction. (arXiv:2108.08468v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08468","description":"<p>We study the problem of query attribute value extraction, which aims to\nidentify named entities from user queries as diverse surface form attribute\nvalues and afterward transform them into formally canonical forms. Such a\nproblem consists of two phases: {named entity recognition (NER)} and {attribute\nvalue normalization (AVN)}. However, existing works only focus on the NER phase\nbut neglect equally important AVN. To bridge this gap, this paper proposes a\nunified query attribute value extraction system in e-commerce search named\nQUEACO, which involves both two phases. Moreover, by leveraging large-scale\nweakly-labeled behavior data, we further improve the extraction performance\nwith less supervision cost. Specifically, for the NER phase, QUEACO adopts a\nnovel teacher-student network, where a teacher network that is trained on the\nstrongly-labeled data generates pseudo-labels to refine the weakly-labeled data\nfor training a student network. Meanwhile, the teacher network can be\ndynamically adapted by the feedback of the student's performance on\nstrongly-labeled data to maximally denoise the noisy supervisions from the weak\nlabels. For the AVN phase, we also leverage the weakly-labeled\nquery-to-attribute behavior data to normalize surface form attribute values\nfrom queries into canonical forms from products. Extensive experiments on a\nreal-world large-scale E-commerce dataset demonstrate the effectiveness of\nQUEACO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Danqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1\">Tianyu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Chen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tony Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yiwei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09084","description":"<p>Transformer is a powerful model for text understanding. However, it is\ninefficient due to its quadratic complexity to input sequence length. Although\nthere are many methods on Transformer acceleration, they are still either\ninefficient on long sequences or not effective enough. In this paper, we\npropose Fastformer, which is an efficient Transformer model based on additive\nattention. In Fastformer, instead of modeling the pair-wise interactions\nbetween tokens, we first use additive attention mechanism to model global\ncontexts, and then further transform each token representation based on its\ninteraction with global context representations. In this way, Fastformer can\nachieve effective context modeling with linear complexity. Extensive\nexperiments on five datasets show that Fastformer is much more efficient than\nmany existing Transformer models and can meanwhile achieve comparable or even\nbetter long text modeling performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fangzhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1\">Tao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Relation Extraction from Tables using Artificially Generated Metadata. (arXiv:2108.10750v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.10750","description":"<p>Relation Extraction (RE) from tables is the task of identifying relations\nbetween pairs of columns of a table. Generally, RE models for this task require\nlabelled tables for training. These labelled tables can also be generated\nartificially from a Knowledge Graph (KG), which makes the cost to acquire them\nmuch lower in comparison to manual annotations. However, unlike real tables,\nthese synthetic tables lack associated metadata, such as, column-headers,\ncaptions, etc; this is because synthetic tables are created out of KGs that do\nnot store such metadata. Meanwhile, previous works have shown that metadata is\nimportant for accurate RE from tables. To address this issue, we propose\nmethods to artificially create some of this metadata for synthetic tables.\nAfterward, we experiment with a BERT-based model, in line with recently\npublished works, that takes as input a combination of proposed artificial\nmetadata and table content. Our empirical results show that this leads to an\nimprovement of 9\\%-45\\% in F1 score, in absolute terms, over 2 tabular\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gaurav Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siffi Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Joshua Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saffari_A/0/1/0/all/0/1\">Amir Saffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.12202","description":"<p>In joint entity and relation extraction, existing work either sequentially\nencode task-specific features, leading to an imbalance in inter-task feature\ninteraction where features extracted later have no direct contact with those\nthat come first. Or they encode entity features and relation features in a\nparallel manner, meaning that feature representation learning for each task is\nlargely independent of each other except for input sharing. We propose a\npartition filter network to model two-way interaction between tasks properly,\nwhere feature encoding is decomposed into two steps: partition and filter. In\nour encoder, we leverage two gates: entity and relation gate, to segment\nneurons into two task partitions and one shared partition. The shared partition\nrepresents inter-task information valuable to both tasks and is evenly shared\nacross two tasks to ensure proper two-way interaction. The task partitions\nrepresent intra-task information and are formed through concerted efforts of\nboth gates, making sure that encoding of task-specific features is dependent\nupon each other. Experiment results on six public datasets show that our model\nperforms significantly better than previous approaches. In addition, contrary\nto what previous work claims, our auxiliary experiments suggest that relation\nprediction is contributory to named entity prediction in a non-negligible way.\nThe source code can be found at https://github.com/Coopercoppers/PFN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13139","description":"<p>Dialogue summarization has drawn much attention recently. Especially in the\ncustomer service domain, agents could use dialogue summaries to help boost\ntheir works by quickly knowing customer's issues and service progress. These\napplications require summaries to contain the perspective of a single speaker\nand have a clear topic flow structure, while neither are available in existing\ndatasets. Therefore, in this paper, we introduce a novel Chinese dataset for\nCustomer Service Dialogue Summarization (CSDS). CSDS improves the abstractive\nsummaries in two aspects: (1) In addition to the overall summary for the whole\ndialogue, role-oriented summaries are also provided to acquire different\nspeakers' viewpoints. (2) All the summaries sum up each topic separately, thus\ncontaining the topic-level structure of the dialogue. We define tasks in CSDS\nas generating the overall summary and different role-oriented summaries for a\ngiven dialogue. Next, we compare various summarization methods on CSDS, and\nexperiment results show that existing methods are prone to generate redundant\nand incoherent summaries. Besides, the performance becomes much worse when\nanalyzing the performance on role-oriented summaries and topic structures. We\nhope that this study could benchmark Chinese dialogue summarization and benefit\nfurther studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Haitao Lin</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liqun Ma</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Junnan Zhu</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1\">Lu Xiang</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yu Zhou</a> (1 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajun Zhang</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Zong_C/0/1/0/all/0/1\">Chengqing Zong</a> (1 and 2) ((1) National Laboratory of Pattern Recognition, Institute of Automation, CAS, Beijing, China, (2) School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China, (3) Fanyu AI Laboratory, Zhongke Fanyu Technology Co., Ltd, Beijing, China)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.13875","description":"<p>Scenario-based question answering (SQA) requires retrieving and reading\nparagraphs from a large corpus to answer a question which is contextualized by\na long scenario description. Since a scenario contains both keyphrases for\nretrieval and much noise, retrieval for SQA is extremely difficult. Moreover,\nit can hardly be supervised due to the lack of relevance labels of paragraphs\nfor SQA. To meet the challenge, in this paper we propose a joint\nretriever-reader model called JEEVES where the retriever is implicitly\nsupervised only using QA labels via a novel word weighting mechanism. JEEVES\nsignificantly outperforms a variety of strong baselines on multiple-choice\nquestions in three SQA datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zixian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Ao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yulin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1\">Gong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yuzhong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M^2-MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues. (arXiv:2109.00430v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00430","description":"<p>Medical dialogue systems (MDSs) aim to assist doctors and patients with a\nrange of professional medical services, i.e., diagnosis, consultation, and\ntreatment. However, one-stop MDS is still unexplored because: (1) no dataset\nhas so large-scale dialogues contains both multiple medical services and\nfine-grained medical labels (i.e., intents, slots, values); (2) no model has\naddressed a MDS based on multiple-service conversations in a unified framework.\nIn this work, we first build a Multiple-domain Multiple-service medical\ndialogue (M^2-MedDialog)dataset, which contains 1,557 conversations between\ndoctors and patients, covering 276 types of diseases, 2,468 medical entities,\nand 3 specialties of medical services. To the best of our knowledge, it is the\nonly medical dialogue dataset that includes both multiple medical services and\nfine-grained medical labels. Then, we formulate a one-stop MDS as a\nsequence-to-sequence generation problem. We unify a MDS with causal language\nmodeling and conditional causal language modeling, respectively. Specifically,\nwe employ several pretrained models (i.e., BERT-WWM, BERT-MED, GPT2, and MT5)\nand their variants to get benchmarks on M^2-MedDialog dataset. We also propose\npseudo labeling and natural perturbation methods to expand M2-MedDialog dataset\nand enhance the state-of-the-art pretrained models. We demonstrate the results\nachieved by the benchmarks so far through extensive experiments on\nM2-MedDialog. We release the dataset, the code, as well as the evaluation\nscripts to facilitate future research in this important research direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1\">Guojun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiahuan Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhumin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Huasheng Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00840","description":"<p>Though language model text embeddings have revolutionized NLP research, their\nability to capture high-level semantic information, such as relations between\nentities in text, is limited. In this paper, we propose a novel contrastive\nlearning framework that trains sentence embeddings to encode the relations in a\ngraph structure. Given a sentence (unstructured text) and its graph, we use\ncontrastive learning to impose relation-related structure on the token-level\nrepresentations of the sentence obtained with a CharacterBERT (El Boukkouri et\nal.,2020) model. The resulting relation-aware sentence embeddings achieve\nstate-of-the-art results on the relation extraction task using only a simple\nKNN classifier, thereby demonstrating the success of the proposed method.\nAdditional visualization by a tSNE analysis shows the effectiveness of the\nlearned representation space compared to baselines. Furthermore, we show that\nwe can learn a different space for named entity recognition, again using a\ncontrastive learning objective, and demonstrate how to successfully combine\nboth representation spaces in an entity-relation task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Theodoropoulos_C/0/1/0/all/0/1\">Christos Theodoropoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coman_A/0/1/0/all/0/1\">Andrei C. Coman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation. (arXiv:2109.01048v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.01048","description":"<p>Existing technologies expand BERT from different perspectives, e.g. designing\ndifferent pre-training tasks, different semantic granularities and different\nmodel architectures. Few models consider expanding BERT from different text\nformats. In this paper, we propose a heterogeneous knowledge language model\n(HKLM), a unified pre-trained language model (PLM) for all forms of text,\nincluding unstructured text, semi-structured text and well-structured text. To\ncapture the corresponding relations among these multi-format knowledge, our\napproach uses masked language model objective to learn word knowledge, uses\ntriple classification objective and title matching objective to learn entity\nknowledge and topic knowledge respectively. To obtain the aforementioned\nmulti-format text, we construct a corpus in the tourism domain and conduct\nexperiments on 5 tourism NLP datasets. The results show that our approach\noutperforms the pre-training of plain text using only 1/4 of the data. The\ncode, datasets, corpus and knowledge graph will be released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hongyin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhiheng Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jinghui Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualized Embeddings based Convolutional Neural Networks for Duplicate Question Identification. (arXiv:2109.01560v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.01560","description":"<p>Question Paraphrase Identification (QPI) is a critical task for large-scale\nQuestion-Answering forums. The purpose of QPI is to determine whether a given\npair of questions are semantically identical or not. Previous approaches for\nthis task have yielded promising results, but have often relied on complex\nrecurrence mechanisms that are expensive and time-consuming in nature. In this\npaper, we propose a novel architecture combining a Bidirectional Transformer\nEncoder with Convolutional Neural Networks for the QPI task. We produce the\npredictions from the proposed architecture using two different inference\nsetups: Siamese and Matched Aggregation. Experimental results demonstrate that\nour model achieves state-of-the-art performance on the Quora Question Pairs\ndataset. We empirically prove that the addition of convolution layers to the\nmodel architecture improves the results in both inference setups. We also\ninvestigate the impact of partial and complete fine-tuning and analyze the\ntrade-off between computational power and accuracy in the process. Based on the\nobtained results, we conclude that the Matched-Aggregation setup consistently\noutperforms the Siamese setup. Our work provides insights into what\narchitecture combinations and setups are likely to produce better results for\nthe QPI task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakhrani_H/0/1/0/all/0/1\">Harsh Sakhrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_S/0/1/0/all/0/1\">Saloni Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratadiya_P/0/1/0/all/0/1\">Pratik Ratadiya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Handwritten Character Recognition of South Indian Scripts: A Review. (arXiv:1106.0107v1 [cs.CV] CROSS LISTED)","link":"http://arxiv.org/abs/1106.0107","description":"<p>Handwritten character recognition is always a frontier area of research in\nthe field of pattern recognition and image processing and there is a large\ndemand for OCR on hand written documents. Even though, sufficient studies have\nperformed in foreign scripts like Chinese, Japanese and Arabic characters, only\na very few work can be traced for handwritten character recognition of Indian\nscripts especially for the South Indian scripts. This paper provides an\noverview of offline handwritten character recognition in South Indian Scripts,\nnamely Malayalam, Tamil, Kannada and Telungu.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jomy_J/0/1/0/all/0/1\">John Jomy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pramod_K/0/1/0/all/0/1\">K. V. Pramod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannan_B/0/1/0/all/0/1\">Balakrishnan Kannan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-06T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/"}}]}]}