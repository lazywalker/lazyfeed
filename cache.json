{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-22T04:27:29.457142492Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"actix_web","link":"https://rustcc.cn/article?id=6413ef06-e6be-4998-aaab-5f9268b2250b","description":"<p>、</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-22 03:05:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-21 Rustacean 中秋节快乐","link":"https://rustcc.cn/article?id=f83ce9ba-7c21-4673-87b2-a97a9c639764","description":"<p>所有 Rustaceans，中秋节快乐。</p>\n<h3>组合 Axum, Hyper, Tonic 和 Tower 一起，开发一个混合的 web/gRPC 应用：第四部分</h3>\n<p>本系列已经更新到第四部分了，也是终结篇。欢迎跟进。</p>\n<p>https://www.fpcomplete.com/blog/axum-hyper-tonic-tower-part4/</p>\n<h3>【播客】使用 Tarpaulin 进行 Rust 工程测试率覆盖</h3>\n<p>Allen Wyma 与软件工程师 Daniel McKenna，也是 Tarpaulin 覆盖测试工具的作者的访谈节目。欢迎收听。</p>\n<p>https://rustacean-station.org/episode/037-daniel-mckenna/</p>\n<h3>Trunk - 一个 Rust 的 WASM web 应用打包器</h3>\n<p>Trunk 会打包 WASM，JS 代码片断，静态资源（images, css, scss 等）。它的配置使用 HTML 文件。</p>\n<p>Trunk 支持所有基于 wasm-bindgen 的框架，包括但不仅限于 Yew 和 Seed。</p>\n<p>官网：https://trunkrs.dev/</p>\n<p>代码仓库：https://github.com/thedodd/trunk</p>\n<h3>Perseus - 另一个前端集成 Web UI 框架</h3>\n<p>perseus 采用 No-VDOM 技术实现页面渲染。实现纯 Rust 前端 Web UI 开发。</p>\n<ul>\n<li>支持服务端静态页面生成</li>\n<li>支持服务端动态渲染</li>\n<li>支持增量生成</li>\n<li>各种定制渲染策略</li>\n<li>命令行工具</li>\n<li>基于 <a href=\"https://projectfluent.org/\" rel=\"noopener noreferrer\">Fluent</a> 的 i18n 支持</li>\n</ul>\n<p>它基于强大的 <a href=\"https://github.com/sycamore-rs/sycamore\" rel=\"noopener noreferrer\">sycamore</a> 实现。实际上，Perseus 与 Yew, Seed 等算竞争对手，但是所采用的技术思路实际是不一样的。</p>\n<p>https://github.com/arctic-hen7/perseus</p>\n<p>--</p>\n<p>From 日报小组 Mike Tang</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li>Rustcc论坛: 支持rss</li>\n<li>微信公众号：Rust语言中文社区</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 13:28:53","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"在rust的async-std中怎么获取当前时间","link":"https://rustcc.cn/article?id=603210f7-0575-44f9-b925-579e3e13a9ba","description":"<p>请问在async_std包裹的区域内怎么获取当前时间， 我使用了chrono获取时间，但似乎因为chrono没有实现futures，所以在代码中有问题</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 11:15:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【武汉 or 远程】来个接地气的招聘","link":"https://rustcc.cn/article?id=76aac56f-ea37-4695-9eb3-7937fe0bd389","description":"<h2>你们做什么</h2>\n<p><a href=\"https://rustdesk.com/\" rel=\"noopener noreferrer\">RustDesk</a>是一款远程桌面软件，目前桌面客户端开源（<a href=\"https://github.com/rustdesk/rustdesk\" rel=\"noopener noreferrer\">项目地址</a>），起源于一个 Rust 练手项目，主要使用 Rust 开发，移动端 UI 采用 Flutter，定位于更开放、更安全、更注重隐私保护，不断完善用户体验。</p>\n<h2>你们团队怎么样</h2>\n<p>最近才拿到两笔投资，一笔国内，一笔国外，目前团队里只有原作者一人，没有硅谷、华尔街亦或者常青藤背景，也没有经历过 996，只是一名华科的普通老毕业生，选择武汉是为了能够更方便照顾老父老母，摸一摸母校的老梧桐。深知这是一个竞争相当激烈的市场，前路布满荆棘，所以更加期待你的加入，大家一起努力，做好产品，接受市场的考验。</p>\n<h2>你们的技术栈是什么？</h2>\n<p>Rust 、Flutter 、React/Javascript</p>\n<h2>我能从这份工作中得到什么？</h2>\n<p>你将是团队的第一批员工，见证一个产品的完整成长过程，团队文化也将由你们来定义。如果你喜欢 Rust，并且不断学习，不甘愿做螺丝钉，追求成就感，欣赏积极主动的工作态度，请考虑加入 RustDesk，我们一起探索国内新的 IT 职业生态。</p>\n<h2>岗位</h2>\n<h3>全栈开发工程师 [15K-35K + 期权（如果你有兴趣）]</h3>\n<p>也许你不喜欢全栈这个词汇，但是 RustDesk 的确在目前阶段还是一款重客户端，轻服务端的跨平台产品。根据你的经验或者喜好，你可以选择你的侧重点。</p>\n<h4>岗位要求：</h4>\n<ul>\n<li>写过 Rust</li>\n<li>了解基础数据结构和算法</li>\n<li>喜欢学习新东西，主动思考，提问前先 Google</li>\n<li>能够接受他人意见，不要对自己的代码迷之自信，也不要轻易吐槽他人的代码</li>\n<li>加分项：不错的 GitHub 项目、能够写出漂亮的 UI 、视频编解码开发经验、网络通信安全开发经验、后端高并发开发经验、网络协议栈开发经验</li>\n</ul>\n<h2>面试方式</h2>\n<p>你不需要准备 LeetCode，也无需通读算法导论，但是请熟悉 GNU STL 里的基础数据结构和算法。我希望你花点时间了解 RustDesk，然后自行选择 GitHub 上的 3 个 issues，我们一起在面试中讨论分享。</p>\n<h2>投递简历</h2>\n<p>Email：info [at] rustdesk.com</p>\n<p>请投递 PDF 版本完整简历（教育+工作经历），包括籍贯</p>\n<p>我会在第一时间回复你，如果你在两天内没有收到回复，请包涵，你依然很优秀，只是我眼拙没能找到彼此的契合点。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 09:57:40","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"请问如何给标准库String增加个方法呢？","link":"https://rustcc.cn/article?id=1f6297e3-ddb4-41c6-9a35-7974d8a19063","description":"<p>比如JS可以这样实现</p>\n<pre><code>String.prototype.countEx = function (sub) {\n\tlet i = 0\n\tfor (var v of this) {\n\t\tif (sub.exist(v)) i++\n\t}\n\treturn i\n}\n\n\n\"123145\".countEx(\"1\")\n\n</code></pre>\n<p>请问我用Rust应该如何实现，学了几天Rust。资料实在太少啦\n是不是trait可以实现？ 还请各位大老帮帮我~</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 09:19:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust Developer(ST) for SIL.Finance (for Soh.cool, Solana Branch)","link":"https://rustcc.cn/article?id=b367e266-92ef-400c-81b0-18bc0346560b","description":"<h2>Location</h2>\n<ul>\n<li>San Mateo, California, On-site.</li>\n<li>Hangzhou, China, On-site.</li>\n<li>Globe, Remote.</li>\n</ul>\n<h3>Rust Engineer</h3>\n<ul>\n<li>\n<p>Responsibilities</p>\n<ul>\n<li>Build smart contracts in Rust, understand Solana BPF</li>\n<li>Build smart contracts in Solidity as well</li>\n<li>Design, scope, and estimate tasks based on requirements</li>\n<li>Collaborate with team to plan projects at the task level</li>\n<li>Collaborate with cross-functional partners on all aspects of product development</li>\n<li>Identify and advocate for team-wide areas of improvement and best practices</li>\n<li>Envision and develop features to help grow SIL</li>\n</ul>\n</li>\n<li>\n<p>Qualifications</p>\n<ul>\n<li>Bachelor's or Master's degree in CS or equivalent experience</li>\n<li>Experience with Rust</li>\n<li>Experience with Solana blockchain</li>\n<li>Experience with Layer 2 scaling</li>\n</ul>\n</li>\n<li>\n<p>Good to have</p>\n<ul>\n<li>Experience with Solidity, and understands gas optimization</li>\n<li>Experience with Truffle/Hardhat</li>\n<li>Experience with migrations and deploy code to EVM compatible networks</li>\n</ul>\n</li>\n</ul>\n<h3>Solidity Engineer</h3>\n<ul>\n<li>\n<p>Responsibilities</p>\n<ul>\n<li>Build smart contracts in Solidity for the EVM compatible blockchains</li>\n<li>Design, scope, and estimate tasks based on requirements</li>\n<li>Collaborate with team to plan projects at the task level</li>\n<li>Collaborate with cross-functional partners on all aspects of product development</li>\n<li>Identify and advocate for team-wide areas of improvement and best practices</li>\n<li>Envision and develop features to help grow SIL</li>\n</ul>\n</li>\n<li>\n<p>Qualifications</p>\n<ul>\n<li>Bachelor's or Master's degree in CS or equivalent experience</li>\n<li>Experience with Solidity, and understands gas optimization</li>\n<li>Experience with Truffle/Hardhat</li>\n<li>Experience with migrations and deploy code to EVM compatible networks</li>\n</ul>\n</li>\n<li>\n<p>Good to have</p>\n<ul>\n<li>Experience with Layer 2 scaling</li>\n<li>Experience with Rust</li>\n<li>Experience with Solana blockchain</li>\n</ul>\n</li>\n</ul>\n<h3>Blockchain QA Engineer</h3>\n<ul>\n<li>\n<p>Responsibilities</p>\n<ul>\n<li>Setup end to end testing tools on dApp (fronend, blockchain)</li>\n<li>Write appropriate end to end tests in order to protect the product from regressions bugs</li>\n<li>Collaborate with team to plan projects at the task level</li>\n<li>Identify and advocate for team-wide areas of improvement and best practices</li>\n</ul>\n</li>\n<li>\n<p>Qualifications</p>\n<ul>\n<li>Experience with automated tests</li>\n<li>Experience with dApp products</li>\n</ul>\n</li>\n<li>\n<p>Good to have</p>\n<ul>\n<li>Experience with EVM compatible blockchains</li>\n<li>Experience with Solidity</li>\n<li>Experience with JavaScript/TypeScript</li>\n</ul>\n</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-20 22:52:18","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"招远程Rust/Solana工程师","link":"https://rustcc.cn/article?id=bec1bd60-b6dc-4128-9683-a986ec950e9e","description":"<p>申请链接： https://cryptocurrencyjobs.co/engineering/vovo-finance-solana-engineer/<br>\n薪资：4万 - 8 万/每月<br>\n团队在新加坡和美国</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-20 16:00:41","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"异步下的生命周期问题","link":"https://rustcc.cn/article?id=a61c0207-65b5-4f5a-a123-34b553fe13fb","description":"<pre><code>\nmod test {\n    use std::{pin::Pin, task::Poll};\n\n    use futures_io::{AsyncBufRead, AsyncRead};\n\n    //不能通过编译\n    struct Body(Vec&lt;u8&gt;);\n\n    impl AsyncRead for Body {\n        fn poll_read(\n            self: Pin&lt;&amp;mut Self&gt;,\n            cx: &amp;mut std::task::Context&lt;'_&gt;,\n            buf: &amp;mut [u8],\n        ) -&gt; Poll&lt;futures_io::Result&lt;usize&gt;&gt; {\n            todo!()\n        }\n    }\n\n    impl AsyncBufRead for Body {\n        fn poll_fill_buf(\n            self: Pin&lt;&amp;mut Self&gt;,\n            cx: &amp;mut std::task::Context&lt;'_&gt;,\n        ) -&gt; Poll&lt;futures_io::Result&lt;&amp;[u8]&gt;&gt; {\n            Poll::Ready(Ok(&amp;self.0))\n        }\n\n        fn consume(self: Pin&lt;&amp;mut Self&gt;, amt: usize) {\n            todo!()\n        }\n    }\n}\n\n</code></pre>\n<p>不能通过编译</p>\n<pre><code>\nerror[E0515]: cannot return value referencing function parameter `self`\n  --&gt; src/main.rs:24:13\n   |\n24 |             Poll::Ready(Ok(&amp;self.0))\n   |             ^^^^^^^^^^^^^^^^----^^^^\n   |             |               |\n   |             |               `self` is borrowed here\n   |             returns a value referencing data owned by the current function\n\nFor more information about this error, try `rustc --explain E0515`.\n\n</code></pre>\n<p>https://play.rust-lang.org/#:~:text=Permalink%20to%20the%20playground</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-20 14:10:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"enum和struct下的生命周期问题","link":"https://rustcc.cn/article?id=a45f8532-4e48-4495-91b9-df56b6ce33de","description":"<pre><code>\nmod test {\n//不能通过编译\n    enum Body {\n        Bytes(Vec&lt;u8&gt;),\n    }\n\n    impl std::io::Read for Body {\n        fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; futures_io::Result&lt;usize&gt; {\n            todo!()\n        }\n    }\n\n    impl std::io::BufRead for Body {\n        fn fill_buf(&amp;mut self) -&gt; futures_io::Result&lt;&amp;[u8]&gt; {\n            match self{\n                Body::Bytes(bytes) =&gt; Ok(bytes.as_ref()),\n            }\n        }\n\n        fn consume(&amp;mut self, amt: usize) {\n            todo!()\n        }\n    }\n}\n\nmod test2 {\n//能通过编译\n    struct Body (Vec&lt;u8&gt;);\n    \n\n    impl std::io::Read for Body {\n        fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; futures_io::Result&lt;usize&gt; {\n            todo!()\n        }\n    }\n\n    impl std::io::BufRead for Body {\n        fn fill_buf(&amp;mut self) -&gt; futures_io::Result&lt;&amp;[u8]&gt; {\n            Ok(self.0.as_ref())\n            \n        }\n\n        fn consume(&amp;mut self, amt: usize) {\n            todo!()\n        }\n    }\n}\n\nfn main(){\n    \n}\n\n</code></pre>\n<p>为什么使用enum就无法通过编译，使用struct就能编译？</p>\n<pre><code>\nerror[E0515]: cannot return value referencing local variable `bytes`\n  --&gt; src/main.rs:16:39\n   |\n16 |                 Body::Bytes(bytes) =&gt; Ok(bytes.as_ref()),\n   |                                       ^^^-----^^^^^^^^^^\n   |                                       |  |\n   |                                       |  `bytes` is borrowed here\n   |                                       returns a value referencing data owned by the current function\n\n</code></pre>\n<p>更新：改成<code>Body::Bytes(ref bytes)</code>就过编译了，不知道为什么。</p>\n<p>playground:</p>\n<p>https://play.rust-lang.org/#:~:text=Permalink%20to%20the%20playground</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-20 13:49:14","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-20 Rust CI/CD: github action 使用","link":"https://rustcc.cn/article?id=f08915d7-1ffc-405c-b627-91d5473c46ec","description":"<h1>Rust CI/CD: github action 使用</h1>\n<p>和任何其他语言一样, 在我们掌握语法之外, 我们往往还有 CI/CD 的需求:</p>\n<ul>\n<li>需要哪些组件来组成CI管道，以确保我的代码是健康的？</li>\n<li>如何部署？</li>\n<li>我需要编写自定义工具还是有社区资源可用？</li>\n</ul>\n<p>作者会用三篇文章来讲解 Rust在 github 中如何使用 action 来完成 CI/CD.</p>\n<p><a href=\"https://www.homeops.dev/continuous-integration-with-github-actions-and-rust/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>使用 Axum, Hyper, Tonic, and Tower 打造 web/gRPC 应用</h1>\n<p>这是使用 Axum, Hyper, Tonic, and Tower 来打造 web/gRPC 应用系列的第四部分. 本次主要讲解如何组合  Axum 和 Tonic.</p>\n<p><a href=\"https://www.fpcomplete.com/blog/axum-hyper-tonic-tower-part4/\" rel=\"noopener noreferrer\">原文链接</a></p>\n<h1>compact_str: 一种内存高效的不可变 string 类型</h1>\n<p>CompactStr 是一种内存效率更高的不可变字符串类型，它可以在堆栈上存储较小的字符串，并透明地在堆上存储更长的字符串。它们大多可以用作String的替换，在解析、反序列化或任何其他可能有较小字符串的应用程序中特别有用。</p>\n<p><a href=\"https://github.com/ParkMyCar/compact_str\" rel=\"noopener noreferrer\">github 地址</a></p>\n<h1>Caches: rust版本的 LRU</h1>\n<p>这是一个 Rust 版本的 LRU 实现. golang 的实现: https://github.com/hashicorp/golang-lru</p>\n<p><a href=\"https://github.com/al8n/caches-rs\" rel=\"noopener noreferrer\">github 地址 </a></p>\n<p>--</p>\n<p>From 日报小组 BobQin，FBI小白</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-20 12:49:06","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 培养提高计划 Vol. 7 - 8 | Rust 项目工程来了","link":"https://rustcc.cn/article?id=9dec6eeb-38d8-4ec4-b75e-783bd11bf24b","description":"<p>我们的 Rust 公开课进行了 6 期了，带大家了解了 ：</p>\n<ol>\n<li>认识面向基础架构语言</li>\n<li>理解 Rust 所有权</li>\n<li>通过实战理解 Rust 宏</li>\n<li>通过 Datafuse 理解全链路跟踪</li>\n<li>Rust 异步编程入门 Future Part 1</li>\n<li>Rust 异步编程入门 Future Part 2</li>\n</ol>\n<p>目前视频回放传到 B 站收获许多好评，赞，也给我们很大的鼓励。希望我们的 Rust 培养提高计划 | Datafuse 可以帮助更多的朋友快速的使用上 Rust 。\n本周给大家排两个公开课：周四晚上，周日晚上。我们 Rust 培养提高计划邀请到第二位分享嘉宾 董泽润老师， 另外 Rust 培养提高计划 的内容上也做了一些调整。</p>\n<hr>\n<p>分享主题：《深入了解rust 闭包》 | Vol. 7</p>\n<p>分享时间： 周四晚上2021-09-09 20:00-21:00</p>\n<p>分享讲师： 董泽润</p>\n<p>内容介绍： 深入浅出了解 rust 闭包工作原理，让大家了解底层实现\n讲师介绍：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/07-%E8%91%A3%E6%B3%BD%E6%B6%A6.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<hr>\n<p>分享主题：《利用 Tokio 实现一个高性能 Mini Http server》 | Vol. 8</p>\n<p>分享时间：  周日晚上2021-09-12 20:00-21:00</p>\n<p>分享讲师： 苏林</p>\n<p>首先感谢苏林老师的坚持付出， 带我们学习 Rust 的重点知识。 经过和苏琳老师沟通，我们后续的课程，会更加往实战方向转变。接下是一个系列的内容：</p>\n<ol>\n<li>利用 Tokio 实现一个 Mini Http server</li>\n<li>基于 Http server提供内容动态的 API 网关</li>\n<li>利用 Redis 实现对 API 网关加速</li>\n<li>学习 Rust RPC 调用，实现微服务调用</li>\n</ol>\n<p>这个内容可能需要4次左右的公开课，目的是带着大家做一些小项目，带大家熟悉一下 Rust 工程，让大家可以快速把 Rust 用到后端开发中。</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<p>Rust 异步编程入门 Future Part 1   | Vol. 5\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<p>Rust 异步编程入门 Future Part 2  | Vol. 6\nhttps://www.bilibili.com/video/bv1oy4y1G7jC</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-07 02:23:16","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust 学习随笔","link":"https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8","description":"<h1>切换镜像源</h1>\n<p>crm =&gt; https://github.com/wtklbm/crm</p>\n<p>常用命令就是 <code>crm best</code></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 14:35:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"pretree 补全文档发布了,再次谢谢大神的指点终于入门了。","link":"https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827","description":"<h1>Pretree</h1>\n<p>pretree is a package for storing and querying routing rules with prefix tree .</p>\n<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>\n<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>\n<p>Inspired by <a href=\"https://github.com/obity/pretree\" rel=\"noopener noreferrer\">obity/pretree</a> (golang)</p>\n<h1>Doc</h1>\n<p>See this document at <a href=\"https://docs.rs/pretree\" rel=\"noopener noreferrer\">API documentation</a></p>\n<h1>Install</h1>\n<p>Add the following line to your Cargo.toml file:</p>\n<pre><code>pretree = \"1.0.0\"\n</code></pre>\n<h1>Example</h1>\n<pre><code>use pretree::Pretree;\nlet mut p = Pretree::new();\np.store(\"GET\",\"account/{id}/info/:name\");\np.store(\"GET\",\"account/:id/login\");\np.store(\"GET\",\"account/{id}\");\np.store(\"GET\",\"bacteria/count_number_by_month\");\nlet (ok,rule,vars) = p.query(\"GET\",\"account/929239\");\nprintln!(\"ok:{} rule:{} vars:{:#?}\",ok,rule,vars);\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 09:37:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-22T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"DisCoDisCo at the DISRPT2021 Shared Task: A System for Discourse Segmentation, Classification, and Connective Detection. (arXiv:2109.09777v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09777","description":"<p>This paper describes our submission to the DISRPT2021 Shared Task on\nDiscourse Unit Segmentation, Connective Detection, and Relation Classification.\nOur system, called DisCoDisCo, is a Transformer-based neural classifier which\nenhances contextualized word embeddings (CWEs) with hand-crafted features,\nrelying on tokenwise sequence tagging for discourse segmentation and connective\ndetection, and a feature-rich, encoder-less sentence pair classifier for\nrelation classification. Our results for the first two tasks outperform SOTA\nscores from the previous 2019 shared task, and results on relation\nclassification suggest strong performance on the new 2021 benchmark. Ablation\ntests show that including features beyond CWEs are helpful for both tasks, and\na partial evaluation of multiple pre-trained Transformer-based language models\nindicates that models pre-trained on the Next Sentence Prediction (NSP) task\nare optimal for relation classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gessler_L/0/1/0/all/0/1\">Luke Gessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behzad_S/0/1/0/all/0/1\">Shabnam Behzad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Janet Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Siyao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yilun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeldes_A/0/1/0/all/0/1\">Amir Zeldes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERT Has Uncommon Sense: Similarity Ranking for Word Sense BERTology. (arXiv:2109.09780v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09780","description":"<p>An important question concerning contextualized word embedding (CWE) models\nlike BERT is how well they can represent different word senses, especially\nthose in the long tail of uncommon senses. Rather than build a WSD system as in\nprevious work, we investigate contextualized embedding neighborhoods directly,\nformulating a query-by-example nearest neighbor retrieval task and examining\nranking performance for words and senses in different frequency bands. In an\nevaluation on two English sense-annotated corpora, we find that several popular\nCWE models all outperform a random baseline even for proportionally rare\nsenses, without explicit sense supervision. However, performance varies\nconsiderably even among models with similar architectures and pretraining\nregimes, with especially large differences for rare word senses, revealing that\nCWE models are not all created equal when it comes to approximating word senses\nin their native representations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gessler_L/0/1/0/all/0/1\">Luke Gessler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inspecting the Factuality of Hallucinated Entities in Abstractive Summarization. (arXiv:2109.09784v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09784","description":"<p>State-of-the-art abstractive summarization systems often generate\n\\emph{hallucinations}; i.e., content that is not directly inferable from the\nsource text. Despite being assumed incorrect, many of the hallucinated contents\nare consistent with world knowledge (factual hallucinations). Including these\nfactual hallucinations into a summary can be beneficial in providing additional\nbackground information. In this work, we propose a novel detection approach\nthat separates factual from non-factual hallucinations of entities. Our method\nis based on an entity's prior and posterior probabilities according to\npre-trained and finetuned masked language models, respectively. Empirical\nresults suggest that our method vastly outperforms three strong baselines in\nboth accuracy and F1 scores and has a strong correlation with human judgments\non factuality classification tasks. Furthermore, our approach can provide\ninsight into whether a particular hallucination is caused by the summarizer's\npre-training or fine-tuning step.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1\">Meng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yue Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_J/0/1/0/all/0/1\">Jackie Chi Kit Cheung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dependency Induction Through the Lens of Visual Perception. (arXiv:2109.09790v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09790","description":"<p>Most previous work on grammar induction focuses on learning phrasal or\ndependency structure purely from text. However, because the signal provided by\ntext alone is limited, recently introduced visually grounded syntax models make\nuse of multimodal information leading to improved performance in constituency\ngrammar induction. However, as compared to dependency grammars, constituency\ngrammars do not provide a straightforward way to incorporate visual information\nwithout enforcing language-specific heuristics. In this paper, we propose an\nunsupervised grammar induction model that leverages word concreteness and a\nstructural vision-based heuristic to jointly learn constituency-structure and\ndependency-structure grammars. Our experiments find that concreteness is a\nstrong indicator for learning dependency grammars, improving the direct\nattachment score (DAS) by over 50\\% as compared to state-of-the-art models\ntrained on pure text. Next, we propose an extension of our model that leverages\nboth word concreteness and visual semantic role labels in constituency and\ndependency parsing. Our experiments show that the proposed extension\noutperforms the current state-of-the-art visually grounded models in\nconstituency parsing even with a smaller grammar size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1\">Ruisi Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijhwani_S/0/1/0/all/0/1\">Shruti Rijhwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transforming Fake News: Robust Generalisable News Classification Using Transformers. (arXiv:2109.09796v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09796","description":"<p>As online news has become increasingly popular and fake news increasingly\nprevalent, the ability to audit the veracity of online news content has become\nmore important than ever. Such a task represents a binary classification\nchallenge, for which transformers have achieved state-of-the-art results. Using\nthe publicly available ISOT and Combined Corpus datasets, this study explores\ntransformers' abilities to identify fake news, with particular attention given\nto investigating generalisation to unseen datasets with varying styles, topics\nand class distributions. Moreover, we explore the idea that opinion-based news\narticles cannot be classified as real or fake due to their subjective nature\nand often sensationalised language, and propose a novel two-step classification\npipeline to remove such articles from both model training and the final\ndeployed inference system. Experiments over the ISOT and Combined Corpus\ndatasets show that transformers achieve an increase in F1 scores of up to 4.9%\nfor out of distribution generalisation compared to baseline approaches, with a\nfurther increase of 10.1% following the implementation of our two-step\nclassification pipeline. To the best of our knowledge, this study is the first\nto investigate generalisation of transformers in this context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Blackledge_C/0/1/0/all/0/1\">Ciara Blackledge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atapour_Abarghouei_A/0/1/0/all/0/1\">Amir Atapour-Abarghouei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Span Representation for Domain-adapted Coreference Resolution. (arXiv:2109.09811v1 [cs.LG])","link":"http://arxiv.org/abs/2109.09811","description":"<p>Recent work has shown fine-tuning neural coreference models can produce\nstrong performance when adapting to different domains. However, at the same\ntime, this can require a large amount of annotated target examples. In this\nwork, we focus on supervised domain adaptation for clinical notes, proposing\nthe use of concept knowledge to more efficiently adapt coreference models to a\nnew domain. We develop methods to improve the span representations via (1) a\nretrofitting loss to incentivize span representations to satisfy a\nknowledge-based distance function and (2) a scaffolding loss to guide the\nrecovery of knowledge from the span representation. By integrating these\nlosses, our model is able to improve our baseline precision and F-1 score. In\nparticular, we show that incorporating knowledge with end-to-end coreference\nmodels results in better performance on the most challenging, domain-specific\nspans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_N/0/1/0/all/0/1\">Nupoor Gandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Field_A/0/1/0/all/0/1\">Anjalie Field</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation Methods for Anaphoric Zero Pronouns. (arXiv:2109.09825v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09825","description":"<p>In pro-drop language like Arabic, Chinese, Italian, Japanese, Spanish, and\nmany others, unrealized (null) arguments in certain syntactic positions can\nrefer to a previously introduced entity, and are thus called anaphoric zero\npronouns. The existing resources for studying anaphoric zero pronoun\ninterpretation are however still limited. In this paper, we use five data\naugmentation methods to generate and detect anaphoric zero pronouns\nautomatically. We use the augmented data as additional training materials for\ntwo anaphoric zero pronoun systems for Arabic. Our experimental results show\nthat data augmentation improves the performance of the two systems, surpassing\nthe state-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aloraini_A/0/1/0/all/0/1\">Abdulrahman Aloraini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poesio_M/0/1/0/all/0/1\">Massimo Poesio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StreamSide: A Fully-Customizable Open-Source Toolkit for Efficient Annotation of Meaning Representations. (arXiv:2109.09853v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09853","description":"<p>This demonstration paper presents StreamSide, an open-source toolkit for\nannotating multiple kinds of meaning representations. StreamSide supports\nframe-based annotation schemes e.g., Abstract Meaning Representation (AMR) and\nframeless annotation schemes e.g., Widely Interpretable Semantic Representation\n(WISeR). Moreover, it supports both sentence-level and document-level\nannotation by allowing annotators to create multi-rooted graphs for input text.\nIt can open and automatically convert between several types of input formats\nincluding plain text, Penman notation, and its own JSON format enabling richer\nannotation. It features reference frames for AMR predicate argument structures,\nand also concept-to-text alignment. StreamSide is released under the Apache 2.0\nlicense, and is completely open-source so that it can be customized to annotate\nenriched meaning representations in different languages (e.g., Uniform Meaning\nRepresentations). All StreamSide resources are publicly distributed through our\nopen source project at: https://github.com/emorynlp/StreamSide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_G/0/1/0/all/0/1\">Gregor Williamson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intensionalizing Abstract Meaning Representations: Non-Veridicality and Scope. (arXiv:2109.09858v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09858","description":"<p>Abstract Meaning Representation (AMR) is a graphical meaning representation\nlanguage designed to represent propositional information about argument\nstructure. However, at present it is unable to satisfyingly represent\nnon-veridical intensional contexts, often licensing inappropriate inferences.\nIn this paper, we show how to resolve the problem of non-veridicality without\nappealing to layered graphs through a mapping from AMRs into Simply-Typed\nLambda Calculus (STLC). At least for some cases, this requires the introduction\nof a new role :content which functions as an intensional operator. The\ntranslation proposed is inspired by the formal linguistics literature on the\nevent semantics of attitude reports. Next, we address the interaction of\nquantifier scope and intensional operators in so-called de re/de dicto\nambiguities. We adopt a scope node from the literature and provide an explicit\nmultidimensional semantics utilizing Cooper storage which allows us to derive\nthe de re and de dicto scope readings as well as intermediate scope readings\nwhich prove difficult for accounts without a scope node.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Williamson_G/0/1/0/all/0/1\">Gregor Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_P/0/1/0/all/0/1\">Patrick Elliott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuxin Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Identification with a Reciprocal Rank Classifier. (arXiv:2109.09862v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09862","description":"<p>Language identification is a critical component of language processing\npipelines (Jauhiainen et al.,2019) and is not a solved problem in real-world\nsettings. We present a lightweight and effective language identifier that is\nrobust to changes of domain and to the absence of copious training data.\n</p>\n<p>The key idea for classification is that the reciprocal of the rank in a\nfrequency table makes an effective additive feature score, hence the term\nReciprocal Rank Classifier (RRC). The key finding for language classification\nis that ranked lists of words and frequencies of characters form a sufficient\nand robust representation of the regularities of key languages and their\northographies.\n</p>\n<p>We test this on two 22-language data sets and demonstrate zero-effort domain\nadaptation from a Wikipedia training set to a Twitter test set. When trained on\nWikipedia but applied to Twitter the macro-averaged F1-score of a\nconventionally trained SVM classifier drops from 90.9% to 77.7%. By contrast,\nthe macro F1-score of RRC drops only from 93.1% to 90.6%. These classifiers are\ncompared with those from fastText and langid. The RRC performs better than\nthese established systems in most experiments, especially on short Wikipedia\ntexts and Twitter.\n</p>\n<p>The RRC classifier can be improved for particular domains and conversational\nsituations by adding words to the ranked lists. Using new terms learned from\nsuch conversations, we demonstrate a further 7.9% increase in accuracy of\nsample message classification, and 1.7% increase for conversation\nclassification. Surprisingly, this made results on Twitter data slightly worse.\n</p>\n<p>The RRC classifier is available as an open source Python package\n(https://github.com/LivePersonInc/lplangid).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Widdows_D/0/1/0/all/0/1\">Dominic Widdows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brew_C/0/1/0/all/0/1\">Chris Brew</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representation Learning for Short Text Clustering. (arXiv:2109.09894v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09894","description":"<p>Effective representation learning is critical for short text clustering due\nto the sparse, high-dimensional and noise attributes of short text corpus.\nExisting pre-trained models (e.g., Word2vec and BERT) have greatly improved the\nexpressiveness for short text representations with more condensed,\nlow-dimensional and continuous features compared to the traditional\nBag-of-Words (BoW) model. However, these models are trained for general\npurposes and thus are suboptimal for the short text clustering task. In this\npaper, we propose two methods to exploit the unsupervised autoencoder (AE)\nframework to further tune the short text representations based on these\npre-trained text models for optimal clustering performance. In our first method\nStructural Text Network Graph Autoencoder (STN-GAE), we exploit the structural\ntext information among the corpus by constructing a text network, and then\nadopt graph convolutional network as encoder to fuse the structural features\nwith the pre-trained text features for text representation learning. In our\nsecond method Soft Cluster Assignment Autoencoder (SCA-AE), we adopt an extra\nsoft cluster assignment constraint on the latent space of autoencoder to\nencourage the learned text representations to be more clustering-friendly. We\ntested two methods on seven popular short text datasets, and the experimental\nresults show that when only using the pre-trained model for short text\nclustering, BERT performs better than BoW and Word2vec. However, as long as we\nfurther tune the pre-trained representations, the proposed method like SCA-AE\ncan greatly increase the clustering performance, and the accuracy improvement\ncompared to use BERT alone could reach as much as 14\\%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hui Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiangyu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shuiqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guangyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generalization in Text-based Games via Hierarchical Reinforcement Learning. (arXiv:2109.09968v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09968","description":"<p>Deep reinforcement learning provides a promising approach for text-based\ngames in studying natural language communication between humans and artificial\nagents. However, the generalization still remains a big challenge as the agents\ndepend critically on the complexity and variety of training tasks. In this\npaper, we address this problem by introducing a hierarchical framework built\nupon the knowledge graph-based RL agent. In the high level, a meta-policy is\nexecuted to decompose the whole game into a set of subtasks specified by\ntextual goals, and select one of them based on the KG. Then a sub-policy in the\nlow level is executed to conduct goal-conditioned reinforcement learning. We\ncarry out experiments on games with various difficulty levels and show that the\nproposed method enjoys favorable generalizability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yunqiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yali Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengqi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Kernel-Smoothed Machine Translation with Retrieved Examples. (arXiv:2109.09991v1 [cs.CL])","link":"http://arxiv.org/abs/2109.09991","description":"<p>How to effectively adapt neural machine translation (NMT) models according to\nemerging cases without retraining? Despite the great success of neural machine\ntranslation, updating the deployed models online remains a challenge. Existing\nnon-parametric approaches that retrieve similar examples from a database to\nguide the translation process are promising but are prone to overfit the\nretrieved examples. However, non-parametric methods are prone to overfit the\nretrieved examples. In this work, we propose to learn Kernel-Smoothed\nTranslation with Example Retrieval (KSTER), an effective approach to adapt\nneural machine translation models online. Experiments on domain adaptation and\nmulti-domain machine translation datasets show that even without expensive\nretraining, KSTER is able to achieve improvement of 1.1 to 1.5 BLEU scores over\nthe best existing online adaptation methods. The code and trained models are\nreleased at https://github.com/jiangqn/KSTER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1\">Qingnan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jun Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Negation-Instance Based Evaluation of End-to-End Negation Resolution. (arXiv:2109.10013v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10013","description":"<p>In this paper, we revisit the task of negation resolution, which includes the\nsubtasks of cue detection (e.g. \"not\", \"never\") and scope resolution. In the\ncontext of previous shared tasks, a variety of evaluation metrics have been\nproposed. Subsequent works usually use different subsets of these, including\nvariations and custom implementations, rendering meaningful comparisons between\nsystems difficult. Examining the problem both from a linguistic perspective and\nfrom a downstream viewpoint, we here argue for a negation-instance based\napproach to evaluating negation resolution. Our proposed metrics correspond to\nexpectations over per-instance scores and hence are intuitively interpretable.\nTo render research comparable and to foster future work, we provide results for\na set of current state-of-the-art systems for negation resolution on three\nEnglish corpora, and make our implementation of the evaluation scripts publicly\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sineva_E/0/1/0/all/0/1\">Elizaveta Sineva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grunewald_S/0/1/0/all/0/1\">Stefan Gr&#xfc;newald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1\">Annemarie Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhn_J/0/1/0/all/0/1\">Jonas Kuhn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not All Comments are Equal: Insights into Comment Moderation from a Topic-Aware Model. (arXiv:2109.10033v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10033","description":"<p>Moderation of reader comments is a significant problem for online news\nplatforms. Here, we experiment with models for automatic moderation, using a\ndataset of comments from a popular Croatian newspaper. Our analysis shows that\nwhile comments that violate the moderation rules mostly share common linguistic\nand thematic features, their content varies across the different sections of\nthe newspaper. We therefore make our models topic-aware, incorporating semantic\nfeatures from a topic model into the classification decision. Our results show\nthat topic information improves the performance of the model, increases its\nconfidence in correct outputs, and helps us understand the model's outputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zosa_E/0/1/0/all/0/1\">Elaine Zosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shekhar_R/0/1/0/all/0/1\">Ravi Shekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karan_M/0/1/0/all/0/1\">Mladen Karan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Something Old, Something New: Grammar-based CCG Parsing with Transformer Models. (arXiv:2109.10044v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10044","description":"<p>This report describes the parsing problem for Combinatory Categorial Grammar\n(CCG), showing how a combination of Transformer-based neural models and a\nsymbolic CCG grammar can lead to substantial gains over existing approaches.\nThe report also documents a 20-year research program, showing how NLP methods\nhave evolved over this time. The staggering accuracy improvements provided by\nneural models for CCG parsing can be seen as a reflection of the improvements\nseen in NLP more generally. The report provides a minimal introduction to CCG\nand CCG parsing, with many pointers to the relevant literature. It then\ndescribes the CCG supertagging problem, and some recent work from Tian et al.\n(2020) which applies Transformer-based models to supertagging with great\neffect. I use this existing model to develop a CCG multitagger, which can serve\nas a front-end to an existing CCG parser. Simply using this new multitagger\nprovides substantial gains in parsing accuracy. I then show how a\nTransformer-based model from the parsing literature can be combined with the\ngrammar-based CCG parser, setting a new state-of-the-art for the CCGbank\nparsing task of almost 93% F-score for labelled dependencies, with complete\nsentence accuracies of over 50%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Clark_S/0/1/0/all/0/1\">Stephen Clark</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stepmothers are mean and academics are pretentious: What do pretrained language models learn about you?. (arXiv:2109.10052v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10052","description":"<p>In this paper, we investigate what types of stereotypical information are\ncaptured by pretrained language models. We present the first dataset comprising\nstereotypical attributes of a range of social groups and propose a method to\nelicit stereotypes encoded by pretrained language models in an unsupervised\nfashion. Moreover, we link the emergent stereotypes to their manifestation as\nbasic emotions as a means to study their emotional effects in a more\ngeneralized manner. To demonstrate how our methods can be used to analyze\nemotion and stereotype shifts due to linguistic experience, we use fine-tuning\non news sources as a case study. Our experiments expose how attitudes towards\ndifferent social groups vary across models and how quickly emotions and\nstereotypes can shift at the fine-tuning stage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choenni_R/0/1/0/all/0/1\">Rochelle Choenni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rooij_R/0/1/0/all/0/1\">Robert van Rooij</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NADE: A Benchmark for Robust Adverse Drug Events Extraction in Face of Negations. (arXiv:2109.10080v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10080","description":"<p>Adverse Drug Event (ADE) extraction mod-els can rapidly examine large\ncollections of so-cial media texts, detecting mentions of drug-related adverse\nreactions and trigger medicalinvestigations. However, despite the recent\nad-vances in NLP, it is currently unknown if suchmodels are robust in face\nofnegation, which ispervasive across language varieties.In this paper we\nevaluate three state-of-the-artsystems, showing their fragility against\nnega-tion, and then we introduce two possible strate-gies to increase the\nrobustness of these mod-els: a pipeline approach, relying on a\nspecificcomponent for negation detection; an augmen-tation of an ADE extraction\ndataset to artifi-cially create negated samples and further trainthe models.We\nshow that both strategies bring significantincreases in performance, lowering\nthe num-ber of spurious entities predicted by the mod-els. Our dataset and code\nwill be publicly re-leased to encourage research on the topic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scaboro_S/0/1/0/all/0/1\">Simone Scaboro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Portelli_B/0/1/0/all/0/1\">Beatrice Portelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1\">Emmanuele Chersoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santus_E/0/1/0/all/0/1\">Enrico Santus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serra_G/0/1/0/all/0/1\">Giuseppe Serra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval. (arXiv:2109.10086v1 [cs.IR])","link":"http://arxiv.org/abs/2109.10086","description":"<p>In neural Information Retrieval (IR), ongoing research is directed towards\nimproving the first retriever in ranking pipelines. Learning dense embeddings\nto conduct retrieval using efficient approximate nearest neighbors methods has\nproven to work well. Meanwhile, there has been a growing interest in learning\n\\emph{sparse} representations for documents and queries, that could inherit\nfrom the desirable properties of bag-of-words models such as the exact matching\nof terms and the efficiency of inverted indexes. Introduced recently, the\nSPLADE model provides highly sparse representations and competitive results\nwith respect to state-of-the-art dense and sparse approaches. In this paper, we\nbuild on SPLADE and propose several significant improvements in terms of\neffectiveness and/or efficiency. More specifically, we modify the pooling\nmechanism, benchmark a model solely based on document expansion, and introduce\nmodels trained with distillation. We also report results on the BEIR benchmark.\nOverall, SPLADE is considerably improved with more than $9$\\% gains on NDCG@10\non TREC DL 2019, leading to state-of-the-art results on the BEIR benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Formal_T/0/1/0/all/0/1\">Thibault Formal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lassance_C/0/1/0/all/0/1\">Carlos Lassance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piwowarski_B/0/1/0/all/0/1\">Benjamin Piwowarski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clinchant_S/0/1/0/all/0/1\">St&#xe9;phane Clinchant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InvBERT: Text Reconstruction from Contextualized Embeddings used for Derived Text Formats of Literary Works. (arXiv:2109.10104v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10104","description":"<p>Digital Humanities and Computational Literary Studies apply text mining\nmethods to investigate literature. Such automated approaches enable\nquantitative studies on large corpora which would not be feasible by manual\ninspection alone. However, due to copyright restrictions, the availability of\nrelevant digitized literary works is limited. Derived Text Formats (DTFs) have\nbeen proposed as a solution. Here, textual materials are transformed in such a\nway that copyright-critical features are removed, but that the use of certain\nanalytical methods remains possible. Contextualized word embeddings produced by\ntransformer-encoders (like BERT) are promising candidates for DTFs because they\nallow for state-of-the-art performance on various analytical tasks and, at\nfirst sight, do not disclose the original text. However, in this paper we\ndemonstrate that under certain conditions the reconstruction of the original\ncopyrighted text becomes feasible and its publication in the form of\ncontextualized word representations is not safe. Our attempts to invert BERT\nsuggest, that publishing parts of the encoder together with the contextualized\nembeddings is critical, since it allows to generate data to train a decoder\nwith a reconstruction accuracy sufficient to violate copyright laws.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hohmann_J/0/1/0/all/0/1\">Johannes H&#xf6;hmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rettinger_A/0/1/0/all/0/1\">Achim Rettinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kugler_K/0/1/0/all/0/1\">Kai Kugler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Difficulty of Segmenting Words with Attention. (arXiv:2109.10107v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10107","description":"<p>Word segmentation, the problem of finding word boundaries in speech, is of\ninterest for a range of tasks. Previous papers have suggested that for\nsequence-to-sequence models trained on tasks such as speech translation or\nspeech recognition, attention can be used to locate and segment the words. We\nshow, however, that even on monolingual data this approach is brittle. In our\nexperiments with different input types, data sizes, and segmentation\nalgorithms, only models trained to predict phones from words succeed in the\ntask. Models trained to predict words from either phones or speech (i.e., the\nopposite direction needed to generalize to new data), yield much worse results,\nsuggesting that attention-based segmentation is only useful in limited\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sanabria_R/0/1/0/all/0/1\">Ramon Sanabria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwater_S/0/1/0/all/0/1\">Sharon Goldwater</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Review on Summarizing Financial News Using Deep Learning. (arXiv:2109.10118v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10118","description":"<p>Investors make investment decisions depending on several factors such as\nfundamental analysis, technical analysis, and quantitative analysis. Another\nfactor on which investors can make investment decisions is through sentiment\nanalysis of news headlines, the sole purpose of this study. Natural Language\nProcessing techniques are typically used to deal with such a large amount of\ndata and get valuable information out of it. NLP algorithms convert raw text\ninto numerical representations that machines can easily understand and\ninterpret. This conversion can be done using various embedding techniques. In\nthis research, embedding techniques used are BoW, TF-IDF, Word2Vec, BERT,\nGloVe, and FastText, and then fed to deep learning models such as RNN and LSTM.\nThis work aims to evaluate these model's performance to choose the robust model\nin identifying the significant factors influencing the prediction. During this\nresearch, it was expected that Deep Leaming would be applied to get the desired\nresults or achieve better accuracy than the state-of-the-art. The models are\ncompared to check their outputs to know which one has performed better.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamal_S/0/1/0/all/0/1\">Saurabh Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Sahil Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConvFiT: Conversational Fine-Tuning of Pretrained Language Models. (arXiv:2109.10126v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10126","description":"<p>Transformer-based language models (LMs) pretrained on large text collections\nare proven to store a wealth of semantic knowledge. However, 1) they are not\neffective as sentence encoders when used off-the-shelf, and 2) thus typically\nlag behind conversationally pretrained (e.g., via response selection) encoders\non conversational tasks such as intent detection (ID). In this work, we propose\nConvFiT, a simple and efficient two-stage procedure which turns any pretrained\nLM into a universal conversational encoder (after Stage 1 ConvFiT-ing) and\ntask-specialised sentence encoder (after Stage 2). We demonstrate that 1)\nfull-blown conversational pretraining is not required, and that LMs can be\nquickly transformed into effective conversational encoders with much smaller\namounts of unannotated data; 2) pretrained LMs can be fine-tuned into\ntask-specialised sentence encoders, optimised for the fine-grained semantics of\na particular task. Consequently, such specialised sentence encoders allow for\ntreating ID as a simple semantic similarity task based on interpretable nearest\nneighbours retrieval. We validate the robustness and versatility of the ConvFiT\nframework with such similarity-based inference on the standard ID evaluation\nsets: ConvFiT-ed LMs achieve state-of-the-art ID performance across the board,\nwith particular gains in the most challenging, few-shot setups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1\">Pei-Hao Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coope_S/0/1/0/all/0/1\">Sam Coope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerz_D/0/1/0/all/0/1\">Daniela Gerz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1\">Pawe&#x142; Budzianowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casanueva_I/0/1/0/all/0/1\">I&#xf1;igo Casanueva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mrksic_N/0/1/0/all/0/1\">Nikola Mrk&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_T/0/1/0/all/0/1\">Tsung-Hsien Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Transformers a Modern Version of ELIZA? Observations on French Object Verb Agreement. (arXiv:2109.10133v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10133","description":"<p>Many recent works have demonstrated that unsupervised sentence\nrepresentations of neural networks encode syntactic information by observing\nthat neural language models are able to predict the agreement between a verb\nand its subject. We take a critical look at this line of research by showing\nthat it is possible to achieve high accuracy on this agreement task with simple\nsurface heuristics, indicating a possible flaw in our assessment of neural\nnetworks' syntactic ability. Our fine-grained analyses of results on the\nlong-range French object-verb agreement show that contrary to LSTMs,\nTransformers are able to capture a non-trivial amount of grammatical structure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wisniewski_G/0/1/0/all/0/1\">Guillaume Wisniewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crabbe_B/0/1/0/all/0/1\">Benoit Crabb&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Distillation with Noisy Labels for Natural Language Understanding. (arXiv:2109.10147v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10147","description":"<p>Knowledge Distillation (KD) is extensively used to compress and deploy large\npre-trained language models on edge devices for real-world applications.\nHowever, one neglected area of research is the impact of noisy (corrupted)\nlabels on KD. We present, to the best of our knowledge, the first study on KD\nwith noisy labels in Natural Language Understanding (NLU). We document the\nscope of the problem and present two methods to mitigate the impact of label\nnoise. Experiments on the GLUE benchmark show that our methods are effective\neven under high noise levels. Nevertheless, our results indicate that more\nresearch is necessary to cope with label noise under the KD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_S/0/1/0/all/0/1\">Shivendra Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaddar_A/0/1/0/all/0/1\">Abbas Ghaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_A/0/1/0/all/0/1\">Ahmad Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_K/0/1/0/all/0/1\">Khalil Bibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1\">Philippe Langlais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation. (arXiv:2109.10164v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10164","description":"<p>Intermediate layer knowledge distillation (KD) can improve the standard KD\ntechnique (which only targets the output of teacher and student models)\nespecially over large pre-trained language models. However, intermediate layer\ndistillation suffers from excessive computational burdens and engineering\nefforts required for setting up a proper layer mapping. To address these\nproblems, we propose a RAndom Intermediate Layer Knowledge Distillation\n(RAIL-KD) approach in which, intermediate layers from the teacher model are\nselected randomly to be distilled into the intermediate layers of the student\nmodel. This randomized selection enforce that: all teacher layers are taken\ninto account in the training process, while reducing the computational cost of\nintermediate layer distillation. Also, we show that it act as a regularizer for\nimproving the generalizability of the student model. We perform extensive\nexperiments on GLUE tasks as well as on out-of-domain test sets. We show that\nour proposed RAIL-KD approach outperforms other state-of-the-art intermediate\nlayer KD methods considerably in both performance and training-time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haidar_M/0/1/0/all/0/1\">Md Akmal Haidar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anchuri_N/0/1/0/all/0/1\">Nithin Anchuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghaddar_A/0/1/0/all/0/1\">Abbas Ghaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1\">Philippe Langlais</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1\">Pascal Poupart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Familiar Does That Sound? Cross-Lingual Representational Similarity Analysis of Acoustic Word Embeddings. (arXiv:2109.10179v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10179","description":"<p>How do neural networks \"perceive\" speech sounds from unknown languages? Does\nthe typological similarity between the model's training language (L1) and an\nunknown language (L2) have an impact on the model representations of L2 speech\nsignals? To answer these questions, we present a novel experimental design\nbased on representational similarity analysis (RSA) to analyze acoustic word\nembeddings (AWEs) -- vector representations of variable-duration spoken-word\nsegments. First, we train monolingual AWE models on seven Indo-European\nlanguages with various degrees of typological similarity. We then employ RSA to\nquantify the cross-lingual similarity by simulating native and non-native\nspoken-word processing using AWEs. Our experiments show that typological\nsimilarity indeed affects the representational similarity of the models in our\nstudy. We further discuss the implications of our work on modeling speech\nprocessing and language similarity with neural networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1\">Badr M. Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaitova_I/0/1/0/all/0/1\">Iuliia Zaitova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avgustinova_T/0/1/0/all/0/1\">Tania Avgustinova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mobius_B/0/1/0/all/0/1\">Bernd M&#xf6;bius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TranslateLocally: Blazing-fast translation running on the local CPU. (arXiv:2109.10194v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10194","description":"<p>Every day, millions of people sacrifice their privacy and browsing habits in\nexchange for online machine translation. Companies and governments with\nconfidentiality requirements often ban online translation or pay a premium to\ndisable logging. To bring control back to the end user and demonstrate speed,\nwe developed translateLocally. Running locally on a desktop or laptop CPU,\ntranslateLocally delivers cloud-like translation speed and quality even on 10\nyear old hardware. The open-source software is based on Marian and runs on\nLinux, Windows, and macOS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bogoychev_N/0/1/0/all/0/1\">Nikolay Bogoychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linde_J/0/1/0/all/0/1\">Jelmer Van der Linde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heafield_K/0/1/0/all/0/1\">Kenneth Heafield</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Source, Two Targets: Challenges and Rewards of Dual Decoding. (arXiv:2109.10197v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10197","description":"<p>Machine translation is generally understood as generating one target text\nfrom an input source document. In this paper, we consider a stronger\nrequirement: to jointly generate two texts so that each output side effectively\ndepends on the other. As we discuss, such a device serves several practical\npurposes, from multi-target machine translation to the generation of controlled\nvariations of the target text. We present an analysis of possible\nimplementations of dual decoding, and experiment with four applications.\nViewing the problem from multiple angles allows us to better highlight the\nchallenges of dual decoding and to also thoroughly analyze the benefits of\ngenerating matched, rather than independent, translations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jitao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blindness to Modality Helps Entailment Graph Mining. (arXiv:2109.10227v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10227","description":"<p>Understanding linguistic modality is widely seen as important for downstream\ntasks such as Question Answering and Knowledge Graph Population. Entailment\nGraph learning might also be expected to benefit from attention to modality. We\nbuild Entailment Graphs using a news corpus filtered with a modality parser,\nand show that stripping modal modifiers from predicates in fact increases\nperformance. This suggests that for some tasks, the pragmatics of modal\nmodification of predicates allows them to contribute as evidence of entailment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guillou_L/0/1/0/all/0/1\">Liane Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vroe_S/0/1/0/all/0/1\">Sander Bijl de Vroe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Mark Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steedman_M/0/1/0/all/0/1\">Mark Steedman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets. (arXiv:2109.10234v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10234","description":"<p>We introduce BERTweetFR, the first large-scale pre-trained language model for\nFrench tweets. Our model is initialized using the general-domain French\nlanguage model CamemBERT which follows the base architecture of RoBERTa.\nExperiments show that BERTweetFR outperforms all previous general-domain French\nlanguage models on two downstream Twitter NLP tasks of offensiveness\nidentification and named entity recognition. The dataset used in the\noffensiveness detection task is first created and annotated by our team,\nfilling in the gap of such analytic datasets in French. We make our model\npublicly available in the transformers library with the aim of promoting future\nresearch in analytic tasks for French tweets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yanzhu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rennard_V/0/1/0/all/0/1\">Virgile Rennard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xypolopoulos_C/0/1/0/all/0/1\">Christos Xypolopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1\">Michalis Vazirgiannis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Vision-and-Language Pretraining Improve Lexical Grounding?. (arXiv:2109.10246v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10246","description":"<p>Linguistic representations derived from text alone have been criticized for\ntheir lack of grounding, i.e., connecting words to their meanings in the\nphysical world. Vision-and-Language (VL) models, trained jointly on text and\nimage or video data, have been offered as a response to such criticisms.\nHowever, while VL pretraining has shown success on multimodal tasks such as\nvisual question answering, it is not yet known how the internal linguistic\nrepresentations themselves compare to their text-only counterparts. This paper\ncompares the semantic representations learned via VL vs. text-only pretraining\nfor two recent VL models using a suite of analyses (clustering, probing, and\nperformance on a commonsense question answering task) in a language-only\nsetting. We find that the multimodal models fail to significantly outperform\nthe text-only variants, suggesting that future work is required if multimodal\npretraining is to be pursued as a means of improving NLP in general.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Tian Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chen Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audiomer: A Convolutional Transformer for Keyword Spotting. (arXiv:2109.10252v1 [cs.LG])","link":"http://arxiv.org/abs/2109.10252","description":"<p>Transformers have seen an unprecedented rise in Natural Language Processing\nand Computer Vision tasks. However, in audio tasks, they are either infeasible\nto train due to extremely large sequence length of audio waveforms or reach\ncompetitive performance after feature extraction through Fourier-based methods,\nincurring a loss-floor. In this work, we introduce an architecture, Audiomer,\nwhere we combine 1D Residual Networks with Performer Attention to achieve\nstate-of-the-art performance in Keyword Spotting with raw audio waveforms,\nout-performing all previous methods while also being computationally cheaper,\nmuch more parameter and data-efficient. Audiomer allows for deployment in\ncompute-constrained devices and training on smaller datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1\">Surya Kant Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1\">Sai Mitheran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamdar_J/0/1/0/all/0/1\">Juhi Kamdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_M/0/1/0/all/0/1\">Meet Gandhi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Task Learning with Sentiment, Emotion, and Target Detection to Recognize Hate Speech and Offensive Language. (arXiv:2109.10255v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10255","description":"<p>The recognition of hate speech and offensive language (HOF) is commonly\nformulated as a classification task to decide if a text contains HOF. We\ninvestigate whether HOF detection can profit by taking into account the\nrelationships between HOF and similar concepts: (a) HOF is related to sentiment\nanalysis because hate speech is typically a negative statement and expresses a\nnegative opinion; (b) it is related to emotion analysis, as expressed hate\npoints to the author experiencing (or pretending to experience) anger while the\naddressees experience (or are intended to experience) fear. (c) Finally, one\nconstituting element of HOF is the mention of a targeted person or group. On\nthis basis, we hypothesize that HOF detection shows improvements when being\nmodeled jointly with these concepts, in a multi-task learning setup. We base\nour experiments on existing data sets for each of these concepts (sentiment,\nemotion, target of HOF) and evaluate our models as a participant (as team\nIMS-SINAI) in the HASOC FIRE 2021 English Subtask 1A. Based on model-selection\nexperiments in which we consider multiple available resources and submissions\nto the shared task, we find that the combination of the CrowdFlower emotion\ncorpus, the SemEval 2016 Sentiment Corpus, and the OffensEval 2019 target\ndetection data leads to an F1 =.79 in a multi-head multi-task learning model\nbased on BERT, in comparison to .7895 of plain BERT. On the HASOC 2019 test\ndata, this result is more substantial with an increase by 2pp in F1 and a\nconsiderable increase in recall. Across both data sets (2019, 2021), the recall\nis particularly increased for the class of HOF (6pp for the 2019 data and 3pp\nfor the 2021 data), showing that MTL with emotion, sentiment, and target\nidentification is an appropriate approach for early warning systems that might\nbe deployed in social media platforms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Plaza_del_Arco_F/0/1/0/all/0/1\">Flor Miriam Plaza-del-Arco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halat_S/0/1/0/all/0/1\">Sercan Halat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Trade-offs of Domain Adaptation for Neural Language Models. (arXiv:2109.10274v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10274","description":"<p>In this paper, we connect language model adaptation with concepts of machine\nlearning theory. We consider a training setup with a large out-of-domain set\nand a small in-domain set. As a first contribution, we derive how the benefit\nof training a model on either set depends on the size of the sets and the\ndistance between their underlying distribution. As a second contribution, we\npresent how the most popular data selection techniques -- importance sampling,\nintelligent data selection and influence functions -- can be presented in a\ncommon framework which highlights their similarity and also their subtle\ndifferences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grangier_D/0/1/0/all/0/1\">David Grangier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models. (arXiv:2109.10282v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10282","description":"<p>Text recognition is a long-standing research problem for document\ndigitalization. Existing approaches for text recognition are usually built\nbased on CNN for image understanding and RNN for char-level text generation. In\naddition, another language model is usually needed to improve the overall\naccuracy as a post-processing step. In this paper, we propose an end-to-end\ntext recognition approach with pre-trained image Transformer and text\nTransformer models, namely TrOCR, which leverages the Transformer architecture\nfor both image understanding and wordpiece-level text generation. The TrOCR\nmodel is simple but effective, and can be pre-trained with large-scale\nsynthetic data and fine-tuned with human-labeled datasets. Experiments show\nthat the TrOCR model outperforms the current state-of-the-art models on both\nprinted and handwritten text recognition tasks. The code and models will be\npublicly available at https://aka.ms/TrOCR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tengchao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yijuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florencio_D/0/1/0/all/0/1\">Dinei Florencio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cha Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From English to Signal Temporal Logic. (arXiv:2109.10294v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10294","description":"<p>Formal methods provide very powerful tools and techniques for the design and\nanalysis of complex systems. Their practical application remains however\nlimited, due to the widely accepted belief that formal methods require\nextensive expertise and a steep learning curve. Writing correct formal\nspecifications in form of logical formulas is still considered to be a\ndifficult and error prone task.\n</p>\n<p>In this paper we propose DeepSTL, a tool and technique for the translation of\ninformal requirements, given as free English sentences, into Signal Temporal\nLogic (STL), a formal specification language for cyber-physical systems, used\nboth by academia and advanced research labs in industry. A major challenge to\ndevise such a translator is the lack of publicly available informal\nrequirements and formal specifications. We propose a two-step workflow to\naddress this challenge. We first design a grammar-based generation technique of\nsynthetic data, where each output is a random STL formula and its associated\nset of possible English translations. In the second step, we use a\nstate-of-the-art transformer-based neural translation technique, to train an\naccurate attentional translator of English to STL. The experimental results\nshow high translation quality for patterns of English requirements that have\nbeen well trained, making this workflow promising to be extended for processing\nmore complex translation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartocci_E/0/1/0/all/0/1\">Ezio Bartocci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nickovic_D/0/1/0/all/0/1\">Dejan Ni&#x10d;kovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isakovic_H/0/1/0/all/0/1\">Haris Isakovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1\">Radu Grosu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents. (arXiv:2109.10341v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10341","description":"<p>Document-level neural machine translation (DocNMT) delivers coherent\ntranslations by incorporating cross-sentence context. However, for most\nlanguage pairs there's a shortage of parallel documents, although parallel\nsentences are readily available. In this paper, we study whether and how\ncontextual modeling in DocNMT is transferable from sentences to documents in a\nzero-shot fashion (i.e. no parallel documents for student languages) through\nmultilingual modeling. Using simple concatenation-based DocNMT, we explore the\neffect of 3 factors on multilingual transfer: the number of document-supervised\nteacher languages, the data schedule for parallel documents at training, and\nthe data condition of parallel documents (genuine vs. backtranslated). Our\nexperiments on Europarl-7 and IWSLT-10 datasets show the feasibility of\nmultilingual transfer for DocNMT, particularly on document-specific metrics. We\nobserve that more teacher languages and adequate data schedule both contribute\nto better transfer quality. Surprisingly, the transfer is less sensitive to the\ndata condition and multilingual DocNMT achieves comparable performance with\nboth back-translated and genuine document pairs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Biao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bapna_A/0/1/0/all/0/1\">Ankur Bapna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabirmoghaddam_A/0/1/0/all/0/1\">Ali Dabirmoghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arivazhagan_N/0/1/0/all/0/1\">Naveen Arivazhagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Relation-Guided Pre-Training for Open-Domain Question Answering. (arXiv:2109.10346v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10346","description":"<p>Answering complex open-domain questions requires understanding the latent\nrelations between involving entities. However, we found that the existing QA\ndatasets are extremely imbalanced in some types of relations, which hurts the\ngeneralization performance over questions with long-tail relations. To remedy\nthis problem, in this paper, we propose a Relation-Guided Pre-Training\n(RGPT-QA) framework. We first generate a relational QA dataset covering a wide\nrange of relations from both the Wikidata triplets and Wikipedia hyperlinks. We\nthen pre-train a QA model to infer the latent relations from the question, and\nthen conduct extractive QA to get the target answer entity. We demonstrate that\nby pretraining with propoed RGPT-QA techique, the popular open-domain QA model,\nDense Passage Retriever (DPR), achieves 2.2%, 2.4%, and 6.3% absolute\nimprovement in Exact Match accuracy on Natural Questions, TriviaQA, and\nWebQuestions. Particularly, we show that RGPT-QA improves significantly on\nquestions with long-tail relations\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Ziniu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yizhou Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Informed Sampling for Diversity in Concept-to-Text NLG. (arXiv:2004.14364v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.14364","description":"<p>Deep-learning models for language generation tasks tend to produce repetitive\noutput. Various methods have been proposed to encourage lexical diversity\nduring decoding, but this often comes at a cost to the perceived fluency and\nadequacy of the output. In this work, we propose to ameliorate this cost by\nusing an Imitation Learning approach to explore the level of diversity that a\nlanguage generation model can reliably produce. Specifically, we augment the\ndecoding process with a meta-classifier trained to distinguish which words at\nany given timestep will lead to high-quality output. We focus our experiments\non concept-to-text generation where models are sensitive to the inclusion of\nirrelevant words due to the strict relation between input and output. Our\nanalysis shows that previous methods for diversity underperform in this\nsetting, while human evaluation suggests that our proposed method achieves a\nhigh level of diversity with minimal effect to the output's fluency and\nadequacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1\">Giulio Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampouras_G/0/1/0/all/0/1\">Gerasimos Lampouras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-Based Reranking: Improving Neural Machine Translation Using Energy-Based Models. (arXiv:2009.13267v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.13267","description":"<p>The discrepancy between maximum likelihood estimation (MLE) and task measures\nsuch as BLEU score has been studied before for autoregressive neural machine\ntranslation (NMT) and resulted in alternative training algorithms (Ranzato et\nal., 2016; Norouzi et al., 2016; Shen et al., 2016; Wu et al., 2018). However,\nMLE training remains the de facto approach for autoregressive NMT because of\nits computational efficiency and stability. Despite this mismatch between the\ntraining objective and task measure, we notice that the samples drawn from an\nMLE-based trained NMT support the desired distribution -- there are samples\nwith much higher BLEU score comparing to the beam decoding output. To benefit\nfrom this observation, we train an energy-based model to mimic the behavior of\nthe task measure (i.e., the energy-based model assigns lower energy to samples\nwith higher BLEU score), which is resulted in a re-ranking algorithm based on\nthe samples drawn from NMT: energy-based re-ranking (EBR). We use both marginal\nenergy models (over target sentence) and joint energy models (over both source\nand target sentences). Our EBR with the joint energy model consistently\nimproves the performance of the Transformer-based NMT: +4 BLEU points on\nIWSLT'14 German-English, +3.0 BELU points on Sinhala-English, +1.2 BLEU on\nWMT'16 English-German tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_S/0/1/0/all/0/1\">Sumanta Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rooshenas_A/0/1/0/all/0/1\">Amirmohammad Rooshenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1\">Subhajit Naskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Simeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not all parameters are born equal: Attention is mostly what you need. (arXiv:2010.11859v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.11859","description":"<p>Transformers are widely used in state-of-the-art machine translation, but the\nkey to their success is still unknown. To gain insight into this, we consider\nthree groups of parameters: embeddings, attention, and feed forward neural\nnetwork (FFN) layers. We examine the relative importance of each by performing\nan ablation study where we initialise them at random and freeze them, so that\ntheir weights do not change over the course of the training. Through this, we\nshow that the attention and FFN are equally important and fulfil the same\nfunctionality in a model. We show that the decision about whether a component\nis frozen or allowed to train is at least as important for the final model\nperformance as its number of parameters. At the same time, the number of\nparameters alone is not indicative of a component's importance. Finally, while\nthe embedding layer is the least essential for machine translation tasks, it is\nthe most important component for language modelling tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bogoychev_N/0/1/0/all/0/1\">Nikolay Bogoychev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Highs and Lows of Simple Lexical Domain Adaptation Approaches for Neural Machine Translation. (arXiv:2101.00421v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00421","description":"<p>Machine translation systems are vulnerable to domain mismatch, especially in\na low-resource scenario. Out-of-domain translations are often of poor quality\nand prone to hallucinations, due to exposure bias and the decoder acting as a\nlanguage model. We adopt two approaches to alleviate this problem: lexical\nshortlisting restricted by IBM statistical alignments, and hypothesis\nre-ranking based on similarity. The methods are computationally cheap, widely\nknown, but not extensively experimented on domain adaptation. We demonstrate\nsuccess on low-resource out-of-domain test sets, however, the methods are\nineffective when there is sufficient data or too great domain mismatch. This is\ndue to both the IBM model losing its advantage over the implicitly learned\nneural alignment, and issues with subword segmentation of out-of-domain words.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bogoychev_N/0/1/0/all/0/1\">Nikolay Bogoychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pinzhen Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open-Retrieval Conversational Machine Reading. (arXiv:2102.08633v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2102.08633","description":"<p>In conversational machine reading, systems need to interpret natural language\nrules, answer high-level questions such as \"May I qualify for VA health care\nbenefits?\", and ask follow-up clarification questions whose answer is necessary\nto answer the original question. However, existing works assume the rule text\nis provided for each user question, which neglects the essential retrieval step\nin real scenarios. In this work, we propose and investigate an open-retrieval\nsetting of conversational machine reading. In the open-retrieval setting, the\nrelevant rule texts are unknown so that a system needs to retrieve\nquestion-relevant evidence from a collection of rule texts, and answer users'\nhigh-level questions according to multiple retrieved rule texts in a\nconversational manner. We propose MUDERN, a Multi-passage Discourse-aware\nEntailment Reasoning Network which extracts conditions in the rule texts\nthrough discourse segmentation, conducts multi-passage entailment reasoning to\nanswer user questions directly, or asks clarification follow-up questions to\ninquiry more information. On our created OR-ShARC dataset, MUDERN achieves the\nstate-of-the-art performance, outperforming existing single-passage\nconversational machine reading models as well as a new multi-passage\nconversational machine reading baseline by a large margin. In addition, we\nconduct in-depth analyses to provide new insights into this new setting and our\nmodel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-autoregressive Mandarin-English Code-switching Speech Recognition. (arXiv:2104.02258v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.02258","description":"<p>Mandarin-English code-switching (CS) is frequently used among East and\nSoutheast Asian people. However, the intra-sentence language switching of the\ntwo very different languages makes recognizing CS speech challenging.\nMeanwhile, the recent successful non-autoregressive (NAR) ASR models remove the\nneed for left-to-right beam decoding in autoregressive (AR) models and achieved\noutstanding performance and fast inference speed, but it has not been applied\nto Mandarin-English CS speech recognition. This paper takes advantage of the\nMask-CTC NAR ASR framework to tackle the CS speech recognition issue. We\nfurther propose to change the Mandarin output target of the encoder to Pinyin\nfor faster encoder training and introduce the Pinyin-to-Mandarin decoder to\nlearn contextualized information. Moreover, we use word embedding label\nsmoothing to regularize the decoder with contextualized information and\nprojection matrix regularization to bridge that gap between the encoder and\ndecoder. We evaluate these methods on the SEAME corpus and achieved exciting\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chuang_S/0/1/0/all/0/1\">Shun-Po Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Heng-Jui Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Sung-Feng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Simple Geometric Method for Cross-Lingual Linguistic Transformations with Pre-trained Autoencoders. (arXiv:2104.03630v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.03630","description":"<p>Powerful sentence encoders trained for multiple languages are on the rise.\nThese systems are capable of embedding a wide range of linguistic properties\ninto vector representations. While explicit probing tasks can be used to verify\nthe presence of specific linguistic properties, it is unclear whether the\nvector representations can be manipulated to indirectly steer such properties.\nFor efficient learning, we investigate the use of a geometric mapping in\nembedding space to transform linguistic properties, without any tuning of the\npre-trained sentence encoder or decoder. We validate our approach on three\nlinguistic properties using a pre-trained multilingual autoencoder and analyze\nthe results in both monolingual and cross-lingual settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raedt_M/0/1/0/all/0/1\">Maarten De Raedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godin_F/0/1/0/all/0/1\">Fr&#xe9;deric Godin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buteneers_P/0/1/0/all/0/1\">Pieter Buteneers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Condenser: a Pre-training Architecture for Dense Retrieval. (arXiv:2104.08253v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08253","description":"<p>Pre-trained Transformer language models (LM) have become go-to text\nrepresentation encoders. Prior research fine-tunes deep LMs to encode text\nsequences such as sentences and passages into single dense vector\nrepresentations for efficient text comparison and retrieval. However, dense\nencoders require a lot of data and sophisticated techniques to effectively\ntrain and suffer in low data situations. This paper finds a key reason is that\nstandard LMs' internal attention structure is not ready-to-use for dense\nencoders, which needs to aggregate text information into the dense\nrepresentation. We propose to pre-train towards dense encoder with a novel\nTransformer architecture, Condenser, where LM prediction CONditions on DENSE\nRepresentation. Our experiments show Condenser improves over standard LM by\nlarge margins on various text retrieval and similarity tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying Offensive Expressions of Opinion in Context. (arXiv:2104.12227v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.12227","description":"<p>Classic information extraction techniques consist in building questions and\nanswers about the facts. Indeed, it is still a challenge to subjective\ninformation extraction systems to identify opinions and feelings in context. In\nsentiment-based NLP tasks, there are few resources to information extraction,\nabove all offensive or hateful opinions in context. To fill this important gap,\nthis short paper provides a new cross-lingual and contextual offensive lexicon,\nwhich consists of explicit and implicit offensive and swearing expressions of\nopinion, which were annotated in two different classes: context dependent and\ncontext-independent offensive. In addition, we provide markers to identify hate\nspeech. Annotation approach was evaluated at the expression-level and achieves\nhigh human inter-annotator agreement. The provided offensive lexicon is\navailable in Portuguese and English languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1\">Francielle Alves Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1\">Isabelle Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goes_F/0/1/0/all/0/1\">Fabiana Rodrigues de G&#xf3;es</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual Lexicon-Based Approach for Hate Speech and Offensive Language Detection. (arXiv:2104.12265v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.12265","description":"<p>This paper provides a new approach for offensive language and hate speech\ndetection on social media. Our approach incorporates an offensive lexicon\ncomposed of implicit and explicit offensive and swearing expressions annotated\nwith binary classes: context-dependent and context-independent offensive. Due\nto the severity of the hate speech and offensive comments in Brazil, and the\nlack of research in Portuguese, Brazilian Portuguese is the language used to\nvalidate the proposed method. Nevertheless, our proposal may be applied to any\nother language or domain. Based on the obtained results, the proposed approach\nshowed high-performance overcoming the current baselines for European and\nBrazilian Portuguese.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1\">Francielle Alves Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goes_F/0/1/0/all/0/1\">Fabiana Rodrigues de G&#xf3;es</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_I/0/1/0/all/0/1\">Isabelle Carvalho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benevenuto_F/0/1/0/all/0/1\">Fabr&#xed;cio Benevenuto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pardo_T/0/1/0/all/0/1\">Thiago Alexandre Salgueiro Pardo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph Construction. (arXiv:2105.15033v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.15033","description":"<p>Knowledge Graph has been proven effective in modeling structured information\nand conceptual knowledge, especially in the medical domain. However, the lack\nof high-quality annotated corpora remains a crucial problem for advancing the\nresearch and applications on this task. In order to accelerate the research for\ndomain-specific knowledge graphs in the medical domain, we introduce DiaKG, a\nhigh-quality Chinese dataset for Diabetes knowledge graph, which contains\n22,050 entities and 6,890 relations in total. We implement recent typical\nmethods for Named Entity Recognition and Relation Extraction as a benchmark to\nevaluate the proposed dataset thoroughly. Empirical results show that the DiaKG\nis challenging for most existing methods and further analysis is conducted to\ndiscuss future research direction for improvements. We hope the release of this\ndataset can assist the construction of diabetes knowledge graphs and facilitate\nAI-based applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Dejie Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mosha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaozhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongdong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1\">Fei Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bangchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiaobin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bilateral Personalized Dialogue Generation with Contrastive Learning. (arXiv:2106.07857v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.07857","description":"<p>Generating personalized responses is one of the major challenges in natural\nhuman-robot interaction. Current researches in this field mainly focus on\ngenerating responses consistent with the robot's pre-assigned persona, while\nignoring the user's persona. Such responses may be inappropriate or even\noffensive, which may lead to the bad user experience. Therefore, we propose a\nBilateral Personalized Dialogue Generation (BPDG) method for dyadic\nconversation, which integrates user and robot personas into dialogue generation\nvia designing a dynamic persona-aware fusion method. To bridge the gap between\nthe learning objective function and evaluation metrics, the Conditional Mutual\nInformation Maximum (CMIM) criterion is adopted with contrastive learning to\nselect the proper response from the generated candidates. Moreover, a bilateral\npersona accuracy metric is designed to measure the degree of bilateral\npersonalization. Experimental results demonstrate that, compared with several\nstate-of-the-art methods, the final results of the proposed method are more\npersonalized and consistent with bilateral personas in terms of both automatic\nand manual evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Hanjun Deng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scientific Language Models for Biomedical Knowledge Base Completion: An Empirical Study. (arXiv:2106.09700v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.09700","description":"<p>Biomedical knowledge graphs (KGs) hold rich information on entities such as\ndiseases, drugs, and genes. Predicting missing links in these graphs can boost\nmany important applications, such as drug design and repurposing. Recent work\nhas shown that general-domain language models (LMs) can serve as \"soft\" KGs,\nand that they can be fine-tuned for the task of KG completion. In this work, we\nstudy scientific LMs for KG completion, exploring whether we can tap into their\nlatent knowledge to enhance biomedical link prediction. We evaluate several\ndomain-specific LMs, fine-tuning them on datasets centered on drugs and\ndiseases that we represent as KGs and enrich with textual entity descriptions.\nWe integrate the LM-based models with KG embedding models, using a router\nmethod that learns to assign each input example to either type of model and\nprovides a substantial boost in performance. Finally, we demonstrate the\nadvantage of LM models in the inductive setting with novel scientific entities.\nOur datasets and code are made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nadkarni_R/0/1/0/all/0/1\">Rahul Nadkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1\">David Wadden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"You should evaluate your language model on marginal likelihood over tokenisations. (arXiv:2109.02550v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.02550","description":"<p>Neural language models typically tokenise input text into sub-word units to\nachieve an open vocabulary. The standard approach is to use a single canonical\ntokenisation at both train and test time. We suggest that this approach is\nunsatisfactory and may bottleneck our evaluation of language model performance.\nUsing only the one-best tokenisation ignores tokeniser uncertainty over\nalternative tokenisations, which may hurt model out-of-domain performance.\n</p>\n<p>In this paper, we argue that instead, language models should be evaluated on\ntheir marginal likelihood over tokenisations. We compare different estimators\nfor the marginal likelihood based on sampling, and show that it is feasible to\nestimate the marginal likelihood with a manageable number of samples. We then\nevaluate pretrained English and German language models on both the\none-best-tokenisation and marginal perplexities, and show that the marginal\nperplexity can be significantly better than the one best, especially on\nout-of-domain data. We link this difference in perplexity to the tokeniser\nuncertainty as measured by tokeniser entropy. We discuss some implications of\nour results for language model training and evaluation, particularly with\nregard to tokenisation robustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_K/0/1/0/all/0/1\">Kris Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rimell_L/0/1/0/all/0/1\">Laura Rimell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perspective-taking and Pragmatics for Generating Empathetic Responses Focused on Emotion Causes. (arXiv:2109.08828v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.08828","description":"<p>Empathy is a complex cognitive ability based on the reasoning of others'\naffective states. In order to better understand others and express stronger\nempathy in dialogues, we argue that two issues must be tackled at the same\ntime: (i) identifying which word is the cause for the other's emotion from his\nor her utterance and (ii) reflecting those specific words in the response\ngeneration. However, previous approaches for recognizing emotion cause words in\ntext require sub-utterance level annotations, which can be demanding. Taking\ninspiration from social cognition, we leverage a generative estimator to infer\nemotion cause words from utterances with no word-level label. Also, we\nintroduce a novel method based on pragmatics to make dialogue models focus on\ntargeted words in the input during generation. Our method is applicable to any\ndialogue models with no additional training on the fly. We show our approach\nimproves multiple best-performing dialogue agents on generating more focused\nempathetic responses in terms of both automatic and human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Byeongchang Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What BERT Based Language Models Learn in Spoken Transcripts: An Empirical Study. (arXiv:2109.09105v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.09105","description":"<p>Language Models (LMs) have been ubiquitously leveraged in various tasks\nincluding spoken language understanding (SLU). Spoken language requires careful\nunderstanding of speaker interactions, dialog states and speech induced\nmultimodal behaviors to generate a meaningful representation of the\nconversation. In this work, we propose to dissect SLU into three representative\nproperties:conversational (disfluency, pause, overtalk), channel (speaker-type,\nturn-tasks) and ASR (insertion, deletion,substitution). We probe BERT based\nlanguage models (BERT, RoBERTa) trained on spoken transcripts to investigate\nits ability to understand multifarious properties in absence of any speech\ncues. Empirical results indicate that LM is surprisingly good at capturing\nconversational properties such as pause prediction and overtalk detection from\nlexical tokens. On the downsides, the LM scores low on turn-tasks and ASR\nerrors predictions. Additionally, pre-training the LM on spoken transcripts\nrestrain its linguistic understanding. Finally, we establish the efficacy and\ntransferability of the mentioned properties on two benchmark datasets:\nSwitchboard Dialog Act and Disfluency datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ayush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundararaman_M/0/1/0/all/0/1\">Mukuntha Narayanan Sundararaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vepa_J/0/1/0/all/0/1\">Jithendra Vepa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Crowdsourcing Protocols for Evaluating the Factual Consistency of Summaries. (arXiv:2109.09195v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.09195","description":"<p>Current pre-trained models applied to summarization are prone to factual\ninconsistencies which either misrepresent the source text or introduce\nextraneous information. Thus, comparing the factual consistency of summaries is\nnecessary as we develop improved models. However, the optimal human evaluation\nsetup for factual consistency has not been standardized. To address this issue,\nwe crowdsourced evaluations for factual consistency using the rating-based\nLikert scale and ranking-based Best-Worst Scaling protocols, on 100 articles\nfrom each of the CNN-Daily Mail and XSum datasets over four state-of-the-art\nmodels, to determine the most reliable evaluation framework. We find that\nranking-based protocols offer a more reliable measure of summary quality across\ndatasets, while the reliability of Likert ratings depends on the target dataset\nand the evaluation design. Our crowdsourcing templates and summary evaluations\nwill be publicly available to facilitate future research on factual consistency\nin summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Ziming Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_G/0/1/0/all/0/1\">Griffin Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Borui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-21T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}