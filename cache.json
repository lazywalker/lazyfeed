{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.1","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-08-30T01:49:53.272297370Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"构建安全易用的链表","link":"https://rustcc.cn/article?id=273831e7-932d-476f-9d31-323151afb123","description":"<p>写了一个链表的Crate，愿景是构建安全且易用的链表。</p>\n<p>欢迎大家来找茬（Bug）或提需求 :)</p>\n<p>Crate IO链接：<a href=\"https://crates.io/crates/cyclic_list\" rel=\"noopener noreferrer\">https://crates.io/crates/cyclic_list</a>;</p>\n<p>GitHub链接：<a href=\"https://github.com/whjpji/cyclic_list\" rel=\"noopener noreferrer\">https://github.com/whjpji/cyclic_list</a></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 15:10:34","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-08-29 Tangram：训练、部署和监控机器学习模型","link":"https://rustcc.cn/article?id=4a218f6c-3c77-4aa0-84d6-90ac2bf1fc7c","description":"<h3>Embedded Rust 第一步：选择一块板子</h3>\n<p>内容整理自 <a href=\"https://github.com/robyoung\" rel=\"noopener noreferrer\">robyoung (Rob Young)</a> 的文章：First steps with Embedded Rust: Selecting a board</p>\n<p>有这么多令人眼花缭乱的微控制器和项目，对于嵌入式经验很少的人来说应该从哪里开始？</p>\n<p><strong>我们在开发板中想要什么？</strong></p>\n<ul>\n<li>良好的架构支持</li>\n<li>良好的芯片支持</li>\n<li>活跃的社区</li>\n<li>内置调试器</li>\n</ul>\n<p><strong>我们需要什么架构？</strong></p>\n<p>拥有最完整库、最详尽指南和最大社区的架构是 ARM Cortex-M。 ARM Cortex-M 是面向微控制器应用的低功耗、低成本处理器。 查看 crates.io 上的下载量虽说不是一个完美的指标，但可以让我们了解规模上的差异。在过去的 90 天内，cortex-m 的下载量超过 250k。 RISC-V、AVR 或 Xtensa 最多有 3k 次下载，cortex-a 有大约 18k 次下载。ARM Cortex-M 独树一帜。</p>\n<ul>\n<li>AVR：AVR 是用于嵌入式系统的 8 位微控制器系列。在 Rust 生态系统中，它们并没有得到很好的支持。直到最近，还需要使用 rustc 的一个分支来构建 AVR。 现在有几个不同的选择，awesome-avr-rust 是一个很好的起点。</li>\n<li>ARM Cortex-A：更强大的多核 ARM 处理器，专为运行更大的东西而设计。 通常会在它们上运行完整的操作系统。  例如这是大多数智能手机和掌上游戏机中使用的架构。查看 <a href=\"https://crates.io/crates/cortex-a\" rel=\"noopener noreferrer\">cortex-a - crates.io: Rust Package Registry</a> 了解更多。</li>\n<li>RISC-V：似乎是机器架构的新热点，它是一种免费且开放的指令集架构 (ISA)。  它也从一开始就被设计成模块化的，这意味着芯片设计人员可以创建各种各样的专用芯片，虽然目前开发板的范围很小。有一个活跃的 Rust RISC-V 社区，SiFive 或 www.riscv.org 都是不错的起点，Rust 方面，可以查看 riscv crate。</li>\n<li>Xtensa：最受欢迎的主板组是来自 Espressif 的 ESP32 系列芯片。它们是小型、廉价、支持 WiFi 的电路板。  需要注意的是，并非所有 ESP32 开发板都使用 Xtensa 芯片，新的 ESP32-C3 是基于 RISC-V 的。在 Xtensa 芯片上使用 Rust 的最大障碍可能是 llvm 不支持它，因此需要构建 Rust 的 fork：<a href=\"https://github.com/esp-rs/rust\" rel=\"noopener noreferrer\">esp-rs/rust</a>。</li>\n</ul>\n<p><strong>我们需要什么芯片？</strong></p>\n<p>因此，我们将使用 ARM Cortex-M。  这缩小了搜索范围，但仍有很多选择。如果我们查看 cortex-m <a href=\"https://crates.io/crates/cortex-m/reverse_dependencies\" rel=\"noopener noreferrer\">crate</a> 的依赖项，我们会看到有两组芯片比其他任何一组都使用得更多； <a href=\"https://www.st.com/content/st_com/en/products/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html\" rel=\"noopener noreferrer\">STM32</a> 系列芯片和 <a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy\" rel=\"noopener noreferrer\">nRF5</a> 系列，这是我们要重点搜索的地方。</p>\n<ul>\n<li>STM32：STM32 系列芯片可能是应用最广泛的嵌入式 Rust ARM Cortex-M 芯片。两种最受欢迎的 STM32 板是 Blue Pill 和 Black Pill。主要的缺点是没有板载调试器。如果想要带有调试器的基于 STM32 的电路板，那么获得 STMicroelectronics <a href=\"https://www.st.com/en/evaluation-tools/stm32-discovery-kits.html#overview\" rel=\"noopener noreferrer\">官方套件</a>是一个不错的选择（STM32F3 或 STM32F4 是不错的选择）。Rust Embedded Discovery 书的原始版本是针对 STM32F3 板编写的，因此有非常高质量的初学者文档，可以从那里开始。</li>\n<li>nRF5：用于嵌入式 Rust 的第二个最广泛使用的 ARM Cortex-M 芯片系列是 Nordic Semiconductor 的 <a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy\" rel=\"noopener noreferrer\">nRF5 系列</a>。官方开发<a href=\"https://www.nordicsemi.com/Products/Bluetooth-Low-Energy/Development-hardware\" rel=\"noopener noreferrer\">套件</a> (DK) 是很棒的入门板。 Ferrous Systems 的 Knurling-rs 会议使用 nRF52840 <a href=\"https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK\" rel=\"noopener noreferrer\">开发套件</a>。Knurling 课程质量非常高，手把手指导，通过有趣好玩的项目教授嵌入 Rust，是使用 Rust 进行嵌入式开发的最佳切入点。另一个很棒的基于 nRF 的开发板是 <a href=\"https://www.microbit.org/\" rel=\"noopener noreferrer\">BBC micro:bit</a>。它配备了板载调试器和一系列有趣的板载外围设备，如板上的 LED 显示屏、按钮和传感器。BBC micro:bit 被设计为一个教育平台，因此硬件在他们的<a href=\"https://tech.microbit.org/\" rel=\"noopener noreferrer\">开发者社区</a>中以非常适合初学者的方式进行记录，并且互联网上有大量项目创意。</li>\n<li>RP2040：<a href=\"https://www.raspberrypi.org/documentation/rp2040/getting-started/\" rel=\"noopener noreferrer\">RP2040</a> 于 2020 年底发布，是 Raspberry Pi 基金会首次尝试设计自己的芯片。由于如此新，Rust 对它的支持仍在开发中。与 BBC micro:bit 一样，RP2040 旨在成为一个教育平台，因此硬件文档是一流的，并且有大量初学者友好的代码示例和其他编程语言的库（没有多少适合初学者的嵌入式 Rust 文档）。这是一个非常令人兴奋的平台，并且在 Embedded Rust 社区中围绕它进行了大量活动，所以一定要密切关注，但它可能不适合作为入门第一块板。</li>\n</ul>\n<p><strong>板载调试器？</strong></p>\n<p>在主机上运行程序时，可以在 shell 中运行它并查看打印输出。这在嵌入式目标上更加困难，调试器填补了这一空白。除了允许单步调试、断点调试外，它还允许将程序加载到设备上并轻松查看输出。不过有一个问题，它通常是连接到主机然后连接到目标设备的单独设备。第一次开始时，这是一笔不可忽视的费用，也是必须正确设置的另一件事。幸运的是，有些设备带有内置调试器，将它们直接插入主机并在瞬间探测运行的代码（通常需要在主机上进行一些设置才能使调试器正常工作，ferrous 有一个很好的设置<a href=\"https://session20q4.ferrous-systems.com/sessions/installation.html\" rel=\"noopener noreferrer\">指南</a>）。</p>\n<p><strong>结论</strong></p>\n<p>以下这些板都有很棒的 HAL 和 BSP crate、活跃友好的社区和板载调试器。</p>\n<ul>\n<li><a href=\"https://www.microbit.org/\" rel=\"noopener noreferrer\">BBC micro:bit</a>（约 13 英镑）：它是新版 Rust Embedded Discovery 书中使用的板。</li>\n<li><a href=\"https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK\" rel=\"noopener noreferrer\">nRF52840 开发套件</a>（约 35 英镑）；  它是 Ferrous Systems 在 Kunrling 会议和培训中使用的板。</li>\n<li><a href=\"https://www.st.com/en/evaluation-tools/stm32f3discovery.html\" rel=\"noopener noreferrer\">STM32F3 探索套件</a>（约 14 英镑）；  它是 Rust Embedded Discovery 书的第一版中使用的板。</li>\n</ul>\n<p>密切关注：</p>\n<ul>\n<li><a href=\"https://www.raspberrypi.org/products/raspberry-pi-pico/\" rel=\"noopener noreferrer\">Raspberry Pi Pico</a>（约 6 英镑，带预焊引脚）； ARM Cortex-M 但没有内置调试器，HAL 仍在开发中。不过目前有很多活动，进展很快。</li>\n<li><a href=\"https://www.sifive.com/boards/hifive1-rev-b\" rel=\"noopener noreferrer\">HiFive1 Rev B</a>（约 50 英镑）； RISC-V 是新的热点。 Rust 中似乎有很多围绕它的活动，但它目前还没有 ARM Cortex-M 的支持。  其他需要关注的开发板是 <a href=\"https://longan.sipeed.com/en/\" rel=\"noopener noreferrer\">Logan Nano</a> 和 <a href=\"https://hackaday.com/2021/02/08/hands-on-the-risc-v-esp32-c3-will-be-your-new-esp8266/\" rel=\"noopener noreferrer\">ESP32-C3</a>。</li>\n</ul>\n<p>部分内容略有轻微调整，更多可阅读原文：<a href=\"https://robyoung.digital/blog/embedded-rust-selecting-a-board/\" rel=\"noopener noreferrer\">Rob Young | digital</a></p>\n<h3>Tangram：训练、部署和监控机器学习模型</h3>\n<p>一个机器学习套件，使用方法如下：</p>\n<pre><code># 训练\n$ tangram train --file heart_disease.csv --target diagnosis --output heart_disease.tangram\n</code></pre>\n<p>推理支持多种语言：<a href=\"https://hex.pm/packages/tangram\" rel=\"noopener noreferrer\">Elixir</a>, <a href=\"https://pkg.go.dev/github.com/tangramdotdev/tangram-go\" rel=\"noopener noreferrer\">Go</a>, <a href=\"https://www.npmjs.com/package/@tangramdotdev/tangram\" rel=\"noopener noreferrer\">JavaScript</a>, <a href=\"https://pypi.org/project/tangram\" rel=\"noopener noreferrer\">Python</a>, <a href=\"https://rubygems.org/gems/tangram\" rel=\"noopener noreferrer\">Ruby</a> 和 <a href=\"https://lib.rs/tangram\" rel=\"noopener noreferrer\">Rust</a>，以 Rust 为例：</p>\n<pre><code>let model: tangram::Model = tangram::Model::from_path(\"heart_disease.tangram\", None).unwrap();\n\nlet input = tangram::predict_input! {\n  \"age\": 63.0,\n  \"gender\": \"male\",\n  // ...\n};\n\nlet output = model.predict_one(input, None);\n# { className: 'Negative', probability: 0.9381780624389648 }\n</code></pre>\n<p>很好奇训练的时候居然没有要指定模型，发现其将模型共分为三类：回归、二分类和多分类，训练时会根据数据自动选择合适（使用评估方法）的模型，每种模型又有两种不同的训练方法：线性方法和树方法。</p>\n<p>自带的监控功能看起来还不错，比如下面这张可以展示特征对输出的贡献：</p>\n<p><img src=\"https://github.com/tangramdotdev/tangram/raw/main/readme/predictions.png\" alt=\"\"></p>\n<p>项目理论上可以用在简单机器学习场景下，尤其是那些还没有支持机器学习的语言，不过推理并没有 Benchmark，生产中使用需要做好性能测试。</p>\n<p>GitHub：<a href=\"https://github.com/tangramdotdev/tangram\" rel=\"noopener noreferrer\">tangramdotdev/tangram: Tangram makes it easy for programmers to train, deploy, and monitor machine learning models.</a></p>\n<p>文档：<a href=\"https://www.tangram.dev/docs/\" rel=\"noopener noreferrer\">Tangram</a></p>\n<h3>lateral：一个在 x86_64 上启动的模块化内核</h3>\n<p>在本地执行：</p>\n<pre><code>$ make run-release ARCH=x86_64\n</code></pre>\n<p>可以根据自己的情况调整 Makefile 第一行 Bash 的配置。执行后如果有安装 QEMU 的话会自动加载：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/tmp-os-1.jpg\" alt=\"\"></p>\n<p>每个组件都建立在窗口管理器之上，而不是像大多数操作系统那样建立在终端之上。</p>\n<p>GitHub：<a href=\"https://github.com/carterisonline/lateral\" rel=\"noopener noreferrer\">carterisonline/lateral: A clean, custom-built modular kernel ready to boot on x86_64.</a></p>\n<h3>tv：显示表格的 cli 工具</h3>\n<p>就是把 json 或 csv 显示成表格，看起来很不错：</p>\n<pre><code>$ cat test.json\n[\n  {\n    \"name\": \"test\",\n    \"age\": 10,\n    \"lang\": \"ja\"\n  },\n  {\n    \"name\": \"uzimaru\",\n    \"age\": 23,\n    \"lang\": \"ja\"\n  },\n  {\n    \"name\": \"hogehoge\",\n    \"age\": 21,\n    \"lang\": \"en\"\n  },\n  {\n    \"name\": \"hugehuge\",\n    \"age\": 32,\n    \"lang\": \"en\"\n  }\n]\n\n$ tv test.json\n|age|lang|    name|\n|---|----|--------|\n| 10|  ja|    test|\n| 23|  ja| uzimaru|\n| 21|  en|hogehoge|\n| 32|  en|hugehuge|\n\n$ cat test.csv\nname,age,lang\ntest,10,ja\nuzimaru,23,ja\nhogehoge,21,en\nhugehuge,32,en\n\n$ tv test.csv\n|age|lang|    name|\n|---|----|--------|\n| 10|  ja|    test|\n| 23|  ja| uzimaru|\n| 21|  en|hogehoge|\n| 32|  en|hugehuge|\n</code></pre>\n<p>Mac 用户 brew 安装：</p>\n<pre><code>$ brew install uzimaru0000/tap/tv\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/uzimaru0000/tv\" rel=\"noopener noreferrer\">uzimaru0000/tv: CLI tool for displaying table</a></p>\n<h3>minesweeper：使用 Rust，WebAssembly 和 Canvas 的扫雷游戏</h3>\n<p>界面长这样：</p>\n<p><img src=\"https://github.com/KarthikNedunchezhiyan/minesweeper/raw/main/www/assets/stage_bomb_triggered.png\" alt=\"\"></p>\n<p>是很好的学习资料。在这里玩儿：<a href=\"https://karthiknedunchezhiyan.me/minesweeper/\" rel=\"noopener noreferrer\">Minesweeper</a></p>\n<p>GitHub：<a href=\"https://github.com/karthikNedunchezhiyan/minesweeper\" rel=\"noopener noreferrer\">KarthikNedunchezhiyan/minesweeper: Minesweeper game developed with Rust, WebAssembly (Wasm), and Canvas</a></p>\n<h3>copy-translator：划词翻译</h3>\n<p>复制后翻译，使用 DeepL 的 API，不过目前只有 Local 版本好用：</p>\n<p><img src=\"http://qnimg.lovevivian.cn/tmp-rust-1.jpg\" alt=\"\"></p>\n<p>当然，也可以使用 Eudic（欧路词典）。</p>\n<p>GitHub：<a href=\"https://github.com/zu1k/copy-translator\" rel=\"noopener noreferrer\">zu1k/copy-translator: Copy Translator, using DeepL api</a></p>\n<h3>veccentric：小巧的 2-D 向量 Library</h3>\n<p>项目受 <a href=\"https://p5js.org/reference/#/p5.Vector\" rel=\"noopener noreferrer\">p5.Vector</a> 启发，使用方法如下：</p>\n<pre><code>use veccentric::Vecc;\n\nlet a = Vecc::new(3_i32, 4);\nlet b = a * 5;\nlet c = Vecc::new(-10, -8);\nlet d = b - c;\nlet e = -d;\n</code></pre>\n<p>GitHub：<a href=\"https://github.com/micouy/veccentric\" rel=\"noopener noreferrer\">micouy/veccentric: Tiny 2D vector library. Inspired by p5.js's p5.Vector.</a></p>\n<hr>\n<p>From 日报小组 长琴</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc 论坛：支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 12:17:36","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"axum如何使用静态文件目录","link":"https://rustcc.cn/article?id=f3fa9c8e-004b-4d95-8d5f-bdf6609c2e8e","description":"<p>再重构一个简单的单页面小程序的时候打算用<code>axum</code>代替<code>warp</code>的时候遇到了个问题。</p>\n<pre><code>    let post = warp::post()\n        .and(warp::body::bytes())\n        .map(move |content: Bytes| {\n            Response::builder().body(server::handle_post_request(content))\n        });\n\n    let routers = warp::get().and(warp::fs::dir(\"./wwwroot\")).or(post);\n\n    warp::serve(routers).run(([127, 0, 0, 1], 3030)).await;\n</code></pre>\n<p>有如上的简单代码，使用<code>wwwroot</code>文件夹目录来生成页面，文件夹里包含有<code>index.html</code>,JS和CSS文件，怎么使用<code>axum</code>改写呢？看了下doc，只看到</p>\n<pre><code>let app = Router::new()\n    // this route cannot fail\n    .route(\"/foo\", get(|| async {}))\n    // this route can fail with io::Error\n    .route(\n        \"/\",\n        service::get(service_fn(|_req: Request&lt;Body&gt;| async {\n            let contents = tokio::fs::read_to_string(\"some_file\").await?;\n            Ok::&lt;_, io::Error&gt;(Response::new(Body::from(contents)))\n        }))\n        .handle_error(handle_io_error),\n    );\n\nfn handle_io_error(error: io::Error) -&gt; Result&lt;impl IntoResponse, Infallible&gt; {\n    // ...\n}\n</code></pre>\n<p>这种写法。看着头大不说，那个<code>some_file</code>只是简单读取文件，完成不了我的要求。</p>\n<p>有大神说说axum完成了这个部分了吗？这框架的代码看着感觉有点过于复杂了。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 07:28:13","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"自己管理内存的测试方法","link":"https://rustcc.cn/article?id=d4e8f317-f43f-44ea-a041-f39dd3ce1578","description":"<p>很漂亮的一段case，来自std</p>\n<p>library/alloc/tests/linked_list.rs</p>\n<pre><code>#[test]\nfn test_drop() {\n    static mut DROPS: i32 = 0;\n    struct Elem;\n    impl Drop for Elem {\n        fn drop(&amp;mut self) {\n            unsafe {\n                DROPS += 1;\n            }\n        }\n    }\n\n    let mut ring = LinkedList::new();\n    ring.push_back(Elem);\n    ring.push_front(Elem);\n    ring.push_back(Elem);\n    ring.push_front(Elem);\n    drop(ring);\n\n    assert_eq!(unsafe { DROPS }, 4);\n}\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 07:14:22","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"问一个Display trait的问题","link":"https://rustcc.cn/article?id=6b59dfb1-87d8-4b79-8820-e9d5397f178a","description":"<p>请问&amp;str, &amp;&amp;str, &amp;&amp;&amp;str 并没有实现Display 的trait, 为什么这个函数调用没问题?</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-29 06:12:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-28 开源操作系统夏令营最终报告会安排","link":"https://rustcc.cn/article?id=ef3dd4e8-a8e8-4fec-bc7e-75703e1117ff","description":"<h3>开源操作系统夏令营最终报告会安排</h3>\n<p>会议主题：开源操作系统夏令营最终报告会\n会议时间：2021/08/29 09:00-11:30 (GMT+08:00) 中国标准时间 - 北京\n点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/Mp7T1h5zeQOk?rs=25\n会议 ID：635 194 989</p>\n<p>下面是9位全程参与夏令营活动同学的报告顺序。每人报告时间最长15分钟。</p>\n<ol>\n<li>杨云枫 王涛 Rustsbi的哪吒开发版移植</li>\n<li>兰陈昕 zCore图形支持</li>\n<li>都秉甲 容器技术学习</li>\n<li>薛潇巍 RVM 的 RISC-V 支持</li>\n<li>陈乐 共享调度器</li>\n<li>吴非凡 基于用户态中断的异步系统调用设计与实现</li>\n<li>彭淳毅 陈志扬 基于rCore-Tutorial的性能分析软件实现</li>\n</ol>\n<h3>crates.live：可视化 Rust crates 依赖项</h3>\n<p>crates.live 是来自 crates.io 的 Rust crates 的依赖可视化工具。 它显示了 Rust crates（包）的依赖树。功能包括：</p>\n<ul>\n<li>依赖解析， crates.live 引擎通过匹配依赖版本来完成完整的依赖解析。</li>\n<li>交互式图表，带有标记的板条箱的可缩放交互式图表。</li>\n<li>图像导出， 将图形导出为 PNG。</li>\n<li>开放 API：（即将推出）GraphQL API。</li>\n</ul>\n<p>crates.live 使用了一堆技术框架，技术栈包括：</p>\n<ul>\n<li>Rust， crates.live 后端和爬虫是用 Rust 和开源 Rust 库开发的。</li>\n<li>GraphQl， WASM 驱动的 GraphQL 服务器。</li>\n<li>React/Bulma， 前端库。</li>\n<li>Terraform， 帮助启动和维护我们的基础设施。</li>\n<li>Cloudflare， Cloudflare 工作人员运行 WASM 后端。</li>\n</ul>\n<p>如果在使用此应用程序时有任何疑问、建议或问题； 可以通过 contact@crates.live 联系。 crates.live 由 Abid Omar 开发，可通过 contact@omarabid.com 联系。</p>\n<p><a href=\"https://crates.live/\" rel=\"noopener noreferrer\">链接</a>：https://crates.live/</p>\n<h3>Obake，版本化数据结构</h3>\n<p>Obake 是一个用于声明和维护版本化数据结构的过程宏。 “obake”这个名字取自日语“お化け（おばけ）”，这是日本民间传说中一类会变形的超自然生物。</p>\n<p>在开发应用程序时，配置格式和内部数据结构通常会在版本之间演变。 然而，保持这些版本之间的向后兼容性需要声明和维护遗留格式的数据结构和用于在它们之间迁移的代码。 Obake 的目标是让这个过程变得轻松。</p>\n<pre><code>#[obake::versioned]                 // create a versioned data-structure\n#[obake(version(\"0.1.0\"))]          // declare some versions\n#[obake(version(\"0.2.0\"))]\n#[derive(PartialEq, Eq, Hash)]      // additional attributes are applied to all versions\nstruct Foo {\n    #[obake(cfg(\"0.1.0\"))]          // enable fields for specific versions with\n    foo: String,                    // semantic version constraints\n   \n    #[obake(cfg(\"&gt;=0.2, &lt;=0.3.0\"))] // any semantic version constraint can appear in\n    bar: u32,                       // a `cfg` attribute \n   \n    #[obake(cfg(\"0.1.0\"))]          // multiple `cfg` attributes are treated as a\n    #[obake(cfg(\"&gt;=0.3\"))]          // disjunction over version constraints\n    baz: char,\n}\n\n// describe migrations between versions using the `From` trait\n// and an automatically generated type-level macro for referring to\n// specific versions of `Foo`\nimpl From&lt;Foo![\"0.1.0\"]&gt; for Foo![\"0.2.0\"] {\n    fn from(foo: Foo![\"0.1.0\"]) -&gt; Self {\n        Self { bar: 0 }\n    }\n}\n\n// an enumeration of all versions of `Foo` is accessed using the\n// `obake::Versioned` trait:\nlet versioned_example: &lt;Foo as obake::Versioned&gt;::Versioned = unimplemented!();\n\n// this enumeration implements `Into&lt;Foo&gt;`, where `Foo` is the latest declared\n// version of `Foo` (in this case, `Foo![\"0.2.0\"]`)\nlet example: Foo = versioned_example.into();\n</code></pre>\n<p>Github<a href=\"https://github.com/doctorn/obake\" rel=\"noopener noreferrer\">链接</a>：https://github.com/doctorn/obake</p>\n<h3>iced，跨平台 GUI 库</h3>\n<p>iced，Rust 的跨平台 GUI 库，专注于简单性和类型安全。 灵感来自<a href=\"https://elm-lang.org/\" rel=\"noopener noreferrer\">Elm</a>。</p>\n<p><img src=\"https://raw.githubusercontent.com/hecrj/iced/master/docs/graphs/ecosystem.png\" alt=\"eco\"></p>\n<p>Github<a href=\"https://github.com/hecrj/iced/\" rel=\"noopener noreferrer\">链接</a>：https://github.com/hecrj/iced/</p>\n<p>示例：https://github.com/hecrj/iced/tree/master/examples</p>\n<hr>\n<p>From 日报小组 <a href=\"https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929\" rel=\"noopener noreferrer\">洋芋</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-28 15:42:07","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust 日报】2021-8-27 Rudra Rust 的内存安全和未定义行为检测工具","link":"https://rustcc.cn/article?id=ce7eb559-fdda-45d7-a53e-293af787a813","description":"<h4>Rudra Rust 的内存安全和未定义行为检测工具</h4>\n<p>Rudra 是一个静态分析器，用于检测 Rust 程序中常见的未定义行为。它能够分析单个 Rust 包以及 crates.io 上的所有包。Rudra 及其相关论文将在 Proceedings of the 28th ACM Symposium on Operating Systems Principles 2021 (SOSP '21) 上发表。</p>\n<ul>\n<li>https://github.com/sslab-gatech/Rudra#readme</li>\n</ul>\n<h4>nom 7.0 版本发布</h4>\n<p>nom 是一个用 Rust 编写的解析器组合库。它的目标是提供工具来构建安全的解析器，而不会影响速度或内存消耗。为此，它广泛使用 Rust 的强类型和内存安全来生成快速且正确的解析器，并提供函数、宏和特征来抽象大部分容易出错的管道。目前7.0已经发布</p>\n<ul>\n<li>https://crates.io/crates/nom</li>\n</ul>\n<h4>egui 0.14 版本发布</h4>\n<p>egui 是一个易于使用的纯 Rust 图形用户界面。egui 可以在 Web 上、本机上以及您最喜欢的游戏引擎中运行。egui 旨在成为最容易使用的 Rust GUI 库，以及在 Rust 中制作 Web 应用程序的最简单方法，它可以在任何可以绘制纹理三角形的地方使用，这意味着您可以轻松地将其集成到您选择的游戏引擎中。</p>\n<ul>\n<li>演示文档：https://emilk.github.io/egui/</li>\n<li>https://github.com/emilk/egui</li>\n</ul>\n<hr>\n<p>From 日报小组 北纬27度，侯盛鑫</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 14:27:47","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"开源项目xiu登上了GitHub rust trending榜","link":"https://rustcc.cn/article?id=86c83d9a-8370-42cf-8993-ef15af6932c4","description":"<p><a href=\"https://github.com/harlanc/xiu\" rel=\"noopener noreferrer\">https://github.com/harlanc/xiu</a></p>\n<p><a href=\"https://github.com/trending/rust?since=daily\" rel=\"noopener noreferrer\">https://github.com/trending/rust?since=daily</a></p>\n<p>感谢大家的支持！！</p>\n<p>PS：</p>\n<p>前三名有两个都在论坛里发过，这个论坛有点狠，哈哈</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 10:43:48","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Salvo - 一个简单的 Web 后端框架","link":"https://rustcc.cn/article?id=e5dc5be9-b1ab-488f-8944-dd7cd97b0128","description":"<h2>为什么要写这个框架</h2>\n<p>因为我笨，无法学会使用 actix-web 等现存的框架。当我想把以前的 go 的 web 服务使用 rust 实现时，一眼看去，似乎每个框架都比 go 里存在框架复杂, 本来 Rust 的学习曲线就够陡峭的了, 又何苦把 Web 框架整得那么复杂?</p>\n<h2>如何做到足够简单</h2>\n<p>很多底层的实现 Hyper 都已经实现，所以，一般需求，基于 Hyper 实现应该没有错。Salvo 也是一样。 核心功能是提供还用简单的API，以及一个功能强大并且灵活的路由系统。</p>\n<p>Salvo 里统一了 Handler 和 Middleware. Middleware 就是 Handler. 通过路由的 before 或者 after 添加到 Router 上。本质上, Middleware 和 Handler 都是处理 Request 请求，并且可能向 Response 写入数据。而 Handler 接收的参数是 Request, Depot, Response 三个, 其中 Depot 用于存储请求处理过程中的临时数据. 为方便书写, 在用不着的情况下可以省略掉某些参数.</p>\n<pre><code>use Salvo::prelude::*;\n\n#[fn_handler]\nasync fn hello_world(_req: &amp;mut Request, _depot: &amp;mut Depot, res: &amp;mut Response) {\n    res.render_plain_text(\"Hello World\");\n}\n#[fn_handler]\nasync fn hello_world2(res: &amp;mut Response) {\n    res.render_plain_text(\"Hello World\");\n}\n</code></pre>\n<p>另外路由系统提供的 API 也是极其简单的, 但是, 功能却是强大的. 正常使用需求下, 基本上就是只关注 Router 一个类型即可.</p>\n<h3>路由系统</h3>\n<p>我自己感觉路由系统是跟其他的框架不太一样的. Router 可以写平，也可以写成树状。这里区业务逻辑树与访问目录树。业务逻辑树是根据业务逻辑需求，划分 router 结构，形成 router 树，它不一定与访问目录树一致。</p>\n<p>正常情况下我们是这样写路由的：</p>\n<pre><code>Router::new().path(\"articles\").get(list_articles).post(create_article);\nRouter::new()\n    .path(\"articles/&lt;id&gt;\")\n    .get(show_article)\n    .patch(edit_article)\n    .delete(delete_article);\n</code></pre>\n<p>往往查看文章和文章列表是不需要用户登录的, 但是创建, 编辑, 删除文章等需要用户登录认证权限才可以. Salvo 中支持嵌套的路由系统可以很好地满足这种需求. 我们可以把不需要用户登录的路由写到一起：</p>\n<pre><code>Router::new()\n    .path(\"articles\")\n    .get(list_articles)\n    .push(Router::new().path(\"&lt;id&gt;\").get(show_article));\n</code></pre>\n<p>然后把需要用户登录的路由写到一起， 并且使用相应的中间件验证用户是否登录：</p>\n<pre><code>Router::new()\n    .path(\"articles\")\n    .before(auth_check)\n    .post(list_articles)\n    .push(Router::new().path(\"&lt;id&gt;\").patch(edit_article).delete(delete_article));\n</code></pre>\n<p>虽然这两个路由都有这同样的 <code>path(\"articles\")</code>, 然而它们依然可以被同时添加到同一个父路由, 所以最后的路由长成了这个样子:</p>\n<pre><code>Router::new()\n    .push(\n        Router::new()\n            .path(\"articles\")\n            .get(list_articles)\n            .push(Router::new().path(\"&lt;id&gt;\").get(show_article)),\n    )\n    .push(\n        Router::new()\n            .path(\"articles\")\n            .before(auth_check)\n            .post(list_articles)\n            .push(Router::new().path(\"&lt;id&gt;\").patch(edit_article).delete(delete_article)),\n    );\n</code></pre>\n<p><code>&lt;id&gt;</code>匹配了路径中的一个片段, 正常情况下文章的 <code>id</code> 只是一个数字, 这是我们可以使用正则表达式限制 <code>id</code> 的匹配规则, <code>r\"&lt;id:/\\d+/&gt;\"</code>.</p>\n<p>更多信息可以查看网站 https://salvo.rs</p>\n<p>源码地址: https://github.com/salvo-rs/salvo</p>\n<p>非常欢迎大家为项目贡献力量，可以通过以下方法为项目作出贡献:</p>\n<ul>\n<li>在 issue 中提交功能需求和 bug report;</li>\n<li>在 issues 或者 require feedback 下留下自己的意见;</li>\n<li>通过 pull requests 提交代码;</li>\n<li>在博客或者技术平台发表 Salvo 相关的技术文章。</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-27 00:23:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"[已解决]println! 严重拖延效能，仅列印一行","link":"https://rustcc.cn/article?id=ab0d06cb-d33d-4e18-b7b3-0b3e889f7b11","description":"<p>当把call函数注解后，或是注解println! 都可以快速运行。</p>\n<p>在 https://play.rust-lang.org/ 上有时候可以 \"\"使用println! \"\" 而且依然编译的很快，有时候则不行，我自己本地电脑都不行。</p>\n<p>这效能差了十万八千里，请大家帮忙，新手总是在 println! 跌坑。</p>\n<p>这边使用 <code>cargo run --release</code> 编译</p>\n<pre><code>use std::time::{Duration, Instant};\n\nstruct Struct {\n    a: String,\n    b: bool,\n}\ntrait Dyn {}\nimpl Dyn for Struct {}\n\nfn main() {\n    let start = Instant::now();\n    let mut count = 0;\n    let count_end = 100_000_000i64;\n\n    while count &lt;= count_end {\n        let m: Box&lt;Struct&gt; = Box::new(Struct {\n            b: false,\n            a: \"str\".to_string(),\n        });\n        if count == count_end {\n            call();               // ---- 这儿\n            m.b;\n            m.a;\n        }\n        count += 1;\n    }\n\n    let duration = start.elapsed();\n    println!(\"Time: {:?}\", duration);\n}\n\nfn call(){\n    println!(\"run call()\\n\");     // ---- 重点在这儿，注解后变超快\n}\n</code></pre>\n<p>Time:</p>\n<table>\n<thead>\n<tr>\n<th align=\"right\">😫使用println!</th>\n<th align=\"right\">😄注解//println!</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"right\">12.863911s</td>\n<td align=\"right\">2.8486ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.2101748s</td>\n<td align=\"right\">2.4661ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.5353751s</td>\n<td align=\"right\">2.0433ms</td>\n</tr>\n<tr>\n<td align=\"right\">13.4852107s</td>\n<td align=\"right\">1.7869ms</td>\n</tr>\n<tr>\n<td align=\"right\">————————</td>\n<td align=\"right\">————————</td>\n</tr>\n</tbody>\n</table>\n<hr>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-26 16:17:11","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：理解Rust的所有权| Vol 2","link":"https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205","description":"<p><strong>课程主题：《理解Rust所有权》</strong></p>\n<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>\n<p><strong>嘉宾讲师： 苏林</strong></p>\n<p><strong>嘉宾介绍：</strong></p>\n<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>\n<p><strong>课程介绍</strong></p>\n<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>\n<p><strong>参加课程</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg\" alt=\"\"></p>\n<p><strong>课程规划</strong></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 02:04:00","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"数据表 Timestamp 日期 Serialize","link":"https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0","description":"<p>主要参考：<a href=\"https://github.com/rustcc/forustm\" rel=\"noopener noreferrer\">Rustcc网站源码库</a></p>\n<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，\n查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>\n<h2>1.依赖的库：</h2>\n<pre><code>[dependencies]\n# 日期时间处理 需要开启 serde 特征 支持序列化\nchrono = { version = \"0.4.19\", features = [\"serde\"] }\n\n# 数据库ORM\ndiesel = { version = \"1.4.4\", features = [\"postgres\", \"chrono\", \"uuid\", \"r2d2\"] }\ndotenv = \"0.15.0\"\nserde = { version = \"1.0.127\", features = [\"derive\"] }\nserde_json = \"1.0.66\"\nuuid = { version = \"0.8.2\", features = [\"serde\", \"v4\"] }\n</code></pre>\n<h2>2.创建数据表</h2>\n<pre><code>CREATE TABLE characters (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(128) UNIQUE NOT NULL,\n    age INTEGER NOT NULL DEFAULT 0,\n    friends VARCHAR NOT NULL DEFAULT '',\n    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n)\n</code></pre>\n<h2>3.数据表对应的 model</h2>\n<pre><code>use chrono::{NaiveDateTime};\nuse serde::{Deserialize, Serialize};\n\n#[derive(Queryable, Serialize, Deserialize, Debug)]\npub struct Characters {\n    pub id: i32,\n    pub name: String,\n    pub age: i32,\n    pub friends: String,\n    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features\n    pub created_at: NaiveDateTime,\n}\n</code></pre>\n<h2>4.获取数据</h2>\n<pre><code>use db::schema::characters;\nuse db::{get_connection};\nuse db::models::{Characters, NewCharacter};\nuse db::schema::characters::dsl::*;\nuse diesel::QueryDsl;\nuse diesel::prelude::*;\n\nfn main() {\n    let conn = get_connection();\n\n    // 查询年龄大于30的10条数据\n    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))\n        .limit(10)\n        .load::&lt;Characters&gt;(&amp;conn)\n        .expect(\"Loading Error\");\n\n    let date_arr = arr.iter()\n        .map(|item| {\n\t    // 数据格式化\n            let t = item.created_at.format(\"%Y-%m-%d %H:%M:%S\").to_string();\n            println!(\"{} {}\", item.name, t);\n            t\n        })\n        .collect::&lt;Vec&lt;String&gt;&gt;();\n}\n</code></pre>\n<p>输出结果类似：</p>\n<pre><code>Box 2021-08-05 09:39:34\nBobe 2021-08-05 09:39:34\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-08 01:40:35","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Cargo workspace config","link":"https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c","description":"<p><a href=\"https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html\" rel=\"noopener noreferrer\">Workspace 文档链接</a></p>\n<h2>目录结构</h2>\n<pre><code>workspace-test/\n    Cargo.toml\n    db/\n        src/\n            bin/\n                init.rs\n        Cargo.tml\n</code></pre>\n<h2>workspace</h2>\n<p>workspace-test/Cargo.toml</p>\n<pre><code>[workspace]\nmembers = [\"db\"]\ndefault-member = \"db\"\n</code></pre>\n<h2>子项目</h2>\n<p>workspace-test/db/Cargo.toml</p>\n<pre><code>[package]\nname = \"db\"\nversion = \"0.1.0\"\nedition = \"2018\"\n\n[dependencies]\n\n# 可选的可执行文件配置\n# [[bin]]\n# name = \"init\"\n# path = \"src/bin/init.rs\"\n</code></pre>\n<h2>操作</h2>\n<pre><code># 运行 init\ncargo run --bin init\n# -p 指定项目\ncargo run -p db --bin init\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-04 09:54:31","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程浅悟（一）","link":"https://rustcc.cn/article?id=120035c3-944d-4a79-9b3a-8390697a6e13","description":"<h1><code>Rust</code>异步编程浅悟（一）</h1>\n<p>不同于<code>javascript</code>的<code>new Promise((resolve, reject) =&gt; {...})</code>构造即运行，<code>Rust</code>中的<code>Future</code>是·惰性·状态机。这体现为：</p>\n<ol>\n<li>【调用异步函数】或【执行异步块】仅只构造一个<code>Future trait object</code>。</li>\n<li>因为<code>Future</code>是惰性状态机，所以它不会自动执行【异步函数】或【异步块】内的任何一行代码 --- 此点与<code>javascript</code>的·活性·状态机完全不同。相反，需要人工激活触发。</li>\n<li>人工启动<code>Future</code>运行，又分为两个场景的两种情况：\n<ol>\n<li>\n<p>已经在<code>async fn</code>内，<code>Future.await</code>激活。但，同时<strong>阻塞</strong>当前异步程序执行流。</p>\n</li>\n<li>\n<p>在<code>async fn</code>外，需要借助由【运行时】提供的【执行器】。就<code>async-std</code>库而言，有两个选择：</p>\n<ol>\n<li><code>task::block_on(Future)</code> 执行<code>Future</code>且阻塞当前线程直到<code>Future</code>被完成。</li>\n<li><code>task::spawn(Future)</code>仅执行<code>Future</code>和不阻塞当前线程。</li>\n</ol>\n<p>无论选择上面哪种方式，若在<code>Future</code>执行期间出现了<code>panic</code>，其都会终止（<code>abort</code>）正在共享同一个执行线程（<code>thread</code>）的所有<code>task</code>（·无栈·协程）的运行。</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>题外话，</p>\n<ol>\n<li>绿色线程是·有栈·协程；异步函数与异步块是·无栈·协程。</li>\n<li>在<code>async-std</code>库的词汇表内，协程被称作<code>task</code>而不是惯例的<code>coroutine</code>。</li>\n<li><code>task::spawn(Future)</code>也能被使用于<code>async fn</code>或<code>async {...}</code>内。它被用来代替<code>.await</code>指令，以<strong>非阻塞</strong><code>async fn</code>或<code>async {...}</code>的方式，激活与执行一个<code>Future</code>实例。</li>\n</ol>\n<h2>例程</h2>\n<pre><code>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {\n    // 1. TcpListener::bind(addr) 返回 Future\n    // 2. .await 于 Future 取得 Result&lt;T, E&gt;\n    // 3. Result&lt;T, E&gt;? 再拿得 Ok&lt;T&gt; 中的 T\n    let listener = TcpListener::bind(addr).await?; // 异步函数内的人工启动 Future\n    let mut incoming = listener.incoming();\n    // 因为没有从语言层面支持 async for loop，所以 while loop + Iterator&lt;Item = T&gt; 来模拟之。\n    while let Some(stream) = incoming.next().await {\n        // TODO\n    }\n    Ok(())\n}\nfn main() {\n    let fut = accept_loop(\"127.0.0.1:8080\");\n    task::block_on(fut); // 异步函数外的人工启动 Future\n}\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-03 00:01:43","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-08-30T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Enhanced Seq2Seq Autoencoder via Contrastive Learning for Abstractive Text Summarization. (arXiv:2108.11992v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11992","description":"<p>In this paper, we present a denoising sequence-to-sequence (seq2seq)\nautoencoder via contrastive learning for abstractive text summarization. Our\nmodel adopts a standard Transformer-based architecture with a multi-layer\nbi-directional encoder and an auto-regressive decoder. To enhance its denoising\nability, we incorporate self-supervised contrastive learning along with various\nsentence-level document augmentation. These two components, seq2seq autoencoder\nand contrastive learning, are jointly trained through fine-tuning, which\nimproves the performance of text summarization with regard to ROUGE scores and\nhuman evaluation. We conduct experiments on two datasets and demonstrate that\nour model outperforms many existing benchmarks and even achieves comparable\nperformance to the state-of-the-art abstractive systems trained with more\ncomplex architecture and extensive computation resources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kunpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Harry Jiannan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Ling Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhe Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Sentence Ordering Method Using BERT Pretrained Model. (arXiv:2108.11994v1 [cs.CL])","link":"http://arxiv.org/abs/2108.11994","description":"<p>Building systems with capability of natural language understanding (NLU) has\nbeen one of the oldest areas of AI. An essential component of NLU is to detect\nlogical succession of events contained in a text. The task of sentence ordering\nis proposed to learn succession of events with applications in AI tasks. The\nperformance of previous works employing statistical methods is poor, while the\nneural networks-based approaches are in serious need of large corpora for model\nlearning. In this paper, we propose a method for sentence ordering which does\nnot need a training phase and consequently a large corpus for learning. To this\nend, we generate sentence embedding using BERT pre-trained model and measure\nsentence similarity using cosine similarity score. We suggest this score as an\nindicator of sequential events' level of coherence. We finally sort the\nsentences through brute-force search to maximize overall similarities of the\nsequenced sentences. Our proposed method outperformed other baselines on\nROCStories, a corpus of 5-sentence human-made stories. The method is\nspecifically more efficient than neural network-based methods when no huge\ncorpus is available. Among other advantages of this method are its\ninterpretability and needlessness to linguistic knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Golestani_M/0/1/0/all/0/1\">Melika Golestani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razavi_S/0/1/0/all/0/1\">Seyedeh Zahra Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faili_H/0/1/0/all/0/1\">Heshaam Faili</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with RoBERTa. (arXiv:2108.12009v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12009","description":"<p>We present EmoBERTa: Speaker-Aware Emotion Recognition in Conversation with\nRoBERTa, a simple yet expressive scheme of solving the ERC (emotion recognition\nin conversation) task. By simply prepending speaker names to utterances and\ninserting separation tokens between the utterances in a dialogue, EmoBERTa can\nlearn intra- and inter- speaker states and context to predict the emotion of a\ncurrent speaker, in an end-to-end manner. Our experiments show that we reach a\nnew state of the art on the two popular ERC datasets using a basic and\nstraight-forward approach. We've open sourced our code and models at\nhttps://github.com/tae898/erc.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taewoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vossen_P/0/1/0/all/0/1\">Piek Vossen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic-based Self-Critical Training For Question Generation. (arXiv:2108.12026v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12026","description":"<p>We present in this work a fully Transformer-based reinforcement learning\ngenerator-evaluator architecture for neural question generation. Question\ngeneration is a task that consists in generating questions given a context and\nanswer. To improve the quality of the generated question, we came up with a\nsemantic-based self-critical training layout in generator-evaluator\narchitecture, which goes beyond typical maximum likelihood training. Evaluation\nmetrics for language modeling only based on n-gram overlapping do not consider\nsemantic relations between reference and candidate strings. To improve the\nevaluation step, we assess our model for both n-gram overlap using BLEU and\nsemantically using BERTScore and NUBIA, a novel state-of-the-art evaluation\nmetric for text generation. Question generation could be used in many\ndownstream applications, including in extending question answering datasets,\nconversational systems, and educational assessment systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lo%5C%22ic/0/1/0/all/0/1\">Lo&#xef;c</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dassi_K/0/1/0/all/0/1\">Kwate Dassi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using GAN-based models to sentimental analysis on imbalanced datasets in education domain. (arXiv:2108.12061v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12061","description":"<p>While the whole world is still struggling with the COVID-19 pandemic, online\nlearning and home office become more common. Many schools transfer their\ncourses teaching to the online classroom. Therefore, it is significant to mine\nthe students' feedback and opinions from their reviews towards studies so that\nboth schools and teachers can know where they need to improve. This paper\ntrains machine learning and deep learning models using both balanced and\nimbalanced datasets for sentiment classification. Two SOTA category-aware text\ngeneration GAN models: CatGAN and SentiGAN, are utilized to synthesize text\nused to balance the highly imbalanced dataset. Results on three datasets with\ndifferent imbalance degree from distinct domains show that when using generated\ntext to balance the dataset, the F1-score of machine learning and deep learning\nmodel on sentiment classification increases 2.79% ~ 9.28%. Also, the results\nindicate that the average growth degree for CR100k is higher than CR23k, the\naverage growth degree for deep learning is more increased than machine learning\nalgorithms, and the average growth degree for more complex deep learning models\nis more increased than simpler deep learning models in experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ru Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edalati_M/0/1/0/all/0/1\">Maryam Edalati</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"4-bit Quantization of LSTM-based Speech Recognition Models. (arXiv:2108.12074v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12074","description":"<p>We investigate the impact of aggressive low-precision representations of\nweights and activations in two families of large LSTM-based architectures for\nAutomatic Speech Recognition (ASR): hybrid Deep Bidirectional LSTM - Hidden\nMarkov Models (DBLSTM-HMMs) and Recurrent Neural Network - Transducers\n(RNN-Ts). Using a 4-bit integer representation, a na\\\"ive quantization approach\napplied to the LSTM portion of these models results in significant Word Error\nRate (WER) degradation. On the other hand, we show that minimal accuracy loss\nis achievable with an appropriate choice of quantizers and initializations. In\nparticular, we customize quantization schemes depending on the local properties\nof the network, improving recognition performance while limiting computational\ntime. We demonstrate our solution on the Switchboard (SWB) and CallHome (CH)\ntest sets of the NIST Hub5-2000 evaluation. DBLSTM-HMMs trained with 300 or\n2000 hours of SWB data achieves $&lt;$0.5% and $&lt;$1% average WER degradation,\nrespectively. On the more challenging RNN-T models, our quantization strategy\nlimits degradation in 4-bit inference to 1.3%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fasoli_A/0/1/0/all/0/1\">Andrea Fasoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chia-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serrano_M/0/1/0/all/0/1\">Mauricio Serrano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Naigang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkataramani_S/0/1/0/all/0/1\">Swagath Venkataramani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saon_G/0/1/0/all/0/1\">George Saon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1\">Xiaodong Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1\">Brian Kingsbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuske_Z/0/1/0/all/0/1\">Zolt&#xe1;n T&#xfc;ske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Kailash Gopalakrishnan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. (arXiv:2108.12084v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12084","description":"<p>Gender is widely discussed in the context of language tasks and when\nexamining the stereotypes propagated by language models. However, current\ndiscussions primarily treat gender as binary, which can perpetuate harms such\nas the cyclical erasure of non-binary gender identities. These harms are driven\nby model and dataset biases, which are consequences of the non-recognition and\nlack of understanding of non-binary genders in society. In this paper, we\nexplain the complexity of gender and language around it, and survey non-binary\npersons to understand harms associated with the treatment of gender as binary\nin English language technologies. We also detail how current language\nrepresentations (e.g., GloVe, BERT) capture and perpetuate these harms and\nrelated challenges that need to be acknowledged and addressed for\nrepresentations to equitably encode gender information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dev_S/0/1/0/all/0/1\">Sunipa Dev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monajatipoor_M/0/1/0/all/0/1\">Masoud Monajatipoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovalle_A/0/1/0/all/0/1\">Anaelia Ovalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramonian_A/0/1/0/all/0/1\">Arjun Subramonian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1\">Jeff M Phillips</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lingxi: A Diversity-aware Chinese Modern Poetry Generation System. (arXiv:2108.12108v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12108","description":"<p>Poetry generation has been a difficult task in natural language processing.\nUnlike plain neural text generation tasks, poetry has a high requirement for\nnovelty, since an easily-understood sentence with too many high frequency words\nmight not be considered as poetic, while adequately ambiguous sentences with\nlow frequency words can possibly be novel and creative. Inspired by this, we\npresent Lingxi, a diversity-aware Chinese modern poetry generation system. We\npropose nucleus sampling with randomized head (NS-RH) algorithm, which\nrandomizes the high frequency part (\"head\") of the predicted distribution, in\norder to emphasize on the \"comparatively low frequency\" words. The proposed\nalgorithm can significantly increase the novelty of generated poetry compared\nwith traditional sampling methods. The permutation of distribution is\ncontrollable by tuning the filtering parameter that determines the \"head\" to\npermutate, achieving diversity-aware sampling. We find that even when a large\nportion of filtered vocabulary is randomized, it can actually generate fluent\npoetry but with notably higher novelty. We also propose a\nsemantic-similarity-based rejection sampling algorithm, which creates longer\nand more informative context on the basis of the short input poetry title while\nmaintaining high semantic similarity to the title, alleviating the off-topic\nissue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinran Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiafeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaobing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Generation of Accurate \\& Fluent Medical X-ray Reports. (arXiv:2108.12126v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12126","description":"<p>Our paper focuses on automating the generation of medical reports from chest\nX-ray image inputs, a critical yet time-consuming task for radiologists. Unlike\nexisting medical re-port generation efforts that tend to produce human-readable\nreports, we aim to generate medical reports that are both fluent and clinically\naccurate. This is achieved by our fully differentiable and end-to-end paradigm\ncontaining three complementary modules: taking the chest X-ray images and\nclinical his-tory document of patients as inputs, our classification module\nproduces an internal check-list of disease-related topics, referred to as\nenriched disease embedding; the embedding representation is then passed to our\ntransformer-based generator, giving rise to the medical reports; meanwhile, our\ngenerator also pro-duces the weighted embedding representation, which is fed to\nour interpreter to ensure consistency with respect to disease-related\ntopics.Our approach achieved promising results on commonly-used metrics\nconcerning language fluency and clinical accuracy. Moreover, noticeable\nperformance gains are consistently ob-served when additional input information\nis available, such as the clinical document and extra scans of different views.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hoang T.N. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_D/0/1/0/all/0/1\">Dong Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Badamdorj_T/0/1/0/all/0/1\">Taivanbat Badamdorj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yingying Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_J/0/1/0/all/0/1\">Jason Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Li Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Secoco: Self-Correcting Encoding for Neural Machine Translation. (arXiv:2108.12137v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12137","description":"<p>This paper presents Self-correcting Encoding (Secoco), a framework that\neffectively deals with input noise for robust neural machine translation by\nintroducing self-correcting predictors. Different from previous robust\napproaches, Secoco enables NMT to explicitly correct noisy inputs and delete\nspecific errors simultaneously with the translation decoding process. Secoco is\nable to achieve significant improvements over strong baselines on two\nreal-world test sets and a benchmark WMT dataset with good interpretability. We\nwill make our code and dataset publicly available soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chengqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving callsign recognition with air-surveillance data in air-traffic communication. (arXiv:2108.12156v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12156","description":"<p>Automatic Speech Recognition (ASR) can be used as the assistance of speech\ncommunication between pilots and air-traffic controllers. Its application can\nsignificantly reduce the complexity of the task and increase the reliability of\ntransmitted information. Evidently, high accuracy predictions are needed to\nminimize the risk of errors. Especially, high accuracy is required in\nrecognition of key information, such as commands and callsigns, used to\nnavigate pilots. Our results prove that the surveillance data containing\ncallsigns can help to considerably improve the recognition of a callsign in an\nutterance when the weights of probable callsign n-grams are reduced per\nutterance. In this paper, we investigate two approaches: (1) G-boosting, when\ncallsigns weights are adjusted at language model level (G) and followed by the\ndynamic decoder with an on-the-fly composition, and (2) lattice rescoring when\ncallsign information is introduced on top of lattices generated using a\nconventional decoder. Boosting callsign n-grams with the combination of two\nmethods allowed us to gain 28.4% of absolute improvement in callsign\nrecognition accuracy and up to 74.2% of relative improvement in WER of callsign\nrecognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braun_R/0/1/0/all/0/1\">Rudolf Braun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grammar Based Identification Of Speaker Role For Improving ATCO And Pilot ASR. (arXiv:2108.12175v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12175","description":"<p>Assistant Based Speech Recognition (ABSR) for air traffic control is\ngenerally trained by pooling both Air Traffic Controller (ATCO) and pilot data.\nIn practice, this is motivated by the fact that the proportion of pilot data is\nlesser compared to ATCO while their standard language of communication is\nsimilar. However, due to data imbalance of ATCO and pilot and their varying\nacoustic conditions, the ASR performance is usually significantly better for\nATCOs than pilots. In this paper, we propose to (1) split the ATCO and pilot\ndata using an automatic approach exploiting ASR transcripts, and (2) consider\nATCO and pilot ASR as two separate tasks for Acoustic Model (AM) training. For\nspeaker role classification of ATCO and pilot data, a hypothesized ASR\ntranscript is generated with a seed model, subsequently used to classify the\nspeaker role based on the knowledge extracted from grammar defined by\nInternational Civil Aviation Organization (ICAO). This approach provides an\naverage speaker role identification accuracy of 83% for ATCO and pilot.\nFinally, we show that training AMs separately for each task, or using a\nmultitask approach is well suited for this data compared to AM trained by\npooling all data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohneiser_O/0/1/0/all/0/1\">Oliver Ohneiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helmke_H/0/1/0/all/0/1\">Hartmut Helmke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarfjoo_S/0/1/0/all/0/1\">Saeed Sarfjoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Offensive Language Identification in Low-resourced Code-mixed Dravidian languages using Pseudo-labeling. (arXiv:2108.12177v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12177","description":"<p>Social media has effectively become the prime hub of communication and\ndigital marketing. As these platforms enable the free manifestation of thoughts\nand facts in text, images and video, there is an extensive need to screen them\nto protect individuals and groups from offensive content targeted at them. Our\nwork intends to classify codemixed social media comments/posts in the Dravidian\nlanguages of Tamil, Kannada, and Malayalam. We intend to improve offensive\nlanguage identification by generating pseudo-labels on the dataset. A custom\ndataset is constructed by transliterating all the code-mixed texts into the\nrespective Dravidian language, either Kannada, Malayalam, or Tamil and then\ngenerating pseudo-labels for the transliterated dataset. The two datasets are\ncombined using the generated pseudo-labels to create a custom dataset called\nCMTRA. As Dravidian languages are under-resourced, our approach increases the\namount of training data for the language models. We fine-tune several recent\npretrained language models on the newly constructed dataset. We extract the\npretrained language embeddings and pass them onto recurrent neural networks. We\nobserve that fine-tuning ULMFiT on the custom dataset yields the best results\non the code-mixed test sets of all three languages. Our approach yields the\nbest results among the benchmarked models on Tamil-English, achieving a\nweighted F1-Score of 0.7934 while scoring competitive weighted F1-Scores of\n0.9624 and 0.7306 on the code-mixed test sets of Malayalam-English and\nKannada-English, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hande_A/0/1/0/all/0/1\">Adeep Hande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puranik_K/0/1/0/all/0/1\">Karthik Puranik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasaswini_K/0/1/0/all/0/1\">Konthala Yasaswini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1\">Ruba Priyadharshini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thavareesan_S/0/1/0/all/0/1\">Sajeetha Thavareesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sampath_A/0/1/0/all/0/1\">Anbukkarasi Sampath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanmugavadivel_K/0/1/0/all/0/1\">Kogilavani Shanmugavadivel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thenmozhi_D/0/1/0/all/0/1\">Durairaj Thenmozhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1\">Bharathi Raja Chakravarthi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query-Focused Extractive Summarisation for Finding Ideal Answers to Biomedical and COVID-19 Questions. (arXiv:2108.12189v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12189","description":"<p>This paper presents Macquarie University's participation to the BioASQ\nSynergy Task, and BioASQ9b Phase B. In each of these tasks, our participation\nfocused on the use of query-focused extractive summarisation to obtain the\nideal answers to medical questions. The Synergy Task is an end-to-end question\nanswering task on COVID-19 where systems are required to return relevant\ndocuments, snippets, and answers to a given question. Given the absence of\ntraining data, we used a query-focused summarisation system that was trained\nwith the BioASQ8b training data set and we experimented with methods to\nretrieve the documents and snippets. Considering the poor quality of the\ndocuments and snippets retrieved by our system, we observed reasonably good\nquality in the answers returned. For phase B of the BioASQ9b task, the relevant\ndocuments and snippets were already included in the test data. Our system split\nthe snippets into candidate sentences and used BERT variants under a sentence\nclassification setup. The system used the question and candidate sentence as\ninput and was trained to predict the likelihood of the candidate sentence being\npart of the ideal answer. The runs obtained either the best or second best\nROUGE-F1 results of all participants to all batches of BioASQ9b. This shows\nthat using BERT in a classification setup is a very strong baseline for the\nidentification of ideal answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Molla_D/0/1/0/all/0/1\">Diego Moll&#xe1;</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Khanna_U/0/1/0/all/0/1\">Urvashi Khanna</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Galat_D/0/1/0/all/0/1\">Dima Galat</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1\">Vincent Nguyen</a> (2 and 3) <a href=\"http://arxiv.org/find/cs/1/au:+Rybinski_M/0/1/0/all/0/1\">Maciej Rybinski</a> (3) ( (1) Macquarie University, (2) CSIRO Data61, (3) Australian National University)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translation Error Detection as Rationale Extraction. (arXiv:2108.12197v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12197","description":"<p>Recent Quality Estimation (QE) models based on multilingual pre-trained\nrepresentations have achieved very competitive results when predicting the\noverall quality of translated sentences. Predicting translation errors, i.e.\ndetecting specifically which words are incorrect, is a more challenging task,\nespecially with limited amounts of training data. We hypothesize that, not\nunlike humans, successful QE models rely on translation errors to predict\noverall sentence quality. By exploring a set of feature attribution methods\nthat assign relevance scores to the inputs to explain model predictions, we\nstudy the behaviour of state-of-the-art sentence-level QE models and show that\nexplanations (i.e. rationales) extracted from these models can indeed be used\nto detect translation errors. We therefore (i) introduce a novel\nsemi-supervised method for word-level QE and (ii) propose to use the QE task as\na new benchmark for evaluating the plausibility of feature attribution, i.e.\nhow interpretable model explanations are to humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fomicheva_M/0/1/0/all/0/1\">Marina Fomicheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1\">Lucia Specia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12202","description":"<p>In joint entity and relation extraction, existing work either sequentially\nencode task-specific features, leading to an imbalance in inter-task feature\ninteraction where features extracted later have no direct contact with those\nthat come first. Or they encode entity features and relation features in a\nparallel manner, meaning that feature representation learning for each task is\nlargely independent of each other except for input sharing. We propose a\npartition filter network to model two-way interaction between tasks properly,\nwhere feature encoding is decomposed into two steps: partition and filter. In\nour encoder, we leverage two gates: entity and relation gate, to segment\nneurons into two task partitions and one shared partition. The shared partition\nrepresents inter-task information valuable to both tasks and is evenly shared\nacross two tasks to ensure proper two-way interaction. The task partitions\nrepresent intra-task information and are formed through concerted efforts of\nboth gates, making sure that encoding of task-specific features are dependent\nupon each other. Experiment results on five public datasets show that our model\nperforms significantly better than previous approaches. The source code can be\nfound in https://github.com/Coopercoppers/PFN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhiheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jinlan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Capacity of a Large-scale Masked Language Model to Recognize Grammatical Errors. (arXiv:2108.12216v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12216","description":"<p>In this paper, we explore the capacity of a language model-based method for\ngrammatical error detection in detail. We first show that 5 to 10% of training\ndata are enough for a BERT-based error detection method to achieve performance\nequivalent to a non-language model-based method can achieve with the full\ntraining data; recall improves much faster with respect to training data size\nin the BERT-based method than in the non-language model method while precision\nbehaves similarly. These suggest that (i) the BERT-based method should have a\ngood knowledge of grammar required to recognize certain types of error and that\n(ii) it can transform the knowledge into error detection rules by fine-tuning\nwith a few training samples, which explains its high generalization ability in\ngrammatical error detection. We further show with pseudo error data that it\nactually exhibits such nice properties in learning rules for recognizing\nvarious types of error. Finally, based on these findings, we explore a\ncost-effective method for detecting grammatical errors with feedback comments\nexplaining relevant grammatical rules to learners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nagata_R/0/1/0/all/0/1\">Ryo Nagata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kimura_M/0/1/0/all/0/1\">Manabu Kimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanawa_K/0/1/0/all/0/1\">Kazuaki Hanawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Injecting Text in Self-Supervised Speech Pretraining. (arXiv:2108.12226v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12226","description":"<p>Self-supervised pretraining for Automated Speech Recognition (ASR) has shown\nvaried degrees of success. In this paper, we propose to jointly learn\nrepresentations during pretraining from two different modalities: speech and\ntext. The proposed method, tts4pretrain complements the power of contrastive\nlearning in self-supervision with linguistic/lexical representations derived\nfrom synthesized speech, effectively learning from untranscribed speech and\nunspoken text. Lexical learning in the speech encoder is enforced through an\nadditional sequence loss term that is coupled with contrastive loss during\npretraining. We demonstrate that this novel pretraining method yields Word\nError Rate (WER) reductions of 10% relative on the well-benchmarked,\nLibrispeech task over a state-of-the-art baseline pretrained with wav2vec2.0\nonly. The proposed method also serves as an effective strategy to compensate\nfor the lack of transcribed speech, effectively matching the performance of\n5000 hours of transcribed speech with just 100 hours of transcribed speech on\nthe AMI meeting transcription task. Finally, we demonstrate WER reductions of\nup to 15% on an in-house Voice Search task over traditional pretraining.\nIncorporating text into encoder pretraining is complimentary to rescoring with\na larger or in-domain language model, resulting in additional 6% relative\nreduction in WER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhehuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_A/0/1/0/all/0/1\">Andrew Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramabhadran_B/0/1/0/all/0/1\">Bhuvana Ramabhadran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gary Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_P/0/1/0/all/0/1\">Pedro Moreno</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12229","description":"<p>The ability to detect Out-of-Domain (OOD) inputs has been a critical\nrequirement in many real-world NLP applications since the inclusion of\nunsupported OOD inputs may lead to catastrophic failure of systems. However, it\nremains an empirical question whether current algorithms can tackle such\nproblem reliably in a realistic scenario where zero OOD training data is\navailable. In this study, we propose ProtoInfoMax, a new architecture that\nextends Prototypical Networks to simultaneously process In-Domain (ID) and OOD\nsentences via Mutual Information Maximization (InfoMax) objective. Experimental\nresults show that our proposed method can substantially improve performance up\nto 20% for OOD detection in low resource settings of text classification. We\nalso show that ProtoInfoMax is less prone to typical over-confidence Error of\nNeural Networks, leading to more reliable ID and OOD prediction outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nimah_I/0/1/0/all/0/1\">Iftitahu Ni&#x27;mah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1\">Vlado Menkovski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1\">Mykola Pechenizkiy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Robustness of Neural Language Models to Input Perturbations. (arXiv:2108.12237v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12237","description":"<p>High-performance neural language models have obtained state-of-the-art\nresults on a wide range of Natural Language Processing (NLP) tasks. However,\nresults for common benchmark datasets often do not reflect model reliability\nand robustness when applied to noisy, real-world data. In this study, we design\nand implement various types of character-level and word-level perturbation\nmethods to simulate realistic scenarios in which input texts may be slightly\nnoisy or different from the data distribution on which NLP systems were\ntrained. Conducting comprehensive experiments on different NLP tasks, we\ninvestigate the ability of high-performance language models such as BERT,\nXLNet, RoBERTa, and ELMo in handling different types of input perturbations.\nThe results suggest that language models are sensitive to input perturbations\nand their performance can decrease even when small changes are introduced. We\nhighlight that models need to be further improved and that current benchmarks\nare not reflecting model robustness well. We argue that evaluations on\nperturbed inputs should routinely complement widely-used benchmarks in order to\nyield a more realistic understanding of NLP systems robustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1\">Milad Moradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1\">Matthias Samwald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep learning models are not robust against noise in clinical text. (arXiv:2108.12242v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12242","description":"<p>Artificial Intelligence (AI) systems are attracting increasing interest in\nthe medical domain due to their ability to learn complicated tasks that require\nhuman intelligence and expert knowledge. AI systems that utilize\nhigh-performance Natural Language Processing (NLP) models have achieved\nstate-of-the-art results on a wide variety of clinical text processing\nbenchmarks. They have even outperformed human accuracy on some tasks. However,\nperformance evaluation of such AI systems have been limited to accuracy\nmeasures on curated and clean benchmark datasets that may not properly reflect\nhow robustly these systems can operate in real-world situations. In order to\naddress this challenge, we introduce and implement a wide variety of\nperturbation methods that simulate different types of noise and variability in\nclinical text data. While noisy samples produced by these perturbation methods\ncan often be understood by humans, they may cause AI systems to make erroneous\ndecisions. Conducting extensive experiments on several clinical text processing\ntasks, we evaluated the robustness of high-performance NLP models against\nvarious types of character-level and word-level noise. The results revealed\nthat the NLP models performance degrades when the input contains small amounts\nof noise. This study is a significant step towards exposing vulnerabilities of\nAI models utilized in clinical text processing systems. The proposed\nperturbation methods can be used in performance evaluation tests to assess how\nrobustly clinical NLP models can operate on noisy data, in real-world settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1\">Milad Moradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blagec_K/0/1/0/all/0/1\">Kathrin Blagec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1\">Matthias Samwald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic. (arXiv:2108.12269v1 [cs.CY])","link":"http://arxiv.org/abs/2108.12269","description":"<p>The spread of misinformation, conspiracy, and questionable content and\ninformation manipulation by foreign adversaries on social media has surged\nalong with the COVID-19 pandemic. Such malicious cyber-enabled actions may\ncause increasing social polarization, health crises, and property loss. In this\npaper, using fine-tuned contextualized embedding trained on Reddit, we tackle\nthe detection of the propaganda of such user accounts and their targeted issues\non Twitter during March 2020 when the COVID-19 epidemic became recognized as a\npandemic. Our result shows that the pro-China group appeared to be tweeting 35\nto 115 times more than the neutral group. At the same time, neutral groups were\ntweeting more positive-attitude content and voicing alarm for the COVID-19\nsituation. The pro-China group was also using more call-for-action words on\npolitical issues not necessarily China-related.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_R/0/1/0/all/0/1\">Rong-Ching Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chu-Hsing Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can the Transformer Be Used as a Drop-in Replacement for RNNs in Text-Generating GANs?. (arXiv:2108.12275v1 [cs.LG])","link":"http://arxiv.org/abs/2108.12275","description":"<p>In this paper we address the problem of fine-tuned text generation with a\nlimited computational budget. For that, we use a well-performing text\ngenerative adversarial network (GAN) architecture - Diversity-Promoting GAN\n(DPGAN), and attempted a drop-in replacement of the LSTM layer with a\nself-attention-based Transformer layer in order to leverage their efficiency.\nThe resulting Self-Attention DPGAN (SADPGAN) was evaluated for performance,\nquality and diversity of generated text and stability. Computational\nexperiments suggested that a transformer architecture is unable to drop-in\nreplace the LSTM layer, under-performing during the pre-training phase and\nundergoing a complete mode collapse during the GAN tuning phase. Our results\nsuggest that the transformer architecture need to be adapted before it can be\nused as a replacement for RNNs in text-generating GANs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Blin_K/0/1/0/all/0/1\">Kevin Blin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kucharavy_A/0/1/0/all/0/1\">Andrei Kucharavy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tree Decomposition Attention for AMR-to-Text Generation. (arXiv:2108.12300v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12300","description":"<p>Text generation from AMR requires mapping a semantic graph to a string that\nit annotates. Transformer-based graph encoders, however, poorly capture vertex\ndependencies that may benefit sequence prediction. To impose order on an\nencoder, we locally constrain vertex self-attention using a graph's tree\ndecomposition. Instead of forming a full query-key bipartite graph, we restrict\nattention to vertices in parent, subtree, and same-depth bags of a vertex. This\nhierarchical context lends both sparsity and structure to vertex state updates.\nWe apply dynamic programming to derive a forest of tree decompositions,\nchoosing the most structurally similar tree to the AMR. Our system outperforms\na self-attentive baseline by 1.6 BLEU and 1.8 chrF++.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lisa Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gildea_D/0/1/0/all/0/1\">Daniel Gildea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Latent Tree Decomposition Parsers for AMR-to-Text Generation. (arXiv:2108.12304v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12304","description":"<p>Graph encoders in AMR-to-text generation models often rely on neighborhood\nconvolutions or global vertex attention. While these approaches apply to\ngeneral graphs, AMRs may be amenable to encoders that target their tree-like\nstructure. By clustering edges into a hierarchy, a tree decomposition\nsummarizes graph structure. Our model encodes a derivation forest of tree\ndecompositions and extracts an expected tree. From tree node embeddings, it\nbuilds graph edge features used in vertex attention of the graph encoder.\nEncoding TD forests instead of shortest-pairwise paths in a self-attentive\nbaseline raises BLEU by 0.7 and chrF++ by 0.3. The forest encoder also\nsurpasses a convolutional baseline for molecular property prediction by 1.92%\nROC-AUC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lisa Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gildea_D/0/1/0/all/0/1\">Daniel Gildea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAPE: Context-Aware Private Embeddings for Private Language Learning. (arXiv:2108.12318v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12318","description":"<p>Deep learning-based language models have achieved state-of-the-art results in\na number of applications including sentiment analysis, topic labelling, intent\nclassification and others. Obtaining text representations or embeddings using\nthese models presents the possibility of encoding personally identifiable\ninformation learned from language and context cues that may present a risk to\nreputation or privacy. To ameliorate these issues, we propose Context-Aware\nPrivate Embeddings (CAPE), a novel approach which preserves privacy during\ntraining of embeddings. To maintain the privacy of text representations, CAPE\napplies calibrated noise through differential privacy, preserving the encoded\nsemantic links while obscuring sensitive information. In addition, CAPE employs\nan adversarial training regime that obscures identified private variables.\nExperimental results demonstrate that the proposed approach reduces private\ninformation leakage better than either single intervention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Plant_R/0/1/0/all/0/1\">Richard Plant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gkatzia_D/0/1/0/all/0/1\">Dimitra Gkatzia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giuffrida_V/0/1/0/all/0/1\">Valerio Giuffrida</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DomiKnowS: A Library for Integration of Symbolic Domain Knowledge in Deep Learning. (arXiv:2108.12370v1 [cs.LG])","link":"http://arxiv.org/abs/2108.12370","description":"<p>We demonstrate a library for the integration of domain knowledge in deep\nlearning architectures. Using this library, the structure of the data is\nexpressed symbolically via graph declarations and the logical constraints over\noutputs or latent variables can be seamlessly added to the deep models. The\ndomain knowledge can be defined explicitly, which improves the models'\nexplainability in addition to the performance and generalizability in the\nlow-data regime. Several approaches for such an integration of symbolic and\nsub-symbolic models have been introduced; however, there is no library to\nfacilitate the programming for such an integration in a generic way while\nvarious underlying algorithms can be used. Our library aims to simplify\nprogramming for such an integration in both training and inference phases while\nseparating the knowledge representation from learning algorithms. We showcase\nvarious NLP benchmark tasks and beyond. The framework is publicly available at\nGithub(https://github.com/HLR/DomiKnowS).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faghihi_H/0/1/0/all/0/1\">Hossein Rajaby Faghihi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Quan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uszok_A/0/1/0/all/0/1\">Andrzej Uszok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nafar_A/0/1/0/all/0/1\">Aliakbar Nafar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raisi_E/0/1/0/all/0/1\">Elaheh Raisi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kordjamshidi_P/0/1/0/all/0/1\">Parisa Kordjamshidi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation. (arXiv:2108.12409v1 [cs.CL])","link":"http://arxiv.org/abs/2108.12409","description":"<p>Since the introduction of the transformer model by Vaswani et al. (2017), a\nfundamental question remains open: how to achieve extrapolation at inference\ntime to longer sequences than seen during training? We first show that\nextrapolation can be improved by changing the position representation method,\nthough we find that existing proposals do not allow efficient extrapolation. We\nintroduce a simple and efficient method, Attention with Linear Biases (ALiBi),\nthat allows for extrapolation. ALiBi does not add positional embeddings to the\nword embeddings; instead, it biases the query-key attention scores with a term\nthat is proportional to their distance. We show that this method allows\ntraining a 1.3 billion parameter model on input sequences of length 1024 that\nextrapolates to input sequences of length 2048, achieving the same perplexity\nas a sinusoidal position embedding model trained on inputs of length 2048, 11%\nfaster and using 11% less memory. ALiBi's inductive bias towards recency allows\nit to outperform multiple strong position methods on the WikiText-103\nbenchmark. Finally, we provide analysis of ALiBi to understand why it leads to\nbetter performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Software Usage in the Social Sciences: A Knowledge Graph Approach. (arXiv:2003.10715v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2003.10715","description":"<p>Knowledge about the software used in scientific investigations is necessary\nfor different reasons, including provenance of the results, measuring software\nimpact to attribute developers, and bibliometric software citation analysis in\ngeneral. Additionally, providing information about whether and how the software\nand the source code are available allows an assessment about the state and role\nof open source software in science in general. While such analyses can be done\nmanually, large scale analyses require the application of automated methods of\ninformation extraction and linking. In this paper, we present SoftwareKG - a\nknowledge graph that contains information about software mentions from more\nthan 51,000 scientific articles from the social sciences. A silver standard\ncorpus, created by a distant and weak supervision approach, and a gold standard\ncorpus, created by manual annotation, were used to train an LSTM based neural\nnetwork to identify software mentions in scientific articles. The model\nachieves a recognition rate of .82 F-score in exact matches. As a result, we\nidentified more than 133,000 software mentions. For entity disambiguation, we\nused the public domain knowledge base DBpedia. Furthermore, we linked the\nentities of the knowledge graph to other knowledge bases such as the Microsoft\nAcademic Knowledge Graph, the Software Ontology, and Wikidata. Finally, we\nillustrate, how SoftwareKG can be used to assess the role of software in the\nsocial sciences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schindler_D/0/1/0/all/0/1\">David Schindler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zapilko_B/0/1/0/all/0/1\">Benjamin Zapilko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruger_F/0/1/0/all/0/1\">Frank Kr&#xfc;ger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A review of on-device fully neural end-to-end automatic speech recognition algorithms. (arXiv:2012.07974v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2012.07974","description":"<p>In this paper, we review various end-to-end automatic speech recognition\nalgorithms and their optimization techniques for on-device applications.\nConventional speech recognition systems comprise a large number of discrete\ncomponents such as an acoustic model, a language model, a pronunciation model,\na text-normalizer, an inverse-text normalizer, a decoder based on a Weighted\nFinite State Transducer (WFST), and so on. To obtain sufficiently high speech\nrecognition accuracy with such conventional speech recognition systems, a very\nlarge language model (up to 100 GB) is usually needed. Hence, the corresponding\nWFST size becomes enormous, which prohibits their on-device implementation.\nRecently, fully neural network end-to-end speech recognition algorithms have\nbeen proposed. Examples include speech recognition systems based on\nConnectionist Temporal Classification (CTC), Recurrent Neural Network\nTransducer (RNN-T), Attention-based Encoder-Decoder models (AED), Monotonic\nChunk-wise Attention (MoChA), transformer-based speech recognition systems, and\nso on. These fully neural network-based systems require much smaller memory\nfootprints compared to conventional algorithms, therefore their on-device\nimplementation has become feasible. In this paper, we review such end-to-end\nspeech recognition models. We extensively discuss their structures,\nperformance, and advantages compared to conventional algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chanwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gowda_D/0/1/0/all/0/1\">Dhananjaya Gowda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongsoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankur Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungsoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Abhinav Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Changwoo Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Disclosive Transparency in NLP Application Descriptions. (arXiv:2101.00433v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00433","description":"<p>Broader disclosive transparency$-$truth and clarity in communication\nregarding the function of AI systems$-$is widely considered desirable.\nUnfortunately, it is a nebulous concept, difficult to both define and quantify.\nThis is problematic, as previous work has demonstrated possible trade-offs and\nnegative consequences to disclosive transparency, such as a confusion effect,\nwhere 'too much information' clouds a reader's understanding of what a system\ndescription means. Disclosive transparency's subjective nature has rendered\ndeep study into these problems and their remedies difficult. To improve this\nstate of affairs, We introduce neural language model-based probabilistic\nmetrics to directly model disclosive transparency, and demonstrate that they\ncorrelate with user and expert opinions of system transparency, making them a\nvalid objective proxy. Finally, we demonstrate the use of these metrics in a\npilot study quantifying the relationships between transparency, confusion, and\nuser perceptions in a corpus of real NLP system descriptions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_S/0/1/0/all/0/1\">Sharon Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual Semi-Supervised Learning: An Approach To Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems. (arXiv:2104.03643v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.03643","description":"<p>Air traffic management and specifically air-traffic control (ATC) rely mostly\non voice communications between Air Traffic Controllers (ATCos) and pilots. In\nmost cases, these voice communications follow a well-defined grammar that could\nbe leveraged in Automatic Speech Recognition (ASR) technologies. The callsign\nused to address an airplane is an essential part of all ATCo-pilot\ncommunications. We propose a two-steps approach to add contextual knowledge\nduring semi-supervised training to reduce the ASR system error rates at\nrecognizing the part of the utterance that contains the callsign. Initially, we\nrepresent in a WFST the contextual knowledge (i.e. air-surveillance data) of an\nATCo-pilot communication. Then, during Semi-Supervised Learning (SSL) the\ncontextual knowledge is added by second-pass decoding (i.e. lattice\nre-scoring). Results show that `unseen domains' (e.g. data from airports not\npresent in the supervised training data) are further aided by contextual SSL\nwhen compared to standalone SSL. For this task, we introduce the Callsign Word\nError Rate (CA-WER) as an evaluation metric, which only assesses ASR\nperformance of the spoken callsign in an utterance. We obtained a 32.1% CA-WER\nrelative improvement applying SSL with an additional 17.5% CA-WER improvement\nby adding contextual knowledge during SSL on a challenging ATC-based test set\ngathered from LiveATC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zuluaga_Gomez_J/0/1/0/all/0/1\">Juan Zuluaga-Gomez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nigmatulina_I/0/1/0/all/0/1\">Iuliia Nigmatulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasad_A/0/1/0/all/0/1\">Amrutha Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vesely_K/0/1/0/all/0/1\">Karel Vesel&#xfd;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocour_M/0/1/0/all/0/1\">Martin Kocour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szoke_I/0/1/0/all/0/1\">Igor Sz&#xf6;ke</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Remove: Towards Isotropic Pre-trained BERT Embedding. (arXiv:2104.05274v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.05274","description":"<p>Pre-trained language models such as BERT have become a more common choice of\nnatural language processing (NLP) tasks. Research in word representation shows\nthat isotropic embeddings can significantly improve performance on downstream\ntasks. However, we measure and analyze the geometry of pre-trained BERT\nembedding and find that it is far from isotropic. We find that the word vectors\nare not centered around the origin, and the average cosine similarity between\ntwo random words is much higher than zero, which indicates that the word\nvectors are distributed in a narrow cone and deteriorate the representation\ncapacity of word embedding. We propose a simple, and yet effective method to\nfix this problem: remove several dominant directions of BERT embedding with a\nset of learnable weights. We train the weights on word similarity tasks and\nshow that processed embedding is more isotropic. Our method is evaluated on\nthree standardized tasks: word similarity, word analogy, and semantic textual\nsimilarity. In all tasks, the word embedding processed by our method\nconsistently outperforms the original embedding (with average improvement of\n13% on word analogy and 16% on semantic textual similarity) and two baseline\nmethods. Our method is also proven to be more robust to changes of\nhyperparameter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuxin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Rui Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Ling Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NAREOR: The Narrative Reordering Problem. (arXiv:2104.06669v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06669","description":"<p>We propose the task of Narrative Reordering (NAREOR) which involves rewriting\na given story in a different narrative order while preserving its plot. We\npresent a dataset, NAREORC, with human rewritings of stories within ROCStories\nin non-linear orders, and conduct a detailed analysis of it. Further, we\npropose novel task-specific training methods with suitable evaluation metrics.\nWe perform experiments on NAREORC using state-of-the-art models such as BART\nand T5 and conduct extensive automatic and human evaluations. We demonstrate\nthat NAREOR is a challenging task with potential for further exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1\">Varun Gangal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Steven Y. Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1\">Teruko Mitamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Surface Form Competition: Why the Highest Probability Answer Isn't Always Right. (arXiv:2104.08315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08315","description":"<p>Large language models have shown promising results in zero-shot settings\n(Brown et al.,2020; Radford et al., 2019). For example, they can perform\nmultiple choice tasks simply by conditioning on a question and selecting the\nanswer with the highest probability.\n</p>\n<p>However, ranking by string probability can be problematic due to surface form\ncompetition-wherein different surface forms compete for probability mass, even\nif they represent the same underlying concept, e.g. \"computer\" and \"PC.\" Since\nprobability mass is finite, this lowers the probability of the correct answer,\ndue to competition from other strings that are valid answers (but not one of\nthe multiple choice options).\n</p>\n<p>We introduce Domain Conditional Pointwise Mutual Information, an alternative\nscoring function that directly compensates for surface form competition by\nsimply reweighing each option according to a term that is proportional to its a\npriori likelihood within the context of the specific zero-shot task. It\nachieves consistent gains in zero-shot performance over both calibrated (Zhao\net al., 2021) and uncalibrated scoring functions on all GPT-2 and GPT-3 models\nover a variety of multiple choice datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1\">Ari Holtzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning. (arXiv:2104.08808v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08808","description":"<p>The ability to continuously expand knowledge over time and utilize it to\nrapidly generalize to new tasks is a key feature of human linguistic\nintelligence. Existing models that pursue rapid generalization to new tasks\n(e.g., few-shot learning methods), however, are mostly trained in a single shot\non fixed datasets, unable to dynamically expand their knowledge; while\ncontinual learning algorithms are not specifically designed for rapid\ngeneralization. We present a new learning setup, Continual Learning of Few-Shot\nLearners (CLIF), to address the challenges of both learning settings in a\nunified setup. CLIF assumes a model learns from a sequence of diverse NLP tasks\narriving sequentially, accumulating knowledge for improved generalization to\nnew tasks, while also retaining performance on the tasks learned earlier. We\nexamine how the generalization ability is affected in the continual learning\nsetup, evaluate a number of continual learning algorithms, and propose a novel\nregularized adapter generation approach. We find that catastrophic forgetting\naffects generalization ability to a less degree than performance on seen tasks;\nwhile continual learning algorithms can still bring considerable benefit to the\ngeneralization ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1\">Mohammad Rostami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciCo: Hierarchical Cross-Document Coreference for Scientific Concepts. (arXiv:2104.08809v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08809","description":"<p>Determining coreference of concept mentions across multiple documents is a\nfundamental task in natural language understanding. Work on cross-document\ncoreference resolution (CDCR) typically considers mentions of events in the\nnews, which seldom involve abstract technical concepts that are prevalent in\nscience and technology. These complex concepts take diverse or ambiguous forms\nand have many hierarchical levels of granularity (e.g., tasks and subtasks),\nposing challenges for CDCR. We present a new task of Hierarchical CDCR (H-CDCR)\nwith the goal of jointly inferring coreference clusters and hierarchy between\nthem. We create SciCo, an expert-annotated dataset for H-CDCR in scientific\npapers, 3X larger than the prominent ECB+ resource. We study strong baseline\nmodels that we customize for H-CDCR, and highlight challenges for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1\">Sophie Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding. (arXiv:2104.08836v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08836","description":"<p>Multimodal pre-training with text, layout, and image has achieved SOTA\nperformance for visually-rich document understanding tasks recently, which\ndemonstrates the great potential for joint learning across different\nmodalities. In this paper, we present LayoutXLM, a multimodal pre-trained model\nfor multilingual document understanding, which aims to bridge the language\nbarriers for visually-rich document understanding. To accurately evaluate\nLayoutXLM, we also introduce a multilingual form understanding benchmark\ndataset named XFUND, which includes form understanding samples in 7 languages\n(Chinese, Japanese, Spanish, French, Italian, German, Portuguese), and\nkey-value pairs are manually labeled for each language. Experiment results show\nthat the LayoutXLM model has significantly outperformed the existing SOTA\ncross-lingual pre-trained models on the XFUND dataset. The pre-trained\nLayoutXLM model and the XFUND dataset are publicly available at\nhttps://aka.ms/layoutxlm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yiheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tengchao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yijuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florencio_D/0/1/0/all/0/1\">Dinei Florencio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cha Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition. (arXiv:2104.09106v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.09106","description":"<p>Subword units are commonly used for end-to-end automatic speech recognition\n(ASR), while a fully acoustic-oriented subword modeling approach is somewhat\nmissing. We propose an acoustic data-driven subword modeling (ADSM) approach\nthat adapts the advantages of several text-based and acoustic-based subword\nmethods into one pipeline. With a fully acoustic-oriented label design and\nlearning process, ADSM produces acoustic-structured subword units and\nacoustic-matched target sequence for further ASR training. The obtained ADSM\nlabels are evaluated with different end-to-end ASR approaches including CTC,\nRNN-Transducer and attention models. Experiments on the LibriSpeech corpus show\nthat ADSM clearly outperforms both byte pair encoding (BPE) and\npronunciation-assisted subword modeling (PASM) in all cases. Detailed analysis\nshows that ADSM achieves acoustically more logical word segmentation and more\nbalanced sequence length, and thus, is suitable for both time-synchronous and\nlabel-synchronous models. We also briefly describe how to apply acoustic-based\nsubword regularization and unseen text segmentation using ADSM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zuoyun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Guided Curriculum Learning for Neural Machine Translation. (arXiv:2105.04475v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.04475","description":"<p>In the field of machine learning, the well-trained model is assumed to be\nable to recover the training labels, i.e. the synthetic labels predicted by the\nmodel should be as close to the ground-truth labels as possible. Inspired by\nthis, we propose a self-guided curriculum strategy to encourage the learning of\nneural machine translation (NMT) models to follow the above recovery criterion,\nwhere we cast the recovery degree of each training example as its learning\ndifficulty. Specifically, we adopt the sentence level BLEU score as the proxy\nof recovery degree. Different from existing curricula relying on linguistic\nprior knowledge or third-party language models, our chosen learning difficulty\nis more suitable to measure the degree of knowledge mastery of the NMT models.\nExperiments on translation benchmarks, including WMT14\nEnglish$\\Rightarrow$German and WMT17 Chinese$\\Rightarrow$English, demonstrate\nthat our approach can consistently improve translation performance against\nstrong baseline Transformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Lei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duh_K/0/1/0/all/0/1\">Kevin Duh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasano_R/0/1/0/all/0/1\">Ryohei Sasano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Koichi Takeda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Twitter User Representation using Weakly Supervised Graph Embedding. (arXiv:2108.08988v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.08988","description":"<p>Social media platforms provide convenient means for users to participate in\nmultiple online activities on various contents and create fast widespread\ninteractions. However, this rapidly growing access has also increased the\ndiverse information, and characterizing user types to understand people's\nlifestyle decisions shared in social media is challenging. In this paper, we\npropose a weakly supervised graph embedding based framework for understanding\nuser types. We evaluate the user embedding learned using weak supervision over\nwell-being related tweets from Twitter, focusing on 'Yoga', 'Keto diet'.\nExperiments on real-world datasets demonstrate that the proposed framework\noutperforms the baselines for detecting user types. Finally, we illustrate data\nanalysis on different types of users (e.g., practitioner vs. promotional) from\nour dataset. While we focus on lifestyle-related tweets (i.e., yoga, keto), our\nmethod for constructing user representation readily generalizes to other\ndomains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tunazzina Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Communication with Adaptive Universal Transformer. (arXiv:2108.09119v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.09119","description":"<p>With the development of deep learning (DL), natural language processing (NLP)\nmakes it possible for us to analyze and understand a large amount of language\ntexts. Accordingly, we can achieve a semantic communication in terms of joint\nsemantic source and channel coding over a noisy channel with the help of NLP.\nHowever, the existing method to realize this goal is to use a fixed transformer\nof NLP while ignoring the difference of semantic information contained in each\nsentence. To solve this problem, we propose a new semantic communication system\nbased on Universal Transformer. Compared with the traditional transformer, an\nadaptive circulation mechanism is introduced in the Universal Transformer.\nThrough the introduction of the circulation mechanism, the new semantic\ncommunication system can be more flexible to transmit sentences with different\nsemantic information, and achieve better end-to-end performance under various\nchannel conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rongpeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhifeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chenghui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honggang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Relation Extraction from Tables using Artificially Generated Metadata. (arXiv:2108.10750v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.10750","description":"<p>Relation Extraction (RE) from tables is the task of identifying relations\nbetween pairs of columns of a table. Generally, RE models for this task require\nlabelled tables for training. These labelled tables can also be generated\nartificially from a Knowledge Graph (KG), which makes the cost to acquire them\nmuch lower in comparison to manual annotations. However, unlike real tables,\nthese synthetic tables lack associated metadata, such as, column-headers,\ncaptions, etc; this is because synthetic tables are created out of KGs that do\nnot store such metadata. Meanwhile, previous works have shown that metadata is\nimportant for accurate RE from tables. To address this issue, we propose\nmethods to artificially create some of this metadata for synthetic tables.\nAfterward, we experiment with a BERT-based model, in line with recently\npublished works, that takes as input a combination of proposed artificial\nmetadata and table content. Our empirical results show that this leads to an\nimprovement of 9\\%-45\\% in F1 score, in absolute terms, over 2 tabular\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+singh_G/0/1/0/all/0/1\">Gaurav singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Siffi Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Joshua Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saffari_A/0/1/0/all/0/1\">Amir Saffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Offensive Language Identification for Tamil Code-Mixed YouTube Comments and Posts. (arXiv:2108.10939v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.10939","description":"<p>Offensive Language detection in social media platforms has been an active\nfield of research over the past years. In non-native English spoken countries,\nsocial media users mostly use a code-mixed form of text in their\nposts/comments. This poses several challenges in the offensive content\nidentification tasks, and considering the low resources available for Tamil,\nthe task becomes much harder. The current study presents extensive experiments\nusing multiple deep learning, and transfer learning models to detect offensive\ncontent on YouTube. We propose a novel and flexible approach of selective\ntranslation and transliteration techniques to reap better results from\nfine-tuning and ensembling multilingual transformer networks like BERT, Distil-\nBERT, and XLM-RoBERTa. The experimental results showed that ULMFiT is the best\nmodel for this task. The best performing models were ULMFiT and mBERTBiLSTM for\nthis Tamil code-mix dataset instead of more popular transfer learning models\nsuch as Distil- BERT and XLM-RoBERTa and hybrid deep learning models. The\nproposed model ULMFiT and mBERTBiLSTM yielded good results and are promising\nfor effective offensive speech identification in low-resourced languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vasantharajan_C/0/1/0/all/0/1\">Charangan Vasantharajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thayasivam_U/0/1/0/all/0/1\">Uthayasanker Thayasivam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LayoutReader: Pre-training of Text and Layout for Reading Order Detection. (arXiv:2108.11591v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11591","description":"<p>Reading order detection is the cornerstone to understanding visually-rich\ndocuments (e.g., receipts and forms). Unfortunately, no existing work took\nadvantage of advanced deep learning models because it is too laborious to\nannotate a large enough dataset. We observe that the reading order of WORD\ndocuments is embedded in their XML metadata; meanwhile, it is easy to convert\nWORD documents to PDFs or images. Therefore, in an automated manner, we\nconstruct ReadingBank, a benchmark dataset that contains reading order, text,\nand layout information for 500,000 document images covering a wide spectrum of\ndocument types. This first-ever large-scale dataset unleashes the power of deep\nneural networks for reading order detection. Specifically, our proposed\nLayoutReader captures the text and layout information for reading order\nprediction using the seq2seq model. It performs almost perfectly in reading\norder detection and significantly improves both open-source and commercial OCR\nengines in ordering text lines in their results in our experiments. We will\nrelease the dataset and model at \\url{https://aka.ms/layoutreader}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yiheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Negative Sampling for Unlabeled Entity Problem in Named Entity Recognition. (arXiv:2108.11607v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.11607","description":"<p>In many situations (e.g., distant supervision), unlabeled entity problem\nseriously degrades the performances of named entity recognition (NER) models.\nRecently, this issue has been well addressed by a notable approach based on\nnegative sampling. In this work, we perform two studies along this direction.\nFirstly, we analyze why negative sampling succeeds both theoretically and\nempirically. Based on the observation that named entities are highly sparse in\ndatasets, we show a theoretical guarantee that, for a long sentence, the\nprobability of containing no unlabeled entities in sampled negatives is high.\nMissampling tests on synthetic datasets have verified our guarantee in\npractice. Secondly, to mine hard negatives and further reduce missampling\nrates, we propose a weighted and adaptive sampling distribution for negative\nsampling. Experiments on synthetic datasets and well-annotated datasets show\nthat our method significantly improves negative sampling in robustness and\neffectiveness. We also have achieved new state-of-the-art results on real-world\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-08-29T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}