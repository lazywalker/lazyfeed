{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.3","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2021-09-24T04:27:42.750435403Z","channels":[{"title":"Rust.cc","link":"https://rustcc.cn/rss","description":"This Is Rust Crustacean Community RSS feed.","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":null,"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"一句话Rust接龙","link":"https://rustcc.cn/article?id=86409c66-5622-46be-a4bf-6416897c5fc4","description":"<p>我先来几个：</p>\n<ol>\n<li>Rust，让一切皆有可能。</li>\n<li>Rust，看不到天花板。</li>\n</ol>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-24 03:25:10","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-23 - 协作编曲工具 Composing Studio","link":"https://rustcc.cn/article?id=fe8af943-9a57-4d6c-b77b-6ee73a9c9152","description":"<h3>Composing Studio - 协作编曲工具</h3>\n<p>Composing Studio 是一款支持在线实时协作的音乐编辑器，使用 Rust、WebAssembly 和 TypeScript 构建，允许任何人创建简单的音乐作品。</p>\n<p>Composing Studio 使用一种名为 ABC 的文本格式来完成对音乐的编辑，可以用于转录简单的歌曲 + 吉他和弦，以及其他一些作品，如合唱和民间音乐。同时提供一个友好直观的 Web 界面，具有语法突出显示、实时预览、音频播放和实时协作等功能。</p>\n<p><img src=\"https://s3.bmp.ovh/imgs/2021/09/fcef25acd954e36e.png\" alt=\"Composing Studio\"></p>\n<p><a href=\"https://github.com/ekzhang/composing.studio\" rel=\"noopener noreferrer\">GitHub - ekzhang/composing.studio</a>: https://github.com/ekzhang/composing.studio</p>\n<p><a href=\"https://composing.studio/productive-animal-5688\" rel=\"noopener noreferrer\">online demo</a>: https://composing.studio/productive-animal-5688</p>\n<h3>termusic - 终端音乐播放器</h3>\n<p>termusic 是一款用 Rust 开发的终端音乐播放器，目前支持 mp3, m4a, flac 和 ogg/vorbis 多种格式。作者曾经是 GOMU 的贡献者，由于在开发时遇到像数据竞争这样的严重问题，所以使用 Rust 进行了重写。</p>\n<p><img src=\"https://s3.bmp.ovh/imgs/2021/09/5a9b980383719ec7.png\" alt=\"termusic\"></p>\n<p><a href=\"https://github.com/tramhao/termusic\" rel=\"noopener noreferrer\">GitHub - tramhao/termusic</a>: https://github.com/tramhao/termusic</p>\n<p><a href=\"https://crates.io/crates/termusic\" rel=\"noopener noreferrer\">Crates.io - termusic</a>: https://crates.io/crates/termusic</p>\n<h3>This Week in Rust 409</h3>\n<p>新一期的 Rust 周报速递发布，快来看看有哪些内容你曾经关注过 :)</p>\n<p><a href=\"https://this-week-in-rust.org/blog/2021/09/22/this-week-in-rust-409/\" rel=\"noopener noreferrer\">This Week in Rust 409</a>: https://this-week-in-rust.org/blog/2021/09/22/this-week-in-rust-409/</p>\n<hr>\n<p>From 日报小组 <a href=\"https://github.com/PsiACE\" rel=\"noopener noreferrer\">PsiACE</a></p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rust.cc 论坛: 支持 rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust 语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-23 14:50:59","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"The Rustonomicon 的中文翻译","link":"https://rustcc.cn/article?id=108c18ae-f5d5-4799-a457-7604149f4972","description":"<p>最近在学习 Rust，发现 Rust 社区真的是有非常丰富的资源，从社区中学到了很多有用的东西。与此同时，也一直想着能够为社区做点什么。</p>\n<p>正好发现<a href=\"https://doc.rust-lang.org/nomicon/\" rel=\"noopener noreferrer\">《The Rustonomicon》</a>（也称为 Rust 秘典、死灵书）之前的一版中文翻译（感谢@tjxing）是更新到了 2018 年，之后就再也没再更新维护过了；而这三年官方也对于这本书进行了大量的迭代升级，于是想着重新翻译一版，并尽可能持续跟进迭代，贡献给社区，也算是尽一份绵薄之力。</p>\n<p>在线阅读地址：<a href=\"https://nomicon.purewhite.io/\" rel=\"noopener noreferrer\">https://nomicon.purewhite.io/</a></p>\n<p>github 地址：https://github.com/PureWhiteWu/nomicon-zh-Hans</p>\n<h1>一些想说的话</h1>\n<p>首先，限于译者自身姿势水平，翻译有可能无法做到完全信达雅，并且有一些专业术语不知道如何翻译到中文，在这里先向大家道歉，请多包涵。</p>\n<p>不过，译者保证所有翻译的内容都是译者阅读并调整过多次的，并且译者会努力将内容调整到满足<strong>能看懂</strong>的要求，并且做到不遗漏原文内容。</p>\n<p>如果大家对于翻译有更好的建议或者想法，欢迎直接 PR~</p>\n<p>目前翻译基于 commit：2747c4bb2cbc0639b733793ddb0bf4e9daa2634e，基于时间：2021/9/19</p>\n<p>Q：为什么不基于之前已有的中文版进行改进？</p>\n<p>A：因为翻译成中文版后，很难再回过头去看和现在的英文版原文到底差了啥，所以还不如完全重新翻译一遍。</p>\n<p>Q：那会不会有一天你的这个版本也过期了？</p>\n<p>A：希望没有那一天。我 watch 了英文原版的所有 PR，如果有变更（希望）能及时更新。当然，也欢迎大家一起贡献 PR。</p>\n<h1>TODO</h1>\n<ul>\n<li> github 增加 action，合入 master 后自动更新线上版本</li>\n<li> 思考是否把英文原版和中文翻译按段落放在一起，方便查阅原版</li>\n</ul>\n<p>也欢迎大家集思广益，一起建设 Rust 社区。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-23 10:18:05","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"一个Rust学习和编写困难的有偿调研","link":"https://rustcc.cn/article?id=8c7ceb65-0c99-494f-a213-913ac55a01c7","description":"<p>美国宾州州立大学的科研团队设计了一项针对Rust开发人员的用户调研，调研的目标是理解Rust学习和编码的难点。要求调研参与者有一定的Rust编程经验，年龄在18岁以上，现在不在欧洲，和具有熟练的英语读写能力。预计的调研时间是20分钟。调研完成后，参与者会获得10美元的亚马逊购物劵。</p>\n<p>宾州州立大学的这个科研团队，有两年的Rust研究经验。之前关于Rust程序缺陷的研究发表在了<a href=\"https://songlh.github.io/paper/rust-study.pdf\" rel=\"noopener noreferrer\">PLDI‘2020</a>上，给Rust设计的开发工具发表成了<a href=\"https://songlh.github.io/paper/vr.pdf\" rel=\"noopener noreferrer\">CCS’2020的demo论文</a>。</p>\n<p>调研的英文说明如下：\nPaid Online Research: Rust Programmers’ On-board Programming Experience and Challenges</p>\n<p>Researchers at the Pennsylvania State University are conducting a study to understand Rust programmers’ on-board programming experience and the challenges they face when programming with Rust. Throughout a survey link, you will answer questions about Rust programming and your programming experience. The survey will take about 20 minutes. You will earn a $10 Amazon gift card for completing the study.</p>\n<p>You are eligible to participate in this study if you are:</p>\n<ul>\n<li>At least 18 years old</li>\n<li>An active user of Rust</li>\n<li>Fluent in English</li>\n<li>Not currently be residing in the EEA</li>\n</ul>\n<p>To participate, please click the following link:\n<a href=\"https://personal.psu.edu/suz305/rust-survey-aug/recruitment.html?s=rust_chinese\" rel=\"noopener noreferrer\">https://personal.psu.edu/suz305/rust-survey-aug/recruitment.html?s=rust_chinese</a>\nPlease finish the survey on PC or Mac, and mobile devices are not supported.</p>\n<p>Many research projects in human-centered computing depend on participation by individuals like yourself. We are very grateful for your help. Also, please DO NOT discuss this survey with others because this might jeopardize our research.</p>\n<p>Thank you again for your participation in this study.\nAny questions, please feel free to contact us.\nEmail: rust.pennstate@gmail.com\nPhone Number: +1 814-865-2370\nYou can also find the contact information of <a href=\"https://songlh.github.io/\" rel=\"noopener noreferrer\">Dr. Linhai Song</a> and <a href=\"https://ist.psu.edu/directory/axx29\" rel=\"noopener noreferrer\">Dr. Aiping Xiong</a> from their homepages.</p>\n<p><em>Due to the nature of the work, you may only complete the survey once. Participants will not be compensated if they are suspected of fraudulent behavior.</em></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-22 21:13:38","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"如何快速深入了解crate库","link":"https://rustcc.cn/article?id=83ab42f4-b4ec-46ed-b574-409781a813c0","description":"<p>最近因为工作需要，要了解ntex-mqtt、ntex库，看了几天代码，外加断点查看调用栈，依旧没有整体认知，感觉有几个原因：</p>\n<ol>\n<li>大量用到了泛型、异步future。这导致光看代码无法整理串联。</li>\n<li>抽象出的service和servicefactory,感觉把一些简单的逻辑变复杂了。</li>\n<li>其他，诸如对mqtt不够熟悉、代码没有注释、没有文档等原因</li>\n</ol>\n<p>挫败之余（求大家别喷），想请教大家，有没有合适的方式方法，能够比较快速、完整、深入的了解crate库？</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-22 15:23:14","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-22 -- kbio基于io_uring的异步 IO 框架","link":"https://rustcc.cn/article?id=e208a573-4fab-4dd0-a10a-c3ddcce40ace","description":"<h3>kbio基于io_uring的异步 IO 框架</h3>\n<ul>\n<li>支持多线程并发任务提交。</li>\n<li>很快。</li>\n<li>实现在 tokio 中引入的 AsyncRead/AsyncWrite trait。</li>\n</ul>\n<p>ReadMore:<a href=\"https://github.com/KuiBaDB/kbio\" rel=\"noopener noreferrer\">https://github.com/KuiBaDB/kbio</a></p>\n<p>Blog:<a href=\"https://blog.hidva.com/2021/09/14/kbio/\" rel=\"noopener noreferrer\">https://blog.hidva.com/2021/09/14/kbio/</a></p>\n<h3>KuiBaDB</h3>\n<p>KuiBaDB是另一个用Asynchronous Rust重写的PostgreSQL，KuiBaDB专注于 OLAP 分析。</p>\n<p>KuiBaDB建立在kbio和tokio之上。只用 tokio 的“rt-multi-thread”、“rt”和“io-util”功能。所有 IO，包括文件 IO 和网络 IO，以及异步系统调用都由kbio提供支持。</p>\n<p>KuiBaDB使用矢量化引擎，也是目录驱动的。KuiBaDB使用了Hologres 中引入的列式存储。但是我删除了Delete Map并为每行添加了xmin，xmax，xmin/xmax保存在行存储中。</p>\n<p>ReadMore:<a href=\"https://github.com/KuiBaDB/KuiBaDB\" rel=\"noopener noreferrer\">https://github.com/KuiBaDB/KuiBaDB</a></p>\n<h3>Robyn</h3>\n<p>Robyn 是一个由用 Rust 编写的异步 Python 后端HTTP服务运行时。</p>\n<p>在 Rust 异步运行时之上运行的 Python 服务。</p>\n<h4>安装</h4>\n<pre><code>pip install robyn\n</code></pre>\n<h4>用法</h4>\n<pre><code>from robyn import Robyn\n\napp = Robyn(__file__)\n\n@app.get(\"/\")\nasync def h():\n    return \"Hello, world!\"\n\napp.start(port=5000)\n</code></pre>\n<h4>GET 请求</h4>\n<pre><code>```python3\n@app.get(\"/\")\nasync def h(request):\n    return \"Hello World\"\n```\n</code></pre>\n<h4>POST 请求</h4>\n<pre><code>```python3\n@app.post(\"/post\")\nasync def postreq(request):\n    return bytearray(request[\"body\"]).decode(\"utf-8\")\n```\n</code></pre>\n<p>ReadMore:<a href=\"https://sansyrox.github.io/robyn\" rel=\"noopener noreferrer\">https://sansyrox.github.io/robyn</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; Mike</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-22 15:06:33","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"actix_web","link":"https://rustcc.cn/article?id=6413ef06-e6be-4998-aaab-5f9268b2250b","description":"<p>、</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-22 03:05:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-09-21 Rustacean 中秋节快乐","link":"https://rustcc.cn/article?id=f83ce9ba-7c21-4673-87b2-a97a9c639764","description":"<p>所有 Rustaceans，中秋节快乐。</p>\n<h3>组合 Axum, Hyper, Tonic 和 Tower 一起，开发一个混合的 web/gRPC 应用：第四部分</h3>\n<p>本系列已经更新到第四部分了，也是终结篇。欢迎跟进。</p>\n<p>https://www.fpcomplete.com/blog/axum-hyper-tonic-tower-part4/</p>\n<h3>【播客】使用 Tarpaulin 进行 Rust 工程测试率覆盖</h3>\n<p>Allen Wyma 与软件工程师 Daniel McKenna，也是 Tarpaulin 覆盖测试工具的作者的访谈节目。欢迎收听。</p>\n<p>https://rustacean-station.org/episode/037-daniel-mckenna/</p>\n<h3>Trunk - 一个 Rust 的 WASM web 应用打包器</h3>\n<p>Trunk 会打包 WASM，JS 代码片断，静态资源（images, css, scss 等）。它的配置使用 HTML 文件。</p>\n<p>Trunk 支持所有基于 wasm-bindgen 的框架，包括但不仅限于 Yew 和 Seed。</p>\n<p>官网：https://trunkrs.dev/</p>\n<p>代码仓库：https://github.com/thedodd/trunk</p>\n<h3>Perseus - 另一个前端集成 Web UI 框架</h3>\n<p>perseus 采用 No-VDOM 技术实现页面渲染。实现纯 Rust 前端 Web UI 开发。</p>\n<ul>\n<li>支持服务端静态页面生成</li>\n<li>支持服务端动态渲染</li>\n<li>支持增量生成</li>\n<li>各种定制渲染策略</li>\n<li>命令行工具</li>\n<li>基于 <a href=\"https://projectfluent.org/\" rel=\"noopener noreferrer\">Fluent</a> 的 i18n 支持</li>\n</ul>\n<p>它基于强大的 <a href=\"https://github.com/sycamore-rs/sycamore\" rel=\"noopener noreferrer\">sycamore</a> 实现。实际上，Perseus 与 Yew, Seed 等算竞争对手，但是所采用的技术思路实际是不一样的。</p>\n<p>https://github.com/arctic-hen7/perseus</p>\n<p>--</p>\n<p>From 日报小组 Mike Tang</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li>Rustcc论坛: 支持rss</li>\n<li>微信公众号：Rust语言中文社区</li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 13:28:53","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"在rust的async-std中怎么获取当前时间","link":"https://rustcc.cn/article?id=603210f7-0575-44f9-b925-579e3e13a9ba","description":"<p>请问在async_std包裹的区域内怎么获取当前时间， 我使用了chrono获取时间，但似乎因为chrono没有实现futures，所以在代码中有问题</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 11:15:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【武汉 or 远程】来个接地气的招聘","link":"https://rustcc.cn/article?id=76aac56f-ea37-4695-9eb3-7937fe0bd389","description":"<h2>你们做什么</h2>\n<p><a href=\"https://rustdesk.com/\" rel=\"noopener noreferrer\">RustDesk</a>是一款远程桌面软件，目前桌面客户端开源（<a href=\"https://github.com/rustdesk/rustdesk\" rel=\"noopener noreferrer\">项目地址</a>），起源于一个 Rust 练手项目，主要使用 Rust 开发，移动端 UI 采用 Flutter，定位于更开放、更安全、更注重隐私保护，不断完善用户体验。</p>\n<h2>你们团队怎么样</h2>\n<p>最近才拿到两笔投资，一笔国内，一笔国外，目前团队里只有原作者一人，没有硅谷、华尔街亦或者常青藤背景，也没有经历过 996，只是一名华科的普通老毕业生，选择武汉是为了能够更方便照顾老父老母，摸一摸母校的老梧桐。深知这是一个竞争相当激烈的市场，前路布满荆棘，所以更加期待你的加入，大家一起努力，做好产品，接受市场的考验。</p>\n<h2>你们的技术栈是什么？</h2>\n<p>Rust 、Flutter 、React/Javascript</p>\n<h2>我能从这份工作中得到什么？</h2>\n<p>你将是团队的第一批员工，见证一个产品的完整成长过程，团队文化也将由你们来定义。如果你喜欢 Rust，并且不断学习，不甘愿做螺丝钉，追求成就感，欣赏积极主动的工作态度，请考虑加入 RustDesk，我们一起探索国内新的 IT 职业生态。</p>\n<h2>岗位</h2>\n<h3>全栈开发工程师 [15K-35K + 期权（如果你有兴趣）]</h3>\n<p>也许你不喜欢全栈这个词汇，但是 RustDesk 的确在目前阶段还是一款重客户端，轻服务端的跨平台产品。根据你的经验或者喜好，你可以选择你的侧重点。</p>\n<h4>岗位要求：</h4>\n<ul>\n<li>写过 Rust</li>\n<li>了解基础数据结构和算法</li>\n<li>喜欢学习新东西，主动思考，提问前先 Google</li>\n<li>能够接受他人意见，不要对自己的代码迷之自信，也不要轻易吐槽他人的代码</li>\n<li>加分项：不错的 GitHub 项目、能够写出漂亮的 UI 、视频编解码开发经验、网络通信安全开发经验、后端高并发开发经验、网络协议栈开发经验</li>\n</ul>\n<h2>面试方式</h2>\n<p>你不需要准备 LeetCode，也无需通读算法导论，但是请熟悉 GNU STL 里的基础数据结构和算法。我希望你花点时间了解 RustDesk，然后自行选择 GitHub 上的 3 个 issues，我们一起在面试中讨论分享。</p>\n<h2>投递简历</h2>\n<p>Email：info [at] rustdesk.com</p>\n<p>请投递 PDF 版本完整简历（教育+工作经历），包括籍贯</p>\n<p>我会在第一时间回复你，如果你在两天内没有收到回复，请包涵，你依然很优秀，只是我眼拙没能找到彼此的契合点。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-21 09:57:40","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 培养提高计划 Vol. 7 - 8 | Rust 项目工程来了","link":"https://rustcc.cn/article?id=9dec6eeb-38d8-4ec4-b75e-783bd11bf24b","description":"<p>我们的 Rust 公开课进行了 6 期了，带大家了解了 ：</p>\n<ol>\n<li>认识面向基础架构语言</li>\n<li>理解 Rust 所有权</li>\n<li>通过实战理解 Rust 宏</li>\n<li>通过 Datafuse 理解全链路跟踪</li>\n<li>Rust 异步编程入门 Future Part 1</li>\n<li>Rust 异步编程入门 Future Part 2</li>\n</ol>\n<p>目前视频回放传到 B 站收获许多好评，赞，也给我们很大的鼓励。希望我们的 Rust 培养提高计划 | Datafuse 可以帮助更多的朋友快速的使用上 Rust 。\n本周给大家排两个公开课：周四晚上，周日晚上。我们 Rust 培养提高计划邀请到第二位分享嘉宾 董泽润老师， 另外 Rust 培养提高计划 的内容上也做了一些调整。</p>\n<hr>\n<p>分享主题：《深入了解rust 闭包》 | Vol. 7</p>\n<p>分享时间： 周四晚上2021-09-09 20:00-21:00</p>\n<p>分享讲师： 董泽润</p>\n<p>内容介绍： 深入浅出了解 rust 闭包工作原理，让大家了解底层实现\n讲师介绍：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/07-%E8%91%A3%E6%B3%BD%E6%B6%A6.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<hr>\n<p>分享主题：《利用 Tokio 实现一个高性能 Mini Http server》 | Vol. 8</p>\n<p>分享时间：  周日晚上2021-09-12 20:00-21:00</p>\n<p>分享讲师： 苏林</p>\n<p>首先感谢苏林老师的坚持付出， 带我们学习 Rust 的重点知识。 经过和苏琳老师沟通，我们后续的课程，会更加往实战方向转变。接下是一个系列的内容：</p>\n<ol>\n<li>利用 Tokio 实现一个 Mini Http server</li>\n<li>基于 Http server提供内容动态的 API 网关</li>\n<li>利用 Redis 实现对 API 网关加速</li>\n<li>学习 Rust RPC 调用，实现微服务调用</li>\n</ol>\n<p>这个内容可能需要4次左右的公开课，目的是带着大家做一些小项目，带大家熟悉一下 Rust 工程，让大家可以快速把 Rust 用到后端开发中。</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<p>Rust 异步编程入门 Future Part 1   | Vol. 5\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<p>Rust 异步编程入门 Future Part 2  | Vol. 6\nhttps://www.bilibili.com/video/bv1oy4y1G7jC</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-07 02:23:16","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"rust 学习随笔","link":"https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8","description":"<h1>切换镜像源</h1>\n<p>crm =&gt; https://github.com/wtklbm/crm</p>\n<p>常用命令就是 <code>crm best</code></p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 14:35:49","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"pretree 补全文档发布了,再次谢谢大神的指点终于入门了。","link":"https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827","description":"<h1>Pretree</h1>\n<p>pretree is a package for storing and querying routing rules with prefix tree .</p>\n<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>\n<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>\n<p>Inspired by <a href=\"https://github.com/obity/pretree\" rel=\"noopener noreferrer\">obity/pretree</a> (golang)</p>\n<h1>Doc</h1>\n<p>See this document at <a href=\"https://docs.rs/pretree\" rel=\"noopener noreferrer\">API documentation</a></p>\n<h1>Install</h1>\n<p>Add the following line to your Cargo.toml file:</p>\n<pre><code>pretree = \"1.0.0\"\n</code></pre>\n<h1>Example</h1>\n<pre><code>use pretree::Pretree;\nlet mut p = Pretree::new();\np.store(\"GET\",\"account/{id}/info/:name\");\np.store(\"GET\",\"account/:id/login\");\np.store(\"GET\",\"account/{id}\");\np.store(\"GET\",\"bacteria/count_number_by_month\");\nlet (ok,rule,vars) = p.query(\"GET\",\"account/929239\");\nprintln!(\"ok:{} rule:{} vars:{:#?}\",ok,rule,vars);\n\n</code></pre>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-06 09:37:30","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6","link":"https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a","description":"<h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>\n<p><strong>课程时间:</strong>  2021年9月5日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识,  Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>\n<h3>课程大纲</h3>\n<p>1、回顾 Rust 异步编程模型.</p>\n<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>\n<p>3、Tokio 介绍.</p>\n<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>\n<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/\nRust 异步编程入门 Future Part 1  回放地址：\nhttps://www.bilibili.com/video/BV1mf4y1N7MJ/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-09-02 08:40:15","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课：《 Rust 异步编程入门 Future 》|Vol. 5","link":"https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70","description":"<h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>\n<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>\n<p><strong>课程介绍:</strong>  讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是  Rust 异步编程的核心基础。</p>\n<h3>课程大纲</h3>\n<p>1、为什么需要异步.</p>\n<p>2、理解异步编程模型.</p>\n<p>3、Future 编程模型讲解.</p>\n<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<p>通过 Datafuse 理解全链路跟踪 | Vol. 4  https://www.bilibili.com/video/BV1YA411c7ia/</p>\n<h3>课程中推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-23 03:14:21","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中","link":"https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c","description":"<h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>\n<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>\n<p>ReadMore:<a href=\"https://twitter.com/m_ou_se/status/1427666611977297924\" rel=\"noopener noreferrer\">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>\n<h3>异步引擎 C++20, Rust &amp; Zig</h3>\n<p>ReadMore:<a href=\"https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/\" rel=\"noopener noreferrer\">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>\n<h3>RG3D -- Rust 3D 游戏引擎</h3>\n<ul>\n<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>\n<li><strong>延迟着色</strong></li>\n<li><strong>内置保存/加载</strong></li>\n<li><strong>独立场景编辑器</strong></li>\n<li><strong>高级物理模型</strong></li>\n<li><strong>分层模型资源</strong></li>\n<li><strong>几何实例化</strong></li>\n</ul>\n<p>ReadMore:<a href=\"https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/\" rel=\"noopener noreferrer\">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>\n<p>ReadMore:<a href=\"https://github.com/rg3dengine/rg3d\" rel=\"noopener noreferrer\">https://github.com/rg3dengine/rg3d</a></p>\n<hr>\n<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>\n<p>社区学习交流平台订阅：</p>\n<ul>\n<li><a href=\"https://rustcc.cn/\" rel=\"noopener noreferrer\">Rustcc论坛: 支持rss</a></li>\n<li><a href=\"https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62\" rel=\"noopener noreferrer\">微信公众号：Rust语言中文社区</a></li>\n</ul>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-18 16:31:44","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4","link":"https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8","description":"<p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>\n<p><strong>课程时间：</strong>  2021年8月22日 20:30-21:30</p>\n<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>\n<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>\n<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>\n<h3>课程大纲</h3>\n<ol>\n<li>\n<p>什么是分布式追踪系统OpenTracing及应用场景</p>\n</li>\n<li>\n<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>\n</li>\n<li>\n<p>为什么需要tokio-rs/tracing库</p>\n</li>\n<li>\n<p>演示Datafuse项目中tokio-rs/tracing的使用</p>\n</li>\n</ol>\n<h3><strong>讲师介绍</strong></h3>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>获取 T-Shirt 的方法：</h3>\n<ol>\n<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>\n<li>进行 Rust，大数据，数据库方面的公开课分享</li>\n<li>社区里分享 datafuse 相关文章</li>\n<li>datafuse.rs 上面文档翻译工作</li>\n</ol>\n<h3>往期课程回放</h3>\n<p>认识面向基础架构语言 Rust | Vol. 1  https://www.bilibili.com/video/BV1mg411778g</p>\n<p>理解 Rust 的所有权 | Vol. 2    https://www.bilibili.com/video/BV1264y1i7U9</p>\n<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n<p>Rust宏的练习项目：   https://github.com/dtolnay/proc-macro-workshop</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-16 03:14:03","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"论坛github账户无法登录解决笔记","link":"https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190","description":"<p>有反映这两天github账户无法登录了。</p>\n<p>报这个错：</p>\n<pre><code>get github user info err\n</code></pre>\n<p>查了几个地方：</p>\n<ol>\n<li>代码是否运行正常：Ok</li>\n<li>https代理是否正常：Ok</li>\n<li>检查了github返回日志，发现是：</li>\n</ol>\n<pre><code>get_github_user_info: response body: \"{\\\"message\\\":\\\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\\\",\\\"documentation_url\\\":\\\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\\\"}\"\nget_github_user_info: Got: Err(Custom(\"read json login error\"))\n</code></pre>\n<p>进入这个地址一看：<a href=\"https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/\" rel=\"noopener noreferrer\">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>\n<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>\n<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>\n<p>特此记录。</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-13 07:03:09","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust 的 Future 与 Javascript 的 Promise 功能对照参考","link":"https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095","description":"<h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>\n<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>\n<blockquote>\n<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>javascript</th>\n<th align=\"center\">rust</th>\n<th align=\"center\">描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Promise.resolve(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Ok(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.reject(...)</td>\n<td align=\"center\">use ::async_std::future;future::ready(Err(...))</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>Promise.catch(err =&gt; err)</td>\n<td align=\"center\">use ::async_std::future;future::ready(...)</td>\n<td align=\"center\">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>\n</tr>\n<tr>\n<td>new Promise(() =&gt; {/* 什么都不做 */})</td>\n<td align=\"center\">use ::async_std::future;future::pending()</td>\n<td align=\"center\"></td>\n</tr>\n<tr>\n<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; {  if (Math.random() &gt; .5) {    resolve(1);  } else {    reject(new Error('1'));  }}, 500))</td>\n<td align=\"center\">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| {    thread::sleep(Duration::from_millis(500));    let mut rng = rand::thread_rng();    if rng.gen() &gt; 0.5f64 {       Ok(1)    } else {       Err('1')    }}).await;</td>\n<td align=\"center\">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被  （1）跨线程传递  （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>\n</tr>\n<tr>\n<td>Promise.all([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_join(future2).try_join(future3).await</td>\n<td align=\"center\">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>\n</tr>\n<tr>\n<td>Promise.all([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.join(future2).join(future3).await</td>\n<td align=\"center\">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>\n</tr>\n<tr>\n<td>Promise.race([promise1, promise2, promise3])</td>\n<td align=\"center\">future1.try_race(future2).try_race(future3).await</td>\n<td align=\"center\">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>\n</tr>\n<tr>\n<td>Promise.race([  promise1.catch(err =&gt; err),  promise2.catch(err =&gt; err)  promise3.catch(err =&gt; err)])</td>\n<td align=\"center\">future1.race(future2).race(future3).await</td>\n<td align=\"center\">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>\n</tr>\n</tbody>\n</table>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-11 23:36:19","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null},{"title":"Rust公开课：《通过实战理解 Rust 宏》| Vol. 3","link":"https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21","description":"<p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>\n<p><strong>课程时间：</strong>  2021年8月15日 20:30-21:30</p>\n<p><strong>课程介绍：</strong></p>\n<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg\" alt=\"\"></p>\n<p>这就是通过宏实现配置的统一行为，代码参考：\nhttps://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>\n<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>\n<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>\n<h3>课程大纲</h3>\n<ul>\n<li>什么是 Rust 宏</li>\n<li>什么是宏运行原理</li>\n<li>如何创建 Rust 宏过程</li>\n<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>\n</ul>\n<p><strong>讲师介绍</strong>\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png\" alt=\"\"></p>\n<p><img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png\" alt=\"\"></p>\n<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。\n<img src=\"https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png\" alt=\"\"></p>\n<h3>课程中苏林老师推荐入门资料：</h3>\n<p>Rust在线编辑器:                     https://play.rust-lang.org/</p>\n<p>《Rust语言程序设计》:            https://kaisery.github.io/trpl-zh-cn/</p>\n<p>打怪通关学习方式Rustlings:   https://github.com/rust-lang/rustlings</p>\n<p>Rust优秀项目Datafuse：        https://github.com/datafuselabs/datafuse</p>\n","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":"2021-08-09 05:46:45","source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":null}],"extensions":{},"itunes_ext":null,"dublin_core_ext":null,"syndication_ext":null,"namespaces":{}}]},{"datetime":"2021-09-24T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Cross-linguistically Consistent Semantic and Syntactic Annotation of Child-directed Speech. (arXiv:2109.10952v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10952","description":"<p>While corpora of child speech and child-directed speech (CDS) have enabled\nmajor contributions to the study of child language acquisition, semantic\nannotation for such corpora is still scarce and lacks a uniform standard. We\ncompile two CDS corpora with sentential logical forms, one in English and the\nother in Hebrew. In compiling the corpora we employ a methodology that enforces\na cross-linguistically consistent representation, building on recent advances\nin dependency representation and semantic parsing. The corpora are based on a\nsizable portion of Brown's Adam corpus from CHILDES (about 80% of its\nchild-directed utterances), and to all child-directed utterances from Berman's\nHebrew CHILDES corpus Hagar.\n</p>\n<p>We begin by annotating the corpora with the Universal Dependencies (UD)\nscheme for syntactic annotation, motivated by its applicability to a wide\nvariety of domains and languages. We then proceed by applying an automatic\nmethod for transducing sentential logical forms (LFs) from UD structures. The\ntwo representations have complementary strengths: UD structures are\nlanguage-neutral and support direct annotation, whereas LFs are neutral as to\nthe interface between syntax and semantics, and transparently encode semantic\ndistinctions. We verify the quality of the annotated UD annotation using an\ninter-annotator agreement study. We then demonstrate the utility of the\ncompiled corpora through a longitudinal corpus study of the prevalence of\ndifferent syntactic and semantic phenomena.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Szubert_I/0/1/0/all/0/1\">Ida Szubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibbon_S/0/1/0/all/0/1\">Samuel Gibbon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwater_S/0/1/0/all/0/1\">Sharon Goldwater</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steedman_M/0/1/0/all/0/1\">Mark Steedman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scalable Fact-checking with Human-in-the-Loop. (arXiv:2109.10992v1 [cs.CL])","link":"http://arxiv.org/abs/2109.10992","description":"<p>Researchers have been investigating automated solutions for fact-checking in\na variety of fronts. However, current approaches often overlook the fact that\nthe amount of information released every day is escalating, and a large amount\nof them overlap. Intending to accelerate fact-checking, we bridge this gap by\ngrouping similar messages and summarizing them into aggregated claims.\nSpecifically, we first clean a set of social media posts (e.g., tweets) and\nbuild a graph of all posts based on their semantics; Then, we perform two\nclustering methods to group the messages for further claim summarization. We\nevaluate the summaries both quantitatively with ROUGE scores and qualitatively\nwith human evaluation. We also generate a graph of summaries to verify that\nthere is no significant overlap among them. The results reduced 28,818 original\nmessages to 700 summary claims, showing the potential to speed up the\nfact-checking process by organizing and selecting representative claims from\nmassive disorganized and redundant messages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vega_Oliveros_D/0/1/0/all/0/1\">Didier Vega-Oliveros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seibt_T/0/1/0/all/0/1\">Tais Seibt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocha_A/0/1/0/all/0/1\">Anderson Rocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alzheimers Dementia Detection using Acoustic & Linguistic features and Pre-Trained BERT. (arXiv:2109.11010v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11010","description":"<p>Alzheimers disease is a fatal progressive brain disorder that worsens with\ntime. It is high time we have inexpensive and quick clinical diagnostic\ntechniques for early detection and care. In previous studies, various Machine\nLearning techniques and Pre-trained Deep Learning models have been used in\nconjunction with the extraction of various acoustic and linguistic features.\nOur study focuses on three models for the classification task in the ADReSS\n(The Alzheimers Dementia Recognition through Spontaneous Speech) 2021\nChallenge. We use the well-balanced dataset provided by the ADReSS Challenge\nfor training and validating our models. Model 1 uses various acoustic features\nfrom the eGeMAPs feature-set, Model 2 uses various linguistic features that we\ngenerated from auto-generated transcripts and Model 3 uses the auto-generated\ntranscripts directly to extract features using a Pre-trained BERT and TF-IDF.\nThese models are described in detail in the models section.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Valsaraj_A/0/1/0/all/0/1\">Akshay Valsaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madala_I/0/1/0/all/0/1\">Ithihas Madala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1\">Nikhil Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baths_V/0/1/0/all/0/1\">Veeky Baths</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Decomposition for Table-based Fact Verification. (arXiv:2109.11020v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11020","description":"<p>Fact verification based on structured data is challenging as it requires\nmodels to understand both natural language and symbolic operations performed\nover tables. Although pre-trained language models have demonstrated a strong\ncapability in verifying simple statements, they struggle with complex\nstatements that involve multiple operations. In this paper, we improve fact\nverification by decomposing complex statements into simpler subproblems.\nLeveraging the programs synthesized by a weakly supervised semantic parser, we\npropose a program-guided approach to constructing a pseudo dataset for\ndecomposition model training. The subproblems, together with their predicted\nanswers, serve as the intermediate evidence to enhance our fact verification\nmodel. Experiments show that our proposed approach achieves the new\nstate-of-the-art performance, an 82.7\\% accuracy, on the TabFact benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditional Poisson Stochastic Beam Search. (arXiv:2109.11034v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11034","description":"<p>Beam search is the default decoding strategy for many sequence generation\ntasks in NLP. The set of approximate K-best items returned by the algorithm is\na useful summary of the distribution for many applications; however, the\ncandidates typically exhibit high overlap and may give a highly biased estimate\nfor expectations under our model. These problems can be addressed by instead\nusing stochastic decoding strategies. In this work, we propose a new method for\nturning beam search into a stochastic process: Conditional Poisson stochastic\nbeam search. Rather than taking the maximizing set at each iteration, we sample\nK candidates without replacement according to the conditional Poisson sampling\ndesign. We view this as a more natural alternative to Kool et. al. 2019's\nstochastic beam search (SBS). Furthermore, we show how samples generated under\nthe CPSBS design can be used to build consistent estimators and sample diverse\nsets from sequence models. In our experiments, we observe CPSBS produces lower\nvariance and more efficient estimators than SBS, even showing improvements in\nhigh entropy settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viera_T/0/1/0/all/0/1\">Tim Viera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlled Evaluation of Grammatical Knowledge in Mandarin Chinese Language Models. (arXiv:2109.11058v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11058","description":"<p>Prior work has shown that structural supervision helps English language\nmodels learn generalizations about syntactic phenomena such as subject-verb\nagreement. However, it remains unclear if such an inductive bias would also\nimprove language models' ability to learn grammatical dependencies in\ntypologically different languages. Here we investigate this question in\nMandarin Chinese, which has a logographic, largely syllable-based writing\nsystem; different word order; and sparser morphology than English. We train\nLSTMs, Recurrent Neural Network Grammars, Transformer language models, and\nTransformer-parameterized generative parsing models on two Mandarin Chinese\ndatasets of different sizes. We evaluate the models' ability to learn different\naspects of Mandarin grammar that assess syntactic and semantic relationships.\nWe find suggestive evidence that structural supervision helps with representing\nsyntactic state across intervening content and improves performance in low-data\nsettings, suggesting that the benefits of hierarchical inductive biases in\nacquiring dependency relationships may extend beyond English.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1\">Peng Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Sociolinguistic Variables to Reveal Changing Attitudes Towards Sexuality and Gender. (arXiv:2109.11061v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11061","description":"<p>Individuals signal aspects of their identity and beliefs through linguistic\nchoices. Studying these choices in aggregate allows us to examine large-scale\nattitude shifts within a population. Here, we develop computational methods to\nstudy word choice within a sociolinguistic lexical variable -- alternate words\nused to express the same concept -- in order to test for change in the United\nStates towards sexuality and gender. We examine two variables: i) referents to\nsignificant others, such as the word \"partner\" and ii) referents to an\nindefinite person, both of which could optionally be marked with gender. The\nlinguistic choices in each variable allow us to study increased rates of\nacceptances of gay marriage and gender equality, respectively. In longitudinal\nanalyses across Twitter and Reddit over 87M messages, we demonstrate that\nattitudes are changing but that these changes are driven by specific\ndemographics within the United States. Further, in a quasi-causal analysis, we\nshow that passages of Marriage Equality Acts in different states are drivers of\nlinguistic change.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+CH_Wang_S/0/1/0/all/0/1\">Sky CH-Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1\">David Jurgens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Actionable Conversational Quality Indicators for Improving Task-Oriented Dialog Systems. (arXiv:2109.11064v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11064","description":"<p>Automatic dialog systems have become a mainstream part of online customer\nservice. Many such systems are built, maintained, and improved by customer\nservice specialists, rather than dialog systems engineers and computer\nprogrammers. As conversations between people and machines become commonplace,\nit is critical to understand what is working, what is not, and what actions can\nbe taken to reduce the frequency of inappropriate system responses. These\nanalyses and recommendations need to be presented in terms that directly\nreflect the user experience rather than the internal dialog processing.\n</p>\n<p>This paper introduces and explains the use of Actionable Conversational\nQuality Indicators (ACQIs), which are used both to recognize parts of dialogs\nthat can be improved, and to recommend how to improve them. This combines\nbenefits of previous approaches, some of which have focused on producing dialog\nquality scoring while others have sought to categorize the types of errors the\ndialog system is making.\n</p>\n<p>We demonstrate the effectiveness of using ACQIs on LivePerson internal dialog\nsystems used in commercial customer service applications, and on the publicly\navailable CMU LEGOv2 conversational dataset (Raux et al. 2005). We report on\nthe annotation and analysis of conversational datasets showing which ACQIs are\nimportant to fix in various situations.\n</p>\n<p>The annotated datasets are then used to build a predictive model which uses a\nturn-based vector embedding of the message texts and achieves an 79% weighted\naverage f1-measure at the task of finding the correct ACQI for a given\nconversation. We predict that if such a model worked perfectly, the range of\npotential improvement actions a bot-builder must consider at each turn could be\nreduced by an average of 81%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Higgins_M/0/1/0/all/0/1\">Michael Higgins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widdows_D/0/1/0/all/0/1\">Dominic Widdows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brew_C/0/1/0/all/0/1\">Chris Brew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christian_G/0/1/0/all/0/1\">Gwen Christian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maurer_A/0/1/0/all/0/1\">Andrew Maurer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunn_M/0/1/0/all/0/1\">Matthew Dunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathi_S/0/1/0/all/0/1\">Sujit Mathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazare_A/0/1/0/all/0/1\">Akshay Hazare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonev_G/0/1/0/all/0/1\">George Bonev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hockey_B/0/1/0/all/0/1\">Beth Ann Hockey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howell_K/0/1/0/all/0/1\">Kristen Howell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradley_J/0/1/0/all/0/1\">Joe Bradley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Universal Dense Retrieval for Open-domain Question Answering. (arXiv:2109.11085v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11085","description":"<p>In open-domain question answering, a model receives a text question as input\nand searches for the correct answer using a large evidence corpus. The\nretrieval step is especially difficult as typical evidence corpora have\n\\textit{millions} of documents, each of which may or may not have the correct\nanswer to the question. Very recently, dense models have replaced sparse\nmethods as the de facto retrieval method. Rather than focusing on lexical\noverlap to determine similarity, dense methods build an encoding function that\ncaptures semantic similarity by learning from a small collection of\nquestion-answer or question-context pairs. In this paper, we investigate dense\nretrieval models in the context of open-domain question answering across\ndifferent input distributions. To do this, first we introduce an entity-rich\nquestion answering dataset constructed from Wikidata facts and demonstrate\ndense models are unable to generalize to unseen input question distributions.\nSecond, we perform analyses aimed at better understanding the source of the\nproblem and propose new training techniques to improve out-of-domain\nperformance on a wide variety of datasets. We encourage the field to further\ninvestigate the creation of a single, universal dense retrieval model that\ngeneralizes well across all input distributions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sciavolino_C/0/1/0/all/0/1\">Christopher Sciavolino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiRdQA: A Bilingual Dataset for Question Answering on Tricky Riddles. (arXiv:2109.11087v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11087","description":"<p>A riddle is a question or statement with double or veiled meanings, followed\nby an unexpected answer. Solving riddle is a challenging task for both machine\nand human, testing the capability of understanding figurative, creative natural\nlanguage and reasoning with commonsense knowledge. We introduce BiRdQA, a\nbilingual multiple-choice question answering dataset with 6614 English riddles\nand 8751 Chinese riddles. For each riddle-answer pair, we provide four\ndistractors with additional information from Wikipedia. The distractors are\nautomatically generated at scale with minimal bias. Existing monolingual and\nmultilingual QA models fail to perform well on our dataset, indicating that\nthere is a long way to go before machine can beat human on solving tricky\nriddles. The dataset has been released to the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distiller: A Systematic Study of Model Distillation Methods in Natural Language Processing. (arXiv:2109.11105v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11105","description":"<p>We aim to identify how different components in the KD pipeline affect the\nresulting performance and how much the optimal KD pipeline varies across\ndifferent datasets/tasks, such as the data augmentation policy, the loss\nfunction, and the intermediate representation for transferring the knowledge\nbetween teacher and student. To tease apart their effects, we propose\nDistiller, a meta KD framework that systematically combines a broad range of\ntechniques across different stages of the KD pipeline, which enables us to\nquantify each component's contribution. Within Distiller, we unify commonly\nused objectives for distillation of intermediate representations under a\nuniversal mutual information (MI) objective and propose a class of MI-$\\alpha$\nobjective functions with better bias/variance trade-off for estimating the MI\nbetween the teacher and the student. On a diverse set of NLP datasets, the best\nDistiller configurations are identified via large-scale hyperparameter\noptimization. Our experiments reveal the following: 1) the approach used to\ndistill the intermediate representations is the most important factor in KD\nperformance, 2) among different objectives for intermediate distillation,\nMI-$\\alpha$ performs the best, and 3) data augmentation provides a large boost\nfor small training datasets or small student networks. Moreover, we find that\ndifferent datasets/tasks prefer different KD algorithms, and thus propose a\nsimple AutoDistiller algorithm that can recommend a good KD pipeline for a new\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haoyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jonas Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1\">Zha Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">George Karypis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Language Model Meta-Pretraining. (arXiv:2109.11129v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11129","description":"<p>The success of pretrained cross-lingual language models relies on two\nessential abilities, i.e., generalization ability for learning downstream tasks\nin a source language, and cross-lingual transferability for transferring the\ntask knowledge to other languages. However, current methods jointly learn the\ntwo abilities in a single-phase cross-lingual pretraining process, resulting in\na trade-off between generalization and cross-lingual transfer. In this paper,\nwe propose cross-lingual language model meta-pretraining, which learns the two\nabilities in different training phases. Our method introduces an additional\nmeta-pretraining phase before cross-lingual pretraining, where the model learns\ngeneralization ability on a large-scale monolingual corpus. Then, the model\nfocuses on learning cross-lingual transfer on a multilingual corpus.\nExperimental results show that our method improves both generalization and\ncross-lingual transfer, and produces better-aligned representations across\ndifferent languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Luyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yu Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xian-Ling Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-Parametric Online Learning from Human Feedback for Neural Machine Translation. (arXiv:2109.11136v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11136","description":"<p>We study the problem of online learning with human feedback in the\nhuman-in-the-loop machine translation, in which the human translators revise\nthe machine-generated translations and then the corrected translations are used\nto improve the neural machine translation (NMT) system. However, previous\nmethods require online model updating or additional translation memory networks\nto achieve high-quality performance, making them inflexible and inefficient in\npractice. In this paper, we propose a novel non-parametric online learning\nmethod without changing the model structure. This approach introduces two\nk-nearest-neighbor (KNN) modules: one module memorizes the human feedback,\nwhich is the correct sentences provided by human translators, while the other\nbalances the usage of the history human feedback and original NMT models\nadaptively. Experiments conducted on EMEA and JRC-Acquis benchmarks demonstrate\nthat our proposed method obtains substantial improvements on translation\naccuracy and achieves better adaptation performance with less repeating human\ncorrection operations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Haoran Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weihua Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint speaker diarisation and tracking in switching state-space model. (arXiv:2109.11140v1 [cs.SD])","link":"http://arxiv.org/abs/2109.11140","description":"<p>Speakers may move around while diarisation is being performed. When a\nmicrophone array is used, the instantaneous locations of where the sounds\noriginated from can be estimated, and previous investigations have shown that\nsuch information can be complementary to speaker embeddings in the diarisation\ntask. However, these approaches often assume that speakers are fairly\nstationary throughout a meeting. This paper relaxes this assumption, by\nproposing to explicitly track the movements of speakers while jointly\nperforming diarisation within a unified model. A state-space model is proposed,\nwhere the hidden state expresses the identity of the current active speaker and\nthe predicted locations of all speakers. The model is implemented as a particle\nfilter. Experiments on a Microsoft rich meeting transcription task show that\nthe proposed joint location tracking and diarisation approach is able to\nperform comparably with other methods that use location information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1\">Jeremy H. M. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yifan Gong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Information Extraction as a Unified Text-to-Triple Translation. (arXiv:2109.11171v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11171","description":"<p>We cast a suite of information extraction tasks into a text-to-triple\ntranslation framework. Instead of solving each task relying on task-specific\ndatasets and models, we formalize the task as a translation between\ntask-specific input text and output triples. By taking the task-specific input,\nwe enable a task-agnostic translation by leveraging the latent knowledge that a\npre-trained language model has about the task. We further demonstrate that a\nsimple pre-training task of predicting which relational information corresponds\nto which input text is an effective way to produce task-specific outputs. This\nenables the zero-shot transfer of our framework to downstream tasks. We study\nthe zero-shot performance of this framework on open information extraction\n(OIE2016, NYT, WEB, PENN), relation classification (FewRel and TACRED), and\nfactual probe (Google-RE and T-REx). The model transfers non-trivially to most\ntasks and is often competitive with a fully supervised method without the need\nfor any task-specific training. For instance, we significantly outperform the\nF1 score of the supervised open information extraction without needing to use\nits training set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1\">Haoyun Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploiting Curriculum Learning in Unsupervised Neural Machine Translation. (arXiv:2109.11177v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11177","description":"<p>Back-translation (BT) has become one of the de facto components in\nunsupervised neural machine translation (UNMT), and it explicitly makes UNMT\nhave translation ability. However, all the pseudo bi-texts generated by BT are\ntreated equally as clean data during optimization without considering the\nquality diversity, leading to slow convergence and limited translation\nperformance. To address this problem, we propose a curriculum learning method\nto gradually utilize pseudo bi-texts based on their quality from multiple\ngranularities. Specifically, we first apply cross-lingual word embedding to\ncalculate the potential translation difficulty (quality) for the monolingual\nsentences. Then, the sentences are fed into UNMT from easy to hard batch by\nbatch. Furthermore, considering the quality of sentences/tokens in a particular\nbatch are also diverse, we further adopt the model itself to calculate the\nfine-grained quality scores, which are served as learning factors to balance\nthe contributions of different parts when computing loss and encourage the UNMT\nmodel to focus on pseudo data with higher quality. Experimental results on WMT\n14 En-Fr, WMT 16 En-De, WMT 16 En-Ro, and LDC En-Zh translation tasks\ndemonstrate that the proposed method achieves consistent improvements with\nfaster convergence speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jinliang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Linguistic Knowledge for Abstractive Multi-document Summarization. (arXiv:2109.11199v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11199","description":"<p>Within natural language processing tasks, linguistic knowledge can always\nserve an important role in assisting the model to learn excel representations\nand better guide the natural language generation. In this work, we develop a\nneural network based abstractive multi-document summarization (MDS) model which\nleverages dependency parsing to capture cross-positional dependencies and\ngrammatical structures. More concretely, we process the dependency information\ninto the linguistic-guided attention mechanism and further fuse it with the\nmulti-head attention for better feature representation. With the help of\nlinguistic signals, sentence-level relations can be correctly captured, thus\nimproving MDS performance. Our model has two versions based on Flat-Transformer\nand Hierarchical Transformer respectively. Empirical studies on both versions\ndemonstrate that this simple but effective method outperforms existing works on\nthe benchmark dataset. Extensive analyses examine different settings and\nconfigurations of the proposed model which provide a good reference to the\ncommunity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Congbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shubham Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Mingyu Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fuzzy Generalised Quantifiers for Natural Language in Categorical Compositional Distributional Semantics. (arXiv:2109.11227v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11227","description":"<p>Recent work on compositional distributional models shows that bialgebras over\nfinite dimensional vector spaces can be applied to treat generalised\nquantifiers for natural language. That technique requires one to construct the\nvector space over powersets, and therefore is computationally costly. In this\npaper, we overcome this problem by considering fuzzy versions of quantifiers\nalong the lines of Zadeh, within the category of many valued relations. We show\nthat this category is a concrete instantiation of the compositional\ndistributional model. We show that the semantics obtained in this model is\nequivalent to the semantics of the fuzzy quantifiers of Zadeh. As a result, we\nare now able to treat fuzzy quantification without requiring a powerset\nconstruction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dostal_M/0/1/0/all/0/1\">Matej Dostal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadrzadeh_M/0/1/0/all/0/1\">Mehrnoosh Sadrzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wijnholds_G/0/1/0/all/0/1\">Gijs Wijnholds</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pregroup Grammars, their Syntax and Semantics. (arXiv:2109.11237v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11237","description":"<p>Pregroup grammars were developed in 1999 and stayed Lambek's preferred\nalgebraic model of grammar. The set-theoretic semantics of pregroups, however,\nfaces an ambiguity problem. In his latest book, Lambek suggests that this\nproblem might be overcome using finite dimensional vector spaces rather than\nsets. What is the right notion of composition in this setting, direct sum or\ntensor product of spaces?\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sadrzadeh_M/0/1/0/all/0/1\">Mehrnoosh Sadrzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Volctrans GLAT System: Non-autoregressive Translation Meets WMT21. (arXiv:2109.11247v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11247","description":"<p>This paper describes the Volctrans' submission to the WMT21 news translation\nshared task for German-&gt;English translation. We build a parallel (i.e.,\nnon-autoregressive) translation system using the Glancing Transformer, which\nenables fast and accurate parallel decoding in contrast to the currently\nprevailing autoregressive models. To the best of our knowledge, this is the\nfirst parallel translation system that can be scaled to such a practical\nscenario like WMT competition. More importantly, our parallel translation\nsystem achieves the best BLEU score (35.0) on German-&gt;English translation task,\noutperforming all strong autoregressive counterparts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Lihua Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zehui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Question Generation Debias Question Answering Models? A Case Study on Question-Context Lexical Overlap. (arXiv:2109.11256v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11256","description":"<p>Question answering (QA) models for reading comprehension have been\ndemonstrated to exploit unintended dataset biases such as question-context\nlexical overlap. This hinders QA models from generalizing to under-represented\nsamples such as questions with low lexical overlap. Question generation (QG), a\nmethod for augmenting QA datasets, can be a solution for such performance\ndegradation if QG can properly debias QA datasets. However, we discover that\nrecent neural QG models are biased towards generating questions with high\nlexical overlap, which can amplify the dataset bias. Moreover, our analysis\nreveals that data augmentation with these QG models frequently impairs the\nperformance on questions with low lexical overlap, while improving that on\nquestions with high lexical overlap. To address this problem, we use a synonym\nreplacement-based approach to augment questions with low lexical overlap. We\ndemonstrate that the proposed data augmentation approach is simple yet\neffective to mitigate the degradation problem with only 70k synthetic examples.\nOur data is publicly available at\nhttps://github.com/KazutoshiShinoda/Synonym-Replacement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1\">Kazutoshi Shinoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1\">Saku Sugawara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't be Contradicted with Anything! CI-ToD: Towards Benchmarking Consistency for Task-oriented Dialogue System. (arXiv:2109.11292v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11292","description":"<p>Consistency Identification has obtained remarkable success on open-domain\ndialogue, which can be used for preventing inconsistent response generation.\nHowever, in contrast to the rapid development in open-domain dialogue, few\nefforts have been made to the task-oriented dialogue direction. In this paper,\nwe argue that consistency problem is more urgent in task-oriented domain. To\nfacilitate the research, we introduce CI-ToD, a novel dataset for Consistency\nIdentification in Task-oriented Dialog system. In addition, we not only\nannotate the single label to enable the model to judge whether the system\nresponse is contradictory, but also provide more fine-grained labels (i.e.,\nDialogue History Inconsistency, User Query Inconsistency and Knowledge Base\nInconsistency) to encourage model to know what inconsistent sources lead to it.\nEmpirical results show that state-of-the-art methods only achieve 51.3%, which\nis far behind the human performance of 93.2%, indicating that there is ample\nroom for improving consistency identification ability. Finally, we conduct\nexhaustive experiments and qualitative analysis to comprehend key challenges\nand provide guidance for future directions. All datasets and models are\npublicly available at \\url{https://github.com/yizhen20133868/CI-ToD}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Libo Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tianbao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shijue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiguang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Knowledge Distillation for Pre-trained Language Models. (arXiv:2109.11295v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11295","description":"<p>Knowledge distillation~(KD) has been proved effective for compressing\nlarge-scale pre-trained language models. However, existing methods conduct KD\nstatically, e.g., the student model aligns its output distribution to that of a\nselected teacher model on the pre-defined training dataset. In this paper, we\nexplore whether a dynamic knowledge distillation that empowers the student to\nadjust the learning procedure according to its competency, regarding the\nstudent performance and learning efficiency. We explore the dynamical\nadjustments on three aspects: teacher model adoption, data selection, and KD\nobjective adaptation. Experimental results show that (1) proper selection of\nteacher model can boost the performance of student model; (2) conducting KD\nwith 10% informative instances achieves comparable performance while greatly\naccelerates the training; (3) the student performance can be boosted by\nadjusting the supervision contribution of different alignment objective. We\nfind dynamic knowledge distillation is promising and provide discussions on\npotential future directions towards more efficient KD methods. Our code is\navailable at https://github.com/lancopku/DynamicKD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking BERT: Understanding its Vulnerabilities for Named Entity Recognition through Adversarial Attack. (arXiv:2109.11308v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11308","description":"<p>Both generic and domain-specific BERT models are widely used for natural\nlanguage processing (NLP) tasks. In this paper we investigate the vulnerability\nof BERT models to variation in input data for Named Entity Recognition (NER)\nthrough adversarial attack. Experimental results show that the original as well\nas the domain-specific BERT models are highly vulnerable to entity replacement:\nThey can be fooled in 89.2 to 99.4% of the cases to mislabel previously correct\nentities. BERT models are also vulnerable to variation in the entity context\nwith 20.2 to 45.0% of entities predicted completely wrong and another 29.3 to\n53.3% of entities predicted wrong partially. Often a single change is\nsufficient to fool the model. BERT models seem most vulnerable to changes in\nthe local context of entities. Of the two domain-specific BERT models, the\nvulnerability of BioBERT is comparable to the original BERT model whereas\nSciBERT is even more vulnerable. Our results chart the vulnerabilities of BERT\nmodels for NER and emphasize the importance of further research into uncovering\nand reducing these weaknesses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dirkson_A/0/1/0/all/0/1\">Anne Dirkson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraaij_W/0/1/0/all/0/1\">Wessel Kraaij</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ParaShoot: A Hebrew Question Answering Dataset. (arXiv:2109.11314v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11314","description":"<p>NLP research in Hebrew has largely focused on morphology and syntax, where\nrich annotated datasets in the spirit of Universal Dependencies are available.\nSemantic datasets, however, are in short supply, hindering crucial advances in\nthe development of NLP technology in Hebrew. In this work, we present\nParaShoot, the first question answering dataset in modern Hebrew. The dataset\nfollows the format and crowdsourcing methodology of SQuAD, and contains\napproximately 3000 annotated examples, similar to other question-answering\ndatasets in low-resource languages. We provide the first baseline results using\nrecently-released BERT-style models for Hebrew, showing that there is\nsignificant room for improvement on this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Keren_O/0/1/0/all/0/1\">Omri Keren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning for Argument Strength Estimation. (arXiv:2109.11319v1 [cs.LG])","link":"http://arxiv.org/abs/2109.11319","description":"<p>High-quality arguments are an essential part of decision-making.\nAutomatically predicting the quality of an argument is a complex task that\nrecently got much attention in argument mining. However, the annotation effort\nfor this task is exceptionally high. Therefore, we test uncertainty-based\nactive learning (AL) methods on two popular argument-strength data sets to\nestimate whether sample-efficient learning can be enabled. Our extensive\nempirical evaluation shows that uncertainty-based acquisition functions can not\nsurpass the accuracy reached with the random acquisition on these data sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kees_N/0/1/0/all/0/1\">Nataliia Kees</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fromm_M/0/1/0/all/0/1\">Michael Fromm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faerman_E/0/1/0/all/0/1\">Evgeniy Faerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seidl_T/0/1/0/all/0/1\">Thomas Seidl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transferring Knowledge from Vision to Language: How to Achieve it and how to Measure it?. (arXiv:2109.11321v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11321","description":"<p>Large language models are known to suffer from the hallucination problem in\nthat they are prone to output statements that are false or inconsistent,\nindicating a lack of knowledge. A proposed solution to this is to provide the\nmodel with additional data modalities that complements the knowledge obtained\nthrough text. We investigate the use of visual data to complement the knowledge\nof large language models by proposing a method for evaluating visual knowledge\ntransfer to text for uni- or multimodal language models. The method is based on\ntwo steps, 1) a novel task querying for knowledge of memory colors, i.e.\ntypical colors of well-known objects, and 2) filtering of model training data\nto clearly separate knowledge contributions. Additionally, we introduce a model\narchitecture that involves a visual imagination step and evaluate it with our\nproposed method. We find that our method can successfully be used to measure\nvisual knowledge transfer capabilities in models and that our novel model\narchitecture shows promising results for leveraging multimodal knowledge in a\nunimodal setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Norlund_T/0/1/0/all/0/1\">Tobias Norlund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagstrom_L/0/1/0/all/0/1\">Lovisa Hagstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johanssom_R/0/1/0/all/0/1\">Richard Johanssom</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Current State of Finnish NLP. (arXiv:2109.11326v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11326","description":"<p>There are a lot of tools and resources available for processing Finnish. In\nthis paper, we survey recent papers focusing on Finnish NLP related to many\ndifferent subcategories of NLP such as parsing, generation, semantics and\nspeech. NLP research is conducted in many different research groups in Finland,\nand it is frequently the case that NLP tools and models resulting from academic\nresearch are made available for others to use on platforms such as Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamalainen_M/0/1/0/all/0/1\">Mika H&#xe4;m&#xe4;l&#xe4;inen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alnajjar_K/0/1/0/all/0/1\">Khalid Alnajjar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Pattern- and Fact-based Fake News Detection via Model Preference Learning. (arXiv:2109.11333v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11333","description":"<p>To defend against fake news, researchers have developed various methods based\non texts. These methods can be grouped as 1) pattern-based methods, which focus\non shared patterns among fake news posts rather than the claim itself; and 2)\nfact-based methods, which retrieve from external sources to verify the claim's\nveracity without considering patterns. The two groups of methods, which have\ndifferent preferences of textual clues, actually play complementary roles in\ndetecting fake news. However, few works consider their integration. In this\npaper, we study the problem of integrating pattern- and fact-based models into\none framework via modeling their preference differences, i.e., making the\npattern- and fact-based models focus on respective preferred parts in a post\nand mitigate interference from non-preferred parts as possible. To this end, we\nbuild a Preference-aware Fake News Detection Framework (Pref-FEND), which\nlearns the respective preferences of pattern- and fact-based models for joint\ndetection. We first design a heterogeneous dynamic graph convolutional network\nto generate the respective preference maps, and then use these maps to guide\nthe joint learning of pattern- and fact-based models for final prediction.\nExperiments on two real-world datasets show that Pref-FEND effectively captures\nmodel preferences and improves the performance of models based on patterns,\nfacts, or both.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Qiang Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xueyao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Juan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1\">Lei Zhong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Second Pandemic? Analysis of Fake News About COVID-19 Vaccines in Qatar. (arXiv:2109.11372v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11372","description":"<p>While COVID-19 vaccines are finally becoming widely available, a second\npandemic that revolves around the circulation of anti-vaxxer fake news may\nhinder efforts to recover from the first one. With this in mind, we performed\nan extensive analysis of Arabic and English tweets about COVID-19 vaccines,\nwith focus on messages originating from Qatar. We found that Arabic tweets\ncontain a lot of false information and rumors, while English tweets are mostly\nfactual. However, English tweets are much more propagandistic than Arabic ones.\nIn terms of propaganda techniques, about half of the Arabic tweets express\ndoubt, and 1/5 use loaded language, while English tweets are abundant in loaded\nlanguage, exaggeration, fear, name-calling, doubt, and flag-waving. Finally, in\nterms of framing, Arabic tweets adopt a health and safety perspective, while in\nEnglish economic concerns dominate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1\">Firoj Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1\">Shaden Shaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martino_G/0/1/0/all/0/1\">Giovanni Da San Martino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WRENCH: A Comprehensive Benchmark for Weak Supervision. (arXiv:2109.11377v1 [cs.LG])","link":"http://arxiv.org/abs/2109.11377","description":"<p>Recent \\emph{Weak Supervision (WS)} approaches have had widespread success in\neasing the bottleneck of labeling training data for machine learning by\nsynthesizing labels from multiple potentially noisy supervision sources.\nHowever, proper measurement and analysis of these approaches remain a\nchallenge. First, datasets used in existing works are often private and/or\ncustom, limiting standardization. Second, WS datasets with the same name and\nbase data often vary in terms of the labels and weak supervision sources used,\na significant \"hidden\" source of evaluation variance. Finally, WS studies often\ndiverge in terms of the evaluation protocol and ablations used. To address\nthese problems, we introduce a benchmark platform, \\benchmark, for a thorough\nand standardized evaluation of WS approaches. It consists of 22 varied\nreal-world datasets for classification and sequence tagging; a range of real,\nsynthetic, and procedurally-generated weak supervision sources; and a modular,\nextensible framework for WS evaluation, including implementations for popular\nWS methods. We use \\benchmark to conduct extensive comparisons over more than\n100 method variants to demonstrate its efficacy as a benchmark platform. The\ncode is available at \\url{https://github.com/JieyuZ2/wrench}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratner_A/0/1/0/all/0/1\">Alexander Ratner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cluster-based Mention Typing for Named Entity Disambiguation. (arXiv:2109.11389v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11389","description":"<p>An entity mention in text such as \"Washington\" may correspond to many\ndifferent named entities such as the city \"Washington D.C.\" or the newspaper\n\"Washington Post.\" The goal of named entity disambiguation is to identify the\nmentioned named entity correctly among all possible candidates. If the type\n(e.g. location or person) of a mentioned entity can be correctly predicted from\nthe context, it may increase the chance of selecting the right candidate by\nassigning low probability to the unlikely ones. This paper proposes\ncluster-based mention typing for named entity disambiguation. The aim of\nmention typing is to predict the type of a given mention based on its context.\nGenerally, manually curated type taxonomies such as Wikipedia categories are\nused. We introduce cluster-based mention typing, where named entities are\nclustered based on their contextual similarities and the cluster ids are\nassigned as types. The hyperlinked mentions and their context in Wikipedia are\nused in order to obtain these cluster-based types. Then, mention typing models\nare trained on these mentions, which have been labeled with their cluster-based\ntypes through distant supervision. At the named entity disambiguation phase,\nfirst the cluster-based types of a given mention are predicted and then, these\ntypes are used as features in a ranking model to select the best entity among\nthe candidates. We represent entities at multiple contextual levels and obtain\ndifferent clusterings (and thus typing models) based on each level. As each\nclustering breaks the entity space differently, mention typing based on each\nclustering discriminates the mention differently. When predictions from all\ntyping models are used together, our system achieves better or comparable\nresults based on randomization tests with respect to the state-of-the-art\nlevels on four defacto test sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Celebi_A/0/1/0/all/0/1\">Arda &#xc7;elebi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozgur_A/0/1/0/all/0/1\">Arzucan &#xd6;zg&#xfc;r</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Named Entity Recognition and Classification on Historical Documents: A Survey. (arXiv:2109.11406v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11406","description":"<p>After decades of massive digitisation, an unprecedented amount of historical\ndocuments is available in digital format, along with their machine-readable\ntexts. While this represents a major step forward with respect to preservation\nand accessibility, it also opens up new opportunities in terms of content\nmining and the next fundamental challenge is to develop appropriate\ntechnologies to efficiently search, retrieve and explore information from this\n'big data of the past'. Among semantic indexing opportunities, the recognition\nand classification of named entities are in great demand among humanities\nscholars. Yet, named entity recognition (NER) systems are heavily challenged\nwith diverse, historical and noisy inputs. In this survey, we present the array\nof challenges posed by historical documents to NER, inventory existing\nresources, describe the main approaches deployed so far, and identify key\npriorities for future developments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ehrmann_M/0/1/0/all/0/1\">Maud Ehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hamdi_A/0/1/0/all/0/1\">Ahmed Hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pontes_E/0/1/0/all/0/1\">Elvys Linhares Pontes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romanello_M/0/1/0/all/0/1\">Matteo Romanello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Antoine Doucet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Algorithm for Generating Gap-Fill Multiple Choice Questions of an Expert System. (arXiv:2109.11421v1 [cs.AI])","link":"http://arxiv.org/abs/2109.11421","description":"<p>This research is aimed to propose an artificial intelligence algorithm\ncomprising an ontology-based design, text mining, and natural language\nprocessing for automatically generating gap-fill multiple choice questions\n(MCQs). The simulation of this research demonstrated an application of the\nalgorithm in generating gap-fill MCQs about software testing. The simulation\nresults revealed that by using 103 online documents as inputs, the algorithm\ncould automatically produce more than 16 thousand valid gap-fill MCQs covering\na variety of topics in the software testing domain. Finally, in the discussion\nsection of this paper we suggest how the proposed algorithm should be applied\nto produce gap-fill MCQs being collected in a question pool used by a knowledge\nexpert system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sirithumgul_P/0/1/0/all/0/1\">Pornpat Sirithumgul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasertsilp_P/0/1/0/all/0/1\">Pimpaka Prasertsilp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olfman_L/0/1/0/all/0/1\">Lorne Olfman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Fact-Checking: A Survey. (arXiv:2109.11427v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11427","description":"<p>As online false information continues to grow, automated fact-checking has\ngained an increasing amount of attention in recent years. Researchers in the\nfield of Natural Language Processing (NLP) have contributed to the task by\nbuilding fact-checking datasets, devising automated fact-checking pipelines and\nproposing NLP methods to further research in the development of different\ncomponents. This paper reviews relevant research on automated fact-checking\ncovering both the claim detection and claim validation components.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xia Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abumansour_A/0/1/0/all/0/1\">Amani S. Abumansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Corpus and Models for Lemmatisation and POS-tagging of Old French. (arXiv:2109.11442v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11442","description":"<p>Old French is a typical example of an under-resourced historic languages,\nthat furtherly displays animportant amount of linguistic variation. In this\npaper, we present the current results of a long going project (2015-...) and\ndescribe how we broached the difficult question of providing lemmatisation\nandPOS models for Old French with the help of neural taggers and the\nprogressive constitution of dedicated corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Camps_J/0/1/0/all/0/1\">Jean-Baptiste Camps</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clerice_T/0/1/0/all/0/1\">Thibault Cl&#xe9;rice</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duval_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Duval</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ing_L/0/1/0/all/0/1\">Lucence Ing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanaoka_N/0/1/0/all/0/1\">Naomi Kanaoka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinche_A/0/1/0/all/0/1\">Ariane Pinche</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Putting Words in BERT's Mouth: Navigating Contextualized Vector Spaces with Pseudowords. (arXiv:2109.11491v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11491","description":"<p>We present a method for exploring regions around individual points in a\ncontextualized vector space (particularly, BERT space), as a way to investigate\nhow these regions correspond to word senses. By inducing a contextualized\n\"pseudoword\" as a stand-in for a static embedding in the input layer, and then\nperforming masked prediction of a word in the sentence, we are able to\ninvestigate the geometry of the BERT-space in a controlled manner around\nindividual instances. Using our method on a set of carefully constructed\nsentences targeting ambiguous English words, we find substantial regularity in\nthe contextualized space, with regions that correspond to distinct word senses;\nbut between these regions there are occasionally \"sense voids\" -- regions that\ndo not correspond to any intelligible sense.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Karidi_T/0/1/0/all/0/1\">Taelin Karidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yichu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Finding a Balanced Degree of Automation for Summary Evaluation. (arXiv:2109.11503v1 [cs.CL])","link":"http://arxiv.org/abs/2109.11503","description":"<p>Human evaluation for summarization tasks is reliable but brings in issues of\nreproducibility and high costs. Automatic metrics are cheap and reproducible\nbut sometimes poorly correlated with human judgment. In this work, we propose\nflexible semiautomatic to automatic summary evaluation metrics, following the\nPyramid human evaluation method. Semi-automatic Lite2Pyramid retains the\nreusable human-labeled Summary Content Units (SCUs) for reference(s) but\nreplaces the manual work of judging SCUs' presence in system summaries with a\nnatural language inference (NLI) model. Fully automatic Lite3Pyramid further\nsubstitutes SCUs with automatically extracted Semantic Triplet Units (STUs) via\na semantic role labeling (SRL) model. Finally, we propose in-between metrics,\nLite2.xPyramid, where we use a simple regressor to predict how well the STUs\ncan simulate SCUs and retain SCUs that are more difficult to simulate, which\nprovides a smooth transition and balance between automation and manual\nevaluation. Comparing to 15 existing metrics, we evaluate human-metric\ncorrelations on 3 existing meta-evaluation datasets and our newly-collected\nPyrXSum (with 100/10 XSum examples/systems). It shows that Lite2Pyramid\nconsistently has the best summary-level correlations; Lite3Pyramid works better\nthan or comparable to other automatic metrics; Lite2.xPyramid trades off small\ncorrelation drops for larger manual effort reduction, which can reduce costs\nfor future data collection. Our code and data are publicly available at:\nhttps://github.com/ZhangShiyue/Lite2-3Pyramid\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiyue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MARMOT: A Deep Learning Framework for Constructing Multimodal Representations for Vision-and-Language Tasks. (arXiv:2109.11526v1 [cs.CV])","link":"http://arxiv.org/abs/2109.11526","description":"<p>Political activity on social media presents a data-rich window into political\nbehavior, but the vast amount of data means that almost all content analyses of\nsocial media require a data labeling step. However, most automated machine\nclassification methods ignore the multimodality of posted content, focusing\neither on text or images. State-of-the-art vision-and-language models are\nunusable for most political science research: they require all observations to\nhave both image and text and require computationally expensive pretraining.\nThis paper proposes a novel vision-and-language framework called multimodal\nrepresentations using modality translation (MARMOT). MARMOT presents two\nmethodological contributions: it can construct representations for observations\nmissing image or text, and it replaces the computationally expensive\npretraining with modality translation. MARMOT outperforms an ensemble text-only\nclassifier in 19 of 20 categories in multilabel classifications of tweets\nreporting election incidents during the 2016 U.S. general election. Moreover,\nMARMOT shows significant improvements over the results of benchmark multimodal\nmodels on the Hateful Memes dataset, improving the best result set by\nVisualBERT in terms of accuracy from 0.6473 to 0.6760 and area under the\nreceiver operating characteristic curve (AUC) from 0.7141 to 0.7530.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Patrick Y. Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mebane_W/0/1/0/all/0/1\">Walter R. Mebane Jr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query-Variant Advertisement Text Generation with Association Knowledge. (arXiv:2004.06438v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2004.06438","description":"<p>Online advertising is an important revenue source for many IT companies. In\nthe search advertising scenario, advertisement text that meets the need of the\nsearch query would be more attractive to the user. However, the manual creation\nof query-variant advertisement texts for massive items is expensive.\nTraditional text generation methods tend to focus on the general searching\nneeds with high frequency while ignoring the diverse personalized searching\nneeds with low frequency. In this paper, we propose the query-variant\nadvertisement text generation task that aims to generate candidate\nadvertisement texts for different web search queries with various needs based\non queries and item keywords. To solve the problem of ignoring low-frequency\nneeds, we propose a dynamic association mechanism to expand the receptive field\nbased on external knowledge, which can obtain associated words to be added to\nthe input. These associated words can serve as bridges to transfer the ability\nof the model from the familiar high-frequency words to the unfamiliar\nlow-frequency words. With association, the model can make use of various\npersonalized needs in queries and generate query-variant advertisement texts.\nBoth automatic and human evaluations show that our model can generate more\nattractive advertisement text than baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Siyu Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_C/0/1/0/all/0/1\">Cai Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yancheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunfang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summary-Source Proposition-level Alignment: Task, Datasets and Supervised Baseline. (arXiv:2009.00590v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.00590","description":"<p>Aligning sentences in a reference summary with their counterparts in source\ndocuments was shown as a useful auxiliary summarization task, notably for\ngenerating training data for salience detection. Despite its assessed utility,\nthe alignment step was mostly approached with heuristic unsupervised methods,\ntypically ROUGE-based, and was never independently optimized or evaluated. In\nthis paper, we propose establishing summary-source alignment as an explicit\ntask, while introducing two major novelties: (1) applying it at the more\naccurate proposition span level, and (2) approaching it as a supervised\nclassification task. To that end, we created a novel training dataset for\nproposition-level alignment, derived automatically from available summarization\nevaluation data. In addition, we crowdsourced dev and test datasets, enabling\nmodel development and proper evaluation. Utilizing these data, we present a\nsupervised proposition alignment baseline model, showing improved\nalignment-quality over the unsupervised approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ernst_O/0/1/0/all/0/1\">Ori Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapira_O/0/1/0/all/0/1\">Ori Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lepioshkin_M/0/1/0/all/0/1\">Michael Lepioshkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1\">Jacob Goldberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"N-LTP: An Open-source Neural Language Technology Platform for Chinese. (arXiv:2009.11616v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2009.11616","description":"<p>We introduce \\texttt{N-LTP}, an open-source neural language technology\nplatform supporting six fundamental Chinese NLP tasks: {lexical analysis}\n(Chinese word segmentation, part-of-speech tagging, and named entity\nrecognition), {syntactic parsing} (dependency parsing), and {semantic parsing}\n(semantic dependency parsing and semantic role labeling). Unlike the existing\nstate-of-the-art toolkits, such as \\texttt{Stanza}, that adopt an independent\nmodel for each task, \\texttt{N-LTP} adopts the multi-task framework by using a\nshared pre-trained model, which has the advantage of capturing the shared\nknowledge across relevant Chinese tasks. In addition, a knowledge distillation\nmethod \\cite{DBLP:journals/corr/abs-1907-04829} where the single-task model\nteaches the multi-task model is further introduced to encourage the multi-task\nmodel to surpass its single-task teacher. Finally, we provide a collection of\neasy-to-use APIs and a visualization tool to make users to use and view the\nprocessing results more easily and directly. To the best of our knowledge, this\nis the first toolkit to support six Chinese NLP fundamental tasks. Source code,\ndocumentation, and pre-trained models are available at\n\\url{https://github.com/HIT-SCIR/ltp}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1\">Wanxiang Che</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yunlong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Libo Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Simultaneous Translation by Incorporating Pseudo-References with Fewer Reorderings. (arXiv:2010.11247v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.11247","description":"<p>Simultaneous translation is vastly different from full-sentence translation,\nin the sense that it starts translation before the source sentence ends, with\nonly a few words delay. However, due to the lack of large-scale, high-quality\nsimultaneous translation datasets, most such systems are still trained on\nconventional full-sentence bitexts. This is far from ideal for the simultaneous\nscenario due to the abundance of unnecessary long-distance reorderings in those\nbitexts. We propose a novel method that rewrites the target side of existing\nfull-sentence corpora into simultaneous-style translation. Experiments on\nZh-&gt;En and Ja-&gt;En simultaneous translation show substantial improvements (up to\n+2.7 BLEU) with the addition of these generated pseudo-references.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Renjie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kita_A/0/1/0/all/0/1\">Atsuhito Kita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingbo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Liang Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Validating Label Consistency in NER Data Annotation. (arXiv:2101.08698v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.08698","description":"<p>Data annotation plays a crucial role in ensuring your named entity\nrecognition (NER) projects are trained with the right information to learn\nfrom. Producing the most accurate labels is a challenge due to the complexity\ninvolved with annotation. Label inconsistency between multiple subsets of data\nannotation (e.g., training set and test set, or multiple training subsets) is\nan indicator of label mistakes. In this work, we present an empirical method to\nexplore the relationship between label (in-)consistency and NER model\nperformance. It can be used to validate the label consistency (or catches the\ninconsistency) in multiple sets of NER data annotation. In experiments, our\nmethod identified the label inconsistency of test data in SCIERC and CoNLL03\ndatasets (with 26.7% and 5.4% label mistakes). It validated the consistency in\nthe corrected version of both datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingkai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mengxia Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tianwen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking. (arXiv:2104.04466v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.04466","description":"<p>Dialogue State Tracking is central to multi-domain task-oriented dialogue\nsystems, responsible for extracting information from user utterances. We\npresent a novel hybrid architecture that augments GPT-2 with representations\nderived from Graph Attention Networks in such a way to allow causal, sequential\nprediction of slot values. The model architecture captures inter-slot\nrelationships and dependencies across domains that otherwise can be lost in\nsequential prediction. We report improvements in state tracking performance in\nMultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified\nsparse training scenario in which DST models are trained only on session-level\nannotations but evaluated at the turn level. We further report detailed\nanalyses to demonstrate the effectiveness of graph models in DST by showing\nthat the proposed graph modules capture inter-slot dependencies and improve the\npredictions of values that are common to multiple domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weizhe Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_B/0/1/0/all/0/1\">Bo-Hsiang Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byrne_B/0/1/0/all/0/1\">Bill Byrne</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effect of Visual Extensions on Natural Language Understanding in Vision-and-Language Models. (arXiv:2104.08066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.08066","description":"<p>A method for creating a vision-and-language (V&amp;L) model is to extend a\nlanguage model through structural modifications and V&amp;L pre-training. Such an\nextension aims to make a V&amp;L model inherit the capability of natural language\nunderstanding (NLU) from the original language model. To see how well this is\nachieved, we propose to evaluate V&amp;L models using an NLU benchmark (GLUE). We\ncompare five V&amp;L models, including single-stream and dual-stream models,\ntrained with the same pre-training. Dual-stream models, with their higher\nmodality independence achieved by approximately doubling the number of\nparameters, are expected to preserve the NLU capability better. Our main\nfinding is that the dual-stream scores are not much different than the\nsingle-stream scores, contrary to expectation. Further analysis shows that\npre-training causes the performance drop in NLU tasks with few exceptions.\nThese results suggest that adopting a single-stream structure and devising the\npre-training could be an effective method for improving the maintenance of\nlanguage knowledge in V&amp;L extensions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iki_T/0/1/0/all/0/1\">Taichi Iki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers: \"The End of History\" for NLP?. (arXiv:2105.00813v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.00813","description":"<p>Recent advances in neural architectures, such as the Transformer, coupled\nwith the emergence of large-scale pre-trained models such as BERT, have\nrevolutionized the field of Natural Language Processing (NLP), pushing the\nstate of the art for a number of NLP tasks. A rich family of variations of\nthese models has been proposed, such as RoBERTa, ALBERT, and XLNet, but\nfundamentally, they all remain limited in their ability to model certain kinds\nof information, and they cannot cope with certain information sources, which\nwas easy for pre-existing models. Thus, here we aim to shed light on some\nimportant theoretical limitations of pre-trained BERT-style models that are\ninherent in the general Transformer architecture. First, we demonstrate in\npractice on two general types of tasks -- segmentation and segment labeling --\nand on four datasets that these limitations are indeed harmful and that\naddressing them, even in some very simple and naive ways, can yield sizable\nimprovements over vanilla RoBERTa and XLNet models. Then, we offer a more\ngeneral discussion on desiderata for future additions to the Transformer\narchitecture that would increase its expressiveness, which we hope could help\nin the design of the next generation of deep NLP architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chernyavskiy_A/0/1/0/all/0/1\">Anton Chernyavskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilvovsky_D/0/1/0/all/0/1\">Dmitry Ilvovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Neural Diarization for Unlimited Numbers of Speakers Using Global and Local Attractors. (arXiv:2107.01545v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2107.01545","description":"<p>Attractor-based end-to-end diarization is achieving comparable accuracy to\nthe carefully tuned conventional clustering-based methods on challenging\ndatasets. However, the main drawback is that it cannot deal with the case where\nthe number of speakers is larger than the one observed during training. This is\nbecause its speaker counting relies on supervised learning. In this work, we\nintroduce an unsupervised clustering process embedded in the attractor-based\nend-to-end diarization. We first split a sequence of frame-wise embeddings into\nshort subsequences and then perform attractor-based diarization for each\nsubsequence. Given subsequence-wise diarization results, inter-subsequence\nspeaker correspondence is obtained by unsupervised clustering of the vectors\ncomputed from the attractors from all the subsequences. This makes it possible\nto produce diarization results of a large number of speakers for the whole\nrecording even if the number of output speakers for each subsequence is\nlimited. Experimental results showed that our method could produce accurate\ndiarization results of an unseen number of speakers. Our method achieved 11.84\n%, 28.33 %, and 19.49 % on the CALLHOME, DIHARD II, and DIHARD III datasets,\nrespectively, each of which is better than the conventional end-to-end\ndiarization methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Horiguchi_S/0/1/0/all/0/1\">Shota Horiguchi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Garcia_P/0/1/0/all/0/1\">Paola Garcia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_Y/0/1/0/all/0/1\">Yawen Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takashima_Y/0/1/0/all/0/1\">Yuki Takashima</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1\">Yohei Kawaguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Token-Level Supervised Contrastive Learning for Punctuation Restoration. (arXiv:2107.09099v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.09099","description":"<p>Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiushi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">H Lilian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xubo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Finetuning Pretrained Transformers into Variational Autoencoders. (arXiv:2108.02446v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.02446","description":"<p>Text variational autoencoders (VAEs) are notorious for posterior collapse, a\nphenomenon where the model's decoder learns to ignore signals from the encoder.\nBecause posterior collapse is known to be exacerbated by expressive decoders,\nTransformers have seen limited adoption as components of text VAEs. Existing\nstudies that incorporate Transformers into text VAEs (Li et al., 2020; Fang et\nal., 2021) mitigate posterior collapse using massive pretraining, a technique\nunavailable to most of the research community without extensive computing\nresources. We present a simple two-phase training scheme to convert a\nsequence-to-sequence Transformer into a VAE with just finetuning. The resulting\nlanguage model is competitive with massively pretrained Transformer-based VAEs\nin some internal metrics while falling short on others. To facilitate training\nwe comprehensively explore the impact of common posterior collapse alleviation\ntechniques in the literature. We release our code for reproducability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seongmin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jihwa Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapted End-to-End Coreference Resolution System for Anaphoric Identities in Dialogues. (arXiv:2109.00185v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00185","description":"<p>We present an effective system adapted from the end-to-end neural coreference\nresolution model, targeting on the task of anaphora resolution in dialogues.\nThree aspects are specifically addressed in our approach, including the support\nof singletons, encoding speakers and turns throughout dialogue interactions,\nand knowledge transfer utilizing existing resources. Despite the simplicity of\nour adaptation strategies, they are shown to bring significant impact to the\nfinal performance, with up to 27 F1 improvement over the baseline. Our final\nsystem ranks the 1st place on the leaderboard of the anaphora resolution track\nin the CRAC 2021 shared task, and achieves the best evaluation results on all\nfour datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Cross-Lingual Transfer via Self-Learning with Uncertainty Estimation. (arXiv:2109.00194v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.00194","description":"<p>Recent multilingual pre-trained language models have achieved remarkable\nzero-shot performance, where the model is only finetuned on one source language\nand directly evaluated on target languages. In this work, we propose a\nself-learning framework that further utilizes unlabeled data of target\nlanguages, combined with uncertainty estimation in the process to select\nhigh-quality silver labels. Three different uncertainties are adapted and\nanalyzed specifically for the cross lingual transfer: Language\nHeteroscedastic/Homoscedastic Uncertainty (LEU/LOU), Evidential Uncertainty\n(EVI). We evaluate our framework with uncertainties on two cross-lingual tasks\nincluding Named Entity Recognition (NER) and Natural Language Inference (NLI)\ncovering 40 languages in total, which outperforms the baselines significantly\nby 10 F1 on average for NER and 2.5 accuracy score for NLI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Liyan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Model Bias in NLP -- Application to Hate Speech Classification. (arXiv:2109.09725v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.09725","description":"<p>This document sums up our results forthe NLP lecture at ETH in the spring\nsemester 2021. In this work, a BERT based neural network model (Devlin et\nal.,2018) is applied to the JIGSAW dataset (Jigsaw/Conversation AI, 2019) in\norder to create a model identifying hateful and toxic comments (strictly\nseperated from offensive language) in online social platforms (English\nlanguage), inthis case Twitter. Three other neural network architectures and a\nGPT-2 (Radfordet al., 2019) model are also applied on the provided data set in\norder to compare these different models. The trained BERT model is then applied\non two different data sets to evaluate its generalisation power, namely on\nanother Twitter data set (Tom Davidson, 2017) (Davidsonet al., 2017) and the\ndata set HASOC 2019 (Thomas Mandl, 2019) (Mandl et al.,2019) which includes\nTwitter and also Facebook comments; we focus on the English HASOC 2019 data. In\naddition, it can be shown that by fine-tuning the trained BERT model on these\ntwo datasets by applying different transfer learning scenarios via retraining\npartial or all layers the predictive scores improve compared to simply applying\nthe model pre-trained on the JIGSAW data set. Withour results, we get\nprecisions from 64% to around 90% while still achieving acceptable recall\nvalues of at least lower 60s%, proving that BERT is suitable for real usecases\nin social platforms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bokstaller_J/0/1/0/all/0/1\">Jonas Bokstaller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patoulidis_G/0/1/0/all/0/1\">Georgios Patoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zagidullina_A/0/1/0/all/0/1\">Aygul Zagidullina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FCM: A Fine-grained Comparison Model for Multi-turn Dialogue Reasoning. (arXiv:2109.10510v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.10510","description":"<p>Despite the success of neural dialogue systems in achieving high performance\non the leader-board, they cannot meet users' requirements in practice, due to\ntheir poor reasoning skills. The underlying reason is that most neural dialogue\nmodels only capture the syntactic and semantic information, but fail to model\nthe logical consistency between the dialogue history and the generated\nresponse. Recently, a new multi-turn dialogue reasoning task has been proposed,\nto facilitate dialogue reasoning research. However, this task is challenging,\nbecause there are only slight differences between the illogical response and\nthe dialogue history. How to effectively solve this challenge is still worth\nexploring. This paper proposes a Fine-grained Comparison Model (FCM) to tackle\nthis problem. Inspired by human's behavior in reading comprehension, a\ncomparison mechanism is proposed to focus on the fine-grained differences in\nthe representation of each response candidate. Specifically, each candidate\nrepresentation is compared with the whole history to obtain a history\nconsistency representation. Furthermore, the consistency signals between each\ncandidate and the speaker's own history are considered to drive a model to\nprefer a candidate that is logically consistent with the speaker's history\nlogic. Finally, the above consistency representations are employed to output a\nranking list of the candidate responses for multi-turn dialogue reasoning.\nExperimental results on two public dialogue datasets show that our method\nobtains higher ranking scores than the baseline models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hainan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yanyan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongshen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zhuoye Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1\">Bo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yanyan Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Small-Bench NLP: Benchmark for small single GPU trained models in Natural Language Processing. (arXiv:2109.10847v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2109.10847","description":"<p>Recent progress in the Natural Language Processing domain has given us\nseveral State-of-the-Art (SOTA) pretrained models which can be finetuned for\nspecific tasks. These large models with billions of parameters trained on\nnumerous GPUs/TPUs over weeks are leading in the benchmark leaderboards. In\nthis paper, we discuss the need for a benchmark for cost and time effective\nsmaller models trained on a single GPU. This will enable researchers with\nresource constraints experiment with novel and innovative ideas on\ntokenization, pretraining tasks, architecture, fine tuning methods etc. We set\nup Small-Bench NLP, a benchmark for small efficient neural language models\ntrained on a single GPU. Small-Bench NLP benchmark comprises of eight NLP tasks\non the publicly available GLUE datasets and a leaderboard to track the progress\nof the community. Our ELECTRA-DeBERTa (15M parameters) small model architecture\nachieves an average score of 81.53 which is comparable to that of BERT-Base's\n82.20 (110M parameters). Our models, code and leaderboard are available at\nhttps://github.com/smallbenchnlp\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kanakarajan_K/0/1/0/all/0/1\">Kamal Raj Kanakarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundumani_B/0/1/0/all/0/1\">Bhuvana Kundumani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankarasubbu_M/0/1/0/all/0/1\">Malaikannan Sankarasubbu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2021-09-23T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}