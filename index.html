<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-31T01:50:18.329923055Z">08-31</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">Rust.cc</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-30 如何来看待 unwrap</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=59dad850-933e-49dd-9ab8-5370d5c77857">
<div class="article-summary-box-inner">
<span><h1>如何来看待 unwrap</h1>
<p><code>unwrap</code> 方法可能会让新手感到困惑。一些建议:</p>
<ul>
<li>可以使用 Expect (&amp;str) 而不是 unwrap() 为 panic 提供上下文。</li>
<li>使用 unwrap 和 expect 类似于断言。如果他们 panic，那只有在不可挽回的情况下才会发生。</li>
<li>避免在库代码中使用。</li>
</ul>
<p><a href="https://owengage.com/writing/2021-08-30-how-to-think-of-unwrap/" rel="noopener noreferrer">原文链接</a></p>
<h1>singleton-cell: 一个更强大的 ghost cell 扩展</h1>
<p>这个库提供了一个安全的、零开销的接口，用于通过访问另一个单例令牌来保护对共享数据的访问。它是 GhostCell的扩展，除了品牌令牌外，它还允许更多普通的单例，使数据成为“静态的”</p>
<p>这个库本身也提供了两个单例实现:</p>
<ul>
<li>通过with_token将限定范围的标记令牌作为 GhostCell</li>
<li>通过new_singleton简单地创建一次单例结构</li>
</ul>
<p><a href="https://crates.io/crates/singleton-cell" rel="noopener noreferrer">crate 地址</a></p>
<h1>Learning Rust: Interfacing with C</h1>
<p>通过本文学习如何使用 Rust 调用 C 方法以及如何在 C 中调用 Rust 方法.</p>
<p><a href="https://piware.de/post/2021-08-27-rust-and-c/" rel="noopener noreferrer">原文链接</a></p>
<h1>RefineDB: Rust编写的强类型文档数据库</h1>
<p>运行在任何事务性 键值存储上的 强类型 文档数据库。</p>
<p>目前支持的 backends 有:</p>
<ul>
<li>FoundationDB</li>
<li>单机部署的 SQLite。</li>
<li>一个简单的内存键值存储。</li>
</ul>
<p><a href="https://github.com/losfair/RefineDB" rel="noopener noreferrer">github 地址</a></p>
<p>--</p>
<p>From 日报小组 BobQin，FBI小白</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">远程办公，不限地域，缴纳社保公积金，周末双休，告别 996，拒绝 007，Nervina Labs 欢迎你！</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=a90b0635-b332-4e23-9a44-eb9282f519ef">
<div class="article-summary-box-inner">
<span><p>rust开发工程师
岗位职责：1、负责智能合约的开发及设计；2、负责区块链业务系统分析与设计工作；3、负责智能合约代码测试、运行和维护。任职要求：1、计算机相关专业本科及以上学历，3年以上工作经验；2、熟练掌握 C/C++、Rust 等系统开发语言至少一种，至少有过两年相关开发经验；3、对数据结构和算法，对密码学，安全协议和加密算法有研究者优先；4、优秀的英语文档撰写与阅读能力者优先；5、了解区块链，有合约开发经验更佳。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">构建安全易用的链表</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=273831e7-932d-476f-9d31-323151afb123">
<div class="article-summary-box-inner">
<span><p>写了一个链表的Crate，愿景是构建安全且易用的链表。</p>
<p>欢迎大家来找茬（Bug）或提需求 :)</p>
<p>Crate IO链接：<a href="https://crates.io/crates/cyclic_list" rel="noopener noreferrer">https://crates.io/crates/cyclic_list</a>;</p>
<p>GitHub链接：<a href="https://github.com/whjpji/cyclic_list" rel="noopener noreferrer">https://github.com/whjpji/cyclic_list</a></p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust 日报】2021-08-29 Tangram：训练、部署和监控机器学习模型</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=4a218f6c-3c77-4aa0-84d6-90ac2bf1fc7c">
<div class="article-summary-box-inner">
<span><h3>Embedded Rust 第一步：选择一块板子</h3>
<p>内容整理自 <a href="https://github.com/robyoung" rel="noopener noreferrer">robyoung (Rob Young)</a> 的文章：First steps with Embedded Rust: Selecting a board</p>
<p>有这么多令人眼花缭乱的微控制器和项目，对于嵌入式经验很少的人来说应该从哪里开始？</p>
<p><strong>我们在开发板中想要什么？</strong></p>
<ul>
<li>良好的架构支持</li>
<li>良好的芯片支持</li>
<li>活跃的社区</li>
<li>内置调试器</li>
</ul>
<p><strong>我们需要什么架构？</strong></p>
<p>拥有最完整库、最详尽指南和最大社区的架构是 ARM Cortex-M。 ARM Cortex-M 是面向微控制器应用的低功耗、低成本处理器。 查看 crates.io 上的下载量虽说不是一个完美的指标，但可以让我们了解规模上的差异。在过去的 90 天内，cortex-m 的下载量超过 250k。 RISC-V、AVR 或 Xtensa 最多有 3k 次下载，cortex-a 有大约 18k 次下载。ARM Cortex-M 独树一帜。</p>
<ul>
<li>AVR：AVR 是用于嵌入式系统的 8 位微控制器系列。在 Rust 生态系统中，它们并没有得到很好的支持。直到最近，还需要使用 rustc 的一个分支来构建 AVR。 现在有几个不同的选择，awesome-avr-rust 是一个很好的起点。</li>
<li>ARM Cortex-A：更强大的多核 ARM 处理器，专为运行更大的东西而设计。 通常会在它们上运行完整的操作系统。 例如这是大多数智能手机和掌上游戏机中使用的架构。查看 <a href="https://crates.io/crates/cortex-a" rel="noopener noreferrer">cortex-a - crates.io: Rust Package Registry</a> 了解更多。</li>
<li>RISC-V：似乎是机器架构的新热点，它是一种免费且开放的指令集架构 (ISA)。 它也从一开始就被设计成模块化的，这意味着芯片设计人员可以创建各种各样的专用芯片，虽然目前开发板的范围很小。有一个活跃的 Rust RISC-V 社区，SiFive 或 www.riscv.org 都是不错的起点，Rust 方面，可以查看 riscv crate。</li>
<li>Xtensa：最受欢迎的主板组是来自 Espressif 的 ESP32 系列芯片。它们是小型、廉价、支持 WiFi 的电路板。 需要注意的是，并非所有 ESP32 开发板都使用 Xtensa 芯片，新的 ESP32-C3 是基于 RISC-V 的。在 Xtensa 芯片上使用 Rust 的最大障碍可能是 llvm 不支持它，因此需要构建 Rust 的 fork：<a href="https://github.com/esp-rs/rust" rel="noopener noreferrer">esp-rs/rust</a>。</li>
</ul>
<p><strong>我们需要什么芯片？</strong></p>
<p>因此，我们将使用 ARM Cortex-M。 这缩小了搜索范围，但仍有很多选择。如果我们查看 cortex-m <a href="https://crates.io/crates/cortex-m/reverse_dependencies" rel="noopener noreferrer">crate</a> 的依赖项，我们会看到有两组芯片比其他任何一组都使用得更多； <a href="https://www.st.com/content/st_com/en/products/microcontrollers-microprocessors/stm32-32-bit-arm-cortex-mcus.html" rel="noopener noreferrer">STM32</a> 系列芯片和 <a href="https://www.nordicsemi.com/Products/Bluetooth-Low-Energy" rel="noopener noreferrer">nRF5</a> 系列，这是我们要重点搜索的地方。</p>
<ul>
<li>STM32：STM32 系列芯片可能是应用最广泛的嵌入式 Rust ARM Cortex-M 芯片。两种最受欢迎的 STM32 板是 Blue Pill 和 Black Pill。主要的缺点是没有板载调试器。如果想要带有调试器的基于 STM32 的电路板，那么获得 STMicroelectronics <a href="https://www.st.com/en/evaluation-tools/stm32-discovery-kits.html#overview" rel="noopener noreferrer">官方套件</a>是一个不错的选择（STM32F3 或 STM32F4 是不错的选择）。Rust Embedded Discovery 书的原始版本是针对 STM32F3 板编写的，因此有非常高质量的初学者文档，可以从那里开始。</li>
<li>nRF5：用于嵌入式 Rust 的第二个最广泛使用的 ARM Cortex-M 芯片系列是 Nordic Semiconductor 的 <a href="https://www.nordicsemi.com/Products/Bluetooth-Low-Energy" rel="noopener noreferrer">nRF5 系列</a>。官方开发<a href="https://www.nordicsemi.com/Products/Bluetooth-Low-Energy/Development-hardware" rel="noopener noreferrer">套件</a> (DK) 是很棒的入门板。 Ferrous Systems 的 Knurling-rs 会议使用 nRF52840 <a href="https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK" rel="noopener noreferrer">开发套件</a>。Knurling 课程质量非常高，手把手指导，通过有趣好玩的项目教授嵌入 Rust，是使用 Rust 进行嵌入式开发的最佳切入点。另一个很棒的基于 nRF 的开发板是 <a href="https://www.microbit.org/" rel="noopener noreferrer">BBC micro:bit</a>。它配备了板载调试器和一系列有趣的板载外围设备，如板上的 LED 显示屏、按钮和传感器。BBC micro:bit 被设计为一个教育平台，因此硬件在他们的<a href="https://tech.microbit.org/" rel="noopener noreferrer">开发者社区</a>中以非常适合初学者的方式进行记录，并且互联网上有大量项目创意。</li>
<li>RP2040：<a href="https://www.raspberrypi.org/documentation/rp2040/getting-started/" rel="noopener noreferrer">RP2040</a> 于 2020 年底发布，是 Raspberry Pi 基金会首次尝试设计自己的芯片。由于如此新，Rust 对它的支持仍在开发中。与 BBC micro:bit 一样，RP2040 旨在成为一个教育平台，因此硬件文档是一流的，并且有大量初学者友好的代码示例和其他编程语言的库（没有多少适合初学者的嵌入式 Rust 文档）。这是一个非常令人兴奋的平台，并且在 Embedded Rust 社区中围绕它进行了大量活动，所以一定要密切关注，但它可能不适合作为入门第一块板。</li>
</ul>
<p><strong>板载调试器？</strong></p>
<p>在主机上运行程序时，可以在 shell 中运行它并查看打印输出。这在嵌入式目标上更加困难，调试器填补了这一空白。除了允许单步调试、断点调试外，它还允许将程序加载到设备上并轻松查看输出。不过有一个问题，它通常是连接到主机然后连接到目标设备的单独设备。第一次开始时，这是一笔不可忽视的费用，也是必须正确设置的另一件事。幸运的是，有些设备带有内置调试器，将它们直接插入主机并在瞬间探测运行的代码（通常需要在主机上进行一些设置才能使调试器正常工作，ferrous 有一个很好的设置<a href="https://session20q4.ferrous-systems.com/sessions/installation.html" rel="noopener noreferrer">指南</a>）。</p>
<p><strong>结论</strong></p>
<p>以下这些板都有很棒的 HAL 和 BSP crate、活跃友好的社区和板载调试器。</p>
<ul>
<li><a href="https://www.microbit.org/" rel="noopener noreferrer">BBC micro:bit</a>（约 13 英镑）：它是新版 Rust Embedded Discovery 书中使用的板。</li>
<li><a href="https://www.nordicsemi.com/Products/Development-hardware/nRF52840-DK" rel="noopener noreferrer">nRF52840 开发套件</a>（约 35 英镑）； 它是 Ferrous Systems 在 Kunrling 会议和培训中使用的板。</li>
<li><a href="https://www.st.com/en/evaluation-tools/stm32f3discovery.html" rel="noopener noreferrer">STM32F3 探索套件</a>（约 14 英镑）； 它是 Rust Embedded Discovery 书的第一版中使用的板。</li>
</ul>
<p>密切关注：</p>
<ul>
<li><a href="https://www.raspberrypi.org/products/raspberry-pi-pico/" rel="noopener noreferrer">Raspberry Pi Pico</a>（约 6 英镑，带预焊引脚）； ARM Cortex-M 但没有内置调试器，HAL 仍在开发中。不过目前有很多活动，进展很快。</li>
<li><a href="https://www.sifive.com/boards/hifive1-rev-b" rel="noopener noreferrer">HiFive1 Rev B</a>（约 50 英镑）； RISC-V 是新的热点。 Rust 中似乎有很多围绕它的活动，但它目前还没有 ARM Cortex-M 的支持。 其他需要关注的开发板是 <a href="https://longan.sipeed.com/en/" rel="noopener noreferrer">Logan Nano</a> 和 <a href="https://hackaday.com/2021/02/08/hands-on-the-risc-v-esp32-c3-will-be-your-new-esp8266/" rel="noopener noreferrer">ESP32-C3</a>。</li>
</ul>
<p>部分内容略有轻微调整，更多可阅读原文：<a href="https://robyoung.digital/blog/embedded-rust-selecting-a-board/" rel="noopener noreferrer">Rob Young | digital</a></p>
<h3>Tangram：训练、部署和监控机器学习模型</h3>
<p>一个机器学习套件，使用方法如下：</p>
<pre><code># 训练
$ tangram train --file heart_disease.csv --target diagnosis --output heart_disease.tangram
</code></pre>
<p>推理支持多种语言：<a href="https://hex.pm/packages/tangram" rel="noopener noreferrer">Elixir</a>, <a href="https://pkg.go.dev/github.com/tangramdotdev/tangram-go" rel="noopener noreferrer">Go</a>, <a href="https://www.npmjs.com/package/@tangramdotdev/tangram" rel="noopener noreferrer">JavaScript</a>, <a href="https://pypi.org/project/tangram" rel="noopener noreferrer">Python</a>, <a href="https://rubygems.org/gems/tangram" rel="noopener noreferrer">Ruby</a> 和 <a href="https://lib.rs/tangram" rel="noopener noreferrer">Rust</a>，以 Rust 为例：</p>
<pre><code>let model: tangram::Model = tangram::Model::from_path("heart_disease.tangram", None).unwrap();

let input = tangram::predict_input! {
  "age": 63.0,
  "gender": "male",
  // ...
};

let output = model.predict_one(input, None);
# { className: 'Negative', probability: 0.9381780624389648 }
</code></pre>
<p>很好奇训练的时候居然没有要指定模型，发现其将模型共分为三类：回归、二分类和多分类，训练时会根据数据自动选择合适（使用评估方法）的模型，每种模型又有两种不同的训练方法：线性方法和树方法。</p>
<p>自带的监控功能看起来还不错，比如下面这张可以展示特征对输出的贡献：</p>
<p><img src="https://github.com/tangramdotdev/tangram/raw/main/readme/predictions.png" alt></p>
<p>项目理论上可以用在简单机器学习场景下，尤其是那些还没有支持机器学习的语言，不过推理并没有 Benchmark，生产中使用需要做好性能测试。</p>
<p>GitHub：<a href="https://github.com/tangramdotdev/tangram" rel="noopener noreferrer">tangramdotdev/tangram: Tangram makes it easy for programmers to train, deploy, and monitor machine learning models.</a></p>
<p>文档：<a href="https://www.tangram.dev/docs/" rel="noopener noreferrer">Tangram</a></p>
<h3>lateral：一个在 x86_64 上启动的模块化内核</h3>
<p>在本地执行：</p>
<pre><code>$ make run-release ARCH=x86_64
</code></pre>
<p>可以根据自己的情况调整 Makefile 第一行 Bash 的配置。执行后如果有安装 QEMU 的话会自动加载：</p>
<p><img src="http://qnimg.lovevivian.cn/tmp-os-1.jpg" alt></p>
<p>每个组件都建立在窗口管理器之上，而不是像大多数操作系统那样建立在终端之上。</p>
<p>GitHub：<a href="https://github.com/carterisonline/lateral" rel="noopener noreferrer">carterisonline/lateral: A clean, custom-built modular kernel ready to boot on x86_64.</a></p>
<h3>tv：显示表格的 cli 工具</h3>
<p>就是把 json 或 csv 显示成表格，看起来很不错：</p>
<pre><code>$ cat test.json
[
  {
    "name": "test",
    "age": 10,
    "lang": "ja"
  },
  {
    "name": "uzimaru",
    "age": 23,
    "lang": "ja"
  },
  {
    "name": "hogehoge",
    "age": 21,
    "lang": "en"
  },
  {
    "name": "hugehuge",
    "age": 32,
    "lang": "en"
  }
]

$ tv test.json
|age|lang|    name|
|---|----|--------|
| 10|  ja|    test|
| 23|  ja| uzimaru|
| 21|  en|hogehoge|
| 32|  en|hugehuge|

$ cat test.csv
name,age,lang
test,10,ja
uzimaru,23,ja
hogehoge,21,en
hugehuge,32,en

$ tv test.csv
|age|lang|    name|
|---|----|--------|
| 10|  ja|    test|
| 23|  ja| uzimaru|
| 21|  en|hogehoge|
| 32|  en|hugehuge|
</code></pre>
<p>Mac 用户 brew 安装：</p>
<pre><code>$ brew install uzimaru0000/tap/tv
</code></pre>
<p>GitHub：<a href="https://github.com/uzimaru0000/tv" rel="noopener noreferrer">uzimaru0000/tv: CLI tool for displaying table</a></p>
<h3>minesweeper：使用 Rust，WebAssembly 和 Canvas 的扫雷游戏</h3>
<p>界面长这样：</p>
<p><img src="https://github.com/KarthikNedunchezhiyan/minesweeper/raw/main/www/assets/stage_bomb_triggered.png" alt></p>
<p>是很好的学习资料。在这里玩儿：<a href="https://karthiknedunchezhiyan.me/minesweeper/" rel="noopener noreferrer">Minesweeper</a></p>
<p>GitHub：<a href="https://github.com/karthikNedunchezhiyan/minesweeper" rel="noopener noreferrer">KarthikNedunchezhiyan/minesweeper: Minesweeper game developed with Rust, WebAssembly (Wasm), and Canvas</a></p>
<h3>copy-translator：划词翻译</h3>
<p>复制后翻译，使用 DeepL 的 API，不过目前只有 Local 版本好用：</p>
<p><img src="http://qnimg.lovevivian.cn/tmp-rust-1.jpg" alt></p>
<p>当然，也可以使用 Eudic（欧路词典）。</p>
<p>GitHub：<a href="https://github.com/zu1k/copy-translator" rel="noopener noreferrer">zu1k/copy-translator: Copy Translator, using DeepL api</a></p>
<h3>veccentric：小巧的 2-D 向量 Library</h3>
<p>项目受 <a href="https://p5js.org/reference/#/p5.Vector" rel="noopener noreferrer">p5.Vector</a> 启发，使用方法如下：</p>
<pre><code>use veccentric::Vecc;

let a = Vecc::new(3_i32, 4);
let b = a * 5;
let c = Vecc::new(-10, -8);
let d = b - c;
let e = -d;
</code></pre>
<p>GitHub：<a href="https://github.com/micouy/veccentric" rel="noopener noreferrer">micouy/veccentric: Tiny 2D vector library. Inspired by p5.js's p5.Vector.</a></p>
<hr>
<p>From 日报小组 长琴</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc 论坛：支持 rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust 语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">axum如何使用静态文件目录</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=f3fa9c8e-004b-4d95-8d5f-bdf6609c2e8e">
<div class="article-summary-box-inner">
<span><p>再重构一个简单的单页面小程序的时候打算用<code>axum</code>代替<code>warp</code>的时候遇到了个问题。</p>
<pre><code>    let post = warp::post()
        .and(warp::body::bytes())
        .map(move |content: Bytes| {
            Response::builder().body(server::handle_post_request(content))
        });

    let routers = warp::get().and(warp::fs::dir("./wwwroot")).or(post);

    warp::serve(routers).run(([127, 0, 0, 1], 3030)).await;
</code></pre>
<p>有如上的简单代码，使用<code>wwwroot</code>文件夹目录来生成页面，文件夹里包含有<code>index.html</code>,JS和CSS文件，怎么使用<code>axum</code>改写呢？看了下doc，只看到</p>
<pre><code>let app = Router::new()
    // this route cannot fail
    .route("/foo", get(|| async {}))
    // this route can fail with io::Error
    .route(
        "/",
        service::get(service_fn(|_req: Request&lt;Body&gt;| async {
            let contents = tokio::fs::read_to_string("some_file").await?;
            Ok::&lt;_, io::Error&gt;(Response::new(Body::from(contents)))
        }))
        .handle_error(handle_io_error),
    );

fn handle_io_error(error: io::Error) -&gt; Result&lt;impl IntoResponse, Infallible&gt; {
    // ...
}
</code></pre>
<p>这种写法。看着头大不说，那个<code>some_file</code>只是简单读取文件，完成不了我的要求。</p>
<p>有大神说说axum完成了这个部分了吗？这框架的代码看着感觉有点过于复杂了。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">自己管理内存的测试方法</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d4e8f317-f43f-44ea-a041-f39dd3ce1578">
<div class="article-summary-box-inner">
<span><p>很漂亮的一段case，来自std</p>
<p>library/alloc/tests/linked_list.rs</p>
<pre><code>#[test]
fn test_drop() {
    static mut DROPS: i32 = 0;
    struct Elem;
    impl Drop for Elem {
        fn drop(&amp;mut self) {
            unsafe {
                DROPS += 1;
            }
        }
    }

    let mut ring = LinkedList::new();
    ring.push_back(Elem);
    ring.push_front(Elem);
    ring.push_back(Elem);
    ring.push_front(Elem);
    drop(ring);

    assert_eq!(unsafe { DROPS }, 4);
}

</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">问一个Display trait的问题</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=6b59dfb1-87d8-4b79-8820-e9d5397f178a">
<div class="article-summary-box-inner">
<span><p>请问&amp;str, &amp;&amp;str, &amp;&amp;&amp;str 并没有实现Display 的trait, 为什么这个函数调用没问题?</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-28 开源操作系统夏令营最终报告会安排</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=ef3dd4e8-a8e8-4fec-bc7e-75703e1117ff">
<div class="article-summary-box-inner">
<span><h3>开源操作系统夏令营最终报告会安排</h3>
<p>会议主题：开源操作系统夏令营最终报告会
会议时间：2021/08/29 09:00-11:30 (GMT+08:00) 中国标准时间 - 北京
点击链接入会，或添加至会议列表： https://meeting.tencent.com/dm/Mp7T1h5zeQOk?rs=25
会议 ID：635 194 989</p>
<p>下面是9位全程参与夏令营活动同学的报告顺序。每人报告时间最长15分钟。</p>
<ol>
<li>杨云枫 王涛 Rustsbi的哪吒开发版移植</li>
<li>兰陈昕 zCore图形支持</li>
<li>都秉甲 容器技术学习</li>
<li>薛潇巍 RVM 的 RISC-V 支持</li>
<li>陈乐 共享调度器</li>
<li>吴非凡 基于用户态中断的异步系统调用设计与实现</li>
<li>彭淳毅 陈志扬 基于rCore-Tutorial的性能分析软件实现</li>
</ol>
<h3>crates.live：可视化 Rust crates 依赖项</h3>
<p>crates.live 是来自 crates.io 的 Rust crates 的依赖可视化工具。 它显示了 Rust crates（包）的依赖树。功能包括：</p>
<ul>
<li>依赖解析， crates.live 引擎通过匹配依赖版本来完成完整的依赖解析。</li>
<li>交互式图表，带有标记的板条箱的可缩放交互式图表。</li>
<li>图像导出， 将图形导出为 PNG。</li>
<li>开放 API：（即将推出）GraphQL API。</li>
</ul>
<p>crates.live 使用了一堆技术框架，技术栈包括：</p>
<ul>
<li>Rust， crates.live 后端和爬虫是用 Rust 和开源 Rust 库开发的。</li>
<li>GraphQl， WASM 驱动的 GraphQL 服务器。</li>
<li>React/Bulma， 前端库。</li>
<li>Terraform， 帮助启动和维护我们的基础设施。</li>
<li>Cloudflare， Cloudflare 工作人员运行 WASM 后端。</li>
</ul>
<p>如果在使用此应用程序时有任何疑问、建议或问题； 可以通过 contact@crates.live 联系。 crates.live 由 Abid Omar 开发，可通过 contact@omarabid.com 联系。</p>
<p><a href="https://crates.live/" rel="noopener noreferrer">链接</a>：https://crates.live/</p>
<h3>Obake，版本化数据结构</h3>
<p>Obake 是一个用于声明和维护版本化数据结构的过程宏。 “obake”这个名字取自日语“お化け（おばけ）”，这是日本民间传说中一类会变形的超自然生物。</p>
<p>在开发应用程序时，配置格式和内部数据结构通常会在版本之间演变。 然而，保持这些版本之间的向后兼容性需要声明和维护遗留格式的数据结构和用于在它们之间迁移的代码。 Obake 的目标是让这个过程变得轻松。</p>
<pre><code>#[obake::versioned]                 // create a versioned data-structure
#[obake(version("0.1.0"))]          // declare some versions
#[obake(version("0.2.0"))]
#[derive(PartialEq, Eq, Hash)]      // additional attributes are applied to all versions
struct Foo {
    #[obake(cfg("0.1.0"))]          // enable fields for specific versions with
    foo: String,                    // semantic version constraints
   
    #[obake(cfg("&gt;=0.2, &lt;=0.3.0"))] // any semantic version constraint can appear in
    bar: u32,                       // a `cfg` attribute 
   
    #[obake(cfg("0.1.0"))]          // multiple `cfg` attributes are treated as a
    #[obake(cfg("&gt;=0.3"))]          // disjunction over version constraints
    baz: char,
}

// describe migrations between versions using the `From` trait
// and an automatically generated type-level macro for referring to
// specific versions of `Foo`
impl From&lt;Foo!["0.1.0"]&gt; for Foo!["0.2.0"] {
    fn from(foo: Foo!["0.1.0"]) -&gt; Self {
        Self { bar: 0 }
    }
}

// an enumeration of all versions of `Foo` is accessed using the
// `obake::Versioned` trait:
let versioned_example: &lt;Foo as obake::Versioned&gt;::Versioned = unimplemented!();

// this enumeration implements `Into&lt;Foo&gt;`, where `Foo` is the latest declared
// version of `Foo` (in this case, `Foo!["0.2.0"]`)
let example: Foo = versioned_example.into();
</code></pre>
<p>Github<a href="https://github.com/doctorn/obake" rel="noopener noreferrer">链接</a>：https://github.com/doctorn/obake</p>
<h3>iced，跨平台 GUI 库</h3>
<p>iced，Rust 的跨平台 GUI 库，专注于简单性和类型安全。 灵感来自<a href="https://elm-lang.org/" rel="noopener noreferrer">Elm</a>。</p>
<p><img src="https://raw.githubusercontent.com/hecrj/iced/master/docs/graphs/ecosystem.png" alt="eco"></p>
<p>Github<a href="https://github.com/hecrj/iced/" rel="noopener noreferrer">链接</a>：https://github.com/hecrj/iced/</p>
<p>示例：https://github.com/hecrj/iced/tree/master/examples</p>
<hr>
<p>From 日报小组 <a href="https://rustcc.cn/blog_with_author?author_id=207704d2-4f5e-4219-a631-6ab4ab4d8929" rel="noopener noreferrer">洋芋</a></p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust 日报】2021-8-27 Rudra Rust 的内存安全和未定义行为检测工具</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=ce7eb559-fdda-45d7-a53e-293af787a813">
<div class="article-summary-box-inner">
<span><h4>Rudra Rust 的内存安全和未定义行为检测工具</h4>
<p>Rudra 是一个静态分析器，用于检测 Rust 程序中常见的未定义行为。它能够分析单个 Rust 包以及 crates.io 上的所有包。Rudra 及其相关论文将在 Proceedings of the 28th ACM Symposium on Operating Systems Principles 2021 (SOSP '21) 上发表。</p>
<ul>
<li>https://github.com/sslab-gatech/Rudra#readme</li>
</ul>
<h4>nom 7.0 版本发布</h4>
<p>nom 是一个用 Rust 编写的解析器组合库。它的目标是提供工具来构建安全的解析器，而不会影响速度或内存消耗。为此，它广泛使用 Rust 的强类型和内存安全来生成快速且正确的解析器，并提供函数、宏和特征来抽象大部分容易出错的管道。目前7.0已经发布</p>
<ul>
<li>https://crates.io/crates/nom</li>
</ul>
<h4>egui 0.14 版本发布</h4>
<p>egui 是一个易于使用的纯 Rust 图形用户界面。egui 可以在 Web 上、本机上以及您最喜欢的游戏引擎中运行。egui 旨在成为最容易使用的 Rust GUI 库，以及在 Rust 中制作 Web 应用程序的最简单方法，它可以在任何可以绘制纹理三角形的地方使用，这意味着您可以轻松地将其集成到您选择的游戏引擎中。</p>
<ul>
<li>演示文档：https://emilk.github.io/egui/</li>
<li>https://github.com/emilk/egui</li>
</ul>
<hr>
<p>From 日报小组 北纬27度，侯盛鑫</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">开源项目xiu登上了GitHub rust trending榜</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=86c83d9a-8370-42cf-8993-ef15af6932c4">
<div class="article-summary-box-inner">
<span><p><a href="https://github.com/harlanc/xiu" rel="noopener noreferrer">https://github.com/harlanc/xiu</a></p>
<p><a href="https://github.com/trending/rust?since=daily" rel="noopener noreferrer">https://github.com/trending/rust?since=daily</a></p>
<p>感谢大家的支持！！</p>
<p>PS：</p>
<p>前三名有两个都在论坛里发过，这个论坛有点狠，哈哈</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课：《 Rust 异步编程入门 Future 》|Vol. 5</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>
<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是 Rust 异步编程的核心基础。</p>
<h3>课程大纲</h3>
<p>1、为什么需要异步.</p>
<p>2、理解异步编程模型.</p>
<p>3、Future 编程模型讲解.</p>
<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c">
<div class="article-summary-box-inner">
<span><h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>
<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>
<p>ReadMore:<a href="https://twitter.com/m_ou_se/status/1427666611977297924" rel="noopener noreferrer">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>
<h3>异步引擎 C++20, Rust &amp; Zig</h3>
<p>ReadMore:<a href="https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/" rel="noopener noreferrer">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>
<h3>RG3D -- Rust 3D 游戏引擎</h3>
<ul>
<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>
<li><strong>延迟着色</strong></li>
<li><strong>内置保存/加载</strong></li>
<li><strong>独立场景编辑器</strong></li>
<li><strong>高级物理模型</strong></li>
<li><strong>分层模型资源</strong></li>
<li><strong>几何实例化</strong></li>
</ul>
<p>ReadMore:<a href="https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/" rel="noopener noreferrer">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>
<p>ReadMore:<a href="https://github.com/rg3dengine/rg3d" rel="noopener noreferrer">https://github.com/rg3dengine/rg3d</a></p>
<hr>
<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8">
<div class="article-summary-box-inner">
<span><p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>
<p><strong>课程时间：</strong> 2021年8月22日 20:30-21:30</p>
<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>
<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>
<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>
<h3>课程大纲</h3>
<ol>
<li>
<p>什么是分布式追踪系统OpenTracing及应用场景</p>
</li>
<li>
<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>
</li>
<li>
<p>为什么需要tokio-rs/tracing库</p>
</li>
<li>
<p>演示Datafuse项目中tokio-rs/tracing的使用</p>
</li>
</ol>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">论坛github账户无法登录解决笔记</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190">
<div class="article-summary-box-inner">
<span><p>有反映这两天github账户无法登录了。</p>
<p>报这个错：</p>
<pre><code>get github user info err
</code></pre>
<p>查了几个地方：</p>
<ol>
<li>代码是否运行正常：Ok</li>
<li>https代理是否正常：Ok</li>
<li>检查了github返回日志，发现是：</li>
</ol>
<pre><code>get_github_user_info: response body: "{\"message\":\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\",\"documentation_url\":\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\"}"
get_github_user_info: Got: Err(Custom("read json login error"))
</code></pre>
<p>进入这个地址一看：<a href="https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/" rel="noopener noreferrer">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>
<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>
<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>
<p>特此记录。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 的 Future 与 Javascript 的 Promise 功能对照参考</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095">
<div class="article-summary-box-inner">
<span><h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>
<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>
<blockquote>
<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>
</blockquote>
<table>
<thead>
<tr>
<th>javascript</th>
<th align="center">rust</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Promise.resolve(...)</td>
<td align="center">use ::async_std::future;future::ready(Ok(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.reject(...)</td>
<td align="center">use ::async_std::future;future::ready(Err(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.catch(err =&gt; err)</td>
<td align="center">use ::async_std::future;future::ready(...)</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>new Promise(() =&gt; {/* 什么都不做 */})</td>
<td align="center">use ::async_std::future;future::pending()</td>
<td align="center"></td>
</tr>
<tr>
<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; { if (Math.random() &gt; .5) { resolve(1); } else { reject(new Error('1')); }}, 500))</td>
<td align="center">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| { thread::sleep(Duration::from_millis(500)); let mut rng = rand::thread_rng(); if rng.gen() &gt; 0.5f64 { Ok(1) } else { Err('1') }}).await;</td>
<td align="center">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被 （1）跨线程传递 （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>
</tr>
<tr>
<td>Promise.all([promise1, promise2, promise3])</td>
<td align="center">future1.try_join(future2).try_join(future3).await</td>
<td align="center">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>
</tr>
<tr>
<td>Promise.all([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.join(future2).join(future3).await</td>
<td align="center">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>
</tr>
<tr>
<td>Promise.race([promise1, promise2, promise3])</td>
<td align="center">future1.try_race(future2).try_race(future3).await</td>
<td align="center">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>
</tr>
<tr>
<td>Promise.race([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.race(future2).race(future3).await</td>
<td align="center">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>
</tr>
</tbody>
</table>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：《通过实战理解 Rust 宏》| Vol. 3</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>
<p><strong>课程时间：</strong> 2021年8月15日 20:30-21:30</p>
<p><strong>课程介绍：</strong></p>
<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg" alt></p>
<p>这就是通过宏实现配置的统一行为，代码参考：
https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>
<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>
<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>
<h3>课程大纲</h3>
<ul>
<li>什么是 Rust 宏</li>
<li>什么是宏运行原理</li>
<li>如何创建 Rust 宏过程</li>
<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>
</ul>
<p><strong>讲师介绍</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：理解Rust的所有权| Vol 2</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：《理解Rust所有权》</strong></p>
<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>
<p><strong>嘉宾讲师： 苏林</strong></p>
<p><strong>嘉宾介绍：</strong></p>
<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>
<p><strong>课程介绍</strong></p>
<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>
<p><strong>参加课程</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg" alt></p>
<p><strong>课程规划</strong></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">数据表 Timestamp 日期 Serialize</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0">
<div class="article-summary-box-inner">
<span><p>主要参考：<a href="https://github.com/rustcc/forustm" rel="noopener noreferrer">Rustcc网站源码库</a></p>
<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，
查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>
<h2>1.依赖的库：</h2>
<pre><code>[dependencies]
# 日期时间处理 需要开启 serde 特征 支持序列化
chrono = { version = "0.4.19", features = ["serde"] }

# 数据库ORM
diesel = { version = "1.4.4", features = ["postgres", "chrono", "uuid", "r2d2"] }
dotenv = "0.15.0"
serde = { version = "1.0.127", features = ["derive"] }
serde_json = "1.0.66"
uuid = { version = "0.8.2", features = ["serde", "v4"] }
</code></pre>
<h2>2.创建数据表</h2>
<pre><code>CREATE TABLE characters (
    id SERIAL PRIMARY KEY,
    name VARCHAR(128) UNIQUE NOT NULL,
    age INTEGER NOT NULL DEFAULT 0,
    friends VARCHAR NOT NULL DEFAULT '',
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
)
</code></pre>
<h2>3.数据表对应的 model</h2>
<pre><code>use chrono::{NaiveDateTime};
use serde::{Deserialize, Serialize};

#[derive(Queryable, Serialize, Deserialize, Debug)]
pub struct Characters {
    pub id: i32,
    pub name: String,
    pub age: i32,
    pub friends: String,
    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features
    pub created_at: NaiveDateTime,
}
</code></pre>
<h2>4.获取数据</h2>
<pre><code>use db::schema::characters;
use db::{get_connection};
use db::models::{Characters, NewCharacter};
use db::schema::characters::dsl::*;
use diesel::QueryDsl;
use diesel::prelude::*;

fn main() {
    let conn = get_connection();

    // 查询年龄大于30的10条数据
    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))
        .limit(10)
        .load::&lt;Characters&gt;(&amp;conn)
        .expect("Loading Error");

    let date_arr = arr.iter()
        .map(|item| {
	    // 数据格式化
            let t = item.created_at.format("%Y-%m-%d %H:%M:%S").to_string();
            println!("{} {}", item.name, t);
            t
        })
        .collect::&lt;Vec&lt;String&gt;&gt;();
}
</code></pre>
<p>输出结果类似：</p>
<pre><code>Box 2021-08-05 09:39:34
Bobe 2021-08-05 09:39:34
</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cargo workspace config</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c">
<div class="article-summary-box-inner">
<span><p><a href="https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html" rel="noopener noreferrer">Workspace 文档链接</a></p>
<h2>目录结构</h2>
<pre><code>workspace-test/
    Cargo.toml
    db/
        src/
            bin/
                init.rs
        Cargo.tml
</code></pre>
<h2>workspace</h2>
<p>workspace-test/Cargo.toml</p>
<pre><code>[workspace]
members = ["db"]
default-member = "db"
</code></pre>
<h2>子项目</h2>
<p>workspace-test/db/Cargo.toml</p>
<pre><code>[package]
name = "db"
version = "0.1.0"
edition = "2018"

[dependencies]

# 可选的可执行文件配置
# [[bin]]
# name = "init"
# path = "src/bin/init.rs"
</code></pre>
<h2>操作</h2>
<pre><code># 运行 init
cargo run --bin init
# -p 指定项目
cargo run -p db --bin init
</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 异步编程浅悟（一）</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=120035c3-944d-4a79-9b3a-8390697a6e13">
<div class="article-summary-box-inner">
<span><h1><code>Rust</code>异步编程浅悟（一）</h1>
<p>不同于<code>javascript</code>的<code>new Promise((resolve, reject) =&gt; {...})</code>构造即运行，<code>Rust</code>中的<code>Future</code>是·惰性·状态机。这体现为：</p>
<ol>
<li>【调用异步函数】或【执行异步块】仅只构造一个<code>Future trait object</code>。</li>
<li>因为<code>Future</code>是惰性状态机，所以它不会自动执行【异步函数】或【异步块】内的任何一行代码 --- 此点与<code>javascript</code>的·活性·状态机完全不同。相反，需要人工激活触发。</li>
<li>人工启动<code>Future</code>运行，又分为两个场景的两种情况：
<ol>
<li>
<p>已经在<code>async fn</code>内，<code>Future.await</code>激活。但，同时<strong>阻塞</strong>当前异步程序执行流。</p>
</li>
<li>
<p>在<code>async fn</code>外，需要借助由【运行时】提供的【执行器】。就<code>async-std</code>库而言，有两个选择：</p>
<ol>
<li><code>task::block_on(Future)</code> 执行<code>Future</code>且阻塞当前线程直到<code>Future</code>被完成。</li>
<li><code>task::spawn(Future)</code>仅执行<code>Future</code>和不阻塞当前线程。</li>
</ol>
<p>无论选择上面哪种方式，若在<code>Future</code>执行期间出现了<code>panic</code>，其都会终止（<code>abort</code>）正在共享同一个执行线程（<code>thread</code>）的所有<code>task</code>（·无栈·协程）的运行。</p>
</li>
</ol>
</li>
</ol>
<p>题外话，</p>
<ol>
<li>绿色线程是·有栈·协程；异步函数与异步块是·无栈·协程。</li>
<li>在<code>async-std</code>库的词汇表内，协程被称作<code>task</code>而不是惯例的<code>coroutine</code>。</li>
<li><code>task::spawn(Future)</code>也能被使用于<code>async fn</code>或<code>async {...}</code>内。它被用来代替<code>.await</code>指令，以<strong>非阻塞</strong><code>async fn</code>或<code>async {...}</code>的方式，激活与执行一个<code>Future</code>实例。</li>
</ol>
<h2>例程</h2>
<pre><code>async fn accept_loop(addr: impl ToSocketAddrs) -&gt; Result&lt;()&gt; {
    // 1. TcpListener::bind(addr) 返回 Future
    // 2. .await 于 Future 取得 Result&lt;T, E&gt;
    // 3. Result&lt;T, E&gt;? 再拿得 Ok&lt;T&gt; 中的 T
    let listener = TcpListener::bind(addr).await?; // 异步函数内的人工启动 Future
    let mut incoming = listener.incoming();
    // 因为没有从语言层面支持 async for loop，所以 while loop + Iterator&lt;Item = T&gt; 来模拟之。
    while let Some(stream) = incoming.next().await {
        // TODO
    }
    Ok(())
}
fn main() {
    let fut = accept_loop("127.0.0.1:8080");
    task::block_on(fut); // 异步函数外的人工启动 Future
}
</code></pre>
</span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-08-31T01:30:00Z">08-31</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">From Pivots to Graphs: Augmented CycleDensity as a Generalization to One Time InverseConsultation. (arXiv:2108.12459v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12459">
<div class="article-summary-box-inner">
<span><p>This paper describes an approach used to generate new translations using raw
bilingual dictionaries as part of the 4th Task Inference Across Dictionaries
(TIAD 2021) shared task. We propose Augmented Cycle Density (ACD) as a
framework that combines insights from two state of the art methods that require
no sense information and parallel corpora: Cycle Density (CD) and One Time
Inverse Consultation (OTIC). The task results show that across 3 unseen
language pairs, ACD's predictions, has more than double (74%) the coverage of
OTIC at almost the same precision (76%). ACD combines CD's scalability -
leveraging rich multilingual graphs for better predictions, and OTIC's data
efficiency - producing good results with the minimum possible resource of one
pivot language.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Text Evaluation through the Lens of Wasserstein Barycenters. (arXiv:2108.12463v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12463">
<div class="article-summary-box-inner">
<span><p>A new metric \texttt{BaryScore} to evaluate text generation based on deep
contextualized embeddings (\textit{e.g.}, BERT, Roberta, ELMo) is introduced.
This metric is motivated by a new framework relying on optimal transport tools,
\textit{i.e.}, Wasserstein distance and barycenter. By modelling the layer
output of deep contextualized embeddings as a probability distribution rather
than by a vector embedding; this framework provides a natural way to aggregate
the different outputs through the Wasserstein space topology. In addition, it
provides theoretical grounds to our metric and offers an alternative to
available solutions (\textit{e.g.}, MoverScore and BertScore). Numerical
evaluation is performed on four different tasks: machine translation,
summarization, data2text generation and image captioning. Our results show that
\texttt{BaryScore} outperforms other BERT based metrics and exhibits more
consistent behaviour in particular for text summarization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Code-switched inspired losses for generic spoken dialog representations. (arXiv:2108.12465v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12465">
<div class="article-summary-box-inner">
<span><p>Spoken dialog systems need to be able to handle both multiple languages and
multilinguality inside a conversation (\textit{e.g} in case of code-switching).
In this work, we introduce new pretraining losses tailored to learn
multilingual spoken dialog representations. The goal of these losses is to
expose the model to code-switched language. To scale up training, we
automatically build a pretraining corpus composed of multilingual conversations
in five different languages (French, Italian, English, German and Spanish) from
\texttt{OpenSubtitles}, a huge multilingual corpus composed of 24.3G tokens. We
test the generic representations on \texttt{MIAM}, a new benchmark composed of
five dialog act corpora on the same aforementioned languages as well as on two
novel multilingual downstream tasks (\textit{i.e} multilingual mask utterance
retrieval and multilingual inconsistency identification). Our experiments show
that our new code switched-inspired losses achieve a better performance in both
monolingual and multilingual settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models. (arXiv:2108.12472v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12472">
<div class="article-summary-box-inner">
<span><p>Automatic construction of relevant Knowledge Bases (KBs) from text, and
generation of semantically meaningful text from KBs are both long-standing
goals in Machine Learning. In this paper, we present ReGen, a bidirectional
generation of text and graph leveraging Reinforcement Learning (RL) to improve
performance. Graph linearization enables us to re-frame both tasks as a
sequence to sequence generation problem regardless of the generative direction,
which in turn allows the use of Reinforcement Learning for sequence training
where the model itself is employed as its own critic leading to Self-Critical
Sequence Training (SCST). We present an extensive investigation demonstrating
that the use of RL via SCST benefits graph and text generation on WebNLG+ 2020
and TekGen datasets. Our system provides state-of-the-art results on WebNLG+
2020 by significantly improving upon published results from the WebNLG 2020+
Challenge for both text-to-graph and graph-to-text generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opinions are Made to be Changed: Temporally Adaptive Stance Classification. (arXiv:2108.12476v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12476">
<div class="article-summary-box-inner">
<span><p>Given the rapidly evolving nature of social media and people's views, word
usage changes over time. Consequently, the performance of a classifier trained
on old textual data can drop dramatically when tested on newer data. While
research in stance classification has advanced in recent years, no effort has
been invested in making these classifiers have persistent performance over
time. To study this phenomenon we introduce two novel large-scale, longitudinal
stance datasets. We then evaluate the performance persistence of stance
classifiers over time and demonstrate how it decays as the temporal gap between
training and testing data increases. We propose a novel approach to mitigate
this performance drop, which is based on temporal adaptation of the word
embeddings used for training the stance classifier. This enables us to make use
of readily available unlabelled data from the current time period instead of
expensive annotation efforts. We propose and compare several approaches to
embedding adaptation and find that the Incremental Temporal Alignment (ITA)
model leads to the best results in reducing performance drop over time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Few-Shot Table-to-Text Generation with Prototype Memory. (arXiv:2108.12516v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12516">
<div class="article-summary-box-inner">
<span><p>Neural table-to-text generation models have achieved remarkable progress on
an array of tasks. However, due to the data-hungry nature of neural models,
their performances strongly rely on large-scale training examples, limiting
their applicability in real-world applications. To address this, we propose a
new framework: Prototype-to-Generate (P2G), for table-to-text generation under
the few-shot scenario. The proposed framework utilizes the retrieved
prototypes, which are jointly selected by an IR system and a novel prototype
selector to help the model bridging the structural gap between tables and
texts. Experimental results on three benchmark datasets with three
state-of-the-art models demonstrate that the proposed framework significantly
improves the model performance across various evaluation metrics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Predicting the Factuality of Reporting of News Media Using Observations About User Attention in Their YouTube Channels. (arXiv:2108.12519v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12519">
<div class="article-summary-box-inner">
<span><p>We propose a novel framework for predicting the factuality of reporting of
news media outlets by studying the user attention cycles in their YouTube
channels. In particular, we design a rich set of features derived from the
temporal evolution of the number of views, likes, dislikes, and comments for a
video, which we then aggregate to the channel level. We develop and release a
dataset for the task, containing observations of user attention on YouTube
channels for 489 news media. Our experiments demonstrate both complementarity
and sizable improvements over state-of-the-art textual representations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TweetBLM: A Hate Speech Dataset and Analysis of Black Lives Matter-related Microblogs on Twitter. (arXiv:2108.12521v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12521">
<div class="article-summary-box-inner">
<span><p>In the past few years, there has been a significant rise in toxic and hateful
content on various social media platforms. Recently Black Lives Matter movement
came into the picture, causing an avalanche of user generated responses on the
internet. In this paper, we have proposed a Black Lives Matter related tweet
hate speech dataset TweetBLM. Our dataset comprises 9165 manually annotated
tweets that target the Black Lives Matter movement. We annotated the tweets
into two classes, i.e., HATE and NONHATE based on their content related to
racism erupted from the movement for the black community. In this work, we also
generated useful statistical insights on our dataset and performed a systematic
analysis of various machine learning models such as Random Forest, CNN, LSTM,
BiLSTM, Fasttext, BERTbase, and BERTlarge for the classification task on our
dataset. Through our work, we aim at contributing to the substantial efforts of
the research community for the identification and mitigation of hate speech on
the internet. The dataset is publicly available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Energy-Based Approximate Inference Networks for Structured Applications in NLP. (arXiv:2108.12522v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12522">
<div class="article-summary-box-inner">
<span><p>Structured prediction in natural language processing (NLP) has a long
history. The complex models of structured application come at the difficulty of
learning and inference. These difficulties lead researchers to focus more on
models with simple structure components (e.g., local classifier). Deep
representation learning has become increasingly popular in recent years. The
structure components of their method, on the other hand, are usually relatively
simple. We concentrate on complex structured models in this dissertation. We
provide a learning framework for complicated structured models as well as an
inference method with a better speed/accuracy/search error trade-off. The
dissertation begins with a general introduction to energy-based models. In NLP
and other applications, an energy function is comparable to the concept of a
scoring function. In this dissertation, we discuss the concept of the energy
function and structured models with different energy functions. Then, we
propose a method in which we train a neural network to do argmax inference
under a structured energy function, referring to the trained networks as
"inference networks" or "energy-based inference networks". We then develop ways
of jointly learning energy functions and inference networks using an
adversarial learning framework. Despite the inference and learning difficulties
of energy-based models, we present approaches in this thesis that enable
energy-based models more easily to be applied in structured NLP applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speech Representations and Phoneme Classification for Preserving the Endangered Language of Ladin. (arXiv:2108.12531v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12531">
<div class="article-summary-box-inner">
<span><p>A vast majority of the world's 7,000 spoken languages are predicted to become
extinct within this century, including the endangered language of Ladin from
the Italian Alps. Linguists who work to preserve a language's phonetic and
phonological structure can spend hours transcribing each minute of speech from
native speakers. To address this problem in the context of Ladin, our paper
presents the first analysis of speech representations and machine learning
models for classifying 32 phonemes of Ladin. We experimented with a novel
dataset of the Fascian dialect of Ladin, collected from native speakers in
Italy. We created frame-level and segment-level speech feature extraction
approaches and conducted extensive experiments with 8 different classifiers
trained on 9 different speech representations. Our speech representations
ranged from traditional features (MFCC, LPC) to features learned with deep
neural network models (autoencoders, LSTM autoencoders, and WaveNet). Our
highest-performing classifier, trained on MFCC representations of speech
signals, achieved an 86% average accuracy across all Ladin phonemes. We also
obtained average accuracies above 77% for all Ladin phoneme subgroups examined.
Our findings contribute insights for learning discriminative Ladin phoneme
representations and demonstrate the potential for leveraging machine learning
and speech signal processing to preserve Ladin and other endangered languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QACE: Asking Questions to Evaluate an Image Caption. (arXiv:2108.12560v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12560">
<div class="article-summary-box-inner">
<span><p>In this paper, we propose QACE, a new metric based on Question Answering for
Caption Evaluation. QACE generates questions on the evaluated caption and
checks its content by asking the questions on either the reference caption or
the source image. We first develop QACE-Ref that compares the answers of the
evaluated caption to its reference, and report competitive results with the
state-of-the-art metrics. To go further, we propose QACE-Img, which asks the
questions directly on the image, instead of reference. A Visual-QA system is
necessary for QACE-Img. Unfortunately, the standard VQA models are framed as a
classification among only a few thousand categories. Instead, we propose
Visual-T5, an abstractive VQA system. The resulting metric, QACE-Img is
multi-modal, reference-less, and explainable. Our experiments show that
QACE-Img compares favorably w.r.t. other reference-less metrics. We will
release the pre-trained models to compute QACE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Goal-driven text descriptions for images. (arXiv:2108.12575v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12575">
<div class="article-summary-box-inner">
<span><p>A big part of achieving Artificial General Intelligence(AGI) is to build a
machine that can see and listen like humans. Much work has focused on designing
models for image classification, video classification, object detection, pose
estimation, speech recognition, etc., and has achieved significant progress in
recent years thanks to deep learning. However, understanding the world is not
enough. An AI agent also needs to know how to talk, especially how to
communicate with a human. While perception (vision, for example) is more common
across animal species, the use of complicated language is unique to humans and
is one of the most important aspects of intelligence.
</p>
<p>In this thesis, we focus on generating textual output given visual input. In
Chapter 3, we focus on generating the referring expression, a text description
for an object in the image so that a receiver can infer which object is being
described. We use a comprehension machine to directly guide the generated
referring expressions to be more discriminative. In Chapter 4, we introduce a
method that encourages discriminability in image caption generation. We show
that more discriminative captioning models generate more descriptive captions.
In Chapter 5, we study how training objectives and sampling methods affect the
models' ability to generate diverse captions. We find that a popular captioning
training strategy will be detrimental to the diversity of generated captions.
In Chapter 6, we propose a model that can control the length of generated
captions. By changing the desired length, one can influence the style and
descriptiveness of the captions. Finally, in Chapter 7, we rank/generate
informative image tags according to their information utility. The proposed
method better matches what humans think are the most important tags for the
images.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling the Knowledge of Large-scale Generative Models into Retrieval Models for Efficient Open-domain Conversation. (arXiv:2108.12582v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12582">
<div class="article-summary-box-inner">
<span><p>Despite the remarkable performance of large-scale generative models in
open-domain conversation, they are known to be less practical for building
real-time conversation systems due to high latency. On the other hand,
retrieval models could return responses with much lower latency but show
inferior performance to the large-scale generative models since the
conversation quality is bounded by the pre-defined response set. To take
advantage of both approaches, we propose a new training method called G2R
(Generative-to-Retrieval distillation) that preserves the efficiency of a
retrieval model while leveraging the conversational ability of a large-scale
generative model by infusing the knowledge of the generative model into the
retrieval model. G2R consists of two distinct techniques of distillation: the
data-level G2R augments the dialogue dataset with additional responses
generated by the large-scale generative model, and the model-level G2R
transfers the response quality score assessed by the generative model to the
score of the retrieval model by the knowledge distillation loss. Through
extensive experiments including human evaluation, we demonstrate that our
retrieval-based conversation system trained with G2R shows a substantially
improved performance compared to the baseline retrieval model while showing
significantly lower inference latency than the large-scale generative models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-training Improves Pre-training for Few-shot Learning in Task-oriented Dialog Systems. (arXiv:2108.12589v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12589">
<div class="article-summary-box-inner">
<span><p>As the labeling cost for different modules in task-oriented dialog (ToD)
systems is expensive, a major challenge is to train different modules with the
least amount of labeled data. Recently, large-scale pre-trained language
models, have shown promising results for few-shot learning in ToD. In this
paper, we devise a self-training approach to utilize the abundant unlabeled
dialog data to further improve state-of-the-art pre-trained models in few-shot
learning scenarios for ToD systems. Specifically, we propose a self-training
approach that iteratively labels the most confident unlabeled data to train a
stronger Student model. Moreover, a new text augmentation technique (GradAug)
is proposed to better train the Student by replacing non-crucial tokens using a
masked language model. We conduct extensive experiments and present analyses on
four downstream tasks in ToD, including intent classification, dialog state
tracking, dialog act prediction, and response selection. Empirical results
demonstrate that the proposed self-training approach consistently improves
state-of-the-art pre-trained models (BERT, ToD-BERT) when only a small number
of labeled data are available.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Layer-wise Model Pruning based on Mutual Information. (arXiv:2108.12594v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12594">
<div class="article-summary-box-inner">
<span><p>The proposed pruning strategy offers merits over weight-based pruning
techniques: (1) it avoids irregular memory access since representations and
matrices can be squeezed into their smaller but dense counterparts, leading to
greater speedup; (2) in a manner of top-down pruning, the proposed method
operates from a more global perspective based on training signals in the top
layer, and prunes each layer by propagating the effect of global signals
through layers, leading to better performances at the same sparsity level.
Extensive experiments show that at the same sparsity level, the proposed
strategy offers both greater speedup and higher performances than weight-based
pruning methods (e.g., magnitude pruning, movement pruning).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigation of Diachronic Bias in Fake News Detection Dataset. (arXiv:2108.12601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12601">
<div class="article-summary-box-inner">
<span><p>Fake news causes significant damage to society.To deal with these fake news,
several studies on building detection models and arranging datasets have been
conducted. Most of the fake news datasets depend on a specific time period.
Consequently, the detection models trained on such a dataset have difficulty
detecting novel fake news generated by political changes and social changes;
they may possibly result in biased output from the input, including specific
person names and organizational names. We refer to this problem as
\textbf{Diachronic Bias} because it is caused by the creation date of news in
each dataset. In this study, we confirm the bias, especially proper nouns
including person names, from the deviation of phrase appearances in each
dataset. Based on these findings, we propose masking methods using Wikidata to
mitigate the influence of person names and validate whether they make fake news
detection models robust through experiments with in-domain and out-of-domain
data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WALNUT: A Benchmark on Weakly Supervised Learning for Natural Language Understanding. (arXiv:2108.12603v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12603">
<div class="article-summary-box-inner">
<span><p>Building quality machine learning models for natural language understanding
(NLU) tasks relies heavily on labeled data. Weak supervision has been shown to
provide valuable supervision when large amount of labeled data is unavailable
or expensive to obtain. Existing works studying weak supervision for NLU either
mostly focus on a specific task or simulate weak supervision signals from
ground-truth labels. To date a benchmark for NLU with real world weak
supervision signals for a collection of NLU tasks is still not available. In
this paper, we propose such a benchmark, named WALNUT, to advocate and
facilitate research on weak supervision for NLU. WALNUT consists of NLU tasks
with different types, including both document-level prediction tasks and
token-level prediction tasks and for each task contains weak labels generated
by multiple real-world weak sources. We conduct baseline evaluations on the
benchmark to systematically test the value of weak supervision for NLU tasks,
with various weak supervision methods and model architectures. We demonstrate
the benefits of weak supervision for low-resource NLU tasks and expect WALNUT
to stimulate further research on methodologies to best leverage weak
supervision. The benchmark and code for baselines will be publicly available at
aka.ms/walnut_benchmark.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HeadlineCause: A Dataset of News Headlines for Detecting Casualties. (arXiv:2108.12626v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12626">
<div class="article-summary-box-inner">
<span><p>Detecting implicit causal relations in texts is a task that requires both
common sense and world knowledge. Existing datasets are focused either on
commonsense causal reasoning or explicit causal relations. In this work, we
present HeadlineCause, a dataset for detecting implicit causal relations
between pairs of news headlines. The dataset includes over 5000 headline pairs
from English news and over 9000 headline pairs from Russian news labeled
through crowdsourcing. The pairs vary from totally unrelated or belonging to
the same general topic to the ones including causation and refutation
relations. We also present a set of models and experiments that demonstrates
the dataset validity, including a multilingual XLM-RoBERTa based model for
causality detection and a GPT-2 based model for possible effects prediction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Oh My Mistake!: Toward Realistic Dialogue State Tracking including Turnback Utterances. (arXiv:2108.12637v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12637">
<div class="article-summary-box-inner">
<span><p>The primary purpose of dialogue state tracking (DST), a critical component of
an end-to-end conversational system, is to build a model that responds well to
real-world situations. Although we often change our minds during ordinary
conversations, current benchmark datasets do not adequately reflect such
occurrences and instead consist of over-simplified conversations, in which no
one changes their mind during a conversation. As the main question inspiring
the present study,``Are current benchmark datasets sufficiently diverse to
handle casual conversations in which one changes their mind?'' We found that
the answer is ``No'' because simply injecting template-based turnback
utterances significantly degrades the DST model performance. The test joint
goal accuracy on the MultiWOZ decreased by over 5\%p when the simplest form of
turnback utterance was injected. Moreover, the performance degeneration worsens
when facing more complicated turnback situations. However, we also observed
that the performance rebounds when a turnback is appropriately included in the
training dataset, implying that the problem is not with the DST models but
rather with the construction of the benchmark dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Event Extraction as Natural Language Generation. (arXiv:2108.12724v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12724">
<div class="article-summary-box-inner">
<span><p>Event extraction (EE), the task that identifies event triggers and their
arguments in text, is usually formulated as a classification or structured
prediction problem. Such models usually reduce labels to numeric identifiers,
making them unable to take advantage of label semantics (e.g. an event type
named Arrest is related to words like arrest, detain, or apprehend). This
prevents the generalization to new event types. In this work, we formulate EE
as a natural language generation task and propose GenEE, a model that not only
captures complex dependencies within an event but also generalizes well to
unseen or rare event types. Given a passage and an event type, GenEE is trained
to generate a natural sentence following a predefined template for that event
type. The generated output is then decoded into trigger and argument
predictions. The autoregressive generation process naturally models the
dependencies among the predictions -- each new word predicted depends on those
already generated in the output sentence. Using carefully designed input
prompts during generation, GenEE is able to capture label semantics, which
enables the generalization to new event types. Empirical results show that our
model achieves strong performance on event extraction tasks under all
zero-shot, few-shot, and high-resource scenarios. Especially, in the
high-resource setting, GenEE outperforms the state-of-the-art model on argument
extraction and gets competitive results with the current best on end-to-end EE
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">$k$Folden: $k$-Fold Ensemble for Out-Of-Distribution Detection. (arXiv:2108.12731v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12731">
<div class="article-summary-box-inner">
<span><p>Out-of-Distribution (OOD) detection is an important problem in natural
language processing (NLP). In this work, we propose a simple yet effective
framework $k$Folden, which mimics the behaviors of OOD detection during
training without the use of any external data. For a task with $k$ training
labels, $k$Folden induces $k$ sub-models, each of which is trained on a subset
with $k-1$ categories with the left category masked unknown to the sub-model.
Exposing an unknown label to the sub-model during training, the model is
encouraged to learn to equally attribute the probability to the seen $k-1$
labels for the unknown label, enabling this framework to simultaneously resolve
in- and out-distribution examples in a natural way via OOD simulations. Taking
text classification as an archetype, we develop benchmarks for OOD detection
using existing text classification datasets. By conducting comprehensive
comparisons and analyses on the developed benchmarks, we demonstrate the
superiority of $k$Folden against current methods in terms of improving OOD
detection performances while maintaining improved in-domain classification
accuracy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SummerTime: Text Summarization Toolkit for Non-experts. (arXiv:2108.12738v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12738">
<div class="article-summary-box-inner">
<span><p>Recent advances in summarization provide models that can generate summaries
of higher quality. Such models now exist for a number of summarization tasks,
including query-based summarization, dialogue summarization, and multi-document
summarization. While such models and tasks are rapidly growing in the research
field, it has also become challenging for non-experts to keep track of them. To
make summarization methods more accessible to a wider audience, we develop
SummerTime by rethinking the summarization task from the perspective of an NLP
non-expert. SummerTime is a complete toolkit for text summarization, including
various models, datasets and evaluation metrics, for a full spectrum of
summarization-related tasks. SummerTime integrates with libraries designed for
NLP researchers, and enables users with easy-to-use APIs. With SummerTime,
users can locate pipeline solutions and search for the best model with their
own data, and visualize the differences, all with a few lines of code. We also
provide explanations for models and evaluation metrics to help users understand
the model behaviors and select models that best suit their needs. Our library,
along with a notebook demo, is available at
https://github.com/Yale-LILY/SummerTime.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sentence Structure and Word Relationship Modeling for Emphasis Selection. (arXiv:2108.12750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12750">
<div class="article-summary-box-inner">
<span><p>Emphasis Selection is a newly proposed task which focuses on choosing words
for emphasis in short sentences. Traditional methods only consider the sequence
information of a sentence while ignoring the rich sentence structure and word
relationship information. In this paper, we propose a new framework that
considers sentence structure via a sentence structure graph and word
relationship via a word similarity graph. The sentence structure graph is
derived from the parse tree of a sentence. The word similarity graph allows
nodes to share information with their neighbors since we argue that in emphasis
selection, similar words are more likely to be emphasized together. Graph
neural networks are employed to learn the representation of each node of these
two graphs. Experimental results demonstrate that our framework can achieve
superior performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Searching for an Effective Defender: Benchmarking Defense against Adversarial Word Substitution. (arXiv:2108.12777v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12777">
<div class="article-summary-box-inner">
<span><p>Recent studies have shown that deep neural networks are vulnerable to
intentionally crafted adversarial examples, and various methods have been
proposed to defend against adversarial word-substitution attacks for neural NLP
models. However, there is a lack of systematic study on comparing different
defense approaches under the same attacking setting. In this paper, we seek to
fill the gap of systematic studies through comprehensive researches on
understanding the behavior of neural text classifiers trained by various
defense methods under representative adversarial attacks. In addition, we
propose an effective method to further improve the robustness of neural text
classifiers against such attacks and achieved the highest accuracy on both
clean and adversarial examples on AGNEWS and IMDB datasets by a significant
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Interpretable Propaganda Detection in News Articles. (arXiv:2108.12802v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12802">
<div class="article-summary-box-inner">
<span><p>Online users today are exposed to misleading and propagandistic news articles
and media posts on a daily basis. To counter thus, a number of approaches have
been designed aiming to achieve a healthier and safer online news and media
consumption. Automatic systems are able to support humans in detecting such
content; yet, a major impediment to their broad adoption is that besides being
accurate, the decisions of such systems need also to be interpretable in order
to be trusted and widely adopted by users. Since misleading and propagandistic
content influences readers through the use of a number of deception techniques,
we propose to detect and to show the use of such techniques as a way to offer
interpretability. In particular, we define qualitatively descriptive features
and we analyze their suitability for detecting deception techniques. We further
show that our interpretable features can be easily combined with pre-trained
language models, yielding state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DropAttack: A Masked Weight Adversarial Training Method to Improve Generalization of Neural Networks. (arXiv:2108.12805v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12805">
<div class="article-summary-box-inner">
<span><p>Adversarial training has been proven to be a powerful regularization method
to improve the generalization of models. However, current adversarial training
methods only attack the original input sample or the embedding vectors, and
their attacks lack coverage and diversity. To further enhance the breadth and
depth of attack, we propose a novel masked weight adversarial training method
called DropAttack, which enhances generalization of model by adding
intentionally worst-case adversarial perturbations to both the input and hidden
layers in different dimensions and minimize the adversarial risks generated by
each layer. DropAttack is a general technique and can be adopt to a wide
variety of neural networks with different architectures. To validate the
effectiveness of the proposed method, we used five public datasets in the
fields of natural language processing (NLP) and computer vision (CV) for
experimental evaluating. We compare the proposed method with other adversarial
training methods and regularization methods, and our method achieves
state-of-the-art on all datasets. In addition, Dropattack can achieve the same
performance when it use only a half training data compared to other standard
training method. Theoretical analysis reveals that DropAttack can perform
gradient regularization at random on some of the input and wight parameters of
the model. Further visualization experiments show that DropAttack can push the
minimum risk of the model to a lower and flatter loss landscapes. Our source
code is publicly available on https://github.com/nishiwen1214/DropAttack.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Analyzing and Mitigating Interference in Neural Architecture Search. (arXiv:2108.12821v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12821">
<div class="article-summary-box-inner">
<span><p>Weight sharing has become the \textit{de facto} approach to reduce the
training cost of neural architecture search (NAS) by reusing the weights of
shared operators from previously trained child models. However, the estimated
accuracy of those child models has a low rank correlation with the ground truth
accuracy due to the interference among different child models caused by weight
sharing. In this paper, we investigate the interference issue by sampling
different child models and calculating the gradient similarity of shared
operators, and observe that: 1) the interference on a shared operator between
two child models is positively correlated to the number of different operators
between them; 2) the interference is smaller when the inputs and outputs of the
shared operator are more similar. Inspired by these two observations, we
propose two approaches to mitigate the interference: 1) rather than randomly
sampling child models for optimization, we propose a gradual modification
scheme by modifying one operator between adjacent optimization steps to
minimize the interference on the shared operators; 2) forcing the inputs and
outputs of the operator across all child models to be similar to reduce the
interference. Experiments on a BERT search space verify that mitigating
interference via each of our proposed methods improves the rank correlation of
super-pet and combining both methods can achieve better results. Our searched
architecture outperforms RoBERTa$_{\rm base}$ by 1.1 and 0.6 scores and
ELECTRA$_{\rm base}$ by 1.6 and 1.1 scores on the dev and test set of GLUE
benchmark. Extensive results on the BERT compression task, SQuAD datasets and
other search spaces also demonstrate the effectiveness and generality of our
proposed methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Extractive and Abstractive Sentence Labelling of Sentiment-bearing Topics. (arXiv:2108.12822v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12822">
<div class="article-summary-box-inner">
<span><p>This paper tackles the problem of automatically labelling sentiment-bearing
topics with descriptive sentence labels. We propose two approaches to the
problem, one extractive and the other abstractive. Both approaches rely on a
novel mechanism to automatically learn the relevance of each sentence in a
corpus to sentiment-bearing topics extracted from that corpus. The extractive
approach uses a sentence ranking algorithm for label selection which for the
first time jointly optimises topic--sentence relevance as well as
aspect--sentiment co-coverage. The abstractive approach instead addresses
aspect--sentiment co-coverage by using sentence fusion to generate a sentential
label that includes relevant content from multiple sentences. To our knowledge,
we are the first to study the problem of labelling sentiment-bearing topics.
Our experimental results on three real-world datasets show that both the
extractive and abstractive approaches outperform four strong baselines in terms
of facilitating topic understanding and interpretation. In addition, when
comparing extractive and abstractive labels, our evaluation shows that our best
performing abstractive method is able to provide more topic information
coverage in fewer words, at the cost of generating less grammatical labels than
the extractive method. We conclude that abstractive methods can effectively
synthesise the rich information contained in sentiment-bearing topics.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Behind the Scenes: An Exploration of Trigger Biases Problem in Few-Shot Event Classification. (arXiv:2108.12844v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12844">
<div class="article-summary-box-inner">
<span><p>Few-Shot Event Classification (FSEC) aims at developing a model for event
prediction, which can generalize to new event types with a limited number of
annotated data. Existing FSEC studies have achieved high accuracy on different
benchmarks. However, we find they suffer from trigger biases that signify the
statistical homogeneity between some trigger words and target event types,
which we summarize as trigger overlapping and trigger separability. The biases
can result in context-bypassing problem, i.e., correct classifications can be
gained by looking at only the trigger words while ignoring the entire context.
Therefore, existing models can be weak in generalizing to unseen data in real
scenarios. To further uncover the trigger biases and assess the generalization
ability of the models, we propose two new sampling methods, Trigger-Uniform
Sampling (TUS) and COnfusion Sampling (COS), for the meta tasks construction
during evaluation. Besides, to cope with the context-bypassing problem in FSEC
models, we introduce adversarial training and trigger reconstruction
techniques. Experiments show these techniques help not only improve the
performance, but also enhance the generalization ability of models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Span Fine-tuning for Pre-trained Language Models. (arXiv:2108.12848v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12848">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PrLM) have to carefully manage input units when
training on a very large text with a vocabulary consisting of millions of
words. Previous works have shown that incorporating span-level information over
consecutive words in pre-training could further improve the performance of
PrLMs. However, given that span-level clues are introduced and fixed in
pre-training, previous methods are time-consuming and lack of flexibility. To
alleviate the inconvenience, this paper presents a novel span fine-tuning
method for PrLMs, which facilitates the span setting to be adaptively
determined by specific downstream tasks during the fine-tuning phase. In
detail, any sentences processed by the PrLM will be segmented into multiple
spans according to a pre-sampled dictionary. Then the segmentation information
will be sent through a hierarchical CNN module together with the representation
outputs of the PrLM and ultimately generate a span-enhanced representation.
Experiments on GLUE benchmark show that the proposed span fine-tuning method
significantly enhances the PrLM, and at the same time, offer more flexibility
in an efficient way.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multiplex Graph Neural Network for Extractive Text Summarization. (arXiv:2108.12870v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12870">
<div class="article-summary-box-inner">
<span><p>Extractive text summarization aims at extracting the most representative
sentences from a given document as its summary. To extract a good summary from
a long text document, sentence embedding plays an important role. Recent
studies have leveraged graph neural networks to capture the inter-sentential
relationship (e.g., the discourse graph) to learn contextual sentence
embedding. However, those approaches neither consider multiple types of
inter-sentential relationships (e.g., semantic similarity &amp; natural
connection), nor model intra-sentential relationships (e.g, semantic &amp;
syntactic relationship among words). To address these problems, we propose a
novel Multiplex Graph Convolutional Network (Multi-GCN) to jointly model
different types of relationships among sentences and words. Based on Multi-GCN,
we propose a Multiplex Graph Summarization (Multi-GraS) model for extractive
text summarization. Finally, we evaluate the proposed models on the
CNN/DailyMail benchmark dataset to demonstrate the effectiveness and
superiority of our method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Investigations on Speech Recognition Systems for Low-Resource Dialectal Arabic-English Code-Switching Speech. (arXiv:2108.12881v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12881">
<div class="article-summary-box-inner">
<span><p>Code-switching (CS), defined as the mixing of languages in conversations, has
become a worldwide phenomenon. The prevalence of CS has been recently met with
a growing demand and interest to build CS ASR systems. In this paper, we
present our work on code-switched Egyptian Arabic-English automatic speech
recognition (ASR). We first contribute in filling the huge gap in resources by
collecting, analyzing and publishing our spontaneous CS Egyptian Arabic-English
speech corpus. We build our ASR systems using DNN-based hybrid and
Transformer-based end-to-end models. In this paper, we present a thorough
comparison between both approaches under the setting of a low-resource,
orthographically unstandardized, and morphologically rich language pair. We
show that while both systems give comparable overall recognition results, each
system provides complementary sets of strength points. We show that recognition
can be improved by combining the outputs of both systems. We propose several
effective system combination approaches, where hypotheses of both systems are
merged on sentence- and word-levels. Our approaches result in overall WER
relative improvement of 4.7%, over a baseline performance of 32.1% WER. In the
case of intra-sentential CS sentences, we achieve WER relative improvement of
4.8%. Our best performing system achieves 30.6% WER on ArzEn test set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Generating Answer Candidates for Quizzes and Answer-Aware Question Generators. (arXiv:2108.12898v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12898">
<div class="article-summary-box-inner">
<span><p>In education, open-ended quiz questions have become an important tool for
assessing the knowledge of students. Yet, manually preparing such questions is
a tedious task, and thus automatic question generation has been proposed as a
possible alternative. So far, the vast majority of research has focused on
generating the question text, relying on question answering datasets with
readily picked answers, and the problem of how to come up with answer
candidates in the first place has been largely ignored. Here, we aim to bridge
this gap. In particular, we propose a model that can generate a specified
number of answer candidates for a given passage of text, which can then be used
by instructors to write questions manually or can be passed as an input to
automatic answer-aware question generators. Our experiments show that our
proposed answer candidate generation model outperforms several baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Grained Chemical Entity Typing with Multimodal Knowledge Representation. (arXiv:2108.12899v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12899">
<div class="article-summary-box-inner">
<span><p>Automated knowledge discovery from trending chemical literature is essential
for more efficient biomedical research. How to extract detailed knowledge about
chemical reactions from the core chemistry literature is a new emerging
challenge that has not been well studied. In this paper, we study the new
problem of fine-grained chemical entity typing, which poses interesting new
challenges especially because of the complex name mentions frequently occurring
in chemistry literature and graphic representation of entities. We introduce a
new benchmark data set (CHEMET) to facilitate the study of the new task and
propose a novel multi-modal representation learning framework to solve the
problem of fine-grained chemical entity typing by leveraging external resources
with chemical structures and using cross-modal attention to learn effective
representation of text in the chemistry domain. Experiment results show that
the proposed framework outperforms multiple state-of-the-art methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mischievous Nominal Constructions in Universal Dependencies. (arXiv:2108.12928v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12928">
<div class="article-summary-box-inner">
<span><p>While the highly multilingual Universal Dependencies (UD) project provides
extensive guidelines for clausal structure as well as structure within
canonical nominal phrases, a standard treatment is lacking for many
"mischievous" nominal phenomena that break the mold. As a result, numerous
inconsistencies within and across corpora can be found, even in languages with
extensive UD treebanking work, such as English. This paper surveys the kinds of
mischievous nominal expressions attested in English UD corpora and proposes
solutions primarily with English in mind, but which may offer paths to
solutions for a variety of UD languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RetroGAN: A Cyclic Post-Specialization System for Improving Out-of-Knowledge and Rare Word Representations. (arXiv:2108.12941v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12941">
<div class="article-summary-box-inner">
<span><p>Retrofitting is a technique used to move word vectors closer together or
further apart in their space to reflect their relationships in a Knowledge Base
(KB). However, retrofitting only works on concepts that are present in that KB.
RetroGAN uses a pair of Generative Adversarial Networks (GANs) to learn a
one-to-one mapping between concepts and their retrofitted counterparts. It
applies that mapping (post-specializes) to handle concepts that do not appear
in the original KB in a manner similar to how some natural language systems
handle out-of-vocabulary entries. We test our system on three word-similarity
benchmarks and a downstream sentence simplification task and achieve the state
of the art (CARD-660). Altogether, our results demonstrate our system's
effectiveness for out-of-knowledge and rare word generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Selective Differential Privacy for Language Modeling. (arXiv:2108.12944v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12944">
<div class="article-summary-box-inner">
<span><p>With the increasing adoption of language models in applications involving
sensitive data, it has become crucial to protect these models from leaking
private information. Previous work has attempted to tackle this challenge by
training RNN-based language models with differential privacy guarantees.
However, applying classical differential privacy to language models leads to
poor model performance as the underlying privacy notion is over-pessimistic and
provides undifferentiated protection for all tokens of the data. Given that the
private information in natural language is sparse (for example, the bulk of an
email might not carry personally identifiable information), we propose a new
privacy notion, selective differential privacy, to provide rigorous privacy
guarantees on the sensitive portion of the data to improve model utility. To
realize such a new notion, we develop a corresponding privacy mechanism,
Selective-DPSGD, for RNN-based language models. Besides language modeling, we
also apply the method to a more concrete application -- dialog systems.
Experiments on both language modeling and dialog system building show that the
proposed privacy-preserving mechanism achieves better utilities while remaining
safe under various privacy attacks compared to the baselines. The data, code
and models are available at https://github.com/wyshi/lm_privacy.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LOT: A Benchmark for Evaluating Chinese Long Text Understanding and Generation. (arXiv:2108.12960v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12960">
<div class="article-summary-box-inner">
<span><p>Standard multi-task benchmarks are essential for driving the progress of
general pretraining models to generalize to various downstream tasks. However,
existing benchmarks such as GLUE and GLGE tend to focus on short text
understanding and generation tasks, without considering long text modeling,
which requires many distinct capabilities such as modeling long-range
commonsense and discourse relations, as well as the coherence and
controllability of generation. The lack of standardized benchmarks makes it
difficult to fully evaluate these capabilities of a model and fairly compare
different models, especially Chinese pretraining models. Therefore, we propose
LOT, a benchmark including two understanding and two generation tasks for
Chinese long text modeling evaluation. We construct the datasets for the tasks
based on various kinds of human-written Chinese stories. Besides, we release an
encoder-decoder Chinese long text pretraining model named LongLM with up to 1
billion parameters. We pretrain LongLM on 120G Chinese novels with two
generative tasks including text infilling and conditional continuation.
Extensive experiments on LOT demonstrate that LongLM matches the performance of
similar-sized pretraining models on the understanding tasks and outperforms
strong baselines substantially on the generation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Scheduled Sampling Based on Decoding Steps for Neural Machine Translation. (arXiv:2108.12963v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12963">
<div class="article-summary-box-inner">
<span><p>Scheduled sampling is widely used to mitigate the exposure bias problem for
neural machine translation. Its core motivation is to simulate the inference
scene during training by replacing ground-truth tokens with predicted tokens,
thus bridging the gap between training and inference. However, vanilla
scheduled sampling is merely based on training steps and equally treats all
decoding steps. Namely, it simulates an inference scene with uniform error
rates, which disobeys the real inference scene, where larger decoding steps
usually have higher error rates due to error accumulations. To alleviate the
above discrepancy, we propose scheduled sampling methods based on decoding
steps, increasing the selection chance of predicted tokens with the growth of
decoding steps. Consequently, we can more realistically simulate the inference
scene during training, thus better bridging the gap between training and
inference. Moreover, we investigate scheduled sampling based on both training
steps and decoding steps for further improvements. Experimentally, our
approaches significantly outperform the Transformer baseline and vanilla
scheduled sampling on three large-scale WMT tasks. Additionally, our approaches
also generalize well to the text summarization task on two popular benchmarks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement Types. (arXiv:2108.12971v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12971">
<div class="article-summary-box-inner">
<span><p>A smart contract is a program executed on a blockchain, based on which many
cryptocurrencies are implemented, and is being used for automating
transactions. Due to the large amount of money that smart contracts deal with,
there is a surging demand for a method that can statically and formally verify
them.
</p>
<p>This article describes our type-based static verification tool HELMHOLTZ for
Michelson, which is a statically typed stack-based language for writing smart
contracts that are executed on the blockchain platform Tezos. HELMHOLTZ is
designed on top of our extension of Michelson's type system with refinement
types. HELMHOLTZ takes a Michelson program annotated with a user-defined
specification written in the form of a refinement type as input; it then
typechecks the program against the specification based on the refinement type
system, discharging the generated verification conditions with the SMT solver
Z3. We briefly introduce our refinement type system for the core calculus
Mini-Michelson of Michelson, which incorporates the characteristic features
such as compound datatypes (e.g., lists and pairs), higher-order functions, and
invocation of another contract. \HELMHOLTZ{} successfully verifies several
practical Michelson programs, including one that transfers money to an account
and that checks a digital signature.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Shatter: An Efficient Transformer Encoder with Single-Headed Self-Attention and Relative Sequence Partitioning. (arXiv:2108.13032v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13032">
<div class="article-summary-box-inner">
<span><p>The highly popular Transformer architecture, based on self-attention, is the
foundation of large pretrained models such as BERT, that have become an
enduring paradigm in NLP. While powerful, the computational resources and time
required to pretrain such models can be prohibitive. In this work, we present
an alternative self-attention architecture, Shatter, that more efficiently
encodes sequence information by softly partitioning the space of relative
positions and applying different value matrices to different parts of the
sequence. This mechanism further allows us to simplify the multi-headed
attention in Transformer to single-headed. We conduct extensive experiments
showing that Shatter achieves better performance than BERT, with pretraining
being faster per step (15% on TPU), converging in fewer steps, and offering
considerable memory savings (&gt;50%). Put together, Shatter can be pretrained on
8 V100 GPUs in 7 days, and match the performance of BERT_Base -- making the
cost of pretraining much more affordable.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ASR-GLUE: A New Multi-task Benchmark for ASR-Robust Natural Language Understanding. (arXiv:2108.13048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13048">
<div class="article-summary-box-inner">
<span><p>Language understanding in speech-based systems have attracted much attention
in recent years with the growing demand for voice interface applications.
However, the robustness of natural language understanding (NLU) systems to
errors introduced by automatic speech recognition (ASR) is under-examined. %To
facilitate the research on ASR-robust general language understanding, In this
paper, we propose ASR-GLUE benchmark, a new collection of 6 different NLU tasks
for evaluating the performance of models under ASR error across 3 different
levels of background noise and 6 speakers with various voice characteristics.
Based on the proposed benchmark, we systematically investigate the effect of
ASR error on NLU tasks in terms of noise intensity, error type and speaker
variants. We further purpose two ways, correction-based method and data
augmentation-based method to improve robustness of the NLU systems. Extensive
experimental results and analysises show that the proposed methods are
effective to some extent, but still far from human performance, demonstrating
that NLU under ASR error is still very challenging and requires further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Base Completion Meets Transfer Learning. (arXiv:2108.13073v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13073">
<div class="article-summary-box-inner">
<span><p>The aim of knowledge base completion is to predict unseen facts from existing
facts in knowledge bases. In this work, we introduce the first approach for
transfer of knowledge from one collection of facts to another without the need
for entity or relation matching. The method works for both canonicalized
knowledge bases and uncanonicalized or open knowledge bases, i.e., knowledge
bases where more than one copy of a real-world entity or relation may exist.
Such knowledge bases are a natural output of automated information extraction
tools that extract structured data from unstructured text. Our main
contribution is a method that can make use of a large-scale pre-training on
facts, collected from unstructured text, to improve predictions on structured
data from a specific domain. The introduced method is the most impactful on
small datasets such as ReVerb20K, where we obtained 6% absolute increase of
mean reciprocal rank and 65% relative decrease of mean rank over the previously
best method, despite not relying on large pre-trained models like BERT.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NEREL: A Russian Dataset with Nested Named Entities and Relations. (arXiv:2108.13112v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13112">
<div class="article-summary-box-inner">
<span><p>In this paper, we present NEREL, a Russian dataset for named entity
recognition and relation extraction. NEREL is significantly larger than
existing Russian datasets: to date it contains 56K annotated named entities and
39K annotated relations. Its important difference from previous datasets is
annotation of nested named entities, as well as relations within nested
entities and at the discourse level. NEREL can facilitate development of novel
models that can extract relations between nested named entities, as well as
relations on both sentence and document levels. NEREL also contains the
annotation of events involving named entities and their roles in the events.
The NEREL collection is available via https://github.com/nerel-ds/NEREL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Factual Consistency Evaluation for Text Summarization via Counterfactual Estimation. (arXiv:2108.13134v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13134">
<div class="article-summary-box-inner">
<span><p>Despite significant progress has been achieved in text summarization, factual
inconsistency in generated summaries still severely limits its practical
applications. Among the key factors to ensure factual consistency, a reliable
automatic evaluation metric is the first and the most crucial one. However,
existing metrics either neglect the intrinsic cause of the factual
inconsistency or rely on auxiliary tasks, leading to an unsatisfied correlation
with human judgments or increasing the inconvenience of usage in practice. In
light of these challenges, we propose a novel metric to evaluate the factual
consistency in text summarization via counterfactual estimation, which
formulates the causal relationship among the source document, the generated
summary, and the language prior. We remove the effect of language prior, which
can cause factual inconsistency, from the total causal effect on the generated
summary, and provides a simple yet effective way to evaluate consistency
without relying on other auxiliary tasks. We conduct a series of experiments on
three public abstractive text summarization datasets, and demonstrate the
advantages of the proposed metric in both improving the correlation with human
judgments and the convenience of usage. The source code is available at
https://github.com/xieyxclack/factual_coco.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neuron-level Interpretation of Deep NLP Models: A Survey. (arXiv:2108.13138v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13138">
<div class="article-summary-box-inner">
<span><p>The proliferation of deep neural networks in various domains has seen an
increased need for interpretability of these methods. A plethora of research
has been carried out to analyze and understand components of the deep neural
network models. Preliminary work done along these lines and papers that
surveyed such, were focused on a more high-level representation analysis.
However, a recent branch of work has concentrated on interpretability at a more
granular level, analyzing neurons and groups of neurons in these large models.
In this paper, we survey work done on fine-grained neuron analysis including:
i) methods developed to discover and understand neurons in a network, ii) their
limitations and evaluation, iii) major findings including cross architectural
comparison that such analyses unravel and iv) direct applications of neuron
analysis such as model behavior control and domain adaptation along with
potential directions for future work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSDS: A Fine-grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13139">
<div class="article-summary-box-inner">
<span><p>Dialogue summarization has drawn much attention recently. Especially in the
customer service domain, agents could use dialogue summaries to help boost
their works by quickly knowing customers' issues and service progress. These
applications require summaries to contain the perspective of a single speaker
and have a clear topic flow structure. Neither are available in existing
datasets. Therefore, in this paper, we introduce a novel Chinese dataset for
Customer Service Dialogue Summarization (CSDS). CSDS improves the abstractive
summaries in two aspects: (1) In addition to the overall summary for the whole
dialogue, role-oriented summaries are also provided to acquire different
speakers' viewpoints. (2) All the summaries sum up each topic separately, thus
containing the topic-level structure of the dialogue. We define tasks in CSDS
as generating the overall summary and different role-oriented summaries for a
given dialogue. Next, we compare various summarization methods on CSDS, and
experiment results show that existing methods are prone to generate redundant
and incoherent summaries. Besides, the performance becomes much worse when
analyzing the performance on role-oriented summaries and topic structures. We
hope that this study could benchmark Chinese dialogue summarization and benefit
further studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Sentiment Analysis Dataset for Trustworthiness Evaluation. (arXiv:2108.13140v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13140">
<div class="article-summary-box-inner">
<span><p>While deep learning models have greatly improved the performance of most
artificial intelligence tasks, they are often criticized to be untrustworthy
due to the black-box problem. Consequently, many works have been proposed to
study the trustworthiness of deep learning. However, as most open datasets are
designed for evaluating the accuracy of model outputs, there is still a lack of
appropriate datasets for evaluating the inner workings of neural networks. The
lack of datasets obviously hinders the development of trustworthiness research.
Therefore, in order to systematically evaluate the factors for building
trustworthy systems, we propose a novel and well-annotated sentiment analysis
dataset to evaluate robustness and interpretability. To evaluate these factors,
our dataset contains diverse annotations about the challenging distribution of
instances, manual adversarial instances and sentiment explanations. Several
evaluation metrics are further proposed for interpretability and robustness.
Based on the dataset and metrics, we conduct comprehensive comparisons for the
trustworthiness of three typical models, and also study the relations between
accuracy, robustness and interpretability. We release this trustworthiness
evaluation dataset at \url{https://github/xyz} and hope our work can facilitate
the progress on building more trustworthy systems for real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners. (arXiv:2108.13161v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13161">
<div class="article-summary-box-inner">
<span><p>Large-scale pre-trained language models have contributed significantly to
natural language processing by demonstrating remarkable abilities as few-shot
learners. However, their effectiveness depends mainly on scaling the model
parameters and prompt design, hindering their implementation in most real-world
applications. This study proposes a novel pluggable, extensible, and efficient
approach named DifferentiAble pRompT (DART), which can convert small language
models into better few-shot learners without any prompt engineering. The main
principle behind this approach involves reformulating potential natural
language processing tasks into the task of a pre-trained language model and
differentially optimizing the prompt template as well as the target label with
backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any
pre-trained language models; (ii) Extended to widespread classification tasks.
A comprehensive evaluation of standard NLP tasks demonstrates that the proposed
approach achieves a better few-shot performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exposure Bias versus Self-Recovery: Are Distortions Really Incremental for Autoregressive Text Generation?. (arXiv:1905.10617v9 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10617">
<div class="article-summary-box-inner">
<span><p>Exposure bias has been regarded as a central problem for auto-regressive
language models (LM). It claims that teacher forcing would cause the test-time
generation to be incrementally distorted due to the training-generation
discrepancy. Although a lot of algorithms have been proposed to avoid teacher
forcing and therefore alleviate exposure bias, there is little work showing how
serious the exposure bias problem actually is. In this work, we focus on the
task of open-ended language generation, propose metrics to quantify the impact
of exposure bias in the aspects of quality, diversity, and consistency. Our key
intuition is that if we feed ground-truth data prefixes (instead of prefixes
generated by the model itself) into the model and ask it to continue the
generation, the performance should become much better because the
training-generation discrepancy in the prefix is removed. Both automatic and
human evaluations are conducted in our experiments. On the contrary to the
popular belief in exposure bias, we find that the the distortion induced by the
prefix discrepancy is limited, and does not seem to be incremental during the
generation. Moreover, our analysis reveals an interesting self-recovery ability
of the LM, which we hypothesize to be countering the harmful effects from
exposure bias.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Keeping it simple: Implementation and performance of the proto-principle of adaptation and learning in the language sciences. (arXiv:2003.03813v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03813">
<div class="article-summary-box-inner">
<span><p>In this paper we present the Widrow-Hoff rule and its applications to
language data. After contextualizing the rule historically and placing it in
the chain of neurally inspired artificial learning models, we explain its
rationale and implementational considerations. Using a number of case studies
we illustrate how the Widrow-Hoff rule offers unexpected opportunities for the
computational simulation of a range of language phenomena that make it possible
to approach old problems from a novel perspective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Zero-Shot Learning with Common Sense Knowledge Graphs. (arXiv:2006.10713v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10713">
<div class="article-summary-box-inner">
<span><p>Zero-shot learning relies on semantic class representations such as
hand-engineered attributes or learned embeddings to predict classes without any
labeled examples. We propose to learn class representations by embedding nodes
from common sense knowledge graphs in a vector space. Common sense knowledge
graphs are an untapped source of explicit high-level knowledge that requires
little human effort to apply to a range of tasks. To capture the knowledge in
the graph, we introduce ZSL-KG, a general-purpose framework with a novel
transformer graph convolutional network (TrGCN) for generating class
representations. Our proposed TrGCN architecture computes non-linear
combinations of node neighbourhoods. Our results show that ZSL-KG improves over
existing WordNet-based methods on five out of six zero-shot benchmark datasets
in language and vision.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Best-First Beam Search. (arXiv:2007.03909v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03909">
<div class="article-summary-box-inner">
<span><p>Decoding for many NLP tasks requires an effective heuristic algorithm for
approximating exact search since the problem of searching the full output space
is often intractable, or impractical in many settings. The default algorithm
for this job is beam search -- a pruned version of breadth-first search. Quite
surprisingly, beam search often returns better results than exact inference due
to beneficial search bias for NLP tasks. In this work, we show that the
standard implementation of beam search can be made up to 10x faster in
practice. Our method assumes that the scoring function is monotonic in the
sequence length, which allows us to safely prune hypotheses that cannot be in
the final set of hypotheses early on. We devise effective monotonic
approximations to popular nonmonontic scoring functions, including length
normalization and mutual information decoding. Lastly, we propose a
memory-reduced variant of Best-First Beam Search, which has a similar
beneficial search bias in terms of downstream performance, but runs in a
fraction of the time.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Audiovisual Speech Synthesis using Tacotron2. (arXiv:2008.00620v2 [eess.AS] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00620">
<div class="article-summary-box-inner">
<span><p>Audiovisual speech synthesis is the problem of synthesizing a talking face
while maximizing the coherency of the acoustic and visual speech. In this
paper, we propose and compare two audiovisual speech synthesis systems for 3D
face models. The first system is the AVTacotron2, which is an end-to-end
text-to-audiovisual speech synthesizer based on the Tacotron2 architecture.
AVTacotron2 converts a sequence of phonemes representing the sentence to
synthesize into a sequence of acoustic features and the corresponding
controllers of a face model. The output acoustic features are used to condition
a WaveRNN to reconstruct the speech waveform, and the output facial controllers
are used to generate the corresponding video of the talking face. The second
audiovisual speech synthesis system is modular, where acoustic speech is
synthesized from text using the traditional Tacotron2. The reconstructed
acoustic speech signal is then used to drive the facial controls of the face
model using an independently trained audio-to-facial-animation neural network.
We further condition both the end-to-end and modular approaches on emotion
embeddings that encode the required prosody to generate emotional audiovisual
speech. We analyze the performance of the two systems and compare them to the
ground truth videos using subjective evaluation tests. The end-to-end and
modular systems are able to synthesize close to human-like audiovisual speech
with mean opinion scores (MOS) of 4.1 and 3.9, respectively, compared to a MOS
of 4.1 for the ground truth generated from professionally recorded videos.
While the end-to-end system gives a better overall quality, the modular
approach is more flexible and the quality of acoustic speech and visual speech
synthesis is almost independent of each other.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rank over Class: The Untapped Potential of Ranking in Natural Language Processing. (arXiv:2009.05160v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05160">
<div class="article-summary-box-inner">
<span><p>Text classification has long been a staple within Natural Language Processing
(NLP) with applications spanning across diverse areas such as sentiment
analysis, recommender systems and spam detection. With such a powerful
solution, it is often tempting to use it as the go-to tool for all NLP problems
since when you are holding a hammer, everything looks like a nail. However, we
argue here that many tasks which are currently addressed using classification
are in fact being shoehorned into a classification mould and that if we instead
address them as a ranking problem, we not only improve the model, but we
achieve better performance. We propose a novel end- to-end ranking approach
consisting of a Transformer network responsible for producing representations
for a pair of text sequences, which are in turn passed into a context
aggregating network outputting ranking scores used to determine an ordering to
the sequences based on some notion of relevance. We perform numerous
experiments on publicly-available datasets and investigate the applications of
ranking in problems often solved using classification. In an experiment on a
heavily-skewed sentiment analysis dataset, converting ranking results to
classification labels yields an approximately 22% improvement over
state-of-the-art text classification, demonstrating the efficacy of text
ranking over text classification in certain scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weight Squeezing: Reparameterization for Knowledge Transfer and Model Compression. (arXiv:2010.06993v3 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06993">
<div class="article-summary-box-inner">
<span><p>In this work, we present a novel approach for simultaneous knowledge transfer
and model compression called Weight Squeezing. With this method, we perform
knowledge transfer from a teacher model by learning the mapping from its
weights to smaller student model weights.
</p>
<p>We applied Weight Squeezing to a pre-trained text classification model based
on BERT-Medium model and compared our method to various other knowledge
transfer and model compression methods on GLUE multitask benchmark. We observed
that our approach produces better results while being significantly faster than
other methods for training student models.
</p>
<p>We also proposed a variant of Weight Squeezing called Gated Weight Squeezing,
for which we combined fine-tuning of BERT-Medium model and learning mapping
from BERT-Base weights. We showed that fine-tuning with Gated Weight Squeezing
outperforms plain fine-tuning of BERT-Medium model as well as other concurrent
SoTA approaches while much being easier to implement.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Topic-Guided Abstractive Text Summarization: a Joint Learning Approach. (arXiv:2010.10323v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10323">
<div class="article-summary-box-inner">
<span><p>We introduce a new approach for abstractive text summarization, Topic-Guided
Abstractive Summarization, which calibrates long-range dependencies from
topic-level features with globally salient content. The idea is to incorporate
neural topic modeling with a Transformer-based sequence-to-sequence (seq2seq)
model in a joint learning framework. This design can learn and preserve the
global semantics of the document, which can provide additional contextual
guidance for capturing important ideas of the document, thereby enhancing the
generation of summary. We conduct extensive experiments on two datasets and the
results show that our proposed model outperforms many extractive and
abstractive systems in terms of both ROUGE measurements and human evaluation.
Our code is available at: https://github.com/chz816/tas.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SlimIPL: Language-Model-Free Iterative Pseudo-Labeling. (arXiv:2010.11524v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11524">
<div class="article-summary-box-inner">
<span><p>Recent results in end-to-end automatic speech recognition have demonstrated
the efficacy of pseudo-labeling for semi-supervised models trained both with
Connectionist Temporal Classification (CTC) and Sequence-to-Sequence (seq2seq)
losses. Iterative Pseudo-Labeling (IPL), which continuously trains a single
model using pseudo-labels iteratively re-generated as the model learns, has
been shown to further improve performance in ASR. We improve upon the IPL
algorithm: as the model learns, we propose to iteratively re-generate
transcriptions with hard labels (the most probable tokens), that is, without a
language model. We call this approach Language-Model-Free IPL (slimIPL) and
give a resultant training setup for low-resource settings with CTC-based
models. slimIPL features a dynamic cache for pseudo-labels which reduces
sensitivity to changes in relabeling hyperparameters and results in improves
training stability. slimIPL is also highly-efficient and requires 3.5-4x fewer
computational resources to converge than other state-of-the-art
semi/self-supervised approaches. With only 10 hours of labeled audio, slimIPL
is competitive with self-supervised approaches, and is state-of-the-art with
100 hours of labeled audio without the use of a language model both at test
time and during pseudo-label generation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BanglaBERT: Combating Embedding Barrier in Multilingual Models for Low-Resource Language Understanding. (arXiv:2101.00204v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00204">
<div class="article-summary-box-inner">
<span><p>In this paper, we introduce ``Embedding Barrier'', a phenomenon that limits
the monolingual performance of multilingual models on low-resource languages
having unique typologies. We build `BanglaBERT', a Bangla language model
pretrained on 18.6 GB Internet-crawled data and benchmark on five standard NLU
tasks. We discover a significant drop in the performance of the
state-of-the-art multilingual model (XLM-R) from BanglaBERT and attribute this
to the Embedding Barrier through comprehensive experiments. We identify that a
multilingual model's performance on a low-resource language is hurt when its
writing script is not similar to any of the high-resource languages. To tackle
the barrier, we propose a straightforward solution by transcribing languages to
a common script, which can effectively improve the performance of a
multilingual model for the Bangla language. As a bi-product of the standard NLU
benchmarks, we introduce a new downstream dataset on natural language inference
(NLI) and show that BanglaBERT outperforms previous state-of-the-art results on
all tasks by up to 3.5%. We are making the BanglaBERT language model and the
new Bangla NLI dataset publicly available in the hope of advancing the
community. The resources can be found at
\url{https://github.com/csebuetnlp/banglabert}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast End-to-End Speech Recognition via Non-Autoregressive Models and Cross-Modal Knowledge Transferring from BERT. (arXiv:2102.07594v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07594">
<div class="article-summary-box-inner">
<span><p>Attention-based encoder-decoder (AED) models have achieved promising
performance in speech recognition. However, because the decoder predicts text
tokens (such as characters or words) in an autoregressive manner, it is
difficult for an AED model to predict all tokens in parallel. This makes the
inference speed relatively slow. We believe that because the encoder already
captures the whole speech utterance, which has the token-level relationship
implicitly, we can predict a token without explicitly autoregressive language
modeling. When the prediction of a token does not rely on other tokens, the
parallel prediction of all tokens in the sequence is realizable. Based on this
idea, we propose a non-autoregressive speech recognition model called LASO
(Listen Attentively, and Spell Once). The model consists of an encoder, a
decoder, and a position dependent summarizer (PDS). The three modules are based
on basic attention blocks. The encoder extracts high-level representations from
the speech. The PDS uses positional encodings corresponding to tokens to
convert the acoustic representations into token-level representations. The
decoder further captures token-level relationships with the self-attention
mechanism. At last, the probability distribution on the vocabulary is computed
for each token position. Therefore, speech recognition is re-formulated as a
position-wise classification problem. Further, we propose a cross-modal
transfer learning method to refine semantics from a large-scale pre-trained
language model BERT for improving the performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A More Fine-Grained Aspect-Sentiment-Opinion Triplet Extraction Task. (arXiv:2103.15255v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15255">
<div class="article-summary-box-inner">
<span><p>Aspect Sentiment Triplet Extraction (ASTE) aims to extract aspect term,
sentiment and opinion term triplets from sentences and tries to provide a
complete solution for aspect-based sentiment analysis (ABSA). However, some
triplets extracted by ASTE are confusing, since the sentiment in a triplet
extracted by ASTE is the sentiment that the sentence expresses toward the
aspect term rather than the sentiment of the aspect term and opinion term pair.
In this paper, we introduce a more fine-grained Aspect-Sentiment-Opinion
Triplet Extraction (ASOTE) Task. ASOTE also extracts aspect term, sentiment and
opinion term triplets. However, the sentiment in a triplet extracted by ASOTE
is the sentiment of the aspect term and opinion term pair. We build four
datasets for ASOTE based on several popular ABSA benchmarks. We propose a
Position-aware BERT-based Framework (PBF) to address this task. PBF first
extracts aspect terms from sentences. For each extracted aspect term, PBF first
generates aspect term-specific sentence representations considering both the
meaning and the position of the aspect term, then extracts associated opinion
terms and predicts the sentiments of the aspect term and opinion term pairs
based on the sentence representations. Experimental results on the four
datasets show the effectiveness of PBF.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Detecting of a Patient's Condition From Clinical Narratives Using Natural Language Representation. (arXiv:2104.03969v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03969">
<div class="article-summary-box-inner">
<span><p>The rapid progress in clinical data management systems and artificial
intelligence approaches enable the era of personalized medicine. Intensive care
units (ICUs) are the ideal clinical research environment for such development
because they collect many clinical data and are highly computerized
environments. We designed a retrospective clinical study on a prospective ICU
database using clinical natural language to help in the early diagnosis of
heart failure in critically ill children. The methodology consisted of
empirical experiments of a learning algorithm to learn the hidden
interpretation and presentation of the French clinical note data. This study
included 1386 patients' clinical notes with 5444 single lines of notes. There
were 1941 positive cases (36 % of total) and 3503 negative cases classified by
two independent physicians using a standardized approach. The multilayer
perceptron neural network outperforms other discriminative and generative
classifiers. Consequently, the proposed framework yields an overall
classification performance with 89 % accuracy, 88 % recall, and 89 % precision.
This study successfully applied learning representation and machine learning
algorithms to detect heart failure from clinical natural language in a single
French institution. Further work is needed to use the same methodology in other
institutions and other languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07650">
<div class="article-summary-box-inner">
<span><p>Recently, prompt-tuning has achieved promising results on some few-shot
classification tasks. The core idea of prompt-tuning is to insert text pieces,
i.e., templates, into the input and transform a classification task into a
masked language modeling problem. However, as for relation extraction,
determining the appropriate prompt template requires domain expertise. Single
label word handcrafted or auto-searched is cumbersome and time-consuming to
verify their effectiveness in non-few-shot scenarios. Further, there exist
abundant semantic knowledge among the entities and relation labels which cannot
be ignored. To this end, we focus on incorporating knowledge into prompt-tuning
for relation extraction and propose a Knowledge-aware prompt-tuning with
synergistic optimization (KNIGHT) approach. Specifically, we inject entity and
relation knowledge into prompt construction with learnable virtual template
words and answer words and jointly optimize their representation with knowledge
constraints. Extensive experimental results on five datasets with standard and
low-resource settings demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cost-effective End-to-end Information Extraction for Semi-structured Document Images. (arXiv:2104.08041v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08041">
<div class="article-summary-box-inner">
<span><p>A real-world information extraction (IE) system for semi-structured document
images often involves a long pipeline of multiple modules, whose complexity
dramatically increases its development and maintenance cost. One can instead
consider an end-to-end model that directly maps the input to the target output
and simplify the entire process. However, such generation approach is known to
lead to unstable performance if not designed carefully. Here we present our
recent effort on transitioning from our existing pipeline-based IE system to an
end-to-end system focusing on practical challenges that are associated with
replacing and deploying the system in real, large-scale production. By
carefully formulating document IE as a sequence generation task, we show that a
single end-to-end IE system can be built and still achieve competent
performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Model Evaluation Beyond Perplexity. (arXiv:2106.00085v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00085">
<div class="article-summary-box-inner">
<span><p>We propose an alternate approach to quantifying how well language models
learn natural language: we ask how well they match the statistical tendencies
of natural language. To answer this question, we analyze whether text generated
from language models exhibits the statistical tendencies present in the
human-generated text on which they were trained. We provide a framework--paired
with significance tests--for evaluating the fit of language models to these
trends. We find that neural language models appear to learn only a subset of
the tendencies considered, but align much more closely with empirical trends
than proposed theoretical distributions (when present). Further, the fit to
different distributions is highly-dependent on both model architecture and
generation strategy. As concrete examples, text generated under the nucleus
sampling scheme adheres more closely to the type--token relationship of natural
language than text produced using standard ancestral sampling; text from LSTMs
reflects the natural language distributions over length, stopwords, and symbols
surprisingly well.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08087">
<div class="article-summary-box-inner">
<span><p>Artificial Intelligence (AI), along with the recent progress in biomedical
language understanding, is gradually changing medical practice. With the
development of biomedical language understanding benchmarks, AI applications
are widely used in the medical field. However, most benchmarks are limited to
English, which makes it challenging to replicate many of the successes in
English for other languages. To facilitate research in this direction, we
collect real-world biomedical data and present the first Chinese Biomedical
Language Understanding Evaluation (CBLUE) benchmark: a collection of natural
language understanding tasks including named entity recognition, information
extraction, clinical diagnosis normalization, single-sentence/sentence-pair
classification, and an associated online platform for model evaluation,
comparison, and analysis. To establish evaluation on these tasks, we report
empirical results with the current 11 pre-trained Chinese models, and
experimental results show that state-of-the-art neural models perform by far
worse than the human ceiling. Our benchmark is released at
\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId=95414&amp;lang=en-us}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RadGraph: Extracting Clinical Entities and Relations from Radiology Reports. (arXiv:2106.14463v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14463">
<div class="article-summary-box-inner">
<span><p>Extracting structured clinical information from free-text radiology reports
can enable the use of radiology report information for a variety of critical
healthcare applications. In our work, we present RadGraph, a dataset of
entities and relations in full-text chest X-ray radiology reports based on a
novel information extraction schema we designed to structure radiology reports.
We release a development dataset, which contains board-certified radiologist
annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579
entities and 10,889 relations), and a test dataset, which contains two
independent sets of board-certified radiologist annotations for 100 radiology
reports split equally across the MIMIC-CXR and CheXpert datasets. Using these
datasets, we train and test a deep learning model, RadGraph Benchmark, that
achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR
and CheXpert test sets respectively. Additionally, we release an inference
dataset, which contains annotations automatically generated by RadGraph
Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4
million relations) and 500 CheXpert reports (13,783 entities and 9,908
relations) with mappings to associated chest radiographs. Our freely available
dataset can facilitate a wide range of research in medical natural language
processing, as well as computer vision and multi-modal learning when linked to
chest radiographs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis. (arXiv:2107.08264v4 [cs.LG] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08264">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis aims to recognize people's attitudes from
multiple communication channels such as verbal content (i.e., text), voice, and
facial expressions. It has become a vibrant and important research topic in
natural language processing. Much research focuses on modeling the complex
intra- and inter-modal interactions between different communication channels.
However, current multimodal models with strong performance are often
deep-learning-based techniques and work like black boxes. It is not clear how
models utilize multimodal information for sentiment predictions. Despite recent
advances in techniques for enhancing the explainability of machine learning
models, they often target unimodal scenarios (e.g., images, sentences), and
little research has been done on explaining multimodal models. In this paper,
we present an interactive visual analytics system, M2Lens, to visualize and
explain multimodal models for sentiment analysis. M2Lens provides explanations
on intra- and inter-modal interactions at the global, subset, and local levels.
Specifically, it summarizes the influence of three typical interaction types
(i.e., dominance, complement, and conflict) on the model predictions. Moreover,
M2Lens identifies frequent and influential multimodal features and supports the
multi-faceted exploration of model behaviors from language, acoustic, and
visual modalities. Through two case studies and expert interviews, we
demonstrate our system can help users gain deep insights into the multimodal
models for sentiment analysis.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link Prediction. (arXiv:2108.02314v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.02314">
<div class="article-summary-box-inner">
<span><p>Enormous hope in the efficacy of vaccines became recently a successful
reality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,
fueled by exposure to social media misinformation about COVID-19 vaccines
became a major hurdle. Therefore, it is essential to automatically detect where
misinformation about COVID-19 vaccines on social media is spread and what kind
of misinformation is discussed, such that inoculation interventions can be
delivered at the right time and in the right place, in addition to
interventions designed to address vaccine hesitancy. This paper is addressing
the first step in tackling hesitancy against COVID-19 vaccines, namely the
automatic detection of known misinformation about the vaccines on Twitter, the
social media platform that has the highest volume of conversations about
COVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged
relevant to several misinformation targets about COVID-19 vaccines on which a
novel method of detecting misinformation was developed. Our method organizes
CoVaxLies in a Misinformation Knowledge Graph as it casts misinformation
detection as a graph link prediction problem. The misinformation detection
method detailed in this paper takes advantage of the link scoring functions
provided by several knowledge embedding methods. The experimental results
demonstrate the superiority of this method when compared with
classification-based methods, widely used currently.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMUS : A Survey of Transformer-based Pretrained Models in Natural Language Processing. (arXiv:2108.05542v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.05542">
<div class="article-summary-box-inner">
<span><p>Transformer-based pretrained language models (T-PTLMs) have achieved great
success in almost every NLP task. The evolution of these models started with
GPT and BERT. These models are built on the top of transformers,
self-supervised learning and transfer learning. Transformed-based PTLMs learn
universal language representations from large volumes of text data using
self-supervised learning and transfer this knowledge to downstream tasks. These
models provide good background knowledge to downstream tasks which avoids
training of downstream models from scratch. In this comprehensive survey paper,
we initially give a brief overview of self-supervised learning. Next, we
explain various core concepts like pretraining, pretraining methods,
pretraining tasks, embeddings and downstream adaptation methods. Next, we
present a new taxonomy of T-PTLMs and then give brief overview of various
benchmarks including both intrinsic and extrinsic. We present a summary of
various useful libraries to work with T-PTLMs. Finally, we highlight some of
the future research directions which will further improve these models. We
strongly believe that this comprehensive survey paper will serve as a good
reference to learn the core concepts as well as to stay updated with the recent
happenings in T-PTLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation. (arXiv:2108.06712v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.06712">
<div class="article-summary-box-inner">
<span><p>Tables are often created with hierarchies, but existing works on table
reasoning mainly focus on flat tables and neglect hierarchical tables.
Hierarchical tables challenge existing methods by hierarchical indexing, as
well as implicit relationships of calculation and semantics. This work presents
HiTab, a free and open dataset to study question answering (QA) and natural
language generation (NLG) over hierarchical tables. HiTab is a cross-domain
dataset constructed from a wealth of statistical reports (analyses) and
Wikipedia pages, and has unique characteristics: (1) nearly all tables are
hierarchical, and (2) both target sentences for NLG and questions for QA are
revised from original, meaningful, and diverse descriptive sentences authored
by analysts and professions of reports. (3) to reveal complex numerical
reasoning in statistical analyses, we provide fine-grained annotations of
entity and quantity alignment. HiTab provides 10,686 QA pairs and descriptive
sentences with well-annotated quantity and entity alignment on 3,597 tables
with broad coverage of table hierarchies and numerical reasoning types.
</p>
<p>Targeting hierarchical structure, we devise a novel hierarchy-aware logical
form for symbolic reasoning over tables, which shows high effectiveness.
Targeting complex numerical reasoning, we propose partially supervised training
given annotations of entity and quantity alignment, which helps models to
largely reduce spurious predictions in the QA task. In the NLG task, we find
that entity and quantity alignment also helps NLG models to generate better
results in a conditional generation setting. Experiment results of
state-of-the-art baselines suggest that this dataset presents a strong
challenge and a valuable benchmark for future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-tuning Pretrained Language Models with Label Attention for Explainable Biomedical Text Classification. (arXiv:2108.11809v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.11809">
<div class="article-summary-box-inner">
<span><p>The massive growth of digital biomedical data is making biomedical text
indexing and classification increasingly important. Accordingly, previous
research has devised numerous deep learning techniques focused on using
feedforward, convolutional or recurrent neural architectures. More recently,
fine-tuned transformers-based pretrained models (PTMs) have demonstrated
superior performance compared to such models in many natural language
processing tasks. However, the direct use of PTMs in the biomedical domain is
only limited to the target documents, ignoring the rich semantic information in
the label descriptions. In this paper, we develop an improved label
attention-based architecture to inject semantic label description into the
fine-tuning process of PTMs. Results on two public medical datasets show that
the proposed fine-tuning scheme outperforms the conventionally fine-tuned PTMs
and prior state-of-the-art models. Furthermore, we show that fine-tuning with
the label attention mechanism is interpretable in the interpretability study.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features are dependent
upon each other. Experiment results on five public datasets show that our model
performs significantly better than previous approaches. The source code can be
found in https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ProtoInfoMax: Prototypical Networks with Mutual Information Maximization for Out-of-Domain Detection. (arXiv:2108.12229v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12229">
<div class="article-summary-box-inner">
<span><p>The ability to detect Out-of-Domain (OOD) inputs has been a critical
requirement in many real-world NLP applications since the inclusion of
unsupported OOD inputs may lead to catastrophic failure of systems. However, it
remains an empirical question whether current algorithms can tackle such
problem reliably in a realistic scenario where zero OOD training data is
available. In this study, we propose ProtoInfoMax, a new architecture that
extends Prototypical Networks to simultaneously process In-Domain (ID) and OOD
sentences via Mutual Information Maximization (InfoMax) objective. Experimental
results show that our proposed method can substantially improve performance up
to 20% for OOD detection in low resource settings of text classification. We
also show that ProtoInfoMax is less prone to typical over-confidence Error of
Neural Networks, leading to more reliable ID and OOD prediction outcomes.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-08-31 01:50:18.375779151 UTC">2021-08-31 01:50:18 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.1</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>