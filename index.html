<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-05T01:53:44.783508817Z">09-05</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">Rust.cc</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">[已解决]使用rocket框架时sqlite出现的问题</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=089f8f06-780e-409a-952e-fa39c2e79dc6">
<div class="article-summary-box-inner">
<span><p>其实应该是diesel的问题
之前sqlite缺少lib我是通过这个博客解决了问题
<a href="https://blog.itdevwu.com/post/915/" rel="noopener noreferrer">解决使用Rust与Sqlite3交互时出现LNK1181错误（Diesel 或 rusqlite）</a>
但是后面的cargo run 阶段又出现了</p>
<pre><code>sqlite3.lib : warning LNK4272:库计算机类型“x86”与目标计算机类型“x64”冲突
          D:\Project\Private\point_plan\target\debug\deps\point_plan.exe : fatal error LNK1120: 60 个无法解析的外部命令
</code></pre>
<p>我明明用的是64位指令编译64位sqlite3.def得到lib的，为啥还会出现这种问题？
麻烦弄过的这方面的朋友指点下</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-04</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=e3c58130-184d-482b-b081-168c54694384">
<div class="article-summary-box-inner">
<span><h3>cURL 中的 Rust</h3>
<p>Allen Wyma 与 cURL 的原作者 Daniel 谈论在 cURL 中使用 Rust。</p>
<ul>
<li>cURL 是一个命令行工具和库，用于通过 URL 传输数据。</li>
<li>cURL 及其数据传输核心 libcurl 都是用 C 编写的，众所周知，这不是内存安全的。</li>
<li>虽然几乎不可能将其重写为另一种语言，但提供一个用 Rust 编写的第三方库可能会更进一步。</li>
</ul>
<p><a href="https://rustacean-station.org/episode/035-daniel-stenberg/" rel="noopener noreferrer">文章链接</a>，https://rustacean-station.org/episode/035-daniel-stenberg/</p>
<h3>NoProto：灵活、快速和紧凑的序列化和rpc</h3>
<ul>
<li>
<p>轻量</p>
<ul>
<li>零依赖</li>
<li>支持no_std，WASM</li>
<li>最紧凑的非编译存储格式</li>
</ul>
</li>
<li>
<p>稳定...</p>
</li>
</ul>
<p><a href="https://github.com/only-cliches/NoProto" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/only-cliches/NoProto</p>
<h3>gradient介绍</h3>
<p>用于玩颜色渐变的命令行工具</p>
<p>Features:</p>
<ul>
<li>许多预设渐变。</li>
<li>自定义渐变。</li>
<li>从 SVG 和 GIMP 渐变 (ggr) 文件中读取渐变
...</li>
</ul>
<p><a href="https://github.com/mazznoer/gradient-rs" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/mazznoer/gradient-rs</p>
<hr>
<p>From 日报小组 <a href="https://rustcc.cn/blog_with_author?author_id=dd4a77ca-2042-459e-901a-b8f9bfeb7db0" rel="noopener noreferrer">TOM</a></p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li>[微信公众号：Rust语言中文社区](https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d88</li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">argh：基于 derive 宏且对二进制体积进行优化的命令行解析工具</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=01a3db1f-b567-47d4-9c3b-08142a11cd3e">
<div class="article-summary-box-inner">
<span><blockquote>
<p>Derive-based argument parsing optimized for code size and conformance to the Fuchsia commandline tools specification.</p>
<p>基于 derive 宏的参数解析工具，针对代码大小进行了优化，并且遵循 Fuchsia 命令行工具规范。</p>
</blockquote>
<p>repo：<a href="https://github.com/google/argh" rel="noopener noreferrer">https://github.com/google/argh</a></p>
<p>由 Google 开发者编写，但并非 Google 官方支持。</p>
<p>官方给的基本例子：</p>
<pre><code>use argh::FromArgs;

#[derive(FromArgs)]
/// Reach new heights.
struct GoUp {
    /// whether or not to jump
    #[argh(switch, short = 'j')]
    jump: bool,

    /// how high to go
    #[argh(option)]
    height: usize,

    /// an optional nickname for the pilot
    #[argh(option)]
    pilot_nickname: Option&lt;String&gt;,
}

fn main() {
    let up: GoUp = argh::from_env();
}
</code></pre>
<pre><code>Usage: cmdname [-j] --height &lt;height&gt; [--pilot-nickname &lt;pilot-nickname&gt;]

Reach new heights.

Options:
  -j, --jump        whether or not to jump
  --height          how high to go
  --pilot-nickname  an optional nickname for the pilot
  --help            display usage information
</code></pre>
<p>过程宏-参数类型：</p>
<ul>
<li><code>switch</code>：用在 bool 类型的字段上，表明命令行参数是可选的，而且一旦提供该命令行参数，则给该字段的值赋给 true 。</li>
<li><code>option</code>：
<ul>
<li>用在 <code>Option</code> 类型上，表明命令行参数是可选的。</li>
<li>用在 <code>Vec</code> 类型上，表明命令行参数可选，而且可以重复出现，即这个参数及其值可以在命令行中出现 0 次或更多次。</li>
<li>用在非 <code>Option</code> 、非 <code>Vec</code> 类型上，则表示命令行参数必选。</li>
</ul>
</li>
<li><code>positional</code>：位置参数，表明按照结构体声明的字段顺序解析命令行参数，无需 <code>--xx value</code> 的 <code>--xx</code> 。最后一个位置参数可以包含默认值，也可以包装在 Option 或 Vec 中来接收可选（指 0 或 1 个）或重复（指 0 或多个）的位置参数。</li>
<li><code>subcommand</code>：需定义一个顶层结构体、一个表示子命令的枚举体（这个枚举体列举所有子命令，子命令以结构体形式呈现，子命令结构体还需要 name 设置名称）</li>
</ul>
<p>过程宏-其他设置：</p>
<ul>
<li><code>short = 'a'</code>：解析 <code>-a</code> 形式的简短参数，只支持 ascii 的 <code>Char</code> 类型，比如大小写、数字。</li>
<li><code>long = "xx-xx"</code>：重新命名这个字段的参数名称，由此可允许参数名称带连字符 <code>--xx-xx</code>。这个设置的默认值为字段名称，只支持 ascii 小写形式的名称，不支持大写和数字。</li>
<li><code>default = "default_height()")</code>、<code>default = "String::from(\"only up\")")</code>：默认值，引号内可以是函数名（带括号）、表达式</li>
<li><code>from_str_fn(always_five)</code>：针对某个解析的参数进行自定义处理，<code>always_five</code> 的函数签名方式为 <code>fn(&amp;str) -&gt; Result&lt;T, String&gt;</code></li>
<li><code>description = "xxxxx"</code>：给参数添加帮助信息。<code>///</code> 文档注释也可以提供用帮助信息，而 <code>description</code> 的内容在命令行帮助信息里会覆盖掉 <code>///</code> 提供的信息。注意：换行和空换行会在 --help 信息里变成一个空格；描述信息不能过长，否则会出现 <code>error: invalid reference to positional arguments 4 and 5 (there is 1 argument</code> （这个报错信息不准确，我也是排查了很久才发现）。</li>
</ul>
<p>trait：</p>
<ul>
<li><code>FromArgs</code> trait：用于 argh 命令行解析的所有结构体和枚举体，都必须 derive 这个 trait 。</li>
<li><code>FromArgValue</code> trait：用于 argh 命令行解析的结构体字段的类型必须实现这个 trait ，argh 已经给所有实现 <code>FromStr</code> trait 的类型实现了这个 trait 。std 的基础类型都实现了 <code>FromStr</code> trait ，所以可以直接使用 std 的基础类型；自定义类型需要实现 <code>FromStr</code> trait 和 <code>FromArgValue</code> trait 。</li>
</ul>
<p>优点：</p>
<ul>
<li>使用简单而直观，上手快，适用于基础的命令行解析场景</li>
<li>生成的体积比 clap 小</li>
<li>依赖少，编译速度快</li>
<li>支持 unicode</li>
</ul>
<p>缺点：</p>
<ul>
<li>终端输出结果非彩色</li>
<li>默认不支持很长的 help 信息；只支持 <code>--help</code> 不支持 <code>-h</code> （但是也带来优点——可以自定义一个字段，short as <code>-h</code>，从而有一份默认简洁的 help info，又有一份完全自定义的 info，比如 <code>#[argh(option, short = 'h')] description: Vec&lt;String&gt;</code> =&gt; <code>cmd -h arg1 arg2</code> 就可以显示 arg1 和 arg2 的说明）</li>
<li>只支持 <code>--option value</code> 和 <code>-o value</code>，不支持 <code>--option=value</code> 和 <code>-ovalue</code></li>
</ul>
<p>其他 args-parser：</p>
<blockquote>
<ul>
<li><a href="https://github.com/blyxxyz/lexopt" rel="noopener noreferrer">lexopt</a>：零依赖、注重正确性的极简 args-parser 。</li>
<li><a href="https://github.com/clap-rs/clap" rel="noopener noreferrer"><code>clap</code></a>/<a href="https://github.com/TeXitoi/structopt" rel="noopener noreferrer"><code>structopt</code></a>: very fully-featured. The only other argument parser for Rust I know of that truly handles invalid unicode properly, if used right. Large.</li>
<li><a href="https://github.com/google/argh" rel="noopener noreferrer"><code>argh</code></a> and <a href="https://github.com/murarth/gumdrop" rel="noopener noreferrer"><code>gumdrop</code></a>: much leaner, yet still convenient and powerful enough for most purposes. Panic on invalid unicode.
<ul>
<li><code>argh</code> adheres to the <a href="https://fuchsia.dev/fuchsia-src/concepts/api/cli#command_line_arguments" rel="noopener noreferrer">Fuchsia specification</a> and therefore does <em>not</em> support <code>--option=value</code> and <code>-ovalue</code>, only <code>--option value</code> and <code>-o value</code>.</li>
</ul>
</li>
<li><a href="https://github.com/RazrFalcon/pico-args" rel="noopener noreferrer"><code>pico-args</code></a>: slightly smaller than lexopt and easier to use (but less rigorous).</li>
<li><a href="https://docs.rs/ap" rel="noopener noreferrer"><code>ap</code></a>: I have not used this, but it seems to support iterative parsing while being less bare-bones than lexopt.</li>
<li>libc's <a href="https://en.wikipedia.org/wiki/Getopt#Examples" rel="noopener noreferrer"><code>getopt</code></a>.</li>
</ul>
<p>src: <a href="https://github.com/blyxxyz/lexopt#see-also" rel="noopener noreferrer">https://github.com/blyxxyz/lexopt#see-also</a></p>
</blockquote>
<p>P.S. 不得不说，Rust 利用抽象的类型系统和宏，在 args-parser 方面太棒了。写 Rust 是一种享受。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">爱死你了，阿克苏姆</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=628500dc-3232-40ff-98f8-03540eaa5d12">
<div class="article-summary-box-inner">
<span><p>最近花了点时间来学习axum, 并成功将一个用warp写的项目改用axum重写。axum太棒了，充分体现了rust这门语言的表达能力。</p>
<ol>
<li>路由设计非常简洁，演示了Rust不用宏，也可以搞DSL的方法。</li>
<li>Extractor与AddExtension极为灵活，简化了warp通过构建参数获取Request与环境数据的设计。</li>
<li>借用Tower生态提高了代码利用率。</li>
</ol>
<p>axum非常稳定，压力测试中同时开15K并发妥妥的。在axum面世之前，warp是最棒的web框架，现在该是阿克苏姆担当主角了。由于两者都是基于hyper平台，从warp移植到axum也是分分钟的事。
下面贴出实战项目中两段代码main.rs与servce.rs。main.rs中演示了如何通过命令行参数切换，实现http与https两种服务，还演示了如何调用了静态文件服务功能。service.rs是放api的地方，演示了如何处理get与post请求，如何获取数据库中的数据，如何提供动态下载内容等功能。</p>
<pre><code>//main.rs
mod addr;
mod base16;
mod bb8_tiberius;
mod ccb_gwk;
mod ccb_socket;
mod config;
mod context;
mod database;
mod json_helper;
mod json_value;
mod parse_exp;
mod parse_param;
mod service;
mod service_da;

use axum::{http::StatusCode, Router};
use tower_http::services::ServeDir;

use std::env::args;

use chrono::prelude::*;
use context::AppContext;
use json_helper::JsonHelper;
use json_value::JsonValue;

const VERSION: &amp;str = "1.3.0";

#[tokio::main]
async fn main() {
    pretty_env_logger::init_timed();

    let is_https = args().nth(1).unwrap_or("http".into()) == "https";

    let context = AppContext::new().await;
    let ctx = context.clone();
    let config = &amp;ctx.config;
    let server_config = &amp;config["config"];
    let ctx = context.clone();
    let app = Router::new()
        .nest(
            "/",
            axum::service::get(ServeDir::new("D:/Js/OnlyOne/public")).handle_error(
                |error: std::io::Error| {
                    Ok::&lt;_, std::convert::Infallible&gt;((
                        StatusCode::INTERNAL_SERVER_ERROR,
                        format!("Unhandled internal error: {}", error),
                    ))
                },
            ),
        )
        .nest("/api", service::api(ctx));

    let addr = addr::Addr::new(server_config, is_https);
    let now = Local::now().to_string();
    let now = &amp;now[0..19];
    println!(
        "{} HTTP{} Server V{} is starting at {:19}, {}",
        server_config["server_name"].string("W3"),
        if is_https { "S" } else { "" },
        VERSION,
        now,
        addr
    );

    let addr = addr.to_string_full();

    if is_https {
        axum_server::bind_rustls(addr)
            .private_key_file("key.pem")
            .certificate_file("cert.pem")
            .serve(app)
            .await
            .unwrap();
    } else {
        axum_server::bind(addr).serve(app).await.unwrap();
    }
}
</code></pre>
<pre><code>//service.rs
use crate::base16;
use crate::ccb_gwk;
use crate::database;
use crate::parse_param;
use crate::service_da::{da_read_about, da_write_about, download_photos, DA_WEBP_DISABLE};
use crate::AppContext;
use crate::JsonHelper;
use crate::JsonValue;
use anyhow::{anyhow, Result};
use encoding::{all::GB18030, EncoderTrap, Encoding};
use serde_json::{json, Value};
use std::collections::HashMap;
use std::sync::Arc;
use tiberius::ToSql;
use tracing::info;

use axum::{
    extract::{Extension, Form, Query},
    response::Json,
    handler::{get, post},
    http::header::{HeaderMap, HeaderName, HeaderValue},
    routing::BoxRoute,
    AddExtensionLayer, Router,
};

fn string_to_gb18030bytes(string: &amp;str) -&gt; Result&lt;Vec&lt;u8&gt;&gt; {
    GB18030
        .encode(string, EncoderTrap::Strict)
        .map_err(|e| anyhow!("string_to_gb18030bytes failure: {:?}", e))
}

pub(crate) fn api(ctx: Arc&lt;AppContext&gt;) -&gt; Router&lt;BoxRoute&gt; {
    Router::new()
        .route("/ask", get(ask))
        .route("/act", post(act))
        .layer(AddExtensionLayer::new(ctx))
        .boxed()
}


pub(crate) async fn ask(
    Query(qs): Query&lt;HashMap&lt;String, String&gt;&gt;,
    Extension(context): Extension&lt;Arc&lt;AppContext&gt;&gt;,
) -&gt; (HeaderMap, Vec&lt;u8&gt;) {
    let mut headers = HeaderMap::new();
    //let qs=format!("{:?}",qs);
    //let bytes=Vec::from(json!({"ask":qs}).to_string());

    let empty = String::from("");
    let dbs = context.dbs.clone();
    let ask = qs.get("ask").unwrap_or(&amp;empty).clone();
    let params = base16::base16_decode(qs.get("params").unwrap_or(&amp;empty)).unwrap();
    let params: Value = serde_json::from_str(&amp;params).unwrap();
    info!("ask={} params={}", ask, params);
    //let content_type = "application/json";
    let p1: JsonValue;
    let p2: JsonValue;
    let p3: JsonValue;
    let p4: JsonValue;
    let p5: JsonValue;
    let pof = |id| JsonValue::of(&amp;params[id]);
    let static_path = context.config["config"]["static_path"].string("wwwroot");
    let da_webp_active = context.config["config"]["da_webp_active"].bool(false);
    let accept_webp = params["acceptWebp"].bool(false);
    let da_webp_quality = if da_webp_active &amp;&amp; accept_webp {
        context.config["config"]["da_webp_quality"].i64(20) as i8
    } else {
        DA_WEBP_DISABLE
    };
    let mut sql: String = "".into();
    let mut sql_params: Vec&lt;&amp;dyn ToSql&gt; = Vec::new();
    let mut pending = true;
    let mut result: String = "null".into();
    let mut about_file: String = "".into();
    let mut voucher_id: &amp;str = &amp;empty;
    let mut attach: String = "".into();

    if ask == "@login" {
        sql = r"EXEC TM_OnlyOneLogin @P1,@P2".into();
        p1 = pof("userId");
        p2 = pof("password");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "workload" {
        sql = "EXEC TM_WorkLoad @P1,@P2,@P3".into();
        p1 = pof("userName");
        p2 = pof("year");
        let more_where = if params["limitMonth"].bool(false) {
            let month_from = params["monthFrom"].i64(1);
            let month_to = params["monthTo"].i64(13);
            let month_to = if month_to &lt; month_from {
                month_from
            } else {
                month_to
            };
            format!(
                " AND z.kjqj BETWEEN '{:02}' AND '{:02}'",
                month_from, month_to
            )
        } else {
            "".to_string()
        };
        //println!("moreWhere:{}",more_where);
        p3 = JsonValue::new(json!(more_where));
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3];
    } else if ask == "wujinFH" {
        sql = "EXEC dbo.TM_UpdateOracleWSZZ4WujinFH @P1,@P2".into();
        p1 = pof("p1");
        p2 = pof("p2");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "salaryVoucher" {
        sql = "EXEC dbo.TM_MakeSalaryVoucher @P1,@P2".into();
        p1 = pof("period");
        p2 = pof("personType");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "salaryVoucherBank" {
        sql = "EXEC dbo.TM_GetSalaryBankDetail @P1,@P2".into();
        p1 = pof("period");
        p2 = pof("personType");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "salaryVoucherSheet" {
        sql = "EXEC dbo.TM_GetSalaryVoucher @P1".into();
        p1 = pof("batch");
        sql_params = vec![&amp;p1];
    } else if ask == "checkncye" {
        sql = "EXEC dbo.TM_CheckNCYE @P1,@P2".into();
        p1 = pof("year");
        p2 = pof("tblname");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "py2code" {
        sql = "EXEC dbo.TM_PY2Code @P1,@P2".into();
        p1 = pof("type");
        p2 = pof("code");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "@aboutvoucher" {
        sql = "EXEC dbo.TM_AboutVoucher @P1".into();
        p1 = pof("pznm");
        sql_params = vec![&amp;p1];
    } else if ask == "@voucherphotos" {
        voucher_id = params["voucherId"].str("");
        match da_read_about(voucher_id, &amp;static_path, da_webp_quality).await {
            Ok((about_file_exists, read_result, about_file_name)) =&gt; {
                about_file = about_file_name;
                if about_file_exists {
                    result = format!("{{\"msg\":\"ok\", \"data\":{}}}", read_result);
                    pending = false;
                }
            }
            Err(e) =&gt; {
                result = format!("{{\"msg\":\"{:?}\"}}", e);
                pending = false;
            }
        }
        if pending {
            sql = "EXEC dbo.TM_VoucherPhotos @P1".into();
            p1 = pof("voucherId");
            sql_params = vec![&amp;p1];
        }
    } else if ask == "@aboutreceipt" {
        sql = "EXEC dbo.TM_AboutReceipt @P1,@P2,@P3,@P4,@P5".into();
        p1 = pof("id");
        p2 = pof("checkSum");
        p3 = pof("datePaid");
        p4 = pof("amount");
        p5 = pof("checker");
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];
    } else if ask == "payee" {
        sql = "EXEC dbo.TM_QueryPayee @P1,@P2".into();
        p1 = pof("bankName");
        p2 = pof("bankAcct");
        sql_params = vec![&amp;p1, &amp;p2];
    } else if ask == "ledger" || ask == "voucher" {
        // CREATE PROCEDURE dbo.TM_QueryLedgerExt
        // @起始年 INT,@终止年 INT,@查询条件 VARCHAR(4096),@排序 VARCHAR(80)='日期,凭证号,笔号',
        // @借贷对冲 BIT=0,@隐藏负值 BIT=0,@Select VARCHAR(250)='*'
        let params = parse_param::params_convert(&amp;context.config, &amp;ask, &amp;params);
        let pof = |id| JsonValue::of(&amp;params[id]);
        let only_sum_line = if ask == "ledger" { ",1" } else { ",0" };
        sql = "EXEC dbo.TM_QueryLedgerExt @P1,@P2,@P3,@P4,0,0,@P5".to_string() + only_sum_line;
        p1 = pof("yearFrom");
        p2 = pof("yearTo");
        p3 = pof("filter");
        p4 = pof("orderby");
        p5 = pof("select");
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];
    } else if ask == "balance" {
        // CREATE PROCEDURE dbo.TM_QueryBalanceExt
        // @起始年 INT,@终止年 INT,@查询条件 VARCHAR(4096),@期初条件 VARCHAR(4096)=NULL,
        // @年初条件 VARCHAR(4096)=NULL,@余额条件 VARCHAR(250)=NULL,
        // @顶层 VARCHAR(10)='科目1级',@底层 VARCHAR(10)='科目4级',
        // @合并 INT=NULL,@合计 BIT=0,@仅底层 BIT=0,@仅编码 BIT=0,@倍率 INT=1,@查项目余额 BIT=0
        let params = parse_param::params_convert(&amp;context.config, &amp;ask, &amp;params);
        let pof = |id| JsonValue::of(&amp;params[id]);
        sql = format!(
            "EXEC dbo.TM_QueryBalanceExt @P1,@P2,@P3,@P4,@P5{}",
            params["params_in_sql"].str("")
        );
        p1 = pof("yearFrom");
        p2 = pof("yearTo");
        p3 = pof("filter");
        p4 = pof("filter_qc");
        p5 = pof("filter_nc");
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];
    }
    if pending {
        let result_json = if !sql.is_empty() {
            let row_is_obj = ask.starts_with('@');
            let result = database::query(dbs, &amp;sql, &amp;sql_params, row_is_obj).await;
            match result {
                Ok(result) =&gt; {
                    if ask == "ledger" {
                        let params =
                            parse_param::params_convert(&amp;context.config, "voucher", &amp;params);
                        json!({ "msg":"ok","voucherColDefs":params["select"], "data":result})
                    } else if ask == "@voucherphotos" {
                        let row_count = result["rowCount"].u64(0);
                        if row_count &gt; 0 {
                            let result = download_photos(context, result, da_webp_quality).await;
                            match da_write_about(&amp;about_file, &amp;result).await {
                                Ok(_) =&gt; json!({ "msg":"ok", "data":result}),
                                Err(e) =&gt; json!({ "msg": format!("{:?}", e) }),
                            }
                        } else {
                            json!({
                                "msg": format!("没有找到凭证{}的影像资料", voucher_id)
                            })
                        }
                    } else if ask == "salaryVoucherSheet" {
                        let empty_vec: Vec&lt;Value&gt; = Vec::new();
                        let sheet = result["rows"].as_array().unwrap_or(&amp;empty_vec);
                        let sheet = sheet
                            .iter()
                            .map(|x| x.get(0).unwrap_or(&amp;Value::Null).string(""))
                            .fold("".to_string(), |lines, line| lines + &amp;line + "\r\n");
                        attach = sheet;
                        json!("attachment")
                    } else {
                        json!({ "msg":"ok", "data":result})
                    }
                }
                Err(err) =&gt; {
                    json!({ "msg": format!("{:?}", err) })
                }
            }
        } else if ask == "checkgwk" {
            let check_all = params["checkAll"].bool(false);
            ccb_gwk::check_gwk(&amp;context.config, check_all)
                .await
                .unwrap()
        } else {
            json!({ "msg": format!("unknown ask {} params:{}", ask, params.to_string()) })
        };
        result = format!("{}", result_json);
    }
    if ask == "salaryVoucherSheet" {
        let file_name = params["fileName"].str("凭证");
        let value = format!("attachment;filename={}.txt", file_name);
        let bytes: Vec&lt;u8&gt; = string_to_gb18030bytes(&amp;attach).unwrap_or_default();
        //reply::with_header(bytes, "Content-disposition", value)
        headers.insert(
            HeaderName::from_static("content-type"),
            HeaderValue::from_static("text/plain"),
        );
        headers.insert(
            HeaderName::from_static("content-disposition"),
            HeaderValue::from_str(&amp;value).unwrap(),
        );
        (headers, bytes)
    } else {
        let bytes: Vec&lt;u8&gt; = result.into_bytes();
        //reply::with_header(bytes, "content-type", content_type)
        headers.insert(
            HeaderName::from_static("content-type"),
            HeaderValue::from_static("application/json"),
        );
        (headers, bytes)
    }
}

async fn act(
    Form(qs): Form&lt;HashMap&lt;String, String&gt;&gt;,
    Extension(context): Extension&lt;Arc&lt;AppContext&gt;&gt;,
) -&gt; Json&lt;Value&gt; {
    let empty = String::from("");
    let dbs = context.dbs.clone();
    let act = qs.get("act").unwrap_or(&amp;empty).clone();
    let params = base16::base16_decode(qs.get("params").unwrap_or(&amp;empty)).unwrap();
    let params: Value = serde_json::from_str(&amp;params).unwrap_or(Value::Null);
    info!("act={} params={}", act, params);
    //let content_type = "application/json";
    let sql: String;
    let p1: JsonValue;
    let p2: JsonValue;
    let p3: JsonValue;
    let p4: JsonValue;
    let p5: JsonValue;
    let sql_params: Vec&lt;&amp;dyn ToSql&gt;;
    let pof = |id| JsonValue::of(&amp;params[id]);
    if act == "exam" {
        sql = r"EXEC dbo.TM_Exam @P1,@P2,@P3,@P4".into();
        p1 = pof("ids");
        p2 = pof("fhr");
        p3 = pof("fhrId");
        p4 = pof("isUndo");
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4];
    } else if act == "changepayee" {
        sql = "EXEC dbo.TM_ChangePayee @P1,@P2,@P3,@P4,@P5".into();
        p1 = pof("bankName");
        p2 = pof("bankAcct");
        p3 = pof("unitCode");
        p4 = pof("updateDate");
        p5 = pof("mark");
        sql_params = vec![&amp;p1, &amp;p2, &amp;p3, &amp;p4, &amp;p5];
    } else if act == "execsql" || act == "@execsql" {
        sql = params["sql"].string("");
        sql_params = Vec::new();
    } else {
        sql = "".into();
        sql_params = Vec::new();
    }
    let result = if !sql.is_empty() {
        let row_is_obj = act.starts_with('@');
        let result = database::query(dbs, &amp;sql, &amp;sql_params, row_is_obj).await;
        match result {
            Ok(result) =&gt; {
                json!({ "msg":"ok", "data":result})
            }
            Err(err) =&gt; {
                json!({ "msg": format!("{:?}", err) })
            }
        }
    } else {
        json!({ "msg": format!("unknown act {} params:{}", act, params.to_string()) })
    };
    Json(result)
}

</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-03 Bebop v2.3.0：为 Bebop 序列化添加 Rust 支持</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=99b9fdf0-4026-4753-a07f-b7355caced95">
<div class="article-summary-box-inner">
<span><h4>Bebop v2.3.0：为 Bebop 序列化添加 Rust 支持</h4>
<p>Bebop 是一种基于模型的二进制序列化技术，类似于 Protocol Buffers 或 MessagePack。特别是，Bebop 试图非常适合需要比 JSON 或 MessagePack 更快、更简洁和类型安全的客户端-服务器或分布式 Web 应用程序。Matthew Conover 2021年8月30日宣布 Bebop 添加了 Rust 的支持</p>
<ul>
<li>https://rainway.com/blog/2021/08/30/bebop-rust/</li>
</ul>
<h4>将 TensorFlow 模型移植到 Rust 的开发成本</h4>
<p>通过 CrowdStrike 的可扩展性，可以立即将 TensorFlow 模型成功转换为纯 Rust 代码，文章介绍了通过这一方法的时间和精力成本</p>
<ul>
<li>https://www.crowdstrike.com/blog/development-cost-of-porting-tensorflow-models-to-pure-rust/</li>
</ul>
<h4>Rust 中的结构更新语法</h4>
<ul>
<li>https://www.reddit.com/r/rust/comments/pchp8h/media_struct_update_syntax_in_rust/</li>
</ul>
<hr>
<p>From 日报小组 北纬27度 侯盛鑫</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rust.cc 论坛: 支持 rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust 语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">bytes::ByteMut 无法写入数据</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=1ab18776-e162-4fbc-80b3-d23bb7402cf3">
<div class="article-summary-box-inner">
<span><p>想用 <a href="https://docs.rs/bytes/1.1.0/bytes/struct.BytesMut.html" rel="noopener noreferrer">ByteMut</a> 作缓冲区，从同步io数据源中读取数据，可是无法读取，也没报错。。。</p>
<pre><code>fn main() -&gt; io::Result&lt;()&gt; {
    let mut buf = BytesMut::with_capacity(10);

    let mut input: Cursor&lt;Vec&lt;u8&gt;&gt; = Cursor::new({
        (0..100).collect()
    });

    loop {
        match input.read(&amp;mut buf)? {
            0 =&gt; {
                println!("[READ OVER]");
                break;
            }
            n =&gt; {
                println!("{:?}", &amp;buf);
                println!("[READ ONCE]");
            }
        }
    }

    Ok(())
}
</code></pre>
<p>如果只用普通的数组，是可以读取数据</p>
<pre><code>let mut buf = [0; 10];
</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">非凸科技 ｜寻找行业内优秀的Rust开发工程师</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=ac57d61f-1742-423a-91db-2cd682843f93">
<div class="article-summary-box-inner">
<span><p>在最近出炉的 Stack Overflow 全球开发者调查报告中，约86.69%的开发人员选择Rust作为他们“最喜爱的语言”。Rust语言虽受好评，但使用群体仍是少数。Rust在系统编程领域很受欢迎，并且近年来被认为将接替C语言用于Linux内核开发，原因之一是Rust可以帮助消除与内存相关的安全漏洞。</p>
<p>非凸科技正成为国内金融市场智能投资交易平台的引领者，潜心打造智能算法交易平台，在原有基础上全面升级到互联网新一代技术架构，结合机器学习等新兴技术，逐步完成各类交易算法的研发迭代，正持续为券商、量化私募等众多大型金融机构提供优质的算法服务。</p>
<p>现阶段，非凸科技正在寻找行业内优秀的Rust开发工程师，薪资福利超级优厚。关键是团队有很好的Rust的开发氛围，Rust大神手把手辅导，助你从Rust新人不断升级。</p>
<p>岗位职责：
1.设计并开发基于RUST的高性能，低时延算法交易系统；
2.设计并开发数据处理平台，监控运维平台；
3.设计并开发面向客户的高可用交易工具等；
4.设计并开发策略相关的回测平台。</p>
<p>岗位要求：
1.本科及以上学历（985优先）。编程基础扎实，具有良好的计算机理论基础；
2.熟练掌握Linux操作，性能分析，具备Rust/C++/Java/Go丰富开发经验，熟悉常用的设计模式，有分布式相关经验加分；
3.有研发高性能，低时延系统经验加分；
4.对技术充满热情，思考深入。自我驱动，能快速学习新鲜事物。</p>
<p>参考薪酬：Base 30K-60K+，有期权激励。
工作地点：上海市漕河泾开发区 凯科国际大厦
投递邮箱：recruit@non-convex.com
联系人微信号：SweeneyTodd333333</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Poem-openapi开源了!</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=334551fe-a8a9-4561-aa63-11987b10e81f">
<div class="article-summary-box-inner">
<span><p>尽管有不少朋友已经知道我这几天在做什么，但当Poem-openapi的第一版准时完成，并且完全按照刚开始的想法正常工作时，我还是按捺不住内心的激动希望跟大家分享。</p>
<p>注意：Poem-openapi只支持Poem，所以你如果希望使用它，Poem是必要的依赖，而且我不会考虑支持其它的web框架。😎</p>
<p>据我所知这是Rust语言里第一个用过程宏来实现OpenAPI规范的库，它的工作方式和<a href="https://crates.io/crates/async-graphql" rel="noopener noreferrer">Async-graphql</a>非常的像，以类型安全的代码来编写符合OpenAPI规范的API并自动生成文档。过程宏的使用完全IDE友好，你绝对不会直接用到过程宏生成的任何代码，避免了IDE满屏幕的红线，或者没法自动完成（我很看重这个，脱离IDE的自动完成我不会写代码）。😂</p>
<p>下面我以一个小例子来介绍它是如何使用的：</p>
<p>这是一个简单的用户管理API实现（别管它有没有什么实际价值，也别告诉我oai这个名字很奇怪，这是官方起的简称，不怪我），我们只看它如何使用。😁</p>
<p>每一个接口都需要定义Request和Response类型，除非它不接收或者返回任何内容。</p>
<p><code>create_user</code>接口创建一个用户，由于它的请求对象类型是Json，所以它只支持<code>content-type</code>为<code>application/json</code>的请求。返回的<code>CreateUserResponse</code>定义了不同状态码对应的响应类型。</p>
<p>所有<code>API</code>宏描述的操作都会自动生成OpenAPI 3.0规范的文档，你可以clone仓库 https://github.com/poem-web/poem-openapi ，然后执行<code>cargo run --example users</code>，浏览器打开<code>http://localhost:3000</code>，就能看到一个非常奢华的Swagger UI（尽管我觉得它离GraphQL Playground的易用度还差得远）。😎</p>
<pre><code>use std::collections::HashMap;

use poem_openapi::{payload::Json, types::Password, OpenAPI, Response, Schema, API};
use tokio::sync::Mutex;

/// Create user schema
#[derive(Debug, Schema, Clone, Eq, PartialEq)]
struct User {
    /// Id
    id: String,
    /// Name
    name: String,
    /// Password
    password: Password,
}

/// Update user schema
#[derive(Debug, Schema, Clone, Eq, PartialEq)]
struct UpdateUser {
    /// Name
    name: Option&lt;String&gt;,
    /// Password
    password: Option&lt;Password&gt;,
}

#[derive(Response)]
enum CreateUserResponse {
    /// Returns when the user is successfully created.
    #[oai(status = 200)]
    Ok,
    /// Returns when the user already exists.
    #[oai(status = 409)]
    UserAlreadyExists,
}

#[derive(Response)]
enum FindUserResponse {
    /// Return the specified user.
    #[oai(status = 200)]
    Ok(Json&lt;User&gt;),
    /// Return when the specified user is not found.
    #[oai(status = 404)]
    NotFound,
}

#[derive(Response)]
enum DeleteUserResponse {
    /// Returns when the user is successfully deleted.
    #[oai(status = 200)]
    Ok,
    /// Return when the specified user is not found.
    #[oai(status = 404)]
    NotFound,
}

#[derive(Response)]
enum UpdateUserResponse {
    /// Returns when the user is successfully updated.
    #[oai(status = 200)]
    Ok,
    /// Return when the specified user is not found.
    #[oai(status = 404)]
    NotFound,
}

#[derive(Default)]
struct Api {
    users: Mutex&lt;HashMap&lt;String, User&gt;&gt;,
}

#[API]
impl Api {
    /// Create a new user
    #[oai(path = "/users", method = "post", tag = "user")]
    async fn create_user(&amp;self, user: Json&lt;User&gt;) -&gt; CreateUserResponse {
        let mut users = self.users.lock().await;
        if users.contains_key(&amp;user.0.id) {
            return CreateUserResponse::UserAlreadyExists;
        }
        users.insert(user.0.id.clone(), user.0);
        CreateUserResponse::Ok
    }

    /// Find user by id
    #[oai(path = "/users/:user_id", method = "get", tag = "user")]
    async fn find_user(
        &amp;self,
        #[oai(name = "user_id", in = "path")] user_id: String,
    ) -&gt; FindUserResponse {
        let users = self.users.lock().await;
        match users.get(&amp;user_id) {
            Some(user) =&gt; FindUserResponse::Ok(Json(user.clone())),
            None =&gt; FindUserResponse::NotFound,
        }
    }

    /// Delete user by id
    #[oai(path = "/users/:user_id", method = "delete", tag = "user")]
    async fn delete_user(
        &amp;self,
        #[oai(name = "user_id", in = "path")] user_id: String,
    ) -&gt; DeleteUserResponse {
        let mut users = self.users.lock().await;
        match users.remove(&amp;user_id) {
            Some(_) =&gt; DeleteUserResponse::Ok,
            None =&gt; DeleteUserResponse::NotFound,
        }
    }

    /// Update user by id
    #[oai(path = "/users/:user_id", method = "put", tag = "user")]
    async fn put_user(
        &amp;self,
        #[oai(name = "user_id", in = "path")] user_id: String,
        update: Json&lt;UpdateUser&gt;,
    ) -&gt; UpdateUserResponse {
        let mut users = self.users.lock().await;
        match users.get_mut(&amp;user_id) {
            Some(user) =&gt; {
                if let Some(name) = update.0.name {
                    user.name = name;
                }
                if let Some(password) = update.0.password {
                    user.password = password;
                }
                UpdateUserResponse::Ok
            }
            None =&gt; UpdateUserResponse::NotFound,
        }
    }
}

#[tokio::main]
async fn main() {
    poem::Server::bind("127.0.0.1:3000")
        .await
        .unwrap()
        .run(
            OpenAPI::new(Api::default())
                .title("poem-openapi")
                .version("0.1.0")
                .server_with_description("http://localhost:3000", "localhost")
                .tag_with_description("user", "Operations about user")
                .ui_path("/"),
        )
        .await
        .unwrap();
}

</code></pre>
<p>要完全支持Open API规范中定义的特性还有不少功能要做，比如JsonSchema的所有校验器，认证，权限等等，如果你觉得这个库有用，并且希望能够为它贡献自己的力量，我非常欢迎！😁</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-02 pixels 0.6.0 发布</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=069ce86c-0ff8-4ded-9367-3a19651144fe">
<div class="article-summary-box-inner">
<span><h3>pilka - 用 Rust 写成跨平台实时编码工具</h3>
<p>Pilka是一种用于创建着色器（shader）演示的跨平台实时编码工具，类似于 Bonzomatic 或 KodeLife 。支持热重载，能够在后台检查和更新资源。</p>
<p><a href="https://github.com/pudnax/pilka" rel="noopener noreferrer">GitHub</a>: https://github.com/pudnax/pilka</p>
<h3>ritecahce - 简单易用的 memory/disk cache</h3>
<p>ritecache 是在流行的 sccache/lru_disk_cache 基础上派生出的内存/磁盘缓存。默认提供 <code>LruCache</code> 和 <code>LruDiskCache</code>，也支持开发者通过实现 <code>Cache</code> 特质来支持基于其他策略的内存/磁盘缓存。</p>
<p>同时，得益于 ritelinked 的支持，性能优于基于 linked-hash-map 的版本。</p>
<p><a href="https://github.com/ritelabs/ritecache" rel="noopener noreferrer">GitHub</a>: https://github.com/ritelabs/ritecache</p>
<p><a href="https://crates.io/crates/ritecache" rel="noopener noreferrer">Crates.io</a>: https://crates.io/crates/ritecache</p>
<h3>hebi - 由 Bevy 引擎驱动的贪吃蛇游戏</h3>
<p>hebi 是一个高度可定制的贪吃蛇游戏复刻，使用 Rust 写就，由 Bevy 引擎驱动，命名源于日语中的“蛇”。</p>
<p><a href="https://github.com/ElnuDev/hebi" rel="noopener noreferrer">GitHub</a>: https://github.com/ElnuDev/hebi</p>
<h3>pixels 0.6.0 发布</h3>
<p>pixels 是用于简单软件侧光栅化的板条箱。它可以提供一个像素缓冲区，用于插入颜色（在 CPU 端完成）。缓冲区作为纹理上载到GPU，所有缩放和剪裁都由默认着色器处理。对于其他控件，可以添加自己的自定义着色器以进行预处理和后处理。</p>
<p><a href="https://github.com/parasyte/pixels" rel="noopener noreferrer">GitHub</a>: https://github.com/parasyte/pixels</p>
<p><a href="https://crates.io/crates/pixels" rel="noopener noreferrer">Crates.io</a>: https://crates.io/crates/pixels</p>
<h3>This Week in Datafuse 5</h3>
<p>Datafuse 发布了第 5 期周报，感兴趣的朋友们可以关注 Datafuse 的最新进展。</p>
<p>Datafuse 是一个开源、易用、便于扩展的云数仓，查询速度极快，并结合云的弹性、简单性和低成本，帮助用户轻松享受下一代数据云。</p>
<p><a href="https://github.com/datafuselabs/datafuse" rel="noopener noreferrer">Datafuse</a>: https://github.com/datafuselabs/datafuse</p>
<p><a href="https://datafuselabs.github.io/weekly/2021-09-01-datafuse-weekly/" rel="noopener noreferrer">This Week in Datafuse 5</a>: https://datafuselabs.github.io/weekly/2021-09-01-datafuse-weekly/</p>
<hr>
<p>From 日报小组 <a href="https://github.com/PsiACE" rel="noopener noreferrer">PsiACE</a></p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rust.cc 论坛: 支持 rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust 语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RustDesk寻找第一位员工，国内或者是新加坡由你决定</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=ae7f2822-173b-45ba-9013-e5cb4e286810">
<div class="article-summary-box-inner">
<span><p>rustcc.cn见证了RustDesk一路的成长，在此接受了很多的鼓励，我受益匪浅。虽然一直都是一个人战斗，可却时刻期盼着优秀的你加入。虽然公司实体还没有注册完成，但是RustDesk已经收获两家投资机构的投资意向，一家国内，一家国外，总共超过千万人民币。如果你也像投资人一样看好RustDesk这个项目，能够理解他的未来发展潜力，请邮件联系我，并附上你的简历。谢谢，期盼我们一起成长。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>
<p><strong>课程时间:</strong> 2021年9月5日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识, Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>
<h3>课程大纲</h3>
<p>1、回顾 Rust 异步编程模型.</p>
<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>
<p>3、Tokio 介绍.</p>
<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>
<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/
Rust 异步编程入门 Future Part 1 回放地址：
https://www.bilibili.com/video/BV1mf4y1N7MJ/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课：《 Rust 异步编程入门 Future 》|Vol. 5</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>
<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是 Rust 异步编程的核心基础。</p>
<h3>课程大纲</h3>
<p>1、为什么需要异步.</p>
<p>2、理解异步编程模型.</p>
<p>3、Future 编程模型讲解.</p>
<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c">
<div class="article-summary-box-inner">
<span><h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>
<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>
<p>ReadMore:<a href="https://twitter.com/m_ou_se/status/1427666611977297924" rel="noopener noreferrer">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>
<h3>异步引擎 C++20, Rust &amp; Zig</h3>
<p>ReadMore:<a href="https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/" rel="noopener noreferrer">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>
<h3>RG3D -- Rust 3D 游戏引擎</h3>
<ul>
<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>
<li><strong>延迟着色</strong></li>
<li><strong>内置保存/加载</strong></li>
<li><strong>独立场景编辑器</strong></li>
<li><strong>高级物理模型</strong></li>
<li><strong>分层模型资源</strong></li>
<li><strong>几何实例化</strong></li>
</ul>
<p>ReadMore:<a href="https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/" rel="noopener noreferrer">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>
<p>ReadMore:<a href="https://github.com/rg3dengine/rg3d" rel="noopener noreferrer">https://github.com/rg3dengine/rg3d</a></p>
<hr>
<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8">
<div class="article-summary-box-inner">
<span><p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>
<p><strong>课程时间：</strong> 2021年8月22日 20:30-21:30</p>
<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>
<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>
<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>
<h3>课程大纲</h3>
<ol>
<li>
<p>什么是分布式追踪系统OpenTracing及应用场景</p>
</li>
<li>
<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>
</li>
<li>
<p>为什么需要tokio-rs/tracing库</p>
</li>
<li>
<p>演示Datafuse项目中tokio-rs/tracing的使用</p>
</li>
</ol>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">论坛github账户无法登录解决笔记</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190">
<div class="article-summary-box-inner">
<span><p>有反映这两天github账户无法登录了。</p>
<p>报这个错：</p>
<pre><code>get github user info err
</code></pre>
<p>查了几个地方：</p>
<ol>
<li>代码是否运行正常：Ok</li>
<li>https代理是否正常：Ok</li>
<li>检查了github返回日志，发现是：</li>
</ol>
<pre><code>get_github_user_info: response body: "{\"message\":\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\",\"documentation_url\":\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\"}"
get_github_user_info: Got: Err(Custom("read json login error"))
</code></pre>
<p>进入这个地址一看：<a href="https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/" rel="noopener noreferrer">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>
<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>
<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>
<p>特此记录。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 的 Future 与 Javascript 的 Promise 功能对照参考</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095">
<div class="article-summary-box-inner">
<span><h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>
<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>
<blockquote>
<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>
</blockquote>
<table>
<thead>
<tr>
<th>javascript</th>
<th align="center">rust</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Promise.resolve(...)</td>
<td align="center">use ::async_std::future;future::ready(Ok(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.reject(...)</td>
<td align="center">use ::async_std::future;future::ready(Err(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.catch(err =&gt; err)</td>
<td align="center">use ::async_std::future;future::ready(...)</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>new Promise(() =&gt; {/* 什么都不做 */})</td>
<td align="center">use ::async_std::future;future::pending()</td>
<td align="center"></td>
</tr>
<tr>
<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; { if (Math.random() &gt; .5) { resolve(1); } else { reject(new Error('1')); }}, 500))</td>
<td align="center">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| { thread::sleep(Duration::from_millis(500)); let mut rng = rand::thread_rng(); if rng.gen() &gt; 0.5f64 { Ok(1) } else { Err('1') }}).await;</td>
<td align="center">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被 （1）跨线程传递 （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>
</tr>
<tr>
<td>Promise.all([promise1, promise2, promise3])</td>
<td align="center">future1.try_join(future2).try_join(future3).await</td>
<td align="center">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>
</tr>
<tr>
<td>Promise.all([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.join(future2).join(future3).await</td>
<td align="center">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>
</tr>
<tr>
<td>Promise.race([promise1, promise2, promise3])</td>
<td align="center">future1.try_race(future2).try_race(future3).await</td>
<td align="center">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>
</tr>
<tr>
<td>Promise.race([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.race(future2).race(future3).await</td>
<td align="center">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>
</tr>
</tbody>
</table>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：《通过实战理解 Rust 宏》| Vol. 3</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>
<p><strong>课程时间：</strong> 2021年8月15日 20:30-21:30</p>
<p><strong>课程介绍：</strong></p>
<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg" alt></p>
<p>这就是通过宏实现配置的统一行为，代码参考：
https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>
<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>
<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>
<h3>课程大纲</h3>
<ul>
<li>什么是 Rust 宏</li>
<li>什么是宏运行原理</li>
<li>如何创建 Rust 宏过程</li>
<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>
</ul>
<p><strong>讲师介绍</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：理解Rust的所有权| Vol 2</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：《理解Rust所有权》</strong></p>
<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>
<p><strong>嘉宾讲师： 苏林</strong></p>
<p><strong>嘉宾介绍：</strong></p>
<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>
<p><strong>课程介绍</strong></p>
<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>
<p><strong>参加课程</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg" alt></p>
<p><strong>课程规划</strong></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">数据表 Timestamp 日期 Serialize</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2ff8a69e-59bb-4502-87c0-c3416ffae8a0">
<div class="article-summary-box-inner">
<span><p>主要参考：<a href="https://github.com/rustcc/forustm" rel="noopener noreferrer">Rustcc网站源码库</a></p>
<p>在处理数据表中日期相关数据时，Seralize序列化相关操作会报错，提示 DateTime 字段不识别，
查了 rustcc 源码才发现依赖中需要开启相应的feature。特此记录。</p>
<h2>1.依赖的库：</h2>
<pre><code>[dependencies]
# 日期时间处理 需要开启 serde 特征 支持序列化
chrono = { version = "0.4.19", features = ["serde"] }

# 数据库ORM
diesel = { version = "1.4.4", features = ["postgres", "chrono", "uuid", "r2d2"] }
dotenv = "0.15.0"
serde = { version = "1.0.127", features = ["derive"] }
serde_json = "1.0.66"
uuid = { version = "0.8.2", features = ["serde", "v4"] }
</code></pre>
<h2>2.创建数据表</h2>
<pre><code>CREATE TABLE characters (
    id SERIAL PRIMARY KEY,
    name VARCHAR(128) UNIQUE NOT NULL,
    age INTEGER NOT NULL DEFAULT 0,
    friends VARCHAR NOT NULL DEFAULT '',
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP
)
</code></pre>
<h2>3.数据表对应的 model</h2>
<pre><code>use chrono::{NaiveDateTime};
use serde::{Deserialize, Serialize};

#[derive(Queryable, Serialize, Deserialize, Debug)]
pub struct Characters {
    pub id: i32,
    pub name: String,
    pub age: i32,
    pub friends: String,
    // 这里的 NaiveDateTime 日期格式序列化需要开启相关 features
    pub created_at: NaiveDateTime,
}
</code></pre>
<h2>4.获取数据</h2>
<pre><code>use db::schema::characters;
use db::{get_connection};
use db::models::{Characters, NewCharacter};
use db::schema::characters::dsl::*;
use diesel::QueryDsl;
use diesel::prelude::*;

fn main() {
    let conn = get_connection();

    // 查询年龄大于30的10条数据
    let arr: Vec&lt;Characters&gt; = characters.filter(characters::age.gt(30))
        .limit(10)
        .load::&lt;Characters&gt;(&amp;conn)
        .expect("Loading Error");

    let date_arr = arr.iter()
        .map(|item| {
	    // 数据格式化
            let t = item.created_at.format("%Y-%m-%d %H:%M:%S").to_string();
            println!("{} {}", item.name, t);
            t
        })
        .collect::&lt;Vec&lt;String&gt;&gt;();
}
</code></pre>
<p>输出结果类似：</p>
<pre><code>Box 2021-08-05 09:39:34
Bobe 2021-08-05 09:39:34
</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cargo workspace config</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=c3dcce30-1fc0-4819-8992-142365c7e21c">
<div class="article-summary-box-inner">
<span><p><a href="https://kaisery.github.io/trpl-zh-cn/ch14-03-cargo-workspaces.html" rel="noopener noreferrer">Workspace 文档链接</a></p>
<h2>目录结构</h2>
<pre><code>workspace-test/
    Cargo.toml
    db/
        src/
            bin/
                init.rs
        Cargo.tml
</code></pre>
<h2>workspace</h2>
<p>workspace-test/Cargo.toml</p>
<pre><code>[workspace]
members = ["db"]
default-member = "db"
</code></pre>
<h2>子项目</h2>
<p>workspace-test/db/Cargo.toml</p>
<pre><code>[package]
name = "db"
version = "0.1.0"
edition = "2018"

[dependencies]

# 可选的可执行文件配置
# [[bin]]
# name = "init"
# path = "src/bin/init.rs"
</code></pre>
<h2>操作</h2>
<pre><code># 运行 init
cargo run --bin init
# -p 指定项目
cargo run -p db --bin init
</code></pre>
</span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-03T01:30:00Z">09-03</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Don't Discard All the Biased Instances: Investigating a Core Assumption in Dataset Bias Mitigation Techniques. (arXiv:2109.00521v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00521">
<div class="article-summary-box-inner">
<span><p>Existing techniques for mitigating dataset bias often leverage a biased model
to identify biased instances. The role of these biased instances is then
reduced during the training of the main model to enhance its robustness to
out-of-distribution data. A common core assumption of these techniques is that
the main model handles biased instances similarly to the biased model, in that
it will resort to biases whenever available. In this paper, we show that this
assumption does not hold in general. We carry out a critical investigation on
two well-known datasets in the domain, MNLI and FEVER, along with two biased
instance detection methods, partial-input and limited-capacity models. Our
experiments show that in around a third to a half of instances, the biased
model is unable to predict the main model's behavior, highlighted by the
significantly different parts of the input on which they base their decisions.
Based on a manual validation, we also show that this estimate is highly in line
with human interpretation. Our findings suggest that down-weighting of
instances detected by bias detection methods, which is a widely-practiced
procedure, is an unnecessary waste of training data. We release our code to
facilitate reproducibility and future research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Text AutoAugment: Learning Compositional Augmentation Policy for Text Classification. (arXiv:2109.00523v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00523">
<div class="article-summary-box-inner">
<span><p>Data augmentation aims to enrich training samples for alleviating the
overfitting issue in low-resource or class-imbalanced situations. Traditional
methods first devise task-specific operations such as Synonym Substitute, then
preset the corresponding parameters such as the substitution rate artificially,
which require a lot of prior knowledge and are prone to fall into the
sub-optimum. Besides, the number of editing operations is limited in the
previous methods, which decreases the diversity of the augmented data and thus
restricts the performance gain. To overcome the above limitations, we propose a
framework named Text AutoAugment (TAA) to establish a compositional and
learnable paradigm for data augmentation. We regard a combination of various
operations as an augmentation policy and utilize an efficient Bayesian
Optimization algorithm to automatically search for the best policy, which
substantially improves the generalization capability of models. Experiments on
six benchmark datasets show that TAA boosts classification accuracy in
low-resource and class-imbalanced regimes by an average of 8.8% and 9.7%,
respectively, outperforming strong baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00527">
<div class="article-summary-box-inner">
<span><p>Can machines learn to use a search engine as an interactive tool for finding
information? That would have far reaching consequences for making the world's
knowledge more accessible. This paper presents first steps in designing agents
that learn meta-strategies for contextual query refinements. Our approach uses
machine reading to guide the selection of refinement terms from aggregated
search results. Agents are then empowered with simple but effective search
operators to exert fine-grained and transparent control over queries and search
results. We develop a novel way of generating synthetic search sessions, which
leverages the power of transformer-based generative language models through
(self-)supervised learning. We also present a reinforcement learning agent with
dynamically constrained actions that can learn interactive search strategies
completely from scratch. In both cases, we obtain significant improvements over
one-shot search with a strong information retrieval baseline. Finally, we
provide an in-depth analysis of the learned search policies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Improving Adversarial Training of NLP Models. (arXiv:2109.00544v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00544">
<div class="article-summary-box-inner">
<span><p>Adversarial training, a method for learning robust deep neural networks,
constructs adversarial examples during training. However, recent methods for
generating NLP adversarial examples involve combinatorial search and expensive
sentence encoders for constraining the generated instances. As a result, it
remains challenging to use vanilla adversarial training to improve NLP models'
performance, and the benefits are mainly uninvestigated. This paper proposes a
simple and improved vanilla adversarial training process for NLP, which we name
Attacking to Training ($\texttt{A2T}$). The core part of $\texttt{A2T}$ is a
new and cheaper word substitution attack optimized for vanilla adversarial
training. We use $\texttt{A2T}$ to train BERT and RoBERTa models on IMDB,
Rotten Tomatoes, Yelp, and SNLI datasets. Our results show that it is possible
to train empirically robust NLP models using a much cheaper adversary. We
demonstrate that vanilla adversarial training with $\texttt{A2T}$ can improve
an NLP model's robustness to the attack it was originally trained with and also
defend the model against other types of attacks. Furthermore, we show that
$\texttt{A2T}$ can improve NLP models' standard accuracy, cross-domain
generalization, and interpretability. Code is available at
<a href="http://github.com/jinyongyoo/A2T">this http URL</a> .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Knowledge Help General NLU? An Empirical Study. (arXiv:2109.00563v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00563">
<div class="article-summary-box-inner">
<span><p>It is often observed in knowledge-centric tasks (e.g., common sense question
and answering, relation classification) that the integration of external
knowledge such as entity representation into language models can help provide
useful information to boost the performance. However, it is still unclear
whether this benefit can extend to general natural language understanding (NLU)
tasks. In this work, we empirically investigated the contribution of external
knowledge by measuring the end-to-end performance of language models with
various knowledge integration methods. We find that the introduction of
knowledge can significantly improve the results on certain tasks while having
no adverse effects on other tasks. We then employ mutual information to reflect
the difference brought by knowledge and a neural interpretation model to reveal
how a language model utilizes external knowledge. Our study provides valuable
insights and guidance for practitioners to equip NLP models with knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">DILBERT: Customized Pre-Training for Domain Adaptation withCategory Shift, with an Application to Aspect Extraction. (arXiv:2109.00571v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00571">
<div class="article-summary-box-inner">
<span><p>The rise of pre-trained language models has yielded substantial progress in
the vast majority of Natural Language Processing (NLP) tasks. However, a
generic approach towards the pre-training procedure can naturally be
sub-optimal in some cases. Particularly, fine-tuning a pre-trained language
model on a source domain and then applying it to a different target domain,
results in a sharp performance decline of the eventual classifier for many
source-target domain pairs. Moreover, in some NLP tasks, the output categories
substantially differ between domains, making adaptation even more challenging.
This, for example, happens in the task of aspect extraction, where the aspects
of interest of reviews of, e.g., restaurants or electronic devices may be very
different. This paper presents a new fine-tuning scheme for BERT, which aims to
address the above challenges. We name this scheme DILBERT: Domain Invariant
Learning with BERT, and customize it for aspect extraction in the unsupervised
domain adaptation setting. DILBERT harnesses the categorical information of
both the source and the target domains to guide the pre-training process
towards a more domain and category invariant representation, thus closing the
gap between the domains. We show that DILBERT yields substantial improvements
over state-of-the-art baselines while using a fraction of the unlabeled data,
particularly in more challenging domain adaptation setups.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQA: Multihop and Multimodal QA. (arXiv:2109.00590v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00590">
<div class="article-summary-box-inner">
<span><p>Web search is fundamentally multimodal and multihop. Often, even before
asking a question we choose to go directly to image search to find our answers.
Further, rarely do we find an answer from a single source but aggregate
information and reason through implications. Despite the frequency of this
everyday occurrence, at present, there is no unified question answering
benchmark that requires a single model to answer long-form natural language
questions from text and open-ended visual sources -- akin to a human's
experience. We propose to bridge this gap between the natural language and
computer vision communities with WebQA. We show that A. our multihop text
queries are difficult for a large-scale transformer model, and B. existing
multi-modal transformers and visual representations do not perform well on
open-domain visual queries. Our challenge for the community is to create a
unified multimodal reasoning model that seamlessly transitions and reasons
regardless of the source modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fight Fire with Fire: Fine-tuning Hate Detectors using Large Samples of Generated Hate Speech. (arXiv:2109.00591v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00591">
<div class="article-summary-box-inner">
<span><p>Automatic hate speech detection is hampered by the scarcity of labeled
datasetd, leading to poor generalization. We employ pretrained language models
(LMs) to alleviate this data bottleneck. We utilize the GPT LM for generating
large amounts of synthetic hate speech sequences from available labeled
examples, and leverage the generated data in fine-tuning large pretrained LMs
on hate detection. An empirical study using the models of BERT, RoBERTa and
ALBERT, shows that this approach improves generalization significantly and
consistently within and across data distributions. In fact, we find that
generating relevant labeled hate speech sequences is preferable to using
out-of-domain, and sometimes also within-domain, human-labeled examples.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latin writing styles analysis with Machine Learning: New approach to old questions. (arXiv:2109.00601v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00601">
<div class="article-summary-box-inner">
<span><p>In the Middle Ages texts were learned by heart and spread using oral means of
communication from generation to generation. Adaptation of the art of prose and
poems allowed keeping particular descriptions and compositions characteristic
for many literary genres. Taking into account such a specific construction of
literature composed in Latin, we can search for and indicate the probability
patterns of familiar sources of specific narrative texts. Consideration of
Natural Language Processing tools allowed us the transformation of textual
objects into numerical ones and then application of machine learning algorithms
to extract information from the dataset. We carried out the task consisting of
the practical use of those concepts and observation to create a tool for
analyzing narrative texts basing on open-source databases. The tool focused on
creating specific search tools resources which could enable us detailed
searching throughout the text. The main objectives of the study take into
account finding similarities between sentences and between documents. Next, we
applied machine learning algorithms on chosen texts to calculate specific
features of them (for instance authorship or centuries) and to recognize
sources of anonymous texts with a certain percentage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Point-of-Interest Type Prediction using Text and Images. (arXiv:2109.00602v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00602">
<div class="article-summary-box-inner">
<span><p>Point-of-interest (POI) type prediction is the task of inferring the type of
a place from where a social media post was shared. Inferring a POI's type is
useful for studies in computational social science including sociolinguistics,
geosemiotics, and cultural geography, and has applications in geosocial
networking technologies such as recommendation and visualization systems. Prior
efforts in POI type prediction focus solely on text, without taking visual
information into account. However in reality, the variety of modalities, as
well as their semiotic relationships with one another, shape communication and
interactions in social media. This paper presents a study on POI type
prediction using multimodal information from text and images available at
posting time. For that purpose, we enrich a currently available data set for
POI type prediction with the images that accompany the text messages. Our
proposed method extracts relevant information from each modality to effectively
capture interactions between text and image achieving a macro F1 of 47.21
across eight categories significantly outperforming the state-of-the-art method
for POI type prediction based on text-only methods. Finally, we provide a
detailed analysis to shed light on cross-modal interactions and the limitations
of our best performing model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An unsupervised framework for tracing textual sources of moral change. (arXiv:2109.00608v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00608">
<div class="article-summary-box-inner">
<span><p>Morality plays an important role in social well-being, but people's moral
perception is not stable and changes over time. Recent advances in natural
language processing have shown that text is an effective medium for informing
moral change, but no attempt has been made to quantify the origins of these
changes. We present a novel unsupervised framework for tracing textual sources
of moral change toward entities through time. We characterize moral change with
probabilistic topical distributions and infer the source text that exerts
prominent influence on the moral time course. We evaluate our framework on a
diverse set of data ranging from social media to news articles. We show that
our framework not only captures fine-grained human moral judgments, but also
identifies coherent source topics of moral change triggered by historical
events. We apply our methodology to analyze the news in the COVID-19 pandemic
and demonstrate its utility in identifying sources of moral change in
high-impact and real-time social events.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Algorithme de recherche approximative dans un dictionnaire fond\'e sur une distance d'\'edition d\'efinie par blocs. (arXiv:2109.00624v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00624">
<div class="article-summary-box-inner">
<span><p>We propose an algorithm for approximative dictionary lookup, where altered
strings are matched against reference forms. The algorithm makes use of a
divergence function between strings -- broadly belonging to the family of edit
distances; it finds dictionary entries whose distance to the search string is
below a certain threshold. The divergence function is not the classical edit
distance (DL distance); it is adaptable to a particular corpus, and is based on
elementary alteration costs defined on character blocks, rather than on
individual characters.
</p>
<p>Nous proposons un algorithme de recherche approximative de cha\^ines dans un
dictionnaire \`a partir de formes alt\'er\'ees. Cet algorithme est fond\'e sur
une fonction de divergence entre cha\^ines~ -- une sorte de distance
d'\'edition: il recherche des entr\'ees pour lesquelles la distance \`a la
cha\^ine cherch\'ee est inf\'erieure \`a un certain seuil. La fonction
utilis\'ee n'est pas la distance d'\'edition classique (distance DL); elle est
adapt\'ee \`a un corpus, et se fonde sur la prise en compte de co\^uts
d'alt\'eration \'el\'ementaires d\'efinis non pas sur des caract\`eres, mais
sur des sous-cha\^ines (des blocs de caract\`eres).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition. (arXiv:2109.00627v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00627">
<div class="article-summary-box-inner">
<span><p>Contextual knowledge is important for real-world automatic speech recognition
(ASR) applications. In this paper, a novel tree-constrained pointer generator
(TCPGen) component is proposed that incorporates such knowledge as a list of
biasing words into both attention-based encoder-decoder and transducer
end-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing
words into an efficient prefix tree to serve as its symbolic input and creates
a neural shortcut between the tree and the final ASR output distribution to
facilitate recognising biasing words during decoding. Systems were trained and
evaluated on the Librispeech corpus where biasing words were extracted at the
scales of an utterance, a chapter, or a book to simulate different application
scenarios. Experimental results showed that TCPGen consistently improved word
error rates (WERs) compared to the baselines, and in particular, achieved
significant WER reductions on the biasing words. TCPGen is highly efficient: it
can handle 5,000 biasing words and distractors and only add a small overhead to
memory use and computation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Ensemble Approach for Annotating Source Code Identifiers with Part-of-speech Tags. (arXiv:2109.00629v1 [cs.SE])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00629">
<div class="article-summary-box-inner">
<span><p>This paper presents an ensemble part-of-speech tagging approach for source
code identifiers. Ensemble tagging is a technique that uses machine-learning
and the output from multiple part-of-speech taggers to annotate natural
language text at a higher quality than the part-of-speech taggers are able to
obtain independently. Our ensemble uses three state-of-the-art part-of-speech
taggers: SWUM, POSSE, and Stanford. We study the quality of the ensemble's
annotations on five different types of identifier names: function, class,
attribute, parameter, and declaration statement at the level of both individual
words and full identifier names. We also study and discuss the weaknesses of
our tagger to promote the future amelioration of these problems through further
research. Our results show that the ensemble achieves 75\% accuracy at the
identifier level and 84-86\% accuracy at the word level. This is an increase of
+17\% points at the identifier level from the closest independent
part-of-speech tagger.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The VoicePrivacy 2020 Challenge: Results and findings. (arXiv:2109.00648v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00648">
<div class="article-summary-box-inner">
<span><p>This paper presents the results and analyses stemming from the first
VoicePrivacy 2020 Challenge which focuses on developing anonymization solutions
for speech technology. We provide a systematic overview of the challenge design
with an analysis of submitted systems and evaluation results. In particular, we
describe the voice anonymization task and datasets used for system development
and evaluation. Also, we present different attack models and the associated
objective and subjective evaluation metrics. We introduce two anonymization
baselines and provide a summary description of the anonymization systems
developed by the challenge participants. We report objective and subjective
evaluation results for baseline and submitted systems. In addition, we present
experimental results for alternative privacy metrics and attack models
developed as a part of the post-evaluation analysis. Finally, we summarize our
insights and observations that will influence the design of the next
VoicePrivacy challenge edition and some directions for future voice
anonymization research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Making the Most of Dialogue Characteristics for Neural Chat Translation. (arXiv:2109.00668v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00668">
<div class="article-summary-box-inner">
<span><p>Neural Chat Translation (NCT) aims to translate conversational text between
speakers of different languages. Despite the promising performance of
sentence-level and context-aware neural machine translation models, there still
remain limitations in current NCT models because the inherent dialogue
characteristics of chat, such as dialogue coherence and speaker personality,
are neglected. In this paper, we propose to promote the chat translation by
introducing the modeling of dialogue characteristics into the NCT model. To
this end, we design four auxiliary tasks including monolingual response
generation, cross-lingual response generation, next utterance discrimination,
and speaker identification. Together with the main chat translation task, we
optimize the NCT model through the training objectives of all these tasks. By
this means, the NCT model can be enhanced by capturing the inherent dialogue
characteristics, thus generating more coherent and speaker-relevant
translations. Comprehensive experiments on four language directions
(English-German and English-Chinese) verify the effectiveness and superiority
of the proposed approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Empirical Exploration in Quality Filtering of Text Data. (arXiv:2109.00698v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00698">
<div class="article-summary-box-inner">
<span><p>While conventional wisdom suggests that more aggressively filtering data from
low-quality sources like Common Crawl always monotonically improves the quality
of training data, we find that aggressive filtering can in fact lead to a
decrease in model quality on a wide array of downstream tasks for a GPT-like
language model. We speculate that this is because optimizing sufficiently
strongly for a proxy metric harms performance on the true objective, suggesting
a need for more robust filtering objectives when attempting to filter more
aggressively. We hope this work leads to detailed analysis of the effects of
dataset filtering design choices on downstream model performance in future
work.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ShopTalk: A System for Conversational Faceted Search. (arXiv:2109.00702v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00702">
<div class="article-summary-box-inner">
<span><p>We present ShopTalk, a multi-turn conversational faceted search system for
shopping that is designed to handle large and complex schemas that are beyond
the scope of state of the art slot-filling systems. ShopTalk decouples dialog
management from fulfillment, thereby allowing the dialog understanding system
to be domain-agnostic and not tied to the particular shopping application. The
dialog understanding system consists of a deep-learned Contextual Language
Understanding module, which interprets user utterances, and a primarily
rules-based Dialog-State Tracker (DST), which updates the dialog state and
formulates search requests intended for the fulfillment engine. The interface
between the two modules consists of a minimal set of domain-agnostic "intent
operators," which instruct the DST on how to update the dialog state. ShopTalk
was deployed in 2020 on the Google Assistant for Shopping searches.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER. (arXiv:2109.00720v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00720">
<div class="article-summary-box-inner">
<span><p>NER in low-resource languages or domains suffers from inadequate training
data. Existing transfer learning approaches for low-resource NER usually have
the challenge that the target domain has different label sets compared with a
resource-rich source domain, which can be concluded as class transfer and
domain transfer problems. In this paper, we propose a lightweight generative
framework with prompt-guided attention for low-resource NER (LightNER) to
address these issues. Concretely, instead of tackling the problem by training
label-specific discriminative classifiers, we convert sequence labeling to
generate the entity pointer index sequence and entity categories without any
label-specific classifiers, which can address the class transfer issue. We
further propose prompt-guided attention by incorporating continuous prompts
into the self-attention layer to re-modulate the attention and adapt
pre-trained weights. Note that we only tune those continuous prompts with the
whole parameter of the pre-trained language model fixed, thus, making our
approach lightweight and flexible for low-resource scenarios and can better
transfer knowledge across domains. Experimental results show that by tuning
only 0.16% of the parameters, LightNER can obtain comparable performance in the
standard setting and outperform standard sequence labeling and prototype-based
methods in low-resource settings.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond. (arXiv:2109.00725v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00725">
<div class="article-summary-box-inner">
<span><p>A fundamental goal of scientific research is to learn about causal
relationships. However, despite its critical role in the life and social
sciences, causality has not had the same importance in Natural Language
Processing (NLP), which has traditionally placed more emphasis on predictive
tasks. This distinction is beginning to fade, with an emerging area of
interdisciplinary research at the convergence of causal inference and language
processing. Still, research on causality in NLP remains scattered across
domains without unified definitions, benchmark datasets and clear articulations
of the remaining challenges. In this survey, we consolidate research across
academic areas and situate it in the broader NLP landscape. We introduce the
statistical challenge of estimating causal effects, encompassing settings where
text is used as an outcome, treatment, or as a means to address confounding. In
addition, we explore potential uses of causal inference to improve the
performance, robustness, fairness, and interpretability of NLP models. We thus
provide a unified overview of causal inference for the computational
linguistics community.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ConQX: Semantic Expansion of Spoken Queries for Intent Detection based on Conditioned Text Generation. (arXiv:2109.00729v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00729">
<div class="article-summary-box-inner">
<span><p>Intent detection of spoken queries is a challenging task due to their noisy
structure and short length. To provide additional information regarding the
query and enhance the performance of intent detection, we propose a method for
semantic expansion of spoken queries, called ConQX, which utilizes the text
generation ability of an auto-regressive language model, GPT-2. To avoid
off-topic text generation, we condition the input query to a structured context
with prompt mining. We then apply zero-shot, one-shot, and few-shot learning.
We lastly use the expanded queries to fine-tune BERT and RoBERTa for intent
detection. The experimental results show that the performance of intent
detection can be improved by our semantic expansion method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural News Recommendation with Collaborative News Encoding and Structural User Encoding. (arXiv:2109.00750v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00750">
<div class="article-summary-box-inner">
<span><p>Automatic news recommendation has gained much attention from the academic
community and industry. Recent studies reveal that the key to this task lies
within the effective representation learning of both news and users. Existing
works typically encode news title and content separately while neglecting their
semantic interaction, which is inadequate for news text comprehension. Besides,
previous models encode user browsing history without leveraging the structural
correlation of user browsed news to reflect user interests explicitly. In this
work, we propose a news recommendation framework consisting of collaborative
news encoding (CNE) and structural user encoding (SUE) to enhance news and user
representation learning. CNE equipped with bidirectional LSTMs encodes news
title and content collaboratively with cross-selection and cross-attention
modules to learn semantic-interactive news representations. SUE utilizes graph
convolutional networks to extract cluster-structural features of user history,
followed by intra-cluster and inter-cluster attention modules to learn
hierarchical user interest representations. Experiment results on the MIND
dataset validate the effectiveness of our model to improve the performance of
news recommendation. Our code is released at
https://github.com/Veason-silverbullet/NNR.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MWPToolkit: An Open-Source Framework for Deep Learning-Based Math Word Problem Solvers. (arXiv:2109.00799v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00799">
<div class="article-summary-box-inner">
<span><p>Developing automatic Math Word Problem (MWP) solvers has been an interest of
NLP researchers since the 1960s. Over the last few years, there are a growing
number of datasets and deep learning-based methods proposed for effectively
solving MWPs. However, most existing methods are benchmarked soly on one or two
datasets, varying in different configurations, which leads to a lack of
unified, standardized, fair, and comprehensive comparison between methods. This
paper presents MWPToolkit, the first open-source framework for solving MWPs. In
MWPToolkit, we decompose the procedure of existing MWP solvers into multiple
core components and decouple their models into highly reusable modules. We also
provide a hyper-parameter search function to boost the performance. In total,
we implement and compare 17 MWP solvers on 4 widely-used single equation
generation benchmarks and 2 multiple equations generation benchmarks. These
features enable our MWPToolkit to be suitable for researchers to reproduce
advanced baseline models and develop new MWP solvers quickly. Code and
documents are available at https://github.com/LYH-YF/MWPToolkit.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00840">
<div class="article-summary-box-inner">
<span><p>Though language model text embeddings have revolutionized NLP research, their
ability to capture high-level semantic information, such as relations between
entities in text, is limited. In this paper, we propose a novel contrastive
learning framework that trains sentence embeddings to encode the relations in a
graph structure. Given a sentence (unstructured text) and its graph, we use
contrastive learning to impose relation-related structure on the token-level
representations of the sentence obtained with a CharacterBERT (El Boukkouri et
al.,2020) model. The resulting relation-aware sentence embeddings achieve
state-of-the-art results on the relation extraction task using only a simple
KNN classifier, thereby demonstrating the success of the proposed method.
Additional visualization by a tSNE analysis shows the effectiveness of the
learned representation space compared to baselines. Furthermore, we show that
we can learn a different space for named entity recognition, again using a
contrastive learning objective, and demonstrate how to successfully combine
both representation spaces in an entity-relation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. (arXiv:2109.00859v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00859">
<div class="article-summary-box-inner">
<span><p>Pre-trained models for Natural Languages (NL) like BERT and GPT have been
recently shown to transfer well to Programming Languages (PL) and largely
benefit a broad set of code-related tasks. Despite their success, most current
methods either rely on an encoder-only (or decoder-only) pre-training that is
suboptimal for generation (resp. understanding) tasks or process the code
snippet in the same way as NL, neglecting the special characteristics of PL
such as token types. We present CodeT5, a unified pre-trained encoder-decoder
Transformer model that better leverages the code semantics conveyed from the
developer-assigned identifiers. Our model employs a unified framework to
seamlessly support both code understanding and generation tasks and allows for
multi-task learning. Besides, we propose a novel identifier-aware pre-training
task that enables the model to distinguish which code tokens are identifiers
and to recover them when they are masked. Furthermore, we propose to exploit
the user-written code comments with a bimodal dual generation task for better
NL-PL alignment. Comprehensive experiments show that CodeT5 significantly
outperforms prior methods on understanding tasks such as code defect detection
and clone detection, and generation tasks across various directions including
PL-NL, NL-PL, and PL-PL. Further analysis reveals that our model can better
capture semantic information from code. Our code and pre-trained models are
released at https: //github.com/salesforce/CodeT5 .
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge Perceived Multi-modal Pretraining in E-commerce. (arXiv:2109.00895v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00895">
<div class="article-summary-box-inner">
<span><p>In this paper, we address multi-modal pretraining of product data in the
field of E-commerce. Current multi-modal pretraining methods proposed for image
and text modalities lack robustness in the face of modality-missing and
modality-noise, which are two pervasive problems of multi-modal product data in
real E-commerce scenarios. To this end, we propose a novel method, K3M, which
introduces knowledge modality in multi-modal pretraining to correct the noise
and supplement the missing of image and text modalities. The modal-encoding
layer extracts the features of each modality. The modal-interaction layer is
capable of effectively modeling the interaction of multiple modalities, where
an initial-interactive feature fusion model is designed to maintain the
independence of image modality and text modality, and a structure aggregation
module is designed to fuse the information of image, text, and knowledge
modalities. We pretrain K3M with three pretraining tasks, including masked
object modeling (MOM), masked language modeling (MLM), and link prediction
modeling (LPM). Experimental results on a real-world E-commerce dataset and a
series of product-based downstream tasks demonstrate that K3M achieves
significant improvements in performances than the baseline and state-of-the-art
methods when modality-noise or modality-missing exists.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">MultiEURLEX -- A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer. (arXiv:2109.00904v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00904">
<div class="article-summary-box-inner">
<span><p>We introduce MULTI-EURLEX, a new multilingual dataset for topic
classification of legal documents. The dataset comprises 65k European Union
(EU) laws, officially translated in 23 languages, annotated with multiple
labels from the EUROVOC taxonomy. We highlight the effect of temporal concept
drift and the importance of chronological, instead of random splits. We use the
dataset as a testbed for zero-shot cross-lingual transfer, where we exploit
annotated training documents in one language (source) to classify documents in
another language (target). We find that fine-tuning a multilingually pretrained
model (XLM-ROBERTA, MT5) in a single source language leads to catastrophic
forgetting of multilingual knowledge and, consequently, poor zero-shot transfer
to other languages. Adaptation strategies, namely partial fine-tuning,
adapters, BITFIT, LNFIT, originally proposed to accelerate fine-tuning for new
end-tasks, help retain multilingual knowledge from pretraining, substantially
improving zero-shot cross-lingual transfer, but their impact also depends on
the pretrained model used and the size of the label set.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coarse-To-Fine And Cross-Lingual ASR Transfer. (arXiv:2109.00916v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00916">
<div class="article-summary-box-inner">
<span><p>End-to-end neural automatic speech recognition systems achieved recently
state-of-the-art results, but they require large datasets and extensive
computing resources. Transfer learning has been proposed to overcome these
difficulties even across languages, e.g., German ASR trained from an English
model. We experiment with much less related languages, reusing an English model
for Czech ASR. To simplify the transfer, we propose to use an intermediate
alphabet, Czech without accents, and document that it is a highly effective
strategy. The technique is also useful on Czech data alone, in the style of
coarse-to-fine training. We achieve substantial eductions in training time as
well as word error rate (WER).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Multimodal fusion via Mutual Dependency Maximisation. (arXiv:2109.00922v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00922">
<div class="article-summary-box-inner">
<span><p>Multimodal sentiment analysis is a trending area of research, and the
multimodal fusion is one of its most active topic. Acknowledging humans
communicate through a variety of channels (i.e visual, acoustic, linguistic),
multimodal systems aim at integrating different unimodal representations into a
synthetic one. So far, a consequent effort has been made on developing complex
architectures allowing the fusion of these modalities. However, such systems
are mainly trained by minimising simple losses such as $L_1$ or cross-entropy.
In this work, we investigate unexplored penalties and propose a set of new
objectives that measure the dependency between modalities. We demonstrate that
our new penalties lead to a consistent improvement (up to $4.3$ on accuracy)
across a large variety of state-of-the-art models on two well-known sentiment
analysis datasets: \texttt{CMU-MOSI} and \texttt{CMU-MOSEI}. Our method not
only achieves a new SOTA on both datasets but also produces representations
that are more robust to modality drops. Finally, a by-product of our methods
includes a statistical network which can be used to interpret the high
dimensional representations learnt by the model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Speaker-Conditioned Hierarchical Modeling for Automated Speech Scoring. (arXiv:2109.00928v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00928">
<div class="article-summary-box-inner">
<span><p>Automatic Speech Scoring (ASS) is the computer-assisted evaluation of a
candidate's speaking proficiency in a language. ASS systems face many
challenges like open grammar, variable pronunciations, and unstructured or
semi-structured content. Recent deep learning approaches have shown some
promise in this domain. However, most of these approaches focus on extracting
features from a single audio, making them suffer from the lack of
speaker-specific context required to model such a complex task. We propose a
novel deep learning technique for non-native ASS, called speaker-conditioned
hierarchical modeling. In our technique, we take advantage of the fact that
oral proficiency tests rate multiple responses for a candidate. We extract
context vectors from these responses and feed them as additional
speaker-specific context to our network to score a particular response. We
compare our technique with strong baselines and find that such modeling
improves the model's average performance by 6.92% (maximum = 12.86%, minimum =
4.51%). We further show both quantitative and qualitative insights into the
importance of this additional context in solving the problem of ASS.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Coordinating Narratives and the Capitol Riots on Parler. (arXiv:2109.00945v1 [cs.SI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00945">
<div class="article-summary-box-inner">
<span><p>Coordinated disinformation campaigns are used to influence social media
users, potentially leading to offline violence. In this study, we introduce a
general methodology to uncover coordinated messaging through analysis of user
parleys on Parler. The proposed method constructs a user-to-user coordination
network graph induced by a user-to-text graph and a text-to-text similarity
graph. The text-to-text graph is constructed based on the textual similarity of
Parler posts. We study three influential groups of users in the 6 January 2020
Capitol riots and detect networks of coordinated user clusters that are all
posting similar textual content in support of different disinformation
narratives related to the U.S. 2020 elections.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language Model Pre-Training. (arXiv:2109.00993v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00993">
<div class="article-summary-box-inner">
<span><p>Large Transformer-based language models such as BERT have led to broad
performance improvements on many NLP tasks. Domain-specific variants of these
models have demonstrated excellent performance on a variety of specialised
tasks. In legal NLP, BERT-based models have led to new state-of-the-art results
on multiple tasks. The exploration of these models has demonstrated the
importance of capturing the specificity of the legal language and its
vocabulary. However, such approaches suffer from high computational costs,
leading to a higher ecological impact and lower accessibility. Our findings,
focusing on English language legal text, show that lightweight LSTM-based
Language Models are able to capture enough information from a small legal text
pretraining corpus and achieve excellent performance on short legal text
classification tasks. This is achieved with a significantly reduced
computational overhead compared to BERT-based models. However, our method also
shows degraded performance on a more complex task, multi-label classification
of longer documents, highlighting the limitations of this lightweight approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation. (arXiv:2109.01048v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01048">
<div class="article-summary-box-inner">
<span><p>Existing technologies expand BERT from different perspectives, e.g. designing
different pre-training tasks, different semantic granularities and different
model architectures. Few models consider expanding BERT from different text
formats. In this paper, we propose a heterogeneous knowledge language model
(HKLM), a unified pre-trained language model (PLM) for all forms of text,
including unstructured text, semi-structured text and well-structured text. To
capture the corresponding relations among these multi-format knowledge, our
approach uses masked language model objective to learn word knowledge, uses
triple classification objective and title matching objective to learn entity
knowledge and topic knowledge respectively. To obtain the aforementioned
multi-format text, we construct a corpus in the tourism domain and conduct
experiments on 5 tourism NLP datasets. The results show that our approach
outperforms the pre-training of plain text using only 1/4 of the data. The
code, datasets, corpus and knowledge graph will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Skim-Attention: Learning to Focus via Document Layout. (arXiv:2109.01078v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01078">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-training techniques of text and layout have proven
effective in a number of document understanding tasks. Despite this success,
multimodal pre-training models suffer from very high computational and memory
costs. Motivated by human reading strategies, this paper presents
Skim-Attention, a new attention mechanism that takes advantage of the structure
of the document and its layout. Skim-Attention only attends to the
2-dimensional position of the words in a document. Our experiments show that
Skim-Attention obtains a lower perplexity than prior works, while being more
computationally efficient. Skim-Attention can be further combined with
long-range Transformers to efficiently process long documents. We also show how
Skim-Attention can be used off-the-shelf as a mask for any Pre-trained Language
Model, allowing to improve their performance while restricting attention.
Finally, we show the emergence of a document structure representation in
Skim-Attention.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">How Suitable Are Subword Segmentation Strategies for Translating Non-Concatenative Morphology?. (arXiv:2109.01100v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01100">
<div class="article-summary-box-inner">
<span><p>Data-driven subword segmentation has become the default strategy for
open-vocabulary machine translation and other NLP tasks, but may not be
sufficiently generic for optimal learning of non-concatenative morphology. We
design a test suite to evaluate segmentation strategies on different types of
morphological phenomena in a controlled, semi-synthetic setting. In our
experiments, we compare how well machine translation models trained on subword-
and character-level can translate these morphological phenomena. We find that
learning to analyse and generate morphologically complex surface
representations is still challenging, especially for non-concatenative
morphological phenomena like reduplication or vowel harmony and for rare word
stems. Based on our results, we recommend that novel text representation
strategies be tested on a range of typologically diverse languages to minimise
the risk of adopting a strategy that inadvertently disadvantages certain
languages.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sequence-to-Sequence Learning with Latent Neural Grammars. (arXiv:2109.01135v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01135">
<div class="article-summary-box-inner">
<span><p>Sequence-to-sequence learning with neural networks has become the de facto
standard for sequence prediction tasks. This approach typically models the
local distribution over the next word with a powerful neural network that can
condition on arbitrary context. While flexible and performant, these models
often require large datasets for training and can fail spectacularly on
benchmarks designed to test for compositional generalization. This work
explores an alternative, hierarchical approach to sequence-to-sequence learning
with quasi-synchronous grammars, where each node in the target tree is
transduced by a node in the source tree. Both the source and target trees are
treated as latent and induced during training. We develop a neural
parameterization of the grammar which enables parameter sharing over the
combinatorial space of derivation rules without the need for manual feature
engineering. We apply this latent neural grammar to various domains -- a
diagnostic language navigation task designed to test for compositional
generalization (SCAN), style transfer, and small-scale machine translation --
and find that it performs respectably compared to standard baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An Iterative Multi-Knowledge Transfer Network for Aspect-Based Sentiment Analysis. (arXiv:2004.01935v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01935">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) mainly involves three subtasks: aspect
term extraction, opinion term extraction, and aspect-level sentiment
classification, which are typically handled in a separate or joint manner.
However, previous approaches do not well exploit the interactive relations
among three subtasks and do not pertinently leverage the easily available
document-level labeled domain/sentiment knowledge, which restricts their
performances. To address these issues, we propose a novel Iterative
Multi-Knowledge Transfer Network (IMKTN) for end-to-end ABSA. For one thing,
through the interactive correlations between the ABSA subtasks, our IMKTN
transfers the task-specific knowledge from any two of the three subtasks to
another one at the token level by utilizing a well-designed routing algorithm,
that is, any two of the three subtasks will help the third one. For another,
our IMKTN pertinently transfers the document-level knowledge, i.e.,
domain-specific and sentiment-related knowledge, to the aspect-level subtasks
to further enhance the corresponding performance. Experimental results on three
benchmark datasets demonstrate the effectiveness and superiority of our
approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Accelerating Real-Time Question Answering via Question Generation. (arXiv:2009.05167v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05167">
<div class="article-summary-box-inner">
<span><p>Although deep neural networks have achieved tremendous success for question
answering (QA), they are still suffering from heavy computational and energy
cost for real product deployment. Further, existing QA systems are bottlenecked
by the encoding time of real-time questions with neural networks, thus
suffering from detectable latency in deployment for large-volume traffic. To
reduce the computational cost and accelerate real-time question answering
(RTQA) for practical usage, we propose to remove all the neural networks from
online QA systems, and present Ocean-Q (an Ocean of Questions), which
introduces a new question generation (QG) model to generate a large pool of QA
pairs offline, then in real time matches an input question with the candidate
QA pool to predict the answer without question encoding. Ocean-Q can be readily
deployed in existing distributed database systems or search engine for
large-scale query usage, and much greener with no additional cost for
maintaining large neural networks. Experiments on SQuAD(-open) and HotpotQA
benchmarks demonstrate that Ocean-Q is able to accelerate the fastest
state-of-the-art RTQA system by 4X times, with only a 3+% accuracy drop.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GMH: A General Multi-hop Reasoning Model for KG Completion. (arXiv:2010.07620v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07620">
<div class="article-summary-box-inner">
<span><p>Knowledge graphs are essential for numerous downstream natural language
processing applications, but are typically incomplete with many facts missing.
This results in research efforts on multi-hop reasoning task, which can be
formulated as a search process and current models typically perform short
distance reasoning. However, the long-distance reasoning is also vital with the
ability to connect the superficially unrelated entities. To the best of our
knowledge, there lacks a general framework that approaches multi-hop reasoning
in mixed long-short distance reasoning scenarios. We argue that there are two
key issues for a general multi-hop reasoning model: i) where to go, and ii)
when to stop. Therefore, we propose a general model which resolves the issues
with three modules: 1) the local-global knowledge module to estimate the
possible paths, 2) the differentiated action dropout module to explore a
diverse set of paths, and 3) the adaptive stopping search module to avoid over
searching. The comprehensive results on three datasets demonstrate the
superiority of our model with significant improvements against baselines in
both short and long distance reasoning scenarios.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-lingual Transfer of Abstractive Summarizer to Less-resource Language. (arXiv:2012.04307v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04307">
<div class="article-summary-box-inner">
<span><p>Automatic text summarization extracts important information from texts and
presents the information in the form of a summary. Abstractive summarization
approaches progressed significantly by switching to deep neural networks, but
results are not yet satisfactory, especially for languages where large training
sets do not exist. In several natural language processing tasks, a
cross-lingual model transfer is successfully applied in less-resource
languages. For summarization, the cross-lingual model transfer was not
attempted due to a non-reusable decoder side of neural models that cannot
correct target language generation. In our work, we use a pre-trained English
summarization model based on deep neural networks and sequence-to-sequence
architecture to summarize Slovene news articles. We address the problem of
inadequate decoder by using an additional language model for the evaluation of
the generated text in target language. We test several cross-lingual
summarization models with different amounts of target data for fine-tuning. We
assess the models with automatic evaluation measures and conduct a small-scale
human evaluation. Automatic evaluation shows that the summaries of our best
cross-lingual model are useful and of quality similar to the model trained only
in the target language. Human evaluation shows that our best model generates
summaries with high accuracy and acceptable readability. However, similar to
other abstractive models, our models are not perfect and may occasionally
produce misleading or absurd content.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Topic Coverage Approach to Evaluation of Topic Models. (arXiv:2012.06274v3 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06274">
<div class="article-summary-box-inner">
<span><p>Topic models are widely used unsupervised models capable of learning topics -
weighted lists of words and documents - from large collections of text
documents. When topic models are used for discovery of topics in text
collections, a question that arises naturally is how well the model-induced
topics correspond to topics of interest to the analyst. In this paper we
revisit and extend a so far neglected approach to topic model evaluation based
on measuring topic coverage - computationally matching model topics with a set
of reference topics that models are expected to uncover. The approach is well
suited for analyzing models' performance in topic discovery and for large-scale
analysis of both topic models and measures of model quality. We propose new
measures of coverage and evaluate, in a series of experiments, different types
of topic models on two distinct text domains for which interest for topic
discovery exists. The experiments include evaluation of model quality, analysis
of coverage of distinct topic categories, and the analysis of the relationship
between coverage and other methods of topic model evaluation. The paper
contributes a new supervised measure of coverage, and the first unsupervised
measure of coverage. The supervised measure achieves topic matching accuracy
close to human agreement. The unsupervised measure correlates highly with the
supervised one (Spearman's $\rho \geq 0.95$). Other contributions include
insights into both topic models and different methods of model evaluation, and
the datasets and code for facilitating future research on topic coverage.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">NewsBERT: Distilling Pre-trained Language Model for Intelligent News Application. (arXiv:2102.04887v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04887">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PLMs) like BERT have made great progress in NLP.
News articles usually contain rich textual information, and PLMs have the
potentials to enhance news text modeling for various intelligent news
applications like news recommendation and retrieval. However, most existing
PLMs are in huge size with hundreds of millions of parameters. Many online news
applications need to serve millions of users with low latency tolerance, which
poses huge challenges to incorporating PLMs in these scenarios. Knowledge
distillation techniques can compress a large PLM into a much smaller one and
meanwhile keeps good performance. However, existing language models are
pre-trained and distilled on general corpus like Wikipedia, which has some gaps
with the news domain and may be suboptimal for news intelligence. In this
paper, we propose NewsBERT, which can distill PLMs for efficient and effective
news intelligence. In our approach, we design a teacher-student joint learning
and distillation framework to collaboratively learn both teacher and student
models, where the student model can learn from the learning experience of the
teacher model. In addition, we propose a momentum distillation method by
incorporating the gradients of teacher model into the update of student model
to better transfer useful knowledge learned by the teacher model. Extensive
experiments on two real-world datasets with three tasks show that NewsBERT can
effectively improve the model performance in various intelligent news
applications with much smaller models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Data-Centric Framework for Composable NLP Workflows. (arXiv:2103.01834v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01834">
<div class="article-summary-box-inner">
<span><p>Empirical natural language processing (NLP) systems in application domains
(e.g., healthcare, finance, education) involve interoperation among multiple
components, ranging from data ingestion, human annotation, to text retrieval,
analysis, generation, and visualization. We establish a unified open-source
framework to support fast development of such sophisticated NLP workflows in a
composable manner. The framework introduces a uniform data representation to
encode heterogeneous results by a wide range of NLP tasks. It offers a large
repository of processors for NLP tasks, visualization, and annotation, which
can be easily assembled with full interoperability under the unified
representation. The highly extensible framework allows plugging in custom
processors from external off-the-shelf NLP and deep learning libraries. The
whole framework is delivered through two modularized yet integratable
open-source projects, namely Forte (for workflow infrastructure and NLP
function processors) and Stave (for user interaction, visualization, and
annotation).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Gradual Fine-Tuning for Low-Resource Domain Adaptation. (arXiv:2103.02205v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02205">
<div class="article-summary-box-inner">
<span><p>Fine-tuning is known to improve NLP models by adapting an initial model
trained on more plentiful but less domain-salient examples to data in a target
domain. Such domain adaptation is typically done using one stage of
fine-tuning. We demonstrate that gradually fine-tuning in a multi-stage process
can yield substantial further gains and can be applied without modifying the
model or learning objective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conceptual similarity and communicative need shape colexification: an experimental study. (arXiv:2103.11024v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11024">
<div class="article-summary-box-inner">
<span><p>Colexification refers to the phenomenon of multiple meanings sharing one word
in a language. Cross-linguistic lexification patterns have been shown to be
largely predictable, as similar concepts are often colexified. We test a recent
claim that, beyond this general tendency, communicative needs play an important
role in shaping colexification patterns. We approach this question by means of
a series of human experiments, using an artificial language communication game
paradigm. Our results across four experiments match the previous
cross-linguistic findings: all other things being equal, speakers do prefer to
colexify similar concepts. However, we also find evidence supporting the
communicative need hypothesis: when faced with a frequent need to distinguish
similar pairs of meanings, speakers adjust their colexification preferences to
maintain communicative efficiency, and avoid colexifying those similar meanings
which need to be distinguished in communication. This research provides further
evidence to support the argument that languages are shaped by the needs and
preferences of their speakers.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowledge-Aware Graph-Enhanced GPT-2 for Dialogue State Tracking. (arXiv:2104.04466v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04466">
<div class="article-summary-box-inner">
<span><p>Dialogue State Tracking is central to multi-domain task-oriented dialogue
systems, responsible for extracting information from user utterances. We
present a novel hybrid architecture that augments GPT-2 with representations
derived from Graph Attention Networks in such a way to allow causal, sequential
prediction of slot values. The model architecture captures inter-slot
relationships and dependencies across domains that otherwise can be lost in
sequential prediction. We report improvements in state tracking performance in
MultiWOZ 2.0 against a strong GPT-2 baseline and investigate a simplified
sparse training scenario in which DST models are trained only on session-level
annotations but evaluated at the turn level. We further report detailed
analyses to demonstrate the effectiveness of graph models in DST by showing
that the proposed graph modules capture inter-slot dependencies and improve the
predictions of values that are common to multiple domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Power of Scale for Parameter-Efficient Prompt Tuning. (arXiv:2104.08691v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08691">
<div class="article-summary-box-inner">
<span><p>In this work, we explore "prompt tuning", a simple yet effective mechanism
for learning "soft prompts" to condition frozen language models to perform
specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft
prompts are learned through backpropagation and can be tuned to incorporate
signal from any number of labeled examples. Our end-to-end learned approach
outperforms GPT-3's "few-shot" learning by a large margin. More remarkably,
through ablations on model size using T5, we show that prompt tuning becomes
more competitive with scale: as models exceed billions of parameters, our
method "closes the gap" and matches the strong performance of model tuning
(where all model weights are tuned). This finding is especially relevant in
that large models are costly to share and serve, and the ability to reuse one
frozen model for multiple downstream tasks can ease this burden. Our method can
be seen as a simplification of the recently proposed "prefix tuning" of Li and
Liang (2021), and we provide a comparison to this and other similar approaches.
Finally, we show that conditioning a frozen model with soft prompts confers
benefits in robustness to domain transfer, as compared to full model tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Probing Commonsense Explanation in Dialogue Response Generation. (arXiv:2104.09574v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09574">
<div class="article-summary-box-inner">
<span><p>Humans use commonsense reasoning (CSR) implicitly to produce natural and
coherent responses in conversations. Aiming to close the gap between current
response generation (RG) models and human communication abilities, we want to
understand why RG models respond as they do by probing RG model's understanding
of commonsense reasoning that elicits proper responses. We formalize the
problem by framing commonsense as a latent variable in the RG task and using
explanations for responses as textual form of commonsense. We collect 6k
annotated explanations justifying responses from four dialogue datasets and ask
humans to verify them and propose two probing settings to evaluate RG models'
CSR capabilities. Probing results show that models fail to capture the logical
relations between commonsense explanations and responses and fine-tuning on
in-domain data and increasing model sizes do not lead to understanding of CSR
for RG. We hope our study motivates more research in making RG models emulate
the human reasoning process in pursuit of smooth human-AI communication.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">AMMU : A Survey of Transformer-based Biomedical Pretrained Language Models. (arXiv:2105.00827v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00827">
<div class="article-summary-box-inner">
<span><p>Transformer-based pretrained language models (PLMs) have started a new era in
modern natural language processing (NLP). These models combine the power of
transformers, transfer learning, and self-supervised learning (SSL). Following
the success of these models in the general domain, the biomedical research
community has developed various in-domain PLMs starting from BioBERT to the
latest BioELECTRA and BioALBERT models. We strongly believe there is a need for
a survey paper that can provide a comprehensive survey of various
transformer-based biomedical pretrained language models (BPLMs). In this
survey, we start with a brief overview of foundational concepts like
self-supervised learning, embedding layer and transformer encoder layers. We
discuss core concepts of transformer-based PLMs like pretraining methods,
pretraining tasks, fine-tuning methods, and various embedding types specific to
biomedical domain. We introduce a taxonomy for transformer-based BPLMs and then
discuss all the models. We discuss various challenges and present possible
solutions. We conclude by highlighting some of the open issues which will drive
the research community to further improve transformer-based BPLMs.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smart Bird: Learnable Sparse Attention for Efficient and Effective Transformer. (arXiv:2108.09193v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09193">
<div class="article-summary-box-inner">
<span><p>Transformer has achieved great success in NLP. However, the quadratic
complexity of the self-attention mechanism in Transformer makes it inefficient
in handling long sequences. Many existing works explore to accelerate
Transformers by computing sparse self-attention instead of a dense one, which
usually attends to tokens at certain positions or randomly selected tokens.
However, manually selected or random tokens may be uninformative for context
modeling. In this paper, we propose Smart Bird, which is an efficient and
effective Transformer with learnable sparse attention. In Smart Bird, we first
compute a sketched attention matrix with a single-head low-dimensional
Transformer, which aims to find potential important interactions between
tokens. We then sample token pairs based on their probability scores derived
from the sketched attention matrix to generate different sparse attention index
matrices for different attention heads. Finally, we select token embeddings
according to the index matrices to form the input of sparse attention networks.
Extensive experiments on six benchmark datasets for different tasks validate
the efficiency and effectiveness of Smart Bird in text modeling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">One Chatbot Per Person: Creating Personalized Chatbots based on Implicit User Profiles. (arXiv:2108.09355v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09355">
<div class="article-summary-box-inner">
<span><p>Personalized chatbots focus on endowing chatbots with a consistent
personality to behave like real users, give more informative responses, and
further act as personal assistants. Existing personalized approaches tried to
incorporate several text descriptions as explicit user profiles. However, the
acquisition of such explicit profiles is expensive and time-consuming, thus
being impractical for large-scale real-world applications. Moreover, the
restricted predefined profile neglects the language behavior of a real user and
cannot be automatically updated together with the change of user interests. In
this paper, we propose to learn implicit user profiles automatically from
large-scale user dialogue history for building personalized chatbots.
Specifically, leveraging the benefits of Transformer on language understanding,
we train a personalized language model to construct a general user profile from
the user's historical responses. To highlight the relevant historical responses
to the input post, we further establish a key-value memory network of
historical post-response pairs, and build a dynamic post-aware user profile.
The dynamic profile mainly describes what and how the user has responded to
similar posts in history. To explicitly utilize users' frequently used words,
we design a personalized decoder to fuse two decoding strategies, including
generating a word from the generic vocabulary and copying one word from the
user's personalized vocabulary. Experiments on two real-world datasets show the
significant improvement of our model compared with existing methods. Our code
is available at https://github.com/zhengyima/DHAP
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on five public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work claims, our auxiliary experiments suggest that relation
prediction is contributory to named entity prediction in a non-negligible way.
The source code can be found at https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree Decomposition Attention for AMR-to-Text Generation. (arXiv:2108.12300v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12300">
<div class="article-summary-box-inner">
<span><p>Text generation from AMR requires mapping a semantic graph to a string that
it annotates. Transformer-based graph encoders, however, poorly capture vertex
dependencies that may benefit sequence prediction. To impose order on an
encoder, we locally constrain vertex self-attention using a graph's tree
decomposition. Instead of forming a full query-key bipartite graph, we restrict
attention to vertices in parent, subtree, and same-depth bags of a vertex. This
hierarchical context lends both sparsity and structure to vertex state updates.
We apply dynamic programming to derive a forest of tree decompositions,
choosing the most structurally similar tree to the AMR. Our system outperforms
a self-attentive baseline by 1.6 BLEU and 1.8 chrF++.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Latent Tree Decomposition Parsers for AMR-to-Text Generation. (arXiv:2108.12304v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12304">
<div class="article-summary-box-inner">
<span><p>Graph encoders in AMR-to-text generation models often rely on neighborhood
convolutions or global vertex attention. While these approaches apply to
general graphs, AMRs may be amenable to encoders that target their tree-like
structure. By clustering edges into a hierarchy, a tree decomposition
summarizes graph structure. Our model encodes a derivation forest of tree
decompositions and extracts an expected tree. From tree node embeddings, it
builds graph edge features used in vertex attention of the graph encoder.
Encoding TD forests instead of shortest-pairwise paths in a self-attentive
baseline raises BLEU by 0.7 and chrF++ by 0.3. The forest encoder also
surpasses a convolutional baseline for molecular property prediction by 1.92%
ROC-AUC.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Smoothing Dialogue States for Open Conversational Machine Reading. (arXiv:2108.12599v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12599">
<div class="article-summary-box-inner">
<span><p>Conversational machine reading (CMR) requires machines to communicate with
humans through multi-turn interactions between two salient dialogue states of
decision making and question generation processes. In open CMR settings, as the
more realistic scenario, the retrieved background knowledge would be noisy,
which results in severe challenges in the information transmission. Existing
studies commonly train independent or pipeline systems for the two subtasks.
However, those methods are trivial by using hard-label decisions to activate
question generation, which eventually hinders the model performance. In this
work, we propose an effective gating strategy by smoothing the two dialogue
states in only one decoder and bridge decision making and question generation
to provide a richer dialogue state reference. Experiments on the OR-ShARC
dataset show the effectiveness of our method, which achieves new
state-of-the-art results.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-05 01:53:44.830782647 UTC">2021-09-05 01:53:44 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>