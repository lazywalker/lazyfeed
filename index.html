<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-20T23:23:40.451584380Z">09-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">Rust.cc</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust Developer(ST) for SIL.Finance (for Soh.cool, Solana Branch)</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=b367e266-92ef-400c-81b0-18bc0346560b">
<div class="article-summary-box-inner">
<span><h2>Location</h2>
<ul>
<li>San Mateo, California, On-site.</li>
<li>Hangzhou, China, On-site.</li>
<li>Globe, Remote.</li>
</ul>
<h3>Rust Engineer</h3>
<ul>
<li>
<p>Responsibilities</p>
<ul>
<li>Build smart contracts in Rust, understand Solana BPF</li>
<li>Build smart contracts in Solidity as well</li>
<li>Design, scope, and estimate tasks based on requirements</li>
<li>Collaborate with team to plan projects at the task level</li>
<li>Collaborate with cross-functional partners on all aspects of product development</li>
<li>Identify and advocate for team-wide areas of improvement and best practices</li>
<li>Envision and develop features to help grow SIL</li>
</ul>
</li>
<li>
<p>Qualifications</p>
<ul>
<li>Bachelor's or Master's degree in CS or equivalent experience</li>
<li>Experience with Rust</li>
<li>Experience with Solana blockchain</li>
<li>Experience with Layer 2 scaling</li>
</ul>
</li>
<li>
<p>Good to have</p>
<ul>
<li>Experience with Solidity, and understands gas optimization</li>
<li>Experience with Truffle/Hardhat</li>
<li>Experience with migrations and deploy code to EVM compatible networks</li>
</ul>
</li>
</ul>
<h3>Solidity Engineer</h3>
<ul>
<li>
<p>Responsibilities</p>
<ul>
<li>Build smart contracts in Solidity for the EVM compatible blockchains</li>
<li>Design, scope, and estimate tasks based on requirements</li>
<li>Collaborate with team to plan projects at the task level</li>
<li>Collaborate with cross-functional partners on all aspects of product development</li>
<li>Identify and advocate for team-wide areas of improvement and best practices</li>
<li>Envision and develop features to help grow SIL</li>
</ul>
</li>
<li>
<p>Qualifications</p>
<ul>
<li>Bachelor's or Master's degree in CS or equivalent experience</li>
<li>Experience with Solidity, and understands gas optimization</li>
<li>Experience with Truffle/Hardhat</li>
<li>Experience with migrations and deploy code to EVM compatible networks</li>
</ul>
</li>
<li>
<p>Good to have</p>
<ul>
<li>Experience with Layer 2 scaling</li>
<li>Experience with Rust</li>
<li>Experience with Solana blockchain</li>
</ul>
</li>
</ul>
<h3>Blockchain QA Engineer</h3>
<ul>
<li>
<p>Responsibilities</p>
<ul>
<li>Setup end to end testing tools on dApp (fronend, blockchain)</li>
<li>Write appropriate end to end tests in order to protect the product from regressions bugs</li>
<li>Collaborate with team to plan projects at the task level</li>
<li>Identify and advocate for team-wide areas of improvement and best practices</li>
</ul>
</li>
<li>
<p>Qualifications</p>
<ul>
<li>Experience with automated tests</li>
<li>Experience with dApp products</li>
</ul>
</li>
<li>
<p>Good to have</p>
<ul>
<li>Experience with EVM compatible blockchains</li>
<li>Experience with Solidity</li>
<li>Experience with JavaScript/TypeScript</li>
</ul>
</li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">招远程Rust/Solana工程师</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=bec1bd60-b6dc-4128-9683-a986ec950e9e">
<div class="article-summary-box-inner">
<span><p>申请链接： https://cryptocurrencyjobs.co/engineering/vovo-finance-solana-engineer/<br>
薪资：4万 - 8 万/每月<br>
团队在新加坡和美国</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">招远程Rust/Solana工程师</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=eaf18058-861e-49f2-a619-47f129fdf87b">
<div class="article-summary-box-inner">
<span><p>职位介绍和申请链接： https://cryptocurrencyjobs.co/engineering/vovo-finance-solana-engineer/<br>
薪资：4万 - 8 万/每月<br>
团队在新加坡和美国</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">异步下的生命周期问题</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=a61c0207-65b5-4f5a-a123-34b553fe13fb">
<div class="article-summary-box-inner">
<span><pre><code>
mod test {
    use std::{pin::Pin, task::Poll};

    use futures_io::{AsyncBufRead, AsyncRead};

    //不能通过编译
    struct Body(Vec&lt;u8&gt;);

    impl AsyncRead for Body {
        fn poll_read(
            self: Pin&lt;&amp;mut Self&gt;,
            cx: &amp;mut std::task::Context&lt;'_&gt;,
            buf: &amp;mut [u8],
        ) -&gt; Poll&lt;futures_io::Result&lt;usize&gt;&gt; {
            todo!()
        }
    }

    impl AsyncBufRead for Body {
        fn poll_fill_buf(
            self: Pin&lt;&amp;mut Self&gt;,
            cx: &amp;mut std::task::Context&lt;'_&gt;,
        ) -&gt; Poll&lt;futures_io::Result&lt;&amp;[u8]&gt;&gt; {
            Poll::Ready(Ok(&amp;self.0))
        }

        fn consume(self: Pin&lt;&amp;mut Self&gt;, amt: usize) {
            todo!()
        }
    }
}

</code></pre>
<p>不能通过编译</p>
<pre><code>
error[E0515]: cannot return value referencing function parameter `self`
  --&gt; src/main.rs:24:13
   |
24 |             Poll::Ready(Ok(&amp;self.0))
   |             ^^^^^^^^^^^^^^^^----^^^^
   |             |               |
   |             |               `self` is borrowed here
   |             returns a value referencing data owned by the current function

For more information about this error, try `rustc --explain E0515`.

</code></pre>
<p>https://play.rust-lang.org/#:~:text=Permalink%20to%20the%20playground</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">enum和struct下的生命周期问题</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=a45f8532-4e48-4495-91b9-df56b6ce33de">
<div class="article-summary-box-inner">
<span><pre><code>
mod test {
//不能通过编译
    enum Body {
        Bytes(Vec&lt;u8&gt;),
    }

    impl std::io::Read for Body {
        fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; futures_io::Result&lt;usize&gt; {
            todo!()
        }
    }

    impl std::io::BufRead for Body {
        fn fill_buf(&amp;mut self) -&gt; futures_io::Result&lt;&amp;[u8]&gt; {
            match self{
                Body::Bytes(bytes) =&gt; Ok(bytes.as_ref()),
            }
        }

        fn consume(&amp;mut self, amt: usize) {
            todo!()
        }
    }
}

mod test2 {
//能通过编译
    struct Body (Vec&lt;u8&gt;);
    

    impl std::io::Read for Body {
        fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; futures_io::Result&lt;usize&gt; {
            todo!()
        }
    }

    impl std::io::BufRead for Body {
        fn fill_buf(&amp;mut self) -&gt; futures_io::Result&lt;&amp;[u8]&gt; {
            Ok(self.0.as_ref())
            
        }

        fn consume(&amp;mut self, amt: usize) {
            todo!()
        }
    }
}

fn main(){
    
}

</code></pre>
<p>为什么使用enum就无法通过编译，使用struct就能编译？</p>
<pre><code>
error[E0515]: cannot return value referencing local variable `bytes`
  --&gt; src/main.rs:16:39
   |
16 |                 Body::Bytes(bytes) =&gt; Ok(bytes.as_ref()),
   |                                       ^^^-----^^^^^^^^^^
   |                                       |  |
   |                                       |  `bytes` is borrowed here
   |                                       returns a value referencing data owned by the current function

</code></pre>
<p>更新：改成<code>Body::Bytes(ref bytes)</code>就过编译了，不知道为什么。</p>
<p>playground:</p>
<p>https://play.rust-lang.org/#:~:text=Permalink%20to%20the%20playground</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-20 Rust CI/CD: github action 使用</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=f08915d7-1ffc-405c-b627-91d5473c46ec">
<div class="article-summary-box-inner">
<span><h1>Rust CI/CD: github action 使用</h1>
<p>和任何其他语言一样, 在我们掌握语法之外, 我们往往还有 CI/CD 的需求:</p>
<ul>
<li>需要哪些组件来组成CI管道，以确保我的代码是健康的？</li>
<li>如何部署？</li>
<li>我需要编写自定义工具还是有社区资源可用？</li>
</ul>
<p>作者会用三篇文章来讲解 Rust在 github 中如何使用 action 来完成 CI/CD.</p>
<p><a href="https://www.homeops.dev/continuous-integration-with-github-actions-and-rust/" rel="noopener noreferrer">原文链接</a></p>
<h1>使用 Axum, Hyper, Tonic, and Tower 打造 web/gRPC 应用</h1>
<p>这是使用 Axum, Hyper, Tonic, and Tower 来打造 web/gRPC 应用系列的第四部分. 本次主要讲解如何组合 Axum 和 Tonic.</p>
<p><a href="https://www.fpcomplete.com/blog/axum-hyper-tonic-tower-part4/" rel="noopener noreferrer">原文链接</a></p>
<h1>compact_str: 一种内存高效的不可变 string 类型</h1>
<p>CompactStr 是一种内存效率更高的不可变字符串类型，它可以在堆栈上存储较小的字符串，并透明地在堆上存储更长的字符串。它们大多可以用作String的替换，在解析、反序列化或任何其他可能有较小字符串的应用程序中特别有用。</p>
<p><a href="https://github.com/ParkMyCar/compact_str" rel="noopener noreferrer">github 地址</a></p>
<h1>Caches: rust版本的 LRU</h1>
<p>这是一个 Rust 版本的 LRU 实现. golang 的实现: https://github.com/hashicorp/golang-lru</p>
<p><a href="https://github.com/al8n/caches-rs" rel="noopener noreferrer">github 地址 </a></p>
<p>--</p>
<p>From 日报小组 BobQin，FBI小白</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">未知长度的迭代器是怎么优化的</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=a2c6af33-7e65-4100-a633-71f8658929fb">
<div class="article-summary-box-inner">
<span><p>我看到书里面说到</p>
<p>Rust 知道这里会迭代 12 次，所以它“展开”（unroll）了循环。展开是一种移除循环控制代码的开销并替换为每个迭代中的重复代码的优化。
所有的系数都被储存在了寄存器中，这意味着访问他们非常快。这里也没有运行时数组访问边界检查。所有这些 Rust 能够提供的优化使得结果代码极为高效。</p>
<p>这是基于已知长度的优化，那么未知长度呢，举个例子，用户可以输入一个n,n就是vec的长度，然后我用迭代器遍历这个vec,rust会怎么优化它呢？
或者说哪里有这些资料</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust match总是不能按预期执行</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=ab509fd4-cf1f-408b-b86f-c043c6193d42">
<div class="article-summary-box-inner">
<span><p>我在db.txt中存放了如下user name数据：
alice
bob
david</p>
<p>下面的函数是从标准输入读取user name, 然后与存放在db.txt中的数据对比，如果存在，则打印exist，如果不存在，则写入到db.txt.
但是下面的函数check_user_exist中，match第一个条件总是匹配的，这是为什么呢？</p>
<pre><code>use std::fs::File;
use std::io::{self, prelude::*, BufReader};
use std::path::Path;
use std::fs::OpenOptions;
use std::io::Write;

pub fn login()-&gt;io::Result&lt;()&gt;{
    db_init();

    let mut name = String::new();
    io::stdin().read_line(&amp;mut name)?;
    match check_user_exist(name.as_str()) {
        Ok(exist) =&gt; println!("{:?}",exist),
        Err(_) =&gt; println!("register new name."),
    }
    Ok(())
}

fn check_user_exist(name:&amp;str) -&gt; io::Result&lt;()&gt; {

    let file = File::open("db.txt")?;
    let reader = BufReader::new(file);
    for line in reader.lines().map(|l| l.unwrap()) {
        match line.as_str(){
            name  =&gt; println!("found str {}",name),   // **always match, why ?? **
            _ =&gt; register(name),
        }
    }
    Ok(())
}  

fn register(name:&amp;str){

    let mut file = OpenOptions::new().append(true).open("db.txt").expect(
        "cannot open file");
     file.write_all(name.as_bytes()).expect("write file faile");
}

fn db_init(){
    if Path::new("db.txt").exists() {
        println!("db already inited!");
    }
    else{
        println!("db not initialized. create db file!");
        let file = File::create("db.txt").expect("create file fail");
    }
}

fn main(){
    println!("start main\n");

    login();
}
</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【已解决】axum路由导致项目编译时间变长</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=cc58b708-43af-477a-80e5-4df42b4a4025">
<div class="article-summary-box-inner">
<span><p>axum的路由设计感觉有点问题，Router::new().route(...)，调用route方法越多，编译时间越长。
如果有和我遇到同样问题的，可以使用此crate： https://github.com/programatik29/axum-router</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-18</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=8812da66-04a5-4d69-908e-ac0c148cbd57">
<div class="article-summary-box-inner">
<span><h3>Goscript现在已经完成了语言功能。</h3>
<p>Go 规范作为脚本语言实现。</p>
<p>尽管距离正式投入生产还有很长的路要走，但这对我来说是一个重要的里程碑。它现在支持 goroutine/channel/defer。</p>
<p>如果您觉得它很有趣，<code>test</code>文件夹会显示它可以做什么。</p>
<p><a href="https://github.com/oxfeeefeee/goscript" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/oxfeeefeee/goscript</p>
<h3>GitHub - seed-rs/seed: 用于创建 Web 应用程序的 Rust 框架</h3>
<p>Seed 是一个 Rust 前端框架，用于创建具有类似 Elm 架构的快速可靠的 Web 应用程序。</p>
<ul>
<li>完全用 Rust 编写，包括模板系统（例如 div！宏）</li>
<li>基于 Elm 架构的内置状态管理。</li>
<li>...</li>
</ul>
<p><a href="https://github.com/seed-rs/seed" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/seed-rs/seed</p>
<h3>Rust 编程语言用于游戏工具（GDC 2021 幻灯片）</h3>
<p>Rust 编程语言已悄然席卷科技界，但游戏工作室的采用速度较慢。
自 2018 年以来，Treyarch 一直在逐步将 Rust 集成到我们的工具和管道中。 本次会议利用这一经验探索 Rust 可以给游戏工具程序员带来的机遇和挑战，并研究 Rust 可以成为工具的强有力的补充。</p>
<p><a href="https://research.activision.com/publications/2021/09/the-rust-programming-language-for-game-tooling" rel="noopener noreferrer">文章链接</a>，https://research.activision.com/publications/2021/09/the-rust-programming-language-for-game-tooling</p>
<hr>
<p>From 日报小组 <a href="https://rustcc.cn/blog_with_author?author_id=dd4a77ca-2042-459e-901a-b8f9bfeb7db0" rel="noopener noreferrer">TOM</a></p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 培养提高计划 Vol. 7 - 8 | Rust 项目工程来了</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=9dec6eeb-38d8-4ec4-b75e-783bd11bf24b">
<div class="article-summary-box-inner">
<span><p>我们的 Rust 公开课进行了 6 期了，带大家了解了 ：</p>
<ol>
<li>认识面向基础架构语言</li>
<li>理解 Rust 所有权</li>
<li>通过实战理解 Rust 宏</li>
<li>通过 Datafuse 理解全链路跟踪</li>
<li>Rust 异步编程入门 Future Part 1</li>
<li>Rust 异步编程入门 Future Part 2</li>
</ol>
<p>目前视频回放传到 B 站收获许多好评，赞，也给我们很大的鼓励。希望我们的 Rust 培养提高计划 | Datafuse 可以帮助更多的朋友快速的使用上 Rust 。
本周给大家排两个公开课：周四晚上，周日晚上。我们 Rust 培养提高计划邀请到第二位分享嘉宾 董泽润老师， 另外 Rust 培养提高计划 的内容上也做了一些调整。</p>
<hr>
<p>分享主题：《深入了解rust 闭包》 | Vol. 7</p>
<p>分享时间： 周四晚上2021-09-09 20:00-21:00</p>
<p>分享讲师： 董泽润</p>
<p>内容介绍： 深入浅出了解 rust 闭包工作原理，让大家了解底层实现
讲师介绍：
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/07-%E8%91%A3%E6%B3%BD%E6%B6%A6.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png" alt></p>
<hr>
<p>分享主题：《利用 Tokio 实现一个高性能 Mini Http server》 | Vol. 8</p>
<p>分享时间： 周日晚上2021-09-12 20:00-21:00</p>
<p>分享讲师： 苏林</p>
<p>首先感谢苏林老师的坚持付出， 带我们学习 Rust 的重点知识。 经过和苏琳老师沟通，我们后续的课程，会更加往实战方向转变。接下是一个系列的内容：</p>
<ol>
<li>利用 Tokio 实现一个 Mini Http server</li>
<li>基于 Http server提供内容动态的 API 网关</li>
<li>利用 Redis 实现对 API 网关加速</li>
<li>学习 Rust RPC 调用，实现微服务调用</li>
</ol>
<p>这个内容可能需要4次左右的公开课，目的是带着大家做一些小项目，带大家熟悉一下 Rust 工程，让大家可以快速把 Rust 用到后端开发中。</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8Ev2.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/</p>
<p>Rust 异步编程入门 Future Part 1 | Vol. 5
https://www.bilibili.com/video/BV1mf4y1N7MJ/</p>
<p>Rust 异步编程入门 Future Part 2 | Vol. 6
https://www.bilibili.com/video/bv1oy4y1G7jC</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">rust 学习随笔</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8">
<div class="article-summary-box-inner">
<span><h1>切换镜像源</h1>
<p>crm =&gt; https://github.com/wtklbm/crm</p>
<p>常用命令就是 <code>crm best</code></p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">pretree 补全文档发布了,再次谢谢大神的指点终于入门了。</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827">
<div class="article-summary-box-inner">
<span><h1>Pretree</h1>
<p>pretree is a package for storing and querying routing rules with prefix tree .</p>
<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>
<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>
<p>Inspired by <a href="https://github.com/obity/pretree" rel="noopener noreferrer">obity/pretree</a> (golang)</p>
<h1>Doc</h1>
<p>See this document at <a href="https://docs.rs/pretree" rel="noopener noreferrer">API documentation</a></p>
<h1>Install</h1>
<p>Add the following line to your Cargo.toml file:</p>
<pre><code>pretree = "1.0.0"
</code></pre>
<h1>Example</h1>
<pre><code>use pretree::Pretree;
let mut p = Pretree::new();
p.store("GET","account/{id}/info/:name");
p.store("GET","account/:id/login");
p.store("GET","account/{id}");
p.store("GET","bacteria/count_number_by_month");
let (ok,rule,vars) = p.query("GET","account/929239");
println!("ok:{} rule:{} vars:{:#?}",ok,rule,vars);

</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>
<p><strong>课程时间:</strong> 2021年9月5日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识, Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>
<h3>课程大纲</h3>
<p>1、回顾 Rust 异步编程模型.</p>
<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>
<p>3、Tokio 介绍.</p>
<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>
<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/
Rust 异步编程入门 Future Part 1 回放地址：
https://www.bilibili.com/video/BV1mf4y1N7MJ/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课：《 Rust 异步编程入门 Future 》|Vol. 5</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>
<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是 Rust 异步编程的核心基础。</p>
<h3>课程大纲</h3>
<p>1、为什么需要异步.</p>
<p>2、理解异步编程模型.</p>
<p>3、Future 编程模型讲解.</p>
<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c">
<div class="article-summary-box-inner">
<span><h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>
<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>
<p>ReadMore:<a href="https://twitter.com/m_ou_se/status/1427666611977297924" rel="noopener noreferrer">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>
<h3>异步引擎 C++20, Rust &amp; Zig</h3>
<p>ReadMore:<a href="https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/" rel="noopener noreferrer">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>
<h3>RG3D -- Rust 3D 游戏引擎</h3>
<ul>
<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>
<li><strong>延迟着色</strong></li>
<li><strong>内置保存/加载</strong></li>
<li><strong>独立场景编辑器</strong></li>
<li><strong>高级物理模型</strong></li>
<li><strong>分层模型资源</strong></li>
<li><strong>几何实例化</strong></li>
</ul>
<p>ReadMore:<a href="https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/" rel="noopener noreferrer">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>
<p>ReadMore:<a href="https://github.com/rg3dengine/rg3d" rel="noopener noreferrer">https://github.com/rg3dengine/rg3d</a></p>
<hr>
<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8">
<div class="article-summary-box-inner">
<span><p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>
<p><strong>课程时间：</strong> 2021年8月22日 20:30-21:30</p>
<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>
<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>
<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>
<h3>课程大纲</h3>
<ol>
<li>
<p>什么是分布式追踪系统OpenTracing及应用场景</p>
</li>
<li>
<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>
</li>
<li>
<p>为什么需要tokio-rs/tracing库</p>
</li>
<li>
<p>演示Datafuse项目中tokio-rs/tracing的使用</p>
</li>
</ol>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">论坛github账户无法登录解决笔记</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190">
<div class="article-summary-box-inner">
<span><p>有反映这两天github账户无法登录了。</p>
<p>报这个错：</p>
<pre><code>get github user info err
</code></pre>
<p>查了几个地方：</p>
<ol>
<li>代码是否运行正常：Ok</li>
<li>https代理是否正常：Ok</li>
<li>检查了github返回日志，发现是：</li>
</ol>
<pre><code>get_github_user_info: response body: "{\"message\":\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\",\"documentation_url\":\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\"}"
get_github_user_info: Got: Err(Custom("read json login error"))
</code></pre>
<p>进入这个地址一看：<a href="https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/" rel="noopener noreferrer">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>
<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>
<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>
<p>特此记录。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 的 Future 与 Javascript 的 Promise 功能对照参考</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095">
<div class="article-summary-box-inner">
<span><h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>
<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>
<blockquote>
<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>
</blockquote>
<table>
<thead>
<tr>
<th>javascript</th>
<th align="center">rust</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Promise.resolve(...)</td>
<td align="center">use ::async_std::future;future::ready(Ok(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.reject(...)</td>
<td align="center">use ::async_std::future;future::ready(Err(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.catch(err =&gt; err)</td>
<td align="center">use ::async_std::future;future::ready(...)</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>new Promise(() =&gt; {/* 什么都不做 */})</td>
<td align="center">use ::async_std::future;future::pending()</td>
<td align="center"></td>
</tr>
<tr>
<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; { if (Math.random() &gt; .5) { resolve(1); } else { reject(new Error('1')); }}, 500))</td>
<td align="center">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| { thread::sleep(Duration::from_millis(500)); let mut rng = rand::thread_rng(); if rng.gen() &gt; 0.5f64 { Ok(1) } else { Err('1') }}).await;</td>
<td align="center">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被 （1）跨线程传递 （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>
</tr>
<tr>
<td>Promise.all([promise1, promise2, promise3])</td>
<td align="center">future1.try_join(future2).try_join(future3).await</td>
<td align="center">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>
</tr>
<tr>
<td>Promise.all([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.join(future2).join(future3).await</td>
<td align="center">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>
</tr>
<tr>
<td>Promise.race([promise1, promise2, promise3])</td>
<td align="center">future1.try_race(future2).try_race(future3).await</td>
<td align="center">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>
</tr>
<tr>
<td>Promise.race([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.race(future2).race(future3).await</td>
<td align="center">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>
</tr>
</tbody>
</table>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：《通过实战理解 Rust 宏》| Vol. 3</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>
<p><strong>课程时间：</strong> 2021年8月15日 20:30-21:30</p>
<p><strong>课程介绍：</strong></p>
<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg" alt></p>
<p>这就是通过宏实现配置的统一行为，代码参考：
https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>
<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>
<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>
<h3>课程大纲</h3>
<ul>
<li>什么是 Rust 宏</li>
<li>什么是宏运行原理</li>
<li>如何创建 Rust 宏过程</li>
<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>
</ul>
<p><strong>讲师介绍</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
</span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-20T01:30:00Z">09-20</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">Fast-Slow Transformer for Visually Grounding Speech. (arXiv:2109.08186v1 [eess.AS])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08186">
<div class="article-summary-box-inner">
<span><p>We present Fast-Slow Transformer for Visually Grounding Speech, or FaST-VGS.
FaST-VGS is a Transformer-based model for learning the associations between raw
speech waveforms and visual images. The model unifies dual-encoder and
cross-attention architectures into a single model, reaping the superior
retrieval speed of the former along with the accuracy of the latter. FaST-VGS
achieves state-of-the-art speech-image retrieval accuracy on benchmark
datasets, and its learned representations exhibit strong performance on the
ZeroSpeech 2021 phonetic and semantic tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Numerical reasoning in machine reading comprehension tasks: are we there yet?. (arXiv:2109.08207v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08207">
<div class="article-summary-box-inner">
<span><p>Numerical reasoning based machine reading comprehension is a task that
involves reading comprehension along with using arithmetic operations such as
addition, subtraction, sorting, and counting. The DROP benchmark (Dua et al.,
2019) is a recent dataset that has inspired the design of NLP models aimed at
solving this task. The current standings of these models in the DROP
leaderboard, over standard metrics, suggest that the models have achieved
near-human performance. However, does this mean that these models have learned
to reason? In this paper, we present a controlled study on some of the
top-performing model architectures for the task of numerical reasoning. Our
observations suggest that the standard metrics are incapable of measuring
progress towards such tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Control of Situated Agents through Natural Language. (arXiv:2109.08214v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08214">
<div class="article-summary-box-inner">
<span><p>When humans conceive how to perform a particular task, they do so
hierarchically: splitting higher-level tasks into smaller sub-tasks. However,
in the literature on natural language (NL) command of situated agents, most
works have treated the procedures to be executed as flat sequences of simple
actions, or any hierarchies of procedures have been shallow at best. In this
paper, we propose a formalism of procedures as programs, a powerful yet
intuitive method of representing hierarchical procedural knowledge for agent
command and control. We further propose a modeling paradigm of hierarchical
modular networks, which consist of a planner and reactors that convert NL
intents to predictions of executable programs and probe the environment for
information necessary to complete the program execution. We instantiate this
framework on the IQA and ALFRED datasets for NL instruction following. Our
model outperforms reactive baselines by a large margin on both datasets. We
also demonstrate that our framework is more data-efficient, and that it allows
for fast iterative development.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Bag of Tricks for Dialogue Summarization. (arXiv:2109.08232v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08232">
<div class="article-summary-box-inner">
<span><p>Dialogue summarization comes with its own peculiar challenges as opposed to
news or scientific articles summarization. In this work, we explore four
different challenges of the task: handling and differentiating parts of the
dialogue belonging to multiple speakers, negation understanding, reasoning
about the situation, and informal language understanding. Using a pretrained
sequence-to-sequence language model, we explore speaker name substitution,
negation scope highlighting, multi-task learning with relevant tasks, and
pretraining on in-domain data. Our experiments show that our proposed
techniques indeed improve summarization performance, outperforming strong
baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Regularized Training of Nearest Neighbor Language Models. (arXiv:2109.08249v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08249">
<div class="article-summary-box-inner">
<span><p>Including memory banks in a natural language processing architecture
increases model capacity by equipping it with additional data at inference
time. In this paper, we build upon $k$NN-LM \citep{khandelwal20generalization},
which uses a pre-trained language model together with an exhaustive $k$NN
search through the training data (memory bank) to achieve state-of-the-art
results. We investigate whether we can improve the $k$NN-LM performance by
instead training a LM with the knowledge that we will be using a $k$NN
post-hoc. We achieved significant improvement using our method on language
modeling tasks on \texttt{WIKI-2} and \texttt{WIKI-103}. The main phenomenon
that we encounter is that adding a simple L2 regularization on the activations
(not weights) of the model, a transformer, improves the post-hoc $k$NN
classification performance. We explore some possible reasons for this
improvement. In particular, we find that the added L2 regularization seems to
improve the performance for high-frequency words without deteriorating the
performance for low frequency ones.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Balancing out Bias: Achieving Fairness Through Training Reweighting. (arXiv:2109.08253v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08253">
<div class="article-summary-box-inner">
<span><p>Bias in natural language processing arises primarily from models learning
characteristics of the author such as gender and race when modelling tasks such
as sentiment and syntactic parsing. This problem manifests as disparities in
error rates across author demographics, typically disadvantaging minority
groups. Existing methods for mitigating and measuring bias do not directly
account for correlations between author demographics and linguistic variables.
Moreover, evaluation of bias has been inconsistent in previous work, in terms
of dataset balance and evaluation methods. This paper introduces a very simple
but highly effective method for countering bias using instance reweighting,
based on the frequency of both task labels and author demographics. We extend
the method in the form of a gated model which incorporates the author
demographic as an input, and show that while it is highly vulnerable to input
data bias, it provides debiased predictions through demographic input
perturbation, and outperforms all other bias mitigation techniques when
combined with instance reweighting.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ethics Sheet for Automatic Emotion Recognition and Sentiment Analysis. (arXiv:2109.08256v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08256">
<div class="article-summary-box-inner">
<span><p>The importance and pervasiveness of emotions in our lives makes affective
computing a tremendously important and vibrant line of work. Systems for
automatic emotion recognition (AER) and sentiment analysis can be facilitators
of enormous progress (e.g., in improving public health and commerce) but also
enablers of great harm (e.g., for suppressing dissidents and manipulating
voters). Thus, it is imperative that the affective computing community actively
engage with the ethical ramifications of their creations. In this paper, I have
synthesized and organized information from AI Ethics and Emotion Recognition
literature to present fifty ethical considerations relevant to AER. Notably,
the sheet fleshes out assumptions hidden in how AER is commonly framed, and in
the choices often made regarding the data, method, and evaluation. Special
attention is paid to the implications of AER on privacy and social groups. The
objective of the sheet is to facilitate and encourage more thoughtfulness on
why to automate, how to automate, and how to judge success well before the
building of AER systems. Additionally, the sheet acts as a useful introductory
document on emotion recognition (complementing survey articles).
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-training with Few-shot Rationalization: Teacher Explanations Aid Student in Few-shot NLU. (arXiv:2109.08259v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08259">
<div class="article-summary-box-inner">
<span><p>While pre-trained language models have obtained state-of-the-art performance
for several natural language understanding tasks, they are quite opaque in
terms of their decision-making process. While some recent works focus on
rationalizing neural predictions by highlighting salient concepts in the text
as justifications or rationales, they rely on thousands of labeled training
examples for both task labels as well as an-notated rationales for every
instance. Such extensive large-scale annotations are infeasible to obtain for
many tasks. To this end, we develop a multi-task teacher-student framework
based on self-training language models with limited task-specific labels and
rationales, and judicious sample selection to learn from informative
pseudo-labeled examples1. We study several characteristics of what constitutes
a good rationale and demonstrate that the neural model performance can be
significantly improved by making it aware of its rationalized predictions,
particularly in low-resource settings. Extensive experiments in several
bench-mark datasets demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Language Models as a Knowledge Source for Cognitive Agents. (arXiv:2109.08270v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08270">
<div class="article-summary-box-inner">
<span><p>Language models (LMs) are sentence-completion engines trained on massive
corpora. LMs have emerged as a significant breakthrough in natural-language
processing, providing capabilities that go far beyond sentence completion
including question answering, summarization, and natural-language inference.
While many of these capabilities have potential application to cognitive
systems, exploiting language models as a source of task knowledge, especially
for task learning, offers significant, near-term benefits. We introduce
language models and the various tasks to which they have been applied and then
review methods of knowledge extraction from language models. The resulting
analysis outlines both the challenges and opportunities for using language
models as a new knowledge source for cognitive systems. It also identifies
possible ways to improve knowledge extraction from language models using the
capabilities provided by cognitive systems. Central to success will be the
ability of a cognitive agent to itself learn an abstract model of the knowledge
implicit in the LM as well as methods to extract high-quality knowledge
effectively and efficiently. To illustrate, we introduce a hypothetical robot
agent and describe how language models could extend its task knowledge and
improve its performance and the kinds of knowledge and methods the agent can
use to exploit the knowledge within a language model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis. (arXiv:2109.08306v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08306">
<div class="article-summary-box-inner">
<span><p>Aspect-based sentiment analysis (ABSA) is an emerging fine-grained sentiment
analysis task that aims to extract aspects, classify corresponding sentiment
polarities and find opinions as the causes of sentiment. The latest research
tends to solve the ABSA task in a unified way with end-to-end frameworks. Yet,
these frameworks get fine-tuned from downstream tasks without any task-adaptive
modification. Specifically, they do not use task-related knowledge well or
explicitly model relations between aspect and opinion terms, hindering them
from better performance. In this paper, we propose SentiPrompt to use sentiment
knowledge enhanced prompts to tune the language model in the unified framework.
We inject sentiment knowledge regarding aspects, opinions, and polarities into
prompt and explicitly model term relations via constructing consistency and
polarity judgment templates from the ground truth triplets. Experimental
results demonstrate that our approach can outperform strong baselines on
Triplet Extraction, Pair Extraction, and Aspect Term Extraction with Sentiment
Classification by a notable margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Multimodal Sentiment Dataset for Video Recommendation. (arXiv:2109.08333v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08333">
<div class="article-summary-box-inner">
<span><p>Recently, multimodal sentiment analysis has seen remarkable advance and a lot
of datasets are proposed for its development. In general, current multimodal
sentiment analysis datasets usually follow the traditional system of
sentiment/emotion, such as positive, negative and so on. However, when applied
in the scenario of video recommendation, the traditional sentiment/emotion
system is hard to be leveraged to represent different contents of videos in the
perspective of visual senses and language understanding. Based on this, we
propose a multimodal sentiment analysis dataset, named baiDu Video Sentiment
dataset (DuVideoSenti), and introduce a new sentiment system which is designed
to describe the sentimental style of a video on recommendation scenery.
Specifically, DuVideoSenti consists of 5,630 videos which displayed on Baidu,
each video is manually annotated with a sentimental style label which describes
the user's real feeling of a video. Furthermore, we propose UNIMO as our
baseline for DuVideoSenti. Experimental results show that DuVideoSenti brings
new challenges to multimodal sentiment analysis, and could be used as a new
benchmark for evaluating approaches designed for video understanding and
multimodal fusion. We also expect our proposed DuVideoSenti could further
improve the development of multimodal sentiment analysis and its application to
video recommendations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Task-adaptive Pre-training of Language Models with Word Embedding Regularization. (arXiv:2109.08354v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08354">
<div class="article-summary-box-inner">
<span><p>Pre-trained language models (PTLMs) acquire domain-independent linguistic
knowledge through pre-training with massive textual resources. Additional
pre-training is effective in adapting PTLMs to domains that are not well
covered by the pre-training corpora. Here, we focus on the static word
embeddings of PTLMs for domain adaptation to teach PTLMs domain-specific
meanings of words. We propose a novel fine-tuning process: task-adaptive
pre-training with word embedding regularization (TAPTER). TAPTER runs
additional pre-training by making the static word embeddings of a PTLM close to
the word embeddings obtained in the target domain with fastText. TAPTER
requires no additional corpus except for the training data of the downstream
task. We confirmed that TAPTER improves the performance of the standard
fine-tuning and the task-adaptive pre-training on BioASQ (question answering in
the biomedical domain) and on SQuAD (the Wikipedia domain) when their
pre-training corpora were not dominated by in-domain data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Distilling Linguistic Context for Language Model Compression. (arXiv:2109.08359v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08359">
<div class="article-summary-box-inner">
<span><p>A computationally expensive and memory intensive neural network lies behind
the recent success of language representation learning. Knowledge distillation,
a major technique for deploying such a vast language model in resource-scarce
environments, transfers the knowledge on individual word representations
learned without restrictions. In this paper, inspired by the recent
observations that language representations are relatively positioned and have
more semantic knowledge as a whole, we present a new knowledge distillation
objective for language representation learning that transfers the contextual
knowledge via two types of relationships across representations: Word Relation
and Layer Transforming Relation. Unlike other recent distillation techniques
for the language models, our contextual distillation does not have any
restrictions on architectural changes between teacher and student. We validate
the effectiveness of our method on challenging benchmarks of language
understanding tasks, not only in architectures of various sizes, but also in
combination with DynaBERT, the recently proposed adaptive size pruning method.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CodeQA: A Question Answering Dataset for Source Code Comprehension. (arXiv:2109.08365v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08365">
<div class="article-summary-box-inner">
<span><p>We propose CodeQA, a free-form question answering dataset for the purpose of
source code comprehension: given a code snippet and a question, a textual
answer is required to be generated. CodeQA contains a Java dataset with 119,778
question-answer pairs and a Python dataset with 70,085 question-answer pairs.
To obtain natural and faithful questions and answers, we implement syntactic
rules and semantic analysis to transform code comments into question-answer
pairs. We present the construction process and conduct systematic analysis of
our dataset. Experiment results achieved by several neural baselines on our
dataset are shown and discussed. While research on question-answering and
machine reading comprehension develops rapidly, few prior work has drawn
attention to code question answering. This new dataset can serve as a useful
research benchmark for source code comprehension.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To be Closer: Learning to Link up Aspects with Opinions. (arXiv:2109.08382v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08382">
<div class="article-summary-box-inner">
<span><p>Dependency parse trees are helpful for discovering the opinion words in
aspect-based sentiment analysis (ABSA). However, the trees obtained from
off-the-shelf dependency parsers are static, and could be sub-optimal in ABSA.
This is because the syntactic trees are not designed for capturing the
interactions between opinion words and aspect words. In this work, we aim to
shorten the distance between aspects and corresponding opinion words by
learning an aspect-centric tree structure. The aspect and opinion words are
expected to be closer along such tree structure compared to the standard
dependency parse tree. The learning process allows the tree structure to
adaptively correlate the aspect and opinion words, enabling us to better
identify the polarity in the ABSA task. We conduct experiments on five
aspect-based sentiment datasets, and the proposed model significantly
outperforms recent strong baselines. Furthermore, our thorough analysis
demonstrates the average distance between aspect and opinion words are
shortened by at least 19% on the standard SemEval Restaurant14 dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">reproducing "ner and pos when nothing is capitalized". (arXiv:2109.08396v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08396">
<div class="article-summary-box-inner">
<span><p>Capitalization is an important feature in many NLP tasks such as Named Entity
Recognition (NER) or Part of Speech Tagging (POS). We are trying to reproduce
results of paper which shows how to mitigate a significant performance drop
when casing is mismatched between training and testing data. In particular we
show that lowercasing 50% of the dataset provides the best performance,
matching the claims of the original paper. We also show that we got slightly
lower performance in almost all experiments we have tried to reproduce,
suggesting that there might be some hidden factors impacting our performance.
Lastly, we make all of our work available in a public github repository.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fine-Tuned Transformers Show Clusters of Similar Representations Across Layers. (arXiv:2109.08406v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08406">
<div class="article-summary-box-inner">
<span><p>Despite the success of fine-tuning pretrained language encoders like BERT for
downstream natural language understanding (NLU) tasks, it is still poorly
understood how neural networks change after fine-tuning. In this work, we use
centered kernel alignment (CKA), a method for comparing learned
representations, to measure the similarity of representations in task-tuned
models across layers. In experiments across twelve NLU tasks, we discover a
consistent block diagonal structure in the similarity of representations within
fine-tuned RoBERTa and ALBERT models, with strong similarity within clusters of
earlier and later layers, but not between them. The similarity of later layer
representations implies that later layers only marginally contribute to task
performance, and we verify in experiments that the top few layers of fine-tuned
Transformers can be discarded without hurting performance, even with no further
tuning.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Role-Selected Sharing Network for Joint Machine-Human Chatting Handoff and Service Satisfaction Analysis. (arXiv:2109.08412v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08412">
<div class="article-summary-box-inner">
<span><p>Chatbot is increasingly thriving in different domains, however, because of
unexpected discourse complexity and training data sparseness, its potential
distrust hatches vital apprehension. Recently, Machine-Human Chatting Handoff
(MHCH), predicting chatbot failure and enabling human-algorithm collaboration
to enhance chatbot quality, has attracted increasing attention from industry
and academia. In this study, we propose a novel model, Role-Selected Sharing
Network (RSSN), which integrates both dialogue satisfaction estimation and
handoff prediction in one multi-task learning framework. Unlike prior efforts
in dialog mining, by utilizing local user satisfaction as a bridge, global
satisfaction detector and handoff predictor can effectively exchange critical
information. Specifically, we decouple the relation and interaction between the
two tasks by the role information after the shared encoder. Extensive
experiments on two public datasets demonstrate the effectiveness of our model.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">New Students on Sesame Street: What Order-Aware Matrix Embeddings Can Learn from BERT. (arXiv:2109.08449v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08449">
<div class="article-summary-box-inner">
<span><p>Large-scale pretrained language models (PreLMs) are revolutionizing natural
language processing across all benchmarks. However, their sheer size is
prohibitive in low-resource or large-scale applications. While common
approaches reduce the size of PreLMs via same-architecture distillation or
pruning, we explore distilling PreLMs into more efficient order-aware embedding
models. Our results on the GLUE benchmark show that embedding-centric students,
which have learned from BERT, yield scores comparable to DistilBERT on QQP and
RTE, often match or exceed the scores of ELMo, and only fall behind on
detecting linguistic acceptability.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Neural Unification for Logic Reasoning over Natural Language. (arXiv:2109.08460v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08460">
<div class="article-summary-box-inner">
<span><p>Automated Theorem Proving (ATP) deals with the development of computer
programs being able to show that some conjectures (queries) are a logical
consequence of a set of axioms (facts and rules). There exists several
successful ATPs where conjectures and axioms are formally provided (e.g.
formalised as First Order Logic formulas). Recent approaches, such as (Clark et
al., 2020), have proposed transformer-based architectures for deriving
conjectures given axioms expressed in natural language (English). The
conjecture is verified through a binary text classifier, where the transformers
model is trained to predict the truth value of a conjecture given the axioms.
The RuleTaker approach of (Clark et al., 2020) achieves appealing results both
in terms of accuracy and in the ability to generalize, showing that when the
model is trained with deep enough queries (at least 3 inference steps), the
transformers are able to correctly answer the majority of queries (97.6%) that
require up to 5 inference steps. In this work we propose a new architecture,
namely the Neural Unifier, and a relative training procedure, which achieves
state-of-the-art results in term of generalisation, showing that mimicking a
well-known inference procedure, the backward chaining, it is possible to answer
deep queries even when the model is trained only on shallow ones. The approach
is demonstrated in experiments using a diverse set of benchmark data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">GoG: Relation-aware Graph-over-Graph Network for Visual Dialog. (arXiv:2109.08475v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08475">
<div class="article-summary-box-inner">
<span><p>Visual dialog, which aims to hold a meaningful conversation with humans about
a given image, is a challenging task that requires models to reason the complex
dependencies among visual content, dialog history, and current questions. Graph
neural networks are recently applied to model the implicit relations between
objects in an image or dialog. However, they neglect the importance of 1)
coreference relations among dialog history and dependency relations between
words for the question representation; and 2) the representation of the image
based on the fully represented question. Therefore, we propose a novel
relation-aware graph-over-graph network (GoG) for visual dialog. Specifically,
GoG consists of three sequential graphs: 1) H-Graph, which aims to capture
coreference relations among dialog history; 2) History-aware Q-Graph, which
aims to fully understand the question through capturing dependency relations
between words based on coreference resolution on the dialog history; and 3)
Question-aware I-Graph, which aims to capture the relations between objects in
an image based on fully question representation. As an additional feature
representation module, we add GoG to the existing visual dialogue model.
Experimental results show that our model outperforms the strong baseline in
both generative and discriminative settings by a significant margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Multimodal Incremental Transformer with Visual Grounding for Visual Dialogue Generation. (arXiv:2109.08478v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08478">
<div class="article-summary-box-inner">
<span><p>Visual dialogue is a challenging task since it needs to answer a series of
coherent questions on the basis of understanding the visual environment.
Previous studies focus on the implicit exploration of multimodal co-reference
by implicitly attending to spatial image features or object-level image
features but neglect the importance of locating the objects explicitly in the
visual content, which is associated with entities in the textual content.
Therefore, in this paper we propose a {\bf M}ultimodal {\bf I}ncremental {\bf
T}ransformer with {\bf V}isual {\bf G}rounding, named MITVG, which consists of
two key parts: visual grounding and multimodal incremental transformer. Visual
grounding aims to explicitly locate related objects in the image guided by
textual entities, which helps the model exclude the visual content that does
not need attention. On the basis of visual grounding, the multimodal
incremental transformer encodes the multi-turn dialogue history combined with
visual scene step by step according to the order of the dialogue and then
generates a contextually and visually coherent response. Experimental results
on the VisDial v0.9 and v1.0 datasets demonstrate the superiority of the
proposed model, which achieves comparable performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Simple Entity-Centric Questions Challenge Dense Retrievers. (arXiv:2109.08535v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08535">
<div class="article-summary-box-inner">
<span><p>Open-domain question answering has exploded in popularity recently due to the
success of dense retrieval models, which have surpassed sparse models using
only a few supervised training examples. However, in this paper, we demonstrate
current dense models are not yet the holy grail of retrieval. We first
construct EntityQuestions, a set of simple, entity-rich questions based on
facts from Wikidata (e.g., "Where was Arve Furset born?"), and observe that
dense retrievers drastically underperform sparse methods. We investigate this
issue and uncover that dense retrievers can only generalize to common entities
unless the question pattern is explicitly observed during training. We discuss
two simple solutions towards addressing this critical problem. First, we
demonstrate that data augmentation is unable to fix the generalization problem.
Second, we argue a more robust passage encoder helps facilitate better question
adaptation using specialized question encoders. We hope our work can shed light
on the challenges in creating a robust, universal dense retriever that works
well across different input distributions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and Symbolic Logic Rules. (arXiv:2109.08544v1 [cs.AI])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08544">
<div class="article-summary-box-inner">
<span><p>One of the challenges faced by conversational agents is their inability to
identify unstated presumptions of their users' commands, a task trivial for
humans due to their common sense. In this paper, we propose a zero-shot
commonsense reasoning system for conversational agents in an attempt to achieve
this. Our reasoner uncovers unstated presumptions from user commands satisfying
a general template of if-(state), then-(action), because-(goal). Our reasoner
uses a state-of-the-art transformer-based generative commonsense knowledge base
(KB) as its source of background knowledge for reasoning. We propose a novel
and iterative knowledge query mechanism to extract multi-hop reasoning chains
from the neural KB which uses symbolic logic rules to significantly reduce the
search space. Similar to any KBs gathered to date, our commonsense KB is prone
to missing knowledge. Therefore, we propose to conversationally elicit the
missing knowledge from human users with our novel dynamic question generation
strategy, which generates and presents contextualized queries to human users.
We evaluate the model with a user study with human users that achieves a 35%
higher success rate compared to SOTA.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Slot Filling for Biomedical Information Extraction. (arXiv:2109.08564v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08564">
<div class="article-summary-box-inner">
<span><p>Information Extraction (IE) from text refers to the task of extracting
structured knowledge from unstructured text. The task typically consists of a
series of sub-tasks such as Named Entity Recognition and Relation Extraction.
Sourcing entity and relation type specific training data is a major bottleneck
in the above sub-tasks.In this work we present a slot filling approach to the
task of biomedical IE, effectively replacing the need for entity and
relation-specific training data, allowing to deal with zero-shot settings. We
follow the recently proposed paradigm of coupling a Tranformer-based
bi-encoder, Dense Passage Retrieval, with a Transformer-based reader model to
extract relations from biomedical text. We assemble a biomedical slot filling
dataset for both retrieval and reading comprehension and conduct a series of
experiments demonstrating that our approach outperforms a number of simpler
baselines. We also evaluate our approach end-to-end for standard as well as
zero-shot settings. Our work provides a fresh perspective on how to solve
biomedical IE tasks, in the absence of relevant training data. Our code, models
and pretrained data are available at
https://github.com/healx/biomed-slot-filling.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Exploring Multitask Learning for Low-Resource AbstractiveSummarization. (arXiv:2109.08565v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08565">
<div class="article-summary-box-inner">
<span><p>This paper explores the effect of using multitask learning for abstractive
summarization in the context of small training corpora. In particular, we
incorporate four different tasks (extractive summarization, language modeling,
concept detection, and paraphrase detection) both individually and in
combination, with the goal of enhancing the target task of abstractive
summarization via multitask learning. We show that for many task combinations,
a model trained in a multitask setting outperforms a model trained only for
abstractive summarization, with no additional summarization data introduced.
Additionally, we do a comprehensive search and find that certain tasks (e.g.
paraphrase detection) consistently benefit abstractive summarization, not only
when combined with other tasks but also when using different architectures and
training corpora.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating Data Scarceness through Data Synthesis, Augmentation and Curriculum for Abstractive Summarization. (arXiv:2109.08569v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08569">
<div class="article-summary-box-inner">
<span><p>This paper explores three simple data manipulation techniques (synthesis,
augmentation, curriculum) for improving abstractive summarization models
without the need for any additional data. We introduce a method of data
synthesis with paraphrasing, a data augmentation technique with sample mixing,
and curriculum learning with two new difficulty metrics based on specificity
and abstractiveness. We conduct experiments to show that these three techniques
can help improve abstractive summarization across two summarization models and
two different small datasets. Furthermore, we show that these techniques can
improve performance when applied in isolation and when combined.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchy-Aware T5 with Path-Adaptive Mask Mechanism for Hierarchical Text Classification. (arXiv:2109.08585v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08585">
<div class="article-summary-box-inner">
<span><p>Hierarchical Text Classification (HTC), which aims to predict text labels
organized in hierarchical space, is a significant task lacking in investigation
in natural language processing. Existing methods usually encode the entire
hierarchical structure and fail to construct a robust label-dependent model,
making it hard to make accurate predictions on sparse lower-level labels and
achieving low Macro-F1. In this paper, we propose a novel PAMM-HiA-T5 model for
HTC: a hierarchy-aware T5 model with path-adaptive mask mechanism that not only
builds the knowledge of upper-level labels into low-level ones but also
introduces path dependency information in label prediction. Specifically, we
generate a multi-level sequential label structure to exploit hierarchical
dependency across different levels with Breadth-First Search (BFS) and T5
model. To further improve label dependency prediction within each path, we then
propose an original path-adaptive mask mechanism (PAMM) to identify the label's
path information, eliminating sources of noises from other paths. Comprehensive
experiments on three benchmark datasets show that our novel PAMM-HiA-T5 model
greatly outperforms all state-of-the-art HTC approaches especially in Macro-F1.
The ablation studies show that the improvements mainly come from our innovative
approach instead of T5.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Does Commonsense help in detecting Sarcasm?. (arXiv:2109.08588v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08588">
<div class="article-summary-box-inner">
<span><p>Sarcasm detection is important for several NLP tasks such as sentiment
identification in product reviews, user feedback, and online forums. It is a
challenging task requiring a deep understanding of language, context, and world
knowledge. In this paper, we investigate whether incorporating commonsense
knowledge helps in sarcasm detection. For this, we incorporate commonsense
knowledge into the prediction process using a graph convolution network with
pre-trained language model embeddings as input. Our experiments with three
sarcasm detection datasets indicate that the approach does not outperform the
baseline model. We perform an exhaustive set of experiments to analyze where
commonsense support adds value and where it hurts classification. Our
implementation is publicly available at:
https://github.com/brcsomnath/commonsense-sarcasm.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Boosting Transformers for Job Expression Extraction and Classification in a Low-Resource Setting. (arXiv:2109.08597v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08597">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore possible improvements of transformer models in a
low-resource setting. In particular, we present our approaches to tackle the
first two of three subtasks of the MEDDOPROF competition, i.e., the extraction
and classification of job expressions in Spanish clinical texts. As neither
language nor domain experts, we experiment with the multilingual XLM-R
transformer model and tackle these low-resource information extraction tasks as
sequence-labeling problems. We explore domain- and language-adaptive
pretraining, transfer learning and strategic datasplits to boost the
transformer model. Our results show strong improvements using these methods by
up to 5.3 F1 points compared to a fine-tuned XLM-R model. Our best models
achieve 83.2 and 79.3 F1 for the first two tasks, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The futility of STILTs for the classification of lexical borrowings in Spanish. (arXiv:2109.08607v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08607">
<div class="article-summary-box-inner">
<span><p>The first edition of the IberLEF 2021 shared task on automatic detection of
borrowings (ADoBo) focused on detecting lexical borrowings that appeared in the
Spanish press and that have recently been imported into the Spanish language.
In this work, we tested supplementary training on intermediate labeled-data
tasks (STILTs) from part of speech (POS), named entity recognition (NER),
code-switching, and language identification approaches to the classification of
borrowings at the token level using existing pre-trained transformer-based
language models. Our extensive experimental results suggest that STILTs do not
provide any improvement over direct fine-tuning of multilingual models.
However, multilingual models trained on small subsets of languages perform
reasonably better than multilingual BERT but not as good as multilingual
RoBERTa for the given dataset.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Adversarial Scrubbing of Demographic Information for Text Classification. (arXiv:2109.08613v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08613">
<div class="article-summary-box-inner">
<span><p>Contextual representations learned by language models can often encode
undesirable attributes, like demographic associations of the users, while being
trained for an unrelated target task. We aim to scrub such undesirable
attributes and learn fair representations while maintaining performance on the
target task. In this paper, we present an adversarial learning framework
"Adversarial Scrubber" (ADS), to debias contextual representations. We perform
theoretical analysis to show that our framework converges without leaking
demographic information under certain conditions. We extend previous evaluation
techniques by evaluating debiasing performance using Minimum Description Length
(MDL) probing. Experimental evaluations on 8 datasets show that ADS generates
representations with minimal information about demographic attributes while
being maximally informative about the target task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CKMorph: A Comprehensive Morphological Analyzer for Central Kurdish. (arXiv:2109.08615v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08615">
<div class="article-summary-box-inner">
<span><p>A morphological analyzer, which is a significant component of many natural
language processing applications especially for morphologically rich languages,
divides an input word into all its composing morphemes and identifies their
morphological roles. In this paper, we introduce a comprehensive morphological
analyzer for Central Kurdish (CK), a low-resourced language with a rich
morphology. Building upon the limited existing literature, we first assembled
and systematically categorized a comprehensive collection of the morphological
and morphophonological rules of the language. Additionally, we collected and
manually labeled a generative lexicon containing nearly 10,000 verb, noun and
adjective stems, named entities, and other types of word stems. We used these
rule sets and resources to implement CKMorph Analyzer based on finite-state
transducers. In order to provide a benchmark for future research, we collected,
manually labeled, and publicly shared test sets for evaluating accuracy and
coverage of the analyzer. CKMorph was able to correctly analyze 95.9% of the
accuracy test set, containing 1,000 CK words morphologically analyzed according
to the context. Moreover, CKMorph gave at least one analysis for 95.5% of 4.22M
CK tokens of the coverage test set. The demonstration of the application and
resources including CK verb database and test sets are openly accessible at
https://github.com/CKMorph.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Classification-based Quality Estimation: Small and Efficient Models for Real-world Applications. (arXiv:2109.08627v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08627">
<div class="article-summary-box-inner">
<span><p>Sentence-level Quality estimation (QE) of machine translation is
traditionally formulated as a regression task, and the performance of QE models
is typically measured by Pearson correlation with human labels. Recent QE
models have achieved previously-unseen levels of correlation with human
judgments, but they rely on large multilingual contextualized language models
that are computationally expensive and make them infeasible for real-world
applications. In this work, we evaluate several model compression techniques
for QE and find that, despite their popularity in other NLP tasks, they lead to
poor performance in this regression setting. We observe that a full model
parameterization is required to achieve SoTA results in a regression task.
However, we argue that the level of expressiveness of a model in a continuous
range is unnecessary given the downstream applications of QE, and show that
reframing QE as a classification problem and evaluating QE models using
classification metrics would better reflect their actual performance in
real-world applications.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Grounding Natural Language Instructions: Can Large Language Models Capture Spatial Information?. (arXiv:2109.08634v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08634">
<div class="article-summary-box-inner">
<span><p>Models designed for intelligent process automation are required to be capable
of grounding user interface elements. This task of interface element grounding
is centred on linking instructions in natural language to their target
referents. Even though BERT and similar pre-trained language models have
excelled in several NLP tasks, their use has not been widely explored for the
UI grounding domain. This work concentrates on testing and probing the
grounding abilities of three different transformer-based models: BERT, RoBERTa
and LayoutLM. Our primary focus is on these models' spatial reasoning skills,
given their importance in this domain. We observe that LayoutLM has a promising
advantage for applications in this domain, even though it was created for a
different original purpose (representing scanned documents): the learned
spatial features appear to be transferable to the UI grounding setting,
especially as they demonstrate the ability to discriminate between target
directions in natural language instructions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Measuring of Readability to Improve Documents Accessibility for Arabic Language Learners. (arXiv:2109.08648v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08648">
<div class="article-summary-box-inner">
<span><p>This paper presents an approach based on supervised machine learning methods
to build a classifier that can identify text complexity in order to present
Arabic language learners with texts suitable to their levels. The approach is
based on machine learning classification methods to discriminate between the
different levels of difficulty in reading and understanding a text. Several
models were trained on a large corpus mined from online Arabic websites and
manually annotated. The model uses both Count and TF-IDF representations and
applies five machine learning algorithms; Multinomial Naive Bayes, Bernoulli
Naive Bayes, Logistic Regression, Support Vector Machine and Random Forest,
using unigrams and bigrams features. With the goal of extracting the text
complexity, the problem is usually addressed by formulating the level
identification as a classification task. Experimental results showed that
n-gram features could be indicative of the reading level of a text and could
substantially improve performance, and showed that SVM and Multinomial Naive
Bayes are the most accurate in predicting the complexity level. Best results
were achieved using TF-IDF Vectors trained by a combination of word-based
unigrams and bigrams with an overall accuracy of 87.14% over four classes of
complexity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Handling Unconstrained User Preferences in Dialogue. (arXiv:2109.08650v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08650">
<div class="article-summary-box-inner">
<span><p>A user input to a schema-driven dialogue information navigation system, such
as venue search, is typically constrained by the underlying database which
restricts the user to specify a predefined set of preferences, or slots,
corresponding to the database fields. We envision a more natural information
navigation dialogue interface where a user has flexibility to specify
unconstrained preferences that may not match a predefined schema. We propose to
use information retrieval from unstructured knowledge to identify entities
relevant to a user request. We update the Cambridge restaurants database with
unstructured knowledge snippets (reviews and information from the web) for each
of the restaurants and annotate a set of query-snippet pairs with a relevance
label. We use the annotated dataset to train and evaluate snippet relevance
classifiers, as a proxy to evaluating recommendation accuracy. We show that
with a pretrained transformer model as an encoder, an unsupervised/supervised
classifier achieves a weighted F1 of .661/.856.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Primer: Searching for Efficient Transformers for Language Modeling. (arXiv:2109.08668v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08668">
<div class="article-summary-box-inner">
<span><p>Large Transformer models have been central to recent advances in natural
language processing. The training and inference costs of these models, however,
have grown rapidly and become prohibitively expensive. Here we aim to reduce
the costs of Transformers by searching for a more efficient variant. Compared
to previous approaches, our search is performed at a lower level, over the
primitives that define a Transformer TensorFlow program. We identify an
architecture, named Primer, that has a smaller training cost than the original
Transformer and other variants for auto-regressive language modeling. Primer's
improvements can be mostly attributed to two simple modifications: squaring
ReLU activations and adding a depthwise convolution layer after each Q, K, and
V projection in self-attention.
</p>
<p>Experiments show Primer's gains over Transformer increase as compute scale
grows and follow a power law with respect to quality at optimal model sizes. We
also verify empirically that Primer can be dropped into different codebases to
significantly speed up training without additional tuning. For example, at a
500M parameter size, Primer improves the original T5 architecture on C4
auto-regressive language modeling, reducing the training cost by 4X.
Furthermore, the reduced training cost means Primer needs much less compute to
reach a target one-shot performance. For instance, in a 1.9B parameter
configuration similar to GPT-3 XL, Primer uses 1/3 of the training compute to
achieve the same one-shot performance as Transformer. We open source our models
and several comparisons in T5 to help with reproducibility.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering. (arXiv:2109.08678v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.08678">
<div class="article-summary-box-inner">
<span><p>Existing KBQA approaches, despite achieving strong performance on i.i.d. test
data, often struggle in generalizing to questions involving unseen KB schema
items. Prior ranking-based approaches have shown some success in
generalization, but suffer from the coverage issue. We present RnG-KBQA, a
Rank-and-Generate approach for KBQA, which remedies the coverage issue with a
generation model while preserving a strong generalization capability. Our
approach first uses a contrastive ranker to rank a set of candidate logical
forms obtained by searching over the knowledge graph. It then introduces a
tailored generation model conditioned on the question and the top-ranked
candidates to compose the final logical form. We achieve new state-of-the-art
results on GrailQA and WebQSP datasets. In particular, our method surpasses the
prior state-of-the-art by a large margin on the GrailQA leaderboard. In
addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP
benchmark, even including the ones that use the oracle entity linking. The
experimental results demonstrate the effectiveness of the interplay between
ranking and generation, which leads to the superior performance of our proposed
approach across all settings with especially strong improvements in zero-shot
generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Capturing Global Informativeness in Open Domain Keyphrase Extraction. (arXiv:2004.13639v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13639">
<div class="article-summary-box-inner">
<span><p>Open-domain KeyPhrase Extraction (KPE) aims to extract keyphrases from
documents without domain or quality restrictions, e.g., web pages with variant
domains and qualities. Recently, neural methods have shown promising results in
many KPE tasks due to their powerful capacity for modeling contextual semantics
of the given documents. However, we empirically show that most neural KPE
methods prefer to extract keyphrases with good phraseness, such as short and
entity-style n-grams, instead of globally informative keyphrases from
open-domain documents. This paper presents JointKPE, an open-domain KPE
architecture built on pre-trained language models, which can capture both local
phraseness and global informativeness when extracting keyphrases. JointKPE
learns to rank keyphrases by estimating their informativeness in the entire
document and is jointly trained on the keyphrase chunking task to guarantee the
phraseness of keyphrase candidates. Experiments on two large KPE datasets with
diverse domains, OpenKP and KP20k, demonstrate the effectiveness of JointKPE on
different pre-trained variants in open-domain scenarios. Further analyses
reveal the significant advantages of JointKPE in predicting long and non-entity
keyphrases, which are challenging for previous neural KPE methods. Our code is
publicly available at https://github.com/thunlp/BERT-KPE.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing. (arXiv:2007.15779v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15779">
<div class="article-summary-box-inner">
<span><p>Pretraining large neural language models, such as BERT, has led to impressive
gains on many natural language processing (NLP) tasks. However, most
pretraining efforts focus on general domain corpora, such as newswire and Web.
A prevailing assumption is that even domain-specific pretraining can benefit by
starting from general-domain language models. In this paper, we challenge this
assumption by showing that for domains with abundant unlabeled text, such as
biomedicine, pretraining language models from scratch results in substantial
gains over continual pretraining of general-domain language models. To
facilitate this investigation, we compile a comprehensive biomedical NLP
benchmark from publicly-available datasets. Our experiments show that
domain-specific pretraining serves as a solid foundation for a wide range of
biomedical NLP tasks, leading to new state-of-the-art results across the board.
Further, in conducting a thorough evaluation of modeling choices, both for
pretraining and task-specific fine-tuning, we discover that some common
practices are unnecessary with BERT models, such as using complex tagging
schemes in named entity recognition (NER). To help accelerate research in
biomedical NLP, we have released our state-of-the-art pretrained and
task-specific models for the community, and created a leaderboard featuring our
BLURB benchmark (short for Biomedical Language Understanding &amp; Reasoning
Benchmark) at https://aka.ms/BLURB.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-supervised Document Clustering Based on BERT with Data Augment. (arXiv:2011.08523v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08523">
<div class="article-summary-box-inner">
<span><p>Contrastive learning is a promising approach to unsupervised learning, as it
inherits the advantages of well-studied deep models without a dedicated and
complex model design. In this paper, based on bidirectional encoder
representations from transformers, we propose self-supervised contrastive
learning (SCL) as well as few-shot contrastive learning (FCL) with unsupervised
data augmentation (UDA) for text clustering. SCL outperforms state-of-the-art
unsupervised clustering approaches for short texts and those for long texts in
terms of several clustering evaluation measures. FCL achieves performance close
to supervised learning, and FCL with UDA further improves the performance for
short texts.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">To what extent do human explanations of model behavior align with actual model behavior?. (arXiv:2012.13354v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13354">
<div class="article-summary-box-inner">
<span><p>Given the increasingly prominent role NLP models (will) play in our lives, it
is important for human expectations of model behavior to align with actual
model behavior. Using Natural Language Inference (NLI) as a case study, we
investigate the extent to which human-generated explanations of models'
inference decisions align with how models actually make these decisions. More
specifically, we define three alignment metrics that quantify how well natural
language explanations align with model sensitivity to input words, as measured
by integrated gradients. Then, we evaluate eight different models (the base and
large versions of BERT, RoBERTa and ELECTRA, as well as anRNN and bag-of-words
model), and find that the BERT-base model has the highest alignment with
human-generated explanations, for all alignment metrics. Focusing in on
transformers, we find that the base versions tend to have higher alignment with
human-generated explanations than their larger counterparts, suggesting that
increasing the number of model parameters leads, in some cases, to worse
alignment with human explanations. Finally, we find that a model's alignment
with human explanations is not predicted by the model's accuracy, suggesting
that accuracy and alignment are complementary ways to evaluate models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ECONET: Effective Continual Pretraining of Language Models for Event Temporal Reasoning. (arXiv:2012.15283v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15283">
<div class="article-summary-box-inner">
<span><p>While pre-trained language models (PTLMs) have achieved noticeable success on
many NLP tasks, they still struggle for tasks that require event temporal
reasoning, which is essential for event-centric applications. We present a
continual pre-training approach that equips PTLMs with targeted knowledge about
event temporal relations. We design self-supervised learning objectives to
recover masked-out event and temporal indicators and to discriminate sentences
from their corrupted counterparts (where event or temporal indicators got
replaced). By further pre-training a PTLM with these objectives jointly, we
reinforce its attention to event and temporal information, yielding enhanced
capability on event temporal reasoning. This effective continual pre-training
framework for event temporal reasoning (ECONET) improves the PTLMs' fine-tuning
performances across five relation extraction and question answering tasks and
achieves new or on-par state-of-the-art performances in most of our downstream
tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">ERNIE-M: Enhanced Multilingual Representation by Aligning Cross-lingual Semantics with Monolingual Corpora. (arXiv:2012.15674v4 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15674">
<div class="article-summary-box-inner">
<span><p>Recent studies have demonstrated that pre-trained cross-lingual models
achieve impressive performance in downstream cross-lingual tasks. This
improvement benefits from learning a large amount of monolingual and parallel
corpora. Although it is generally acknowledged that parallel corpora are
critical for improving the model performance, existing methods are often
constrained by the size of parallel corpora, especially for low-resource
languages. In this paper, we propose ERNIE-M, a new training method that
encourages the model to align the representation of multiple languages with
monolingual corpora, to overcome the constraint that the parallel corpus size
places on the model performance. Our key insight is to integrate
back-translation into the pre-training process. We generate pseudo-parallel
sentence pairs on a monolingual corpus to enable the learning of semantic
alignments between different languages, thereby enhancing the semantic modeling
of cross-lingual models. Experimental results show that ERNIE-M outperforms
existing cross-lingual models and delivers new state-of-the-art results in
various cross-lingual downstream tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Understanding Politics via Contextualized Discourse Processing. (arXiv:2012.15784v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15784">
<div class="article-summary-box-inner">
<span><p>Politicians often have underlying agendas when reacting to events. Arguments
in contexts of various events reflect a fairly consistent set of agendas for a
given entity. In spite of recent advances in Pretrained Language Models (PLMs),
those text representations are not designed to capture such nuanced patterns.
In this paper, we propose a Compositional Reader model consisting of encoder
and composer modules, that attempts to capture and leverage such information to
generate more effective representations for entities, issues, and events. These
representations are contextualized by tweets, press releases, issues, news
articles, and participating entities. Our model can process several documents
at once and generate composed representations for multiple entities over
several issues or events. Via qualitative and quantitative empirical analysis,
we show that these representations are meaningful and effective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Is Everything in Order? A Simple Way to Order Sentences. (arXiv:2104.07064v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07064">
<div class="article-summary-box-inner">
<span><p>The task of organizing a shuffled set of sentences into a coherent text has
been used to evaluate a machine's understanding of causal and temporal
relations. We formulate the sentence ordering task as a conditional
text-to-marker generation problem. We present Reorder-BART (Re-BART) that
leverages a pre-trained Transformer-based model to identify a coherent order
for a given set of shuffled sentences. The model takes a set of shuffled
sentences with sentence-specific markers as input and generates a sequence of
position markers of the sentences in the ordered text. Re-BART achieves the
state-of-the-art performance across 7 datasets in Perfect Match Ratio (PMR) and
Kendall's tau ($\tau$). We perform evaluations in a zero-shot setting,
showcasing that our model is able to generalize well across other datasets. We
additionally perform several experiments to understand the functioning and
limitations of our framework.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hierarchical Learning for Generation with Long Source Sequences. (arXiv:2104.07545v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07545">
<div class="article-summary-box-inner">
<span><p>One of the challenges for current sequence to sequence (seq2seq) models is
processing long sequences, such as those in summarization and document level
machine translation tasks. These tasks require the model to reason at the token
level as well as the sentence and paragraph level. We design and study a new
Hierarchical Attention Transformer-based architecture (HAT) that outperforms
standard Transformers on several sequence to sequence tasks. Furthermore, our
model achieves state-of-the-art ROUGE scores on four summarization tasks,
including PubMed, arXiv, CNN/DM, SAMSum, and AMI. Our model outperforms
document-level machine translation baseline on the WMT20 English to German
translation task. We investigate what the hierarchical layers learn by
visualizing the hierarchical encoder-decoder attention. Finally, we study
hierarchical learning on encoder-only pre-training and analyze its performance
on classification tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v2 [cs.CV] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04484">
<div class="article-summary-box-inner">
<span><p>Deep learning algorithms have shown promising results in visual question
answering (VQA) tasks, but a more careful look reveals that they often do not
understand the rich signal they are being fed with. To understand and better
measure the generalization capabilities of VQA systems, we look at their
robustness to counterfactually augmented data. Our proposed augmentations are
designed to make a focused intervention on a specific property of the question
such that the answer changes. Using these augmentations, we propose a new
robustness measure, Robustness to Augmented Data (RAD), which measures the
consistency of model predictions between original and augmented examples.
Through extensive experimentation, we show that RAD, unlike classical accuracy
measures, can quantify when state-of-the-art systems are not robust to
counterfactuals. We find substantial failure cases which reveal that current
VQA systems are still brittle. Finally, we connect between robustness and
generalization, demonstrating the predictive power of RAD for performance on
unseen augmentations.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Domain-Specific Pretraining for Vertical Search: Case Study on Biomedical Literature. (arXiv:2106.13375v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13375">
<div class="article-summary-box-inner">
<span><p>Information overload is a prevalent challenge in many high-value domains. A
prominent case in point is the explosion of the biomedical literature on
COVID-19, which swelled to hundreds of thousands of papers in a matter of
months. In general, biomedical literature expands by two papers every minute,
totalling over a million new papers every year. Search in the biomedical realm,
and many other vertical domains is challenging due to the scarcity of direct
supervision from click logs. Self-supervised learning has emerged as a
promising direction to overcome the annotation bottleneck. We propose a general
approach for vertical search based on domain-specific pretraining and present a
case study for the biomedical domain. Despite being substantially simpler and
not using any relevance labels for training or development, our method performs
comparably or better than the best systems in the official TREC-COVID
evaluation, a COVID-related biomedical search competition. Using distributed
computing in modern cloud infrastructure, our system can scale to tens of
millions of articles on PubMed and has been deployed as Microsoft Biomedical
Search, a new search experience for biomedical literature:
https://aka.ms/biomedsearch.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Ethics Sheets for AI Tasks. (arXiv:2107.01183v3 [cs.AI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01183">
<div class="article-summary-box-inner">
<span><p>Recent innovations such as Datasheets for Datasets and Model Cards for Model
Reporting have made useful contributions to furthering ethical research. Yet,
several high-profile events, such as the mass testing of emotion recognition
systems on vulnerable sub-populations, have highlighted how technology will
often lead to more adverse outcomes for those that are already marginalized. In
this paper, I will make a case for thinking about ethical considerations not
just at the level of individual models and datasets, but also at the level of
AI tasks. I will present a new form of such an effort, Ethics Sheets for AI
Tasks, dedicated to fleshing out the assumptions and ethical considerations
hidden in how a task is commonly framed and in the choices we make regarding
the data, method, and evaluation. Finally, I will provide an example ethics
sheet for automatic emotion recognition. Ethics sheets are a mechanism to
document ethical considerations \textit{before} building datasets and systems.
Such pre-production activities (e.g., ethics analyses) and associated artifacts
(e.g., accessible documentation) are crucial for responsible AI: for
communicating risks to all stakeholders, to help decision and policy making,
and for developing more effective post-production documents such as Data Sheets
and Model Cards.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pattern-based Acquisition of Scientific Entities from Scholarly Article Titles. (arXiv:2109.00199v2 [cs.IR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00199">
<div class="article-summary-box-inner">
<span><p>We describe a rule-based approach for the automatic acquisition of salient
scientific entities from Computational Linguistics (CL) scholarly article
titles. Two observations motivated the approach: (i) noting salient aspects of
an article's contribution in its title; and (ii) pattern regularities capturing
the salient terms that could be expressed in a set of rules. Only those
lexico-syntactic patterns were selected that were easily recognizable, occurred
frequently, and positionally indicated a scientific entity type. The rules were
developed on a collection of 50,237 CL titles covering all articles in the ACL
Anthology. In total, 19,799 research problems, 18,111 solutions, 20,033
resources, 1,059 languages, 6,878 tools, and 21,687 methods were extracted at
an average precision of 75%.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">WebQA: Multihop and Multimodal QA. (arXiv:2109.00590v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00590">
<div class="article-summary-box-inner">
<span><p>Web search is fundamentally multimodal and multihop. Often, even before
asking a question we choose to go directly to image search to find our answers.
Further, rarely do we find an answer from a single source but aggregate
information and reason through implications. Despite the frequency of this
everyday occurrence, at present, there is no unified question answering
benchmark that requires a single model to answer long-form natural language
questions from text and open-ended visual sources -- akin to a human's
experience. We propose to bridge this gap between the natural language and
computer vision communities with WebQA. We show that A. our multihop text
queries are difficult for a large-scale transformer model, and B. existing
multi-modal transformers and visual representations do not perform well on
open-domain visual queries. Our challenge for the community is to create a
unified multimodal reasoning model that seamlessly transitions and reasons
regardless of the source modality.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Tree-constrained Pointer Generator for End-to-end Contextual Speech Recognition. (arXiv:2109.00627v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00627">
<div class="article-summary-box-inner">
<span><p>Contextual knowledge is important for real-world automatic speech recognition
(ASR) applications. In this paper, a novel tree-constrained pointer generator
(TCPGen) component is proposed that incorporates such knowledge as a list of
biasing words into both attention-based encoder-decoder and transducer
end-to-end ASR models in a neural-symbolic way. TCPGen structures the biasing
words into an efficient prefix tree to serve as its symbolic input and creates
a neural shortcut between the tree and the final ASR output distribution to
facilitate recognising biasing words during decoding. Systems were trained and
evaluated on the Librispeech corpus where biasing words were extracted at the
scales of an utterance, a chapter, or a book to simulate different application
scenarios. Experimental results showed that TCPGen consistently improved word
error rates (WERs) compared to the baselines, and in particular, achieved
significant WER reductions on the biasing words. TCPGen is highly efficient: it
can handle 5,000 biasing words and distractors and only add a small overhead to
memory use and computation cost.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Biomedical and Clinical Language Models for Spanish: On the Benefits of Domain-Specific Pretraining in a Mid-Resource Scenario. (arXiv:2109.03570v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.03570">
<div class="article-summary-box-inner">
<span><p>This work presents biomedical and clinical language models for Spanish by
experimenting with different pretraining choices, such as masking at word and
subword level, varying the vocabulary size and testing with domain data,
looking for better language representations. Interestingly, in the absence of
enough clinical data to train a model from scratch, we applied mixed-domain
pretraining and cross-domain transfer approaches to generate a performant
bio-clinical model suitable for real-world clinical data. We evaluated our
models on Named Entity Recognition (NER) tasks for biomedical documents and
challenging hospital discharge reports. When compared against the competitive
mBERT and BETO models, we outperform them in all NER tasks by a significant
margin. Finally, we studied the impact of the model's vocabulary on the NER
performances by offering an interesting vocabulary-centric analysis. The
results confirm that domain-specific pretraining is fundamental to achieving
higher performances in downstream NER tasks, even within a mid-resource
scenario. To the best of our knowledge, we provide the first biomedical and
clinical transformer-based pretrained language models for Spanish, intending to
boost native Spanish NLP applications in biomedicine. Our best models are
freely available in the HuggingFace hub: https://huggingface.co/BSC-TeMU.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fixing exposure bias with imitation learning needs powerful oracles. (arXiv:2109.04114v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04114">
<div class="article-summary-box-inner">
<span><p>We apply imitation learning (IL) to tackle the NMT exposure bias problem with
error-correcting oracles, and evaluate an SMT lattice-based oracle which,
despite its excellent performance in an unconstrained oracle translation task,
turned out to be too pruned and idiosyncratic to serve as the oracle for IL.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cartography Active Learning. (arXiv:2109.04282v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.04282">
<div class="article-summary-box-inner">
<span><p>We propose Cartography Active Learning (CAL), a novel Active Learning (AL)
algorithm that exploits the behavior of the model on individual instances
during training as a proxy to find the most informative instances for labeling.
CAL is inspired by data maps, which were recently proposed to derive insights
into dataset quality (Swayamdipta et al., 2020). We compare our method on
popular text classification tasks to commonly used AL strategies, which instead
rely on post-training behavior. We demonstrate that CAL is competitive to other
common AL methods, showing that training dynamics derived from small seed data
can be successfully used for AL. We provide insights into our new AL method by
analyzing batch-level statistics utilizing the data maps. Our results further
show that CAL results in a more data-efficient learning strategy, achieving
comparable or better results with considerably less training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Asking Questions Like Educational Experts: Automatically Generating Question-Answer Pairs on Real-World Examination Data. (arXiv:2109.05179v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.05179">
<div class="article-summary-box-inner">
<span><p>Generating high quality question-answer pairs is a hard but meaningful task.
Although previous works have achieved great results on answer-aware question
generation, it is difficult to apply them into practical application in the
education field. This paper for the first time addresses the question-answer
pair generation task on the real-world examination data, and proposes a new
unified framework on RACE. To capture the important information of the input
passage we first automatically generate(rather than extracting) keyphrases,
thus this task is reduced to keyphrase-question-answer triplet joint
generation. Accordingly, we propose a multi-agent communication model to
generate and optimize the question and keyphrases iteratively, and then apply
the generated question and keyphrases to guide the generation of answers. To
establish a solid benchmark, we build our model on the strong generative
pre-training model. Experimental results show that our model makes great
breakthroughs in the question-answer pair generation task. Moreover, we make a
comprehensive analysis on our model, suggesting new directions for this
challenging task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">RankNAS: Efficient Neural Architecture Search by Pairwise Ranking. (arXiv:2109.07383v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.07383">
<div class="article-summary-box-inner">
<span><p>This paper addresses the efficiency challenge of Neural Architecture Search
(NAS) by formulating the task as a ranking problem. Previous methods require
numerous training examples to estimate the accurate performance of
architectures, although the actual goal is to find the distinction between
"good" and "bad" candidates. Here we do not resort to performance predictors.
Instead, we propose a performance ranking method (RankNAS) via pairwise
ranking. It enables efficient architecture search using much fewer training
examples. Moreover, we develop an architecture selection method to prune the
search space and concentrate on more promising candidates. Extensive
experiments on machine translation and language modeling tasks show that
RankNAS can design high-performance architectures while being orders of
magnitude faster than state-of-the-art NAS systems.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-20 23:23:40.490637373 UTC">2021-09-20 23:23:40 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>