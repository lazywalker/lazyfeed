<!DOCTYPE html>
<html lang="en">
<head>
<title>ArxivDaily</title>
<meta charset="utf-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="robots" content="noindex, nofollow"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico"/>
<link href="index.css" rel="stylesheet"/>
</head>
<body>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-07T01:49:01.662660085Z">09-07</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">Rust.cc</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-06 加快 Rust 的编译</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=28141388-ce4a-4421-95b4-e2059e3b2347">
<div class="article-summary-box-inner">
<span><h1>加快 Rust 的编译</h1>
<p>众所周知，Rust代码编译起来很慢。但我有一种强烈的直觉，大多数Rust代码的编译速度比它本可以的要慢得多。</p>
<p>例如, Rust 的 <code>rust-analyzer</code> CI 在 GitHub 上操作需要8分钟。这是一个相当大和复杂的项目，有20万行自己的代码和100万行依赖。</p>
<p>跟随作者, 让我们进一步了解如何使编译时间保持在合理的范围内!</p>
<p><a href="https://matklad.github.io/2021/09/04/fast-rust-builds.html" rel="noopener noreferrer">原文链接</a></p>
<h1>async 的另外一个语法方案</h1>
<p>作者对于 <code>async</code>的语法方案提出了完整的自己的解决方案, 非常有趣.</p>
<p><a href="https://ibraheem.ca/writings/an-alternative-async-fn-syntax/" rel="noopener noreferrer">原文链接</a></p>
<h1>Rust 插件</h1>
<p>这是作者的第二篇关于 Rust插件的文章!
在这里，作者将尝试编写一些 PDK (Plugin Development Kit, 插件开发工具包) 可能是什么样子的简单代码，并对在编写过程中出现的问题做一些研究。</p>
<p><a href="https://nullderef.com/blog/plugin-start/" rel="noopener noreferrer">原文链接</a></p>
<h1>sentinel-rust: Rust 版本的 sentinel</h1>
<p><code>Sentinel</code> 是一个面向分布式服务架构的高可用流量控制组件. 现在 Rust 版本已加入</p>
<p><a href="https://github.com/sentinel-group/sentinel-rust" rel="noopener noreferrer">github 地址</a></p>
<h1><code>&lt;&lt;Programming Rust&gt;&gt;</code> 第二版电子书已上架</h1>
<p><code>&lt;&lt;Programming Rust&gt;&gt;</code> 第二版的在线电子书现已上架.</p>
<p><a href="https://www.lunaticai.com/2021/09/programming-rust-2nd-edition-pdf-github.html" rel="noopener noreferrer">原文链接</a></p>
<p>--</p>
<p>From 日报小组 BobQin，FBI小白</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">rust ffi 调用C++函数,C++函数返回 之指向智能对象的指针</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=6060f204-1000-4bc2-a492-1e452c7ae9ef">
<div class="article-summary-box-inner">
<span><p>\stable-x86_64-pc-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libcompiler_builtins-0f3806ca1d72c7be.rlib" "kernel32.lib" "ws2_32.lib" "advapi32.lib" "userenv.lib" "kernel32.lib" "msvcrt.lib" "/NXCOMPAT" "/LIBPATH:C:\Users\xiake\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib" "/OUT:D:\other\github\rust_nav\testffi\target\debug\deps\testffi.exe" "/OPT:REF,NOICF" "/DEBUG" "/NATVIS:C:\Users\xiake\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\etc\intrinsic.natvis" "/NATVIS:C:\Users\xiake\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\etc\liballoc.natvis" "/NATVIS:C:\Users\xiake\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\etc\libcore.natvis" "/NATVIS:C:\Users\xiake\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\etc\libstd.natvis"
= note: navapp.lib(pch.obj) : MSIL .netmodule or module compiled with /GL found; restarting link with /LTCG; add /LTCG to the link command line to improve linker performance
Creating library D:\other\github\rust_nav\testffi\target\debug\deps\testffi.lib and object D:\other\github\rust_nav\testffi\target\debug\deps\testffi.exp
navapp.lib(navapp.obj) : error LNK2001: unresolved external symbol "public: class KBEngine::SmartPointer __cdecl KBEngine::Navigation::findNavigation(class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;)" (?findNavigation@Navigation@KBEngine@@QEAA?AV?$SmartPointer@VNavigationHandle@KBEngine@@@2@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)
navapp.lib(navapp.obj) : error LNK2001: unresolved external symbol "public: class KBEngine::SmartPointer <em><em>cdecl KBEngine::Navigation::loadNavigation(class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;,class std::map&lt;int,class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt;,struct std::less,class std::allocator&lt;struct std::pair&lt;int const ,class std::basic_string&lt;char,struct std::char_traits,class std::allocator &gt; &gt; &gt; &gt; const &amp;)" (?loadNavigation@Navigation@KBEngine@@QEAA?AV?$SmartPointer@VNavigationHandle@KBEngine@@@2@V?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV?$map@HV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@U?$less@H@2@V?$allocator@U?$pair@$$CBHV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@std@@@2@@5@@Z)
navapp.lib(navapp.obj) : error LNK2001: unresolved external symbol "protected: static class KBEngine::Navigation * KBEngine::Singleton::singleton</em>" (?singleton</em>@?$Singleton@VNavigation@KBEngine@@@KBEngine@@1PEAVNavigation@2@EA)
D:\other\github\rust_nav\testffi\target\debug\deps\testffi.exe : fatal error LNK1120: 3 unresolved externals</p>
<p>C++部分</p>
<p>DLLEXPORT KBEngine::NavigationHandlePtr* get_nav_handle(char* resPath_);</p>
<p>typedef SmartPointer NavigationHandlePtr;</p>
<p>template
class SmartPointer : public ConstSmartPointer
{
public:
typedef ConstSmartPointer ConstProxy;</p>
<pre><code>SmartPointer(T* obj = 0, typename ConstProxy::REF_TAG tag = ConstProxy::NEW_REF):
ConstProxy(obj, tag)
{
}

SmartPointer( const SmartPointer&lt;T&gt;&amp; P ) : ConstProxy( P ) { }

template&lt;class DerivedType&gt;
SmartPointer( ConstSmartPointer&lt;DerivedType&gt;&amp; dt ) :
	ConstProxy( dt.get() )
{
}
</code></pre>
<p>代码太长省略</p>
<p>求大佬给点提示 实在找不到原因</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">有没有方法将一个usize的值转成i32的-1</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=7f247165-5483-4b7e-b39b-7f2db042e5df">
<div class="article-summary-box-inner">
<span><p>今天写leetcode的每日一题的时候突发奇想</p>
<pre><code>impl Solution {
    pub fn search(nums: Vec&lt;i32&gt;, target: i32) -&gt; i32 {
        nums.binary_search(&amp;target).unwrap_or_default() as i32
    }
}
</code></pre>
<p>像这里能不能用一个unwrap_or(x) 然后转成失败返回-1</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">又见Rust区块链招聘 -_-!, but 这个点进来不后悔^_^</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=640daecb-eec5-4b6d-87a1-02b640bb0433">
<div class="article-summary-box-inner">
<span><p>大家好，我们是Deeper Network, 官网是deeper.network, 一个总部位于硅谷的区块链初创企业,我们跟绝大部分区块链公司不同的是，我们有顶级的产品来支撑我们的业务和发展愿景。重要的事情说三遍，有产品，有产品，有产品，而且是业界领先的产品！</p>
<p>我们的旗舰产品Deeper Connect已经迭代到最新的第四代产品，其中Deeper Connect mini在Indiegogo平台首发，仅预售成绩就超过270万美元，在Indiegogo历史上的一百多万个项目中排名前10。(前十中的绝大部分项目都是Sony, 华为这样级别的公司)</p>
<p>我们即将发售的最新产品pico的介绍，可以在下面找到：</p>
<p>http://dev.deepernetwork.com:8088/down/tmp/pico.png</p>
<p>世界上最小，最轻，最薄，功能最强大的网络安全+区块链产品：Deeper Connect Pico</p>
<p>目前我们在全球150多个国家拥有20，000+的用户，30，000+节点。</p>
<p>我们于2020年入选了波卡的builders program并且获得了Web 3.0基金会赞助，是波卡生态重要的一员。</p>
<p>2021年，我们的区块链网络Deeper Chain获得波卡第一届黑客松比赛的社区最受欢迎奖和决赛亚军。</p>
<p>Deeper Connect + Deeper Chain是目前世界上唯一的全栈WEB3.0解决方案,包括：web3.0网关，去中心化安全网络，去中心化广告，去中心化视频点播平台，去中心化CDN等等。</p>
<p>目前公司已经盈利，现金贮备丰厚，正在对接业界最等级的风险投资机构，处于起飞的前夕。</p>
<p>我们希望您具有以下技能：</p>
<p>基本要求：</p>
<p>1、扎实的计算机科学基础知识</p>
<p>2、动手能力强，有死磕精神</p>
<p>3、有丰富的 Rust 开发经验</p>
<p>4、曾经独立完成或者主导完成过具有挑战性的项目</p>
<p>5、对工作有高度的责任心</p>
<p>加分项：</p>
<p>1、区块链相关数据结构与算法</p>
<p>2、Substrate或其他区块链节点开发经验</p>
<p>3、跨链、Layer 2 开发经验</p>
<p>待遇：</p>
<p>丰厚的薪资待遇：40K~80K/月</p>
<p>灵活的工作方式：您可以在任何时间，任何地点，只要有网络就行</p>
<p>表现合格者提供股票/币权的丰厚激励</p>
<p>表现优异者提供美国/加拿大移民机会（目前闹瘟疫，说实话也没啥好移的）</p>
<p>有意向的选手，请发个人简历到:jobs@deeper.network, 我们在这里等你！</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-05</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=f480ea38-5b5e-423e-9c78-e78bd1344c6e">
<div class="article-summary-box-inner">
<span><h3>rust-tui-template：使用 tui-rs 和 crossterm 引导 Rust TUI 应用程序的模板</h3>
<p>项目结构如下：</p>
<pre><code>src/
├── app.rs     -&gt; holds the states and renders the widgets
├── event.rs   -&gt; handles the terminal events (key press, mouse click, resize, etc.)
├── handler.rs -&gt; handles the key press events and updates the application
├── lib.rs     -&gt; module definitions
├── main.rs    -&gt; entry-point
└── tui.rs     -&gt; initializes/exits the terminal interface
</code></pre>
<p>按 README 下载执行后效果如下：</p>
<p><img src="http://qnimg.lovevivian.cn/rust-daily-20210905-1.jpg" alt></p>
<p>GitHub：<a href="https://github.com/orhun/rust-tui-template" rel="noopener noreferrer">orhun/rust-tui-template: A template for bootstrapping a Rust TUI application with tui-rs &amp; crossterm</a></p>
<h3>perseus：完全支持 SSR 和 SSG 的 Rust 高端前端开发框架</h3>
<p>Perseus 是一个使用 Rust 构建的极快的前端 Web 开发框架，它支持主要的渲染策略、在没有虚拟 DOM 的情况下具有反应性，并且具有极高的可定制性。它封装了 Sycamore 的底层功能，提供了一个类似 NextJS 的 API！</p>
<p>✨ 支持静态生成（只提供静态资源）
✨ 支持服务端渲染（服务动态资源）
✨ 支持一段时间后重新验证和 / 或使用自定义逻辑（更新已渲染页面）
✨ 支持增量重建（按需构建）
✨开放构建矩阵（主要使用任何渲染策略和其他任何东西）
✨ CLI 工具，让您轻松自信地构建应用程序</p>
<p>项目的主要目标是：支持每一个主要的渲染策略，并为开发人员提供使用 Rust 高效创建超快速应用程序的能力和炫酷的的开发体验！</p>
<p>文档：<a href="https://arctic-hen7.github.io/perseus/" rel="noopener noreferrer">Introduction - Perseus Book</a></p>
<p>GitHub：<a href="https://github.com/arctic-hen7/perseus" rel="noopener noreferrer">arctic-hen7/perseus: A high-level frontend development framework for Rust with full support for SSR and SSG.</a></p>
<h3>Rust 构建 LC-3 虚拟机</h3>
<p>Little Computer 3，或 LC-3，是一种计算机教育编程语言，一种汇编语言。它具有相对简单的指令集，但可用于编写中等复杂的汇编程序，是 C 编译器的可行目标。 该语言不如 x86 汇编语言复杂，但具有许多类似于更复杂语言的功能。 这些功能使其对入门教学非常有用，因此它最常用于向计算机科学和计算机工程专业的学生教授编程和计算机体系结构的基础知识。</p>
<p>教程地址：<a href="https://www.rodrigoaraujo.me/posts/lets-build-an-lc-3-virtual-machine/" rel="noopener noreferrer">Let's build an LC-3 Virtual Machine :: Rodrigo Araujo — Computer Scientist and Software Engineer</a></p>
<p>另外附上 2 个之前的一个教程：</p>
<ul>
<li><a href="https://github.com/KuldeepSinh/lc3_vm" rel="noopener noreferrer">KuldeepSinh/lc3_vm: LC-3 (Little Computer 3) VM implemented in Rust</a></li>
<li><a href="https://github.com/justinmeiners/lc3-vm" rel="noopener noreferrer">justinmeiners/lc3-vm: Write your own virtual machine for the LC-3 computer!</a></li>
</ul>
<h3>RustGameJam 中使用的游戏引擎分布</h3>
<p>GameJam 是一个游戏开发者的 hackathon，<a href="https://itch.io/jam/rusty-jam" rel="noopener noreferrer">第一届 Rust Game Jam</a> 是于2021年8月22号到8月29号举办，游戏开发者们使用的游戏引擎最多的是 Bevy，其次是 macroquad，当然还有其他引擎，比如：pixels、 RG3D、minifb。想看GameJam的游戏作品，请点击下面链接。</p>
<ul>
<li>https://itch.io/jam/rusty-jam</li>
</ul>
<h3>memuse 一个分析动态内存使用的库</h3>
<pre><code>use memuse::DynamicUsage;

assert_eq!(7u64.dynamic_usage(), 0);
assert_eq("I'm simple!".dynamic_usage(), 0);
assert_eq(vec![7u64; 2].dynamic_usage(), 16);

let empty: Vec&lt;u32&gt; = Vec::with_capacity(100);
assert_eq!(empty.len(), 0);
assert_eq!(empty.dynamic_usage, 400);
</code></pre>
<ul>
<li>Repo <a href="https://crates.io/crates/memuse" rel="noopener noreferrer">crates.io/crates/memuse</a></li>
</ul>
<hr>
<p>From 日报小组 太子长琴，李冬杰</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rust.cc/" rel="noopener noreferrer">Rustcc 论坛: 支持 rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f620" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">rust ffi link 错误</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=6497a814-b6d9-4b32-9d9d-35cc2fe53845">
<div class="article-summary-box-inner">
<span><p>Clionerror: linking with <code>link.exe</code> failed: exit code: 1112
|
= note: "C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC
\Tools\MSVC\14.25.28610\bin\HostX64\x64\link.exe" "/NOLOGO" "/NXCOMPAT" "
/LIBPATH:C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-windows
-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib" "D:\rust\test\test11\targe
t\debug\deps\test11.1inhodm0mguvy78p.rcgu.o" "D:\rust\test\test11\target<br>
\debug\deps\test11.1itxz1f879gxqo0r.rcgu.o" "D:\rust\test\test11\target\d
ebug\deps\test11.1nfdhbezxkijr69v.rcgu.o" "D:\rust\test\test11\target\deb
ug\deps\test11.1okn7si93kck3d1v.rcgu.o" "D:\rust\test\test11\target\debug
\deps\test11.1r7eavti91oymq20.rcgu.o" "D:\rust\test\test11\target\debug\
deps\test11.24nm5lpcn3t54lyd.rcgu.o" "D:\rust\test\test11\target\debug\de
ps\test11.2hyws9epzawmgilt.rcgu.o" "D:\rust\test\test11\target\debug\deps
\test11.2old9hh0jdnzckpx.rcgu.o" "D:\rust\test\test11\target\debug\deps\
test11.3bc649uegqq66vdn.rcgu.o" "D:\rust\test\test11\target\debug\deps\te
st11.3nyjusu4bu7ihnwt.rcgu.o" "D:\rust\test\test11\target\debug\deps\test
11.44jxfqx2w1so8gxa.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11
.47a9u7imyimutge1.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4
9azsbqjuetnb404.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4bk
fakiuuxmwqfyp.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4mu1b
nojyqp0utjl.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4rszv42
zy3ba1jb2.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4t77rmx77
tcvwir6.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4tr7ij9mclu
clpsg.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4xi12smsmm3qs
mbh.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.4yye09rafbxycx8
1.rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.56g0yr2v0k1zblp9.
rcgu.o" "D:\rust\test\test11\target\debug\deps\test11.yv2gzy9b0ix4k8o.rcg
u.o" "D:\rust\test\test11\target\debug\deps\test11.zu1yaj42bq3ogyk.rcgu.o
" "/OUT:D:\rust\test\test11\target\debug\deps\test11.exe" "D:\rust\test
\test11\target\debug\deps\test11.sic3ibelt8jd29e.rcgu.o" "/OPT:REF,NOICF" "
/DEBUG" "/NATVIS:C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc
-windows-msvc\lib\rustlib\etc\intrinsic.natvis" "/NATVIS:C:\Users\Administ
rator\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\etc\li
balloc.natvis" "/NATVIS:C:\Users\Administrator\.rustup\toolchains\stable-x8
6_64-pc-windows-msvc\lib\rustlib\etc\libcore.natvis" "/NATVIS:C:\Users\Adm
inistrator\.rustup\toolchains\stable-x86_64-pc-windows-msvc\lib\rustlib\et
c\libstd.natvis" "/LIBPATH:D:\rust\test\test11\target\debug\deps" "/LIBPA
TH:C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-windows-msvc<br>
\lib\rustlib\x86_64-pc-windows-msvc\lib" "./libs/nav-apps.lib" "/WHOLEARCHIVE
:./libs/nav-apps.lib" "D:\rust\test\test11\target\debug\deps\liblibc-bc05
adbb061c4c16.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64
-pc-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libstd-1feb4ba9912f
83e4.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-wind
ows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libpanic_unwind-10caf631bf1
7818d.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-win
dows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\librustc_demangle-5f5b841e
7dcb5069.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-
windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libhashbrown-886e420424
40a542.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-wi
ndows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\librustc_std_workspace_al
loc-fc3dfd2deda68757.rlib" "C:\Users\Administrator\.rustup\toolchains\stabl
e-x86_64-pc-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libunwind-4
765baa3d9fc6a1b.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86
_64-pc-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libcfg_if-2af04b
7075550e2b.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-p
c-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\liblibc-9f4eae3434a19
b51.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-windo
ws-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\liballoc-14b08c3097e998dc.rl
ib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-windows-msv
c\lib\rustlib\x86_64-pc-windows-msvc\lib\librustc_std_workspace_core-9c0450
bb353ef0cc.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-p
c-windows-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libcore-4856f32e5e48b
ded.rlib" "C:\Users\Administrator\.rustup\toolchains\stable-x86_64-pc-windo
ws-msvc\lib\rustlib\x86_64-pc-windows-msvc\lib\libcompiler_builtins-0f66c8d
6b2ebbbc4.rlib" "advapi32.lib" "ws2_32.lib" "userenv.lib" "msvcrt.lib"
= note: Non-UTF-8 output: nav-apps.lib(base64.obj) : \xd5\xd2\xb5\xbd MSIL .ne
tmodule \xbb\xf2\xca\xb9\xd3\xc3 /GL \xb1\xe0\xd2\xeb\xb5\xc4\xc4\xa3\xbf\xe9\xa
3\xbb\xd5\xfd\xd4\xda\xca\xb9\xd3\xc3 /LTCG \xd6\xd8\xd0\xc2\xc6\xf4\xb6\xaf\xc1
\xb4\xbd\xd3\xa3\xbb\xbd\xab /LTCG \xcc\xed\xbc\xd3\xb5\xbd\xc1\xb4\xbd\xd3\xc3<br>
xfc\xc1\xee\xd0\xd0\xd2\xd4\xb8\xc4\xbd\xf8\xc1\xb4\xbd\xd3\xc6\xf7\xd0\xd4\xc4<br>
xdc\r\ntest11.4mu1bnojyqp0utjl.rcgu.o : error LNK2005: main \xd2\xd1\xbe\xad\xd4
\xda test11.4mu1bnojyqp0utjl.rcgu.o \xd6\xd0\xb6\xa8\xd2\xe5\r\nnav-apps.lib(lib
mysql32.dll) : fatal error LNK1112: \xc4\xa3\xbf\xe9\xbc\xc6\xcb\xe3\xbb\xfa\xc0
\xe0\xd0\xcd\xa1\xb0x86\xa1\xb1\xd3\xeb\xc4\xbf\xb1\xea\xbc\xc6\xcb\xe3\xbb\xfa<br>
xc0\xe0\xd0\xcd\xa1\xb0x64\xa1\xb1\xb3\xe5\xcd\xbb\r\n</p>
<p>求大佬给点提示</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">分享一个命令行文本美化工具库，https://crates.io/crates/colorstyle</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=73d264ed-5f2d-43db-b3ec-12965ccaa550">
<div class="article-summary-box-inner">
<span><p>ColorStyle is a library of styles for command-line text.
Used to modify the style of text for standard output to the terminal interface, you can change the foreground colour of the text, the background colour, add underline and bold, etc.</p>
<p>ColorStyle 是一个用于命令行文本的样式库。
用于标准输出到终端界面的文本的样式修改，可以修改文本前景色，背景色，增加下划线和加粗显等。</p>
<p>可以作为一个新手docs.rs 文档编写参考。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">[已解决]使用rocket框架时sqlite出现的问题</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=089f8f06-780e-409a-952e-fa39c2e79dc6">
<div class="article-summary-box-inner">
<span><p>其实应该是diesel的问题
之前sqlite缺少lib我是通过这个博客解决了问题
<a href="https://blog.itdevwu.com/post/915/" rel="noopener noreferrer">解决使用Rust与Sqlite3交互时出现LNK1181错误（Diesel 或 rusqlite）</a>
但是后面的cargo run 阶段又出现了</p>
<pre><code>sqlite3.lib : warning LNK4272:库计算机类型“x86”与目标计算机类型“x64”冲突
          D:\Project\Private\point_plan\target\debug\deps\point_plan.exe : fatal error LNK1120: 60 个无法解析的外部命令
</code></pre>
<p>我明明用的是64位指令编译64位sqlite3.def得到lib的，为啥还会出现这种问题？
麻烦弄过的这方面的朋友指点下</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-09-04</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=e3c58130-184d-482b-b081-168c54694384">
<div class="article-summary-box-inner">
<span><h3>cURL 中的 Rust</h3>
<p>Allen Wyma 与 cURL 的原作者 Daniel 谈论在 cURL 中使用 Rust。</p>
<ul>
<li>cURL 是一个命令行工具和库，用于通过 URL 传输数据。</li>
<li>cURL 及其数据传输核心 libcurl 都是用 C 编写的，众所周知，这不是内存安全的。</li>
<li>虽然几乎不可能将其重写为另一种语言，但提供一个用 Rust 编写的第三方库可能会更进一步。</li>
</ul>
<p><a href="https://rustacean-station.org/episode/035-daniel-stenberg/" rel="noopener noreferrer">文章链接</a>，https://rustacean-station.org/episode/035-daniel-stenberg/</p>
<h3>NoProto：灵活、快速和紧凑的序列化和rpc</h3>
<ul>
<li>
<p>轻量</p>
<ul>
<li>零依赖</li>
<li>支持no_std，WASM</li>
<li>最紧凑的非编译存储格式</li>
</ul>
</li>
<li>
<p>稳定...</p>
</li>
</ul>
<p><a href="https://github.com/only-cliches/NoProto" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/only-cliches/NoProto</p>
<h3>gradient介绍</h3>
<p>用于玩颜色渐变的命令行工具</p>
<p>Features:</p>
<ul>
<li>许多预设渐变。</li>
<li>自定义渐变。</li>
<li>从 SVG 和 GIMP 渐变 (ggr) 文件中读取渐变
...</li>
</ul>
<p><a href="https://github.com/mazznoer/gradient-rs" rel="noopener noreferrer">Gitlab 链接</a>，https://github.com/mazznoer/gradient-rs</p>
<hr>
<p>From 日报小组 <a href="https://rustcc.cn/blog_with_author?author_id=dd4a77ca-2042-459e-901a-b8f9bfeb7db0" rel="noopener noreferrer">TOM</a></p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li>[微信公众号：Rust语言中文社区](https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d88</li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">argh：基于 derive 宏且对二进制体积进行优化的命令行解析工具</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=01a3db1f-b567-47d4-9c3b-08142a11cd3e">
<div class="article-summary-box-inner">
<span><blockquote>
<p>Derive-based argument parsing optimized for code size and conformance to the Fuchsia commandline tools specification.</p>
<p>基于 derive 宏的参数解析工具，针对代码大小进行了优化，并且遵循 Fuchsia 命令行工具规范。</p>
</blockquote>
<p>repo：<a href="https://github.com/google/argh" rel="noopener noreferrer">https://github.com/google/argh</a></p>
<p>由 Google 开发者编写，但并非 Google 官方支持。</p>
<p>官方给的基本例子：</p>
<pre><code>use argh::FromArgs;

#[derive(FromArgs)]
/// Reach new heights.
struct GoUp {
    /// whether or not to jump
    #[argh(switch, short = 'j')]
    jump: bool,

    /// how high to go
    #[argh(option)]
    height: usize,

    /// an optional nickname for the pilot
    #[argh(option)]
    pilot_nickname: Option&lt;String&gt;,
}

fn main() {
    let up: GoUp = argh::from_env();
}
</code></pre>
<pre><code>Usage: cmdname [-j] --height &lt;height&gt; [--pilot-nickname &lt;pilot-nickname&gt;]

Reach new heights.

Options:
  -j, --jump        whether or not to jump
  --height          how high to go
  --pilot-nickname  an optional nickname for the pilot
  --help            display usage information
</code></pre>
<p>过程宏-参数类型：</p>
<ul>
<li><code>switch</code>：用在 bool 类型的字段上，表明命令行参数是可选的，而且一旦提供该命令行参数，则给该字段的值赋给 true 。</li>
<li><code>option</code>：
<ul>
<li>用在 <code>Option</code> 类型上，表明命令行参数是可选的。</li>
<li>用在 <code>Vec</code> 类型上，表明命令行参数可选，而且可以重复出现，即这个参数及其值可以在命令行中出现 0 次或更多次。</li>
<li>用在非 <code>Option</code> 、非 <code>Vec</code> 类型上，则表示命令行参数必选。</li>
</ul>
</li>
<li><code>positional</code>：位置参数，表明按照结构体声明的字段顺序解析命令行参数，无需 <code>--xx value</code> 的 <code>--xx</code> 。最后一个位置参数可以包含默认值，也可以包装在 Option 或 Vec 中来接收可选（指 0 或 1 个）或重复（指 0 或多个）的位置参数。</li>
<li><code>subcommand</code>：需定义一个顶层结构体、一个表示子命令的枚举体（这个枚举体列举所有子命令，子命令以结构体形式呈现，子命令结构体还需要 name 设置名称）</li>
</ul>
<p>过程宏-其他设置：</p>
<ul>
<li><code>short = 'a'</code>：解析 <code>-a</code> 形式的简短参数，只支持 ascii 的 <code>Char</code> 类型，比如大小写、数字。</li>
<li><code>long = "xx-xx"</code>：重新命名这个字段的参数名称，由此可允许参数名称带连字符 <code>--xx-xx</code>。这个设置的默认值为字段名称，只支持 ascii 小写形式的名称，不支持大写和数字。</li>
<li><code>default = "default_height()")</code>、<code>default = "String::from(\"only up\")")</code>：默认值，引号内可以是函数名（带括号）、表达式</li>
<li><code>from_str_fn(always_five)</code>：针对某个解析的参数进行自定义处理，<code>always_five</code> 的函数签名方式为 <code>fn(&amp;str) -&gt; Result&lt;T, String&gt;</code></li>
<li><code>description = "xxxxx"</code>：给参数添加帮助信息。<code>///</code> 文档注释也可以提供用帮助信息，而 <code>description</code> 的内容在命令行帮助信息里会覆盖掉 <code>///</code> 提供的信息。注意：换行和空换行会在 --help 信息里变成一个空格；描述信息不能过长，否则会出现 <code>error: invalid reference to positional arguments 4 and 5 (there is 1 argument</code> （这个报错信息不准确，我也是排查了很久才发现）。</li>
</ul>
<p>trait：</p>
<ul>
<li><code>FromArgs</code> trait：用于 argh 命令行解析的所有结构体和枚举体，都必须 derive 这个 trait 。</li>
<li><code>FromArgValue</code> trait：用于 argh 命令行解析的结构体字段的类型必须实现这个 trait ，argh 已经给所有实现 <code>FromStr</code> trait 的类型实现了这个 trait 。std 的基础类型都实现了 <code>FromStr</code> trait ，所以可以直接使用 std 的基础类型；自定义类型需要实现 <code>FromStr</code> trait 和 <code>FromArgValue</code> trait 。</li>
</ul>
<p>优点：</p>
<ul>
<li>使用简单而直观，上手快，适用于基础的命令行解析场景</li>
<li>生成的体积比 clap 小</li>
<li>依赖少，编译速度快</li>
<li>支持 unicode</li>
</ul>
<p>缺点：</p>
<ul>
<li>终端输出结果非彩色</li>
<li>默认不支持很长的 help 信息；只支持 <code>--help</code> 不支持 <code>-h</code> （但是也带来优点——可以自定义一个字段，short as <code>-h</code>，从而有一份默认简洁的 help info，又有一份完全自定义的 info，比如 <code>#[argh(option, short = 'h')] description: Vec&lt;String&gt;</code> =&gt; <code>cmd -h arg1 arg2</code> 就可以显示 arg1 和 arg2 的说明）</li>
<li>只支持 <code>--option value</code> 和 <code>-o value</code>，不支持 <code>--option=value</code> 和 <code>-ovalue</code></li>
</ul>
<p>其他 args-parser：</p>
<blockquote>
<ul>
<li><a href="https://github.com/blyxxyz/lexopt" rel="noopener noreferrer">lexopt</a>：零依赖、注重正确性的极简 args-parser 。</li>
<li><a href="https://github.com/clap-rs/clap" rel="noopener noreferrer"><code>clap</code></a>/<a href="https://github.com/TeXitoi/structopt" rel="noopener noreferrer"><code>structopt</code></a>: very fully-featured. The only other argument parser for Rust I know of that truly handles invalid unicode properly, if used right. Large.</li>
<li><a href="https://github.com/google/argh" rel="noopener noreferrer"><code>argh</code></a> and <a href="https://github.com/murarth/gumdrop" rel="noopener noreferrer"><code>gumdrop</code></a>: much leaner, yet still convenient and powerful enough for most purposes. Panic on invalid unicode.
<ul>
<li><code>argh</code> adheres to the <a href="https://fuchsia.dev/fuchsia-src/concepts/api/cli#command_line_arguments" rel="noopener noreferrer">Fuchsia specification</a> and therefore does <em>not</em> support <code>--option=value</code> and <code>-ovalue</code>, only <code>--option value</code> and <code>-o value</code>.</li>
</ul>
</li>
<li><a href="https://github.com/RazrFalcon/pico-args" rel="noopener noreferrer"><code>pico-args</code></a>: slightly smaller than lexopt and easier to use (but less rigorous).</li>
<li><a href="https://docs.rs/ap" rel="noopener noreferrer"><code>ap</code></a>: I have not used this, but it seems to support iterative parsing while being less bare-bones than lexopt.</li>
<li>libc's <a href="https://en.wikipedia.org/wiki/Getopt#Examples" rel="noopener noreferrer"><code>getopt</code></a>.</li>
</ul>
<p>src: <a href="https://github.com/blyxxyz/lexopt#see-also" rel="noopener noreferrer">https://github.com/blyxxyz/lexopt#see-also</a></p>
</blockquote>
<p>P.S. 不得不说，Rust 利用抽象的类型系统和宏，在 args-parser 方面太棒了。写 Rust 是一种享受。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">rust 学习随笔</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=aea829f0-61d7-413a-a030-8ddd413f26d8">
<div class="article-summary-box-inner">
<span><h1>切换镜像源</h1>
<p>crm =&gt; https://github.com/wtklbm/crm</p>
<p>常用命令就是 <code>crm best</code></p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">pretree 补全文档发布了,再次谢谢大神的指点终于入门了。</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=49d6f015-c98a-4415-95eb-1554cf80d827">
<div class="article-summary-box-inner">
<span><h1>Pretree</h1>
<p>pretree is a package for storing and querying routing rules with prefix tree .</p>
<p>pretree 是一个用于存储和查询路由规则的包。它用前缀树存储路由规则，支持包含变量的路由。</p>
<p>pretree is a package for storing and querying routing rules. It uses prefix tree to store routing rules and supports routing with variables.</p>
<p>Inspired by <a href="https://github.com/obity/pretree" rel="noopener noreferrer">obity/pretree</a> (golang)</p>
<h1>Doc</h1>
<p>See this document at <a href="https://docs.rs/pretree" rel="noopener noreferrer">API documentation</a></p>
<h1>Install</h1>
<p>Add the following line to your Cargo.toml file:</p>
<pre><code>pretree = "1.0.0"
</code></pre>
<h1>Example</h1>
<pre><code>use pretree::Pretree;
let mut p = Pretree::new();
p.store("GET","account/{id}/info/:name");
p.store("GET","account/:id/login");
p.store("GET","account/{id}");
p.store("GET","bacteria/count_number_by_month");
let (ok,rule,vars) = p.query("GET","account/929239");
println!("ok:{} rule:{} vars:{:#?}",ok,rule,vars);

</code></pre>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 异步编程二: Tokio 入门运行时介绍 | Rust 培养提高计划 Vol. 6</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfff3602-cc0c-4423-b48b-e200b624db1a">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程二: Tokio 入门运行时介绍》|Vol. 6</h3>
<p><strong>课程时间:</strong> 2021年9月5日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 上周公开课我们讲解了 Rust 异步编程模型（ 属于一个非常经典的内容，建议观看 ）, 大家对 Rust 异步编程模型有了一个初步认识, Rust 异步编程模型里需要 Executor、Reactor、Future 等, 本周公开课将以 Tokio 框架为基础, 和大家一起聊聊 Tokio 里的 Executor、Reactor、Future 是什么?</p>
<h3>课程大纲</h3>
<p>1、回顾 Rust 异步编程模型.</p>
<p>2、谈谈对 Rust 异步框架的认识 ( futures-rs、async-std、tokio ) .</p>
<p>3、Tokio 介绍.</p>
<p>4、Tokio 里的 Executor、Reactor、Future 如何使用.</p>
<p>5、使用 Tokio 实现一个简单的服务端与客户端程序.</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/
Rust 异步编程入门 Future Part 1 回放地址：
https://www.bilibili.com/video/BV1mf4y1N7MJ/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
<p>Rust 异步编程教材：https://rust-lang.github.io/async-book/</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课：《 Rust 异步编程入门 Future 》|Vol. 5</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d2927245-abd1-4ce4-bab2-0870ff229e70">
<div class="article-summary-box-inner">
<span><h3>本周公开课：《 Rust 异步编程入门 Future 》|Vol. 5</h3>
<p><strong>课程时间:</strong> 2021年8月29日 20:00-21:00</p>
<p><strong>课程介绍:</strong> 讲到 Rust 使用 Future 异步编程，就不得不说 futures 和 tokio 这两个 crate，其实标准库中的 future，以及 async/await 就是从 futures 库中整合进标准库的, Tokio 拥有极快的性能，是大部分系统异步处理的选择，其构建于 future 之上。Future 是 Rust 异步编程的核心基础。</p>
<h3>课程大纲</h3>
<p>1、为什么需要异步.</p>
<p>2、理解异步编程模型.</p>
<p>3、Future 编程模型讲解.</p>
<p>4、带领大家实现一个简化版的 future , 再次帮忙大家理解</p>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<p>通过 Datafuse 理解全链路跟踪 | Vol. 4 https://www.bilibili.com/video/BV1YA411c7ia/</p>
<h3>课程中推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">【Rust日报】2021-08-19 -- Rust Edition 2021 可能会出现在 Rust 1.56中</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=7a3f7b1a-836a-4eab-a014-e5f354640f8c">
<div class="article-summary-box-inner">
<span><h3>Rust Edition 2021 可能会出现在 Rust 1.56中</h3>
<p>已经在下载次数最多的前 10000 个crate 上测试了版本迁移,并且将测试所有公共的 crate。</p>
<p>ReadMore:<a href="https://twitter.com/m_ou_se/status/1427666611977297924" rel="noopener noreferrer">https://twitter.com/m_ou_se/status/1427666611977297924</a></p>
<h3>异步引擎 C++20, Rust &amp; Zig</h3>
<p>ReadMore:<a href="https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/" rel="noopener noreferrer">https://www.reddit.com/r/rust/comments/p63o4g/async_engines_in_c20_rust_zig/</a></p>
<h3>RG3D -- Rust 3D 游戏引擎</h3>
<ul>
<li><strong>PC（Windows、Linux、macOS）和 Web (WebAssembly)</strong> 支持。</li>
<li><strong>延迟着色</strong></li>
<li><strong>内置保存/加载</strong></li>
<li><strong>独立场景编辑器</strong></li>
<li><strong>高级物理模型</strong></li>
<li><strong>分层模型资源</strong></li>
<li><strong>几何实例化</strong></li>
</ul>
<p>ReadMore:<a href="https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/" rel="noopener noreferrer">https://gamefromscratch.com/rg3d-open-source-rust-3d-game-engine/</a></p>
<p>ReadMore:<a href="https://github.com/rg3dengine/rg3d" rel="noopener noreferrer">https://github.com/rg3dengine/rg3d</a></p>
<hr>
<p>From 日报小组 冰山上的 mook &amp;&amp; 挺肥</p>
<p>社区学习交流平台订阅：</p>
<ul>
<li><a href="https://rustcc.cn/" rel="noopener noreferrer">Rustcc论坛: 支持rss</a></li>
<li><a href="https://rustcc.cn/article?id=ed7c9379-d681-47cb-9532-0db97d883f62" rel="noopener noreferrer">微信公众号：Rust语言中文社区</a></li>
</ul>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">公开课: 通过 Datafuse 理解全链路跟踪 | Vol. 4</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=d07779e9-c748-4179-b365-4990a09c55e8">
<div class="article-summary-box-inner">
<span><p><strong>本周公开课：《通过Datafuse理解全链路跟踪》| Vol. 4</strong></p>
<p><strong>课程时间：</strong> 2021年8月22日 20:30-21:30</p>
<p><strong>课程介绍：</strong> 数据库系统也是一个非常复杂，庞大的系统。特别是在调试和观察SQL执行，多线程任务切换，因为没有内存调用或堆栈跟踪，这也是分布式追踪的由来。这里面涉及到多进行分布式追踪为描述和分析跨进程事务提供了一种解决方案。Google Dapper(Dapper: 大规模分布式系统链路追踪基础设施)论文(各tracer的基础)中描述了分布式追踪的一些使用案例包括异常检测、诊断稳态问题、分布式分析、资源属性和微服务的工作负载建模。</p>
<p>本次公开课通 Google 的 OpenTraceing 介绍，结合Rust的 tokio-rs/tracing 使用，最终结合 Datafuse 项目给大家展示一下大型应用的全链路跟踪分析过程。</p>
<p>关于Datafuse : https://github.com/datafuselabs/datafuse</p>
<h3>课程大纲</h3>
<ol>
<li>
<p>什么是分布式追踪系统OpenTracing及应用场景</p>
</li>
<li>
<p>介绍 tokio-rs/tracing 及在程序开发中的作用</p>
</li>
<li>
<p>为什么需要tokio-rs/tracing库</p>
</li>
<li>
<p>演示Datafuse项目中tokio-rs/tracing的使用</p>
</li>
</ol>
<h3><strong>讲师介绍</strong></h3>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：Datafuse项目、Rust语言中文社区、知数堂 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>获取 T-Shirt 的方法：</h3>
<ol>
<li>给 https://github.com/datafuselabs/datafuse 提 issue/pr</li>
<li>进行 Rust，大数据，数据库方面的公开课分享</li>
<li>社区里分享 datafuse 相关文章</li>
<li>datafuse.rs 上面文档翻译工作</li>
</ol>
<h3>往期课程回放</h3>
<p>认识面向基础架构语言 Rust | Vol. 1 https://www.bilibili.com/video/BV1mg411778g</p>
<p>理解 Rust 的所有权 | Vol. 2 https://www.bilibili.com/video/BV1264y1i7U9</p>
<p>通过实战理解 Rust 宏 | Vol. 3 (https://www.bilibili.com/video/BV1Yb4y1U7r1</p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
<p>Rust宏的练习项目： https://github.com/dtolnay/proc-macro-workshop</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">论坛github账户无法登录解决笔记</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=8be810c8-be92-4ca5-96ed-a5b638952190">
<div class="article-summary-box-inner">
<span><p>有反映这两天github账户无法登录了。</p>
<p>报这个错：</p>
<pre><code>get github user info err
</code></pre>
<p>查了几个地方：</p>
<ol>
<li>代码是否运行正常：Ok</li>
<li>https代理是否正常：Ok</li>
<li>检查了github返回日志，发现是：</li>
</ol>
<pre><code>get_github_user_info: response body: "{\"message\":\"Must specify access token via Authorization header. https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param\",\"documentation_url\":\"https://docs.github.com/v3/#oauth2-token-sent-in-a-header\"}"
get_github_user_info: Got: Err(Custom("read json login error"))
</code></pre>
<p>进入这个地址一看：<a href="https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/" rel="noopener noreferrer">https://developer.github.com/changes/2020-02-10-deprecating-auth-through-query-param/</a></p>
<p>原来2020年2月就已经说了，要改要改。不过我确实没留意到这个信息。：（</p>
<p>意思就是说access_token不要放在query参数中，而是要放在header里面。照它说的，改了后就好了。</p>
<p>特此记录。</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust 的 Future 与 Javascript 的 Promise 功能对照参考</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=2d0a7629-2740-435f-9ef7-98735bf4f095">
<div class="article-summary-box-inner">
<span><h1><code>Rust</code>的<code>Future</code>与<code>Javascript</code>的<code>Promise</code>功能对照参考</h1>
<p>学习新鲜技术时，我总是会习惯性向曾经熟悉的内容上靠，甚至套用现有的认知模型。这次也不例外，对照<code>Javascript - Promise/A+ API</code>来记忆一部分<code>Rust Future</code>常用<code>API</code>。</p>
<blockquote>
<p>注意：所有的<code>Rust - Future</code>操作都是以<code>.await</code>结尾的。这是因为，不同于<code>Javascript - Promise/A+</code>，<code>Rust - Future</code>是惰性的。只有被<code>.await</code>指令激活后，在<code>Rust - Future</code>内封装的操作才会被真正地执行。</p>
</blockquote>
<table>
<thead>
<tr>
<th>javascript</th>
<th align="center">rust</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Promise.resolve(...)</td>
<td align="center">use ::async_std::future;future::ready(Ok(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.reject(...)</td>
<td align="center">use ::async_std::future;future::ready(Err(...))</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>Promise.catch(err =&gt; err)</td>
<td align="center">use ::async_std::future;future::ready(...)</td>
<td align="center">在 rust 中，Future 自身不区分异步成功，还是异步失败。需要给异步计算结果套上 Result&lt;T, E&gt; 马甲，来做 resolve 与 reject 的差别处理。</td>
</tr>
<tr>
<td>new Promise(() =&gt; {/* 什么都不做 */})</td>
<td align="center">use ::async_std::future;future::pending()</td>
<td align="center"></td>
</tr>
<tr>
<td>new Promise((resolve, reject) =&gt; setTimeout(() =&gt; { if (Math.random() &gt; .5) { resolve(1); } else { reject(new Error('1')); }}, 500))</td>
<td align="center">use ::async_std::task;use ::std::{thread, time::Duration};use ::rand::prelude::*;task::spawn_blocking(|| { thread::sleep(Duration::from_millis(500)); let mut rng = rand::thread_rng(); if rng.gen() &gt; 0.5f64 { Ok(1) } else { Err('1') }}).await;</td>
<td align="center">1. future::poll_fn&lt;F, T&gt;(f: F) -&gt; T where F: FnMut(&amp;mut Context&lt;'_&gt;) -&gt; Poll 不能被用来构造包含了异步操作的 Future 实例，因为【回调闭包】内的【可修改引用】&amp;mut Context&lt;'_&gt; 不能被 （1）跨线程传递 （2）传递出闭包作用域2. task::spawn_blocking() 【回调闭包】输入参数内的 thread::sleep() 不是阻塞运行 task::spawn_blocking() 的主线程，而是阻塞从【阻塞任务线程池】中分配来运行阻塞任务的【工作线程】。</td>
</tr>
<tr>
<td>Promise.all([promise1, promise2, promise3])</td>
<td align="center">future1.try_join(future2).try_join(future3).await</td>
<td align="center">1. 有一个 promise/future 失败就整体性地失败。2. try_join 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;(T1, T2, T3), E&gt;</td>
</tr>
<tr>
<td>Promise.all([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.join(future2).join(future3).await</td>
<td align="center">1. promise/future 的成功与失败结果都收集2. 返回结果：(T1, T2, T3)</td>
</tr>
<tr>
<td>Promise.race([promise1, promise2, promise3])</td>
<td align="center">future1.try_race(future2).try_race(future3).await</td>
<td align="center">1. 仅只收集第一个成功的 promise/future2. try_race 成员方法要求其 Self 为 Future&lt;Output = Result&lt;T, E&gt;&gt;3. 返回结果：Result&lt;T, E&gt;</td>
</tr>
<tr>
<td>Promise.race([ promise1.catch(err =&gt; err), promise2.catch(err =&gt; err) promise3.catch(err =&gt; err)])</td>
<td align="center">future1.race(future2).race(future3).await</td>
<td align="center">1. 收集第一个结束的 promise/future，无论它是成功结束还是失败收场。2. 返回结果：T</td>
</tr>
</tbody>
</table>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：《通过实战理解 Rust 宏》| Vol. 3</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=dfb80624-2266-448f-87b1-d10f1e8d7c21">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：</strong>《通过实战理解 Rust 宏》</p>
<p><strong>课程时间：</strong> 2021年8月15日 20:30-21:30</p>
<p><strong>课程介绍：</strong></p>
<p>如果想用 Rust 开发大型目，或者学习大型项目代码，特别是框架级别的项目，那么 Rust 的宏机制肯定是一个必须掌握的技能。 例如 datafuse 中的一些配置管理：
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/3/rust-macro-1628478411126.jpg" alt></p>
<p>这就是通过宏实现配置的统一行为，代码参考：
https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/settings.rs#L19</p>
<p>https://github.com/datafuselabs/datafuse/blob/master/fusequery/query/src/sessions/macros.rs</p>
<p>Rust 语言强大的一个特点就是可以创建和利用宏，不过创建宏看起来挺复杂，常常令刚接触 Rust 的开发者生畏惧。 在本次公开课中帮助你理解 Rust Macro 的基本原理，学习如何创自已的 Rust 宏，以及查看源码学习宏的实现。</p>
<h3>课程大纲</h3>
<ul>
<li>什么是 Rust 宏</li>
<li>什么是宏运行原理</li>
<li>如何创建 Rust 宏过程</li>
<li>阅读 datafuse 项目源码， 学习项目中宏的实现</li>
</ul>
<p><strong>讲师介绍</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E8%8B%8F%E6%9E%97%E4%BB%8B%E7%BB%8D.png" alt></p>
<p><img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/%E6%89%AB%E7%A0%81%E5%8F%82%E4%B8%8E.png" alt></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud 项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/T-shirt.png" alt></p>
<h3>课程中苏林老师推荐入门资料：</h3>
<p>Rust在线编辑器: https://play.rust-lang.org/</p>
<p>《Rust语言程序设计》: https://kaisery.github.io/trpl-zh-cn/</p>
<p>打怪通关学习方式Rustlings: https://github.com/rust-lang/rustlings</p>
<p>Rust优秀项目Datafuse： https://github.com/datafuselabs/datafuse</p>
</span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Rust公开课：理解Rust的所有权| Vol 2</summary>
<a class="article-summary-link article-summary-box-outer" href="https://rustcc.cn/article?id=c107b830-9fe1-43dd-94a3-9efcd5544205">
<div class="article-summary-box-inner">
<span><p><strong>课程主题：《理解Rust所有权》</strong></p>
<p><strong>课程时间：2021年8月8日 20:30-21:30</strong></p>
<p><strong>嘉宾讲师： 苏林</strong></p>
<p><strong>嘉宾介绍：</strong></p>
<p>Rust中文社区成员，多点Dmall技术Leader，前折800互联网研发团队负责人、10余年一线研发经验。具有多年的软件开发经验, 熟练Ruby、Java、Rust等开发语言, 同时也参与过Rust中文社区日报维护工作。</p>
<p><strong>课程介绍</strong></p>
<p>本次课程通过10个左右的小例子，带大家理解一下Rust的所有权，Rust引用和借用，Rust变量克隆和复制的理念。</p>
<p><strong>参加课程</strong>
<img src="https://datafuse-1255499614.cos.ap-beijing.myqcloud.com/pbc/Rust-pbc-1.jpg" alt></p>
<p><strong>课程规划</strong></p>
<p>本次活动由：知数堂、Datafuse项目、Rust语言中文社区 共同发起。后期也欢迎Rust爱好者，Rust优秀项目， Data Cloud项目来分享，公开课分享合作联系微信：82565387 备注：Rust 。 公开课嘉宾 &amp; Datafuse contributor都可以获取Datafuse纪念T恤。</p>
</span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<section class="daily-content">
<h2 class="daily-heading">
<time datetime="2021-09-07T01:30:00Z">09-07</time>
</h2>
<ul class="sources card">
<li class="source">
<section>
<h3 class="source-name">cs.CL updates on arXiv.org</h3>
<section class="articles-per-source">
<article>
<details class="article-expander">
<summary class="article-expander__title">ALLWAS: Active Learning on Language models in WASserstein space. (arXiv:2109.01691v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01691">
<div class="article-summary-box-inner">
<span><p>Active learning has emerged as a standard paradigm in areas with scarcity of
labeled training data, such as in the medical domain. Language models have
emerged as the prevalent choice of several natural language tasks due to the
performance boost offered by these models. However, in several domains, such as
medicine, the scarcity of labeled training data is a common issue. Also, these
models may not work well in cases where class imbalance is prevalent. Active
learning may prove helpful in these cases to boost the performance with a
limited label budget. To this end, we propose a novel method using sampling
techniques based on submodular optimization and optimal transport for active
learning in language models, dubbed ALLWAS. We construct a sampling strategy
based on submodular optimization of the designed objective in the gradient
domain. Furthermore, to enable learning from few samples, we propose a novel
strategy for sampling from the Wasserstein barycenters. Our empirical
evaluations on standard benchmark datasets for text classification show that
our methods perform significantly better (&gt;20% relative increase in some cases)
than existing approaches for active learning on language models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Error Detection in Large-Scale Natural Language Understanding Systems Using Transformer Models. (arXiv:2109.01754v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01754">
<div class="article-summary-box-inner">
<span><p>Large-scale conversational assistants like Alexa, Siri, Cortana and Google
Assistant process every utterance using multiple models for domain, intent and
named entity recognition. Given the decoupled nature of model development and
large traffic volumes, it is extremely difficult to identify utterances
processed erroneously by such systems. We address this challenge to detect
domain classification errors using offline Transformer models. We combine
utterance encodings from a RoBERTa model with the Nbest hypothesis produced by
the production system. We then fine-tune end-to-end in a multitask setting
using a small dataset of humanannotated utterances with domain classification
errors. We tested our approach for detecting misclassifications from one domain
that accounts for &lt;0.5% of the traffic in a large-scale conversational AI
system. Our approach achieves an F1 score of 30% outperforming a bi- LSTM
baseline by 16.9% and a standalone RoBERTa model by 4.8%. We improve this
further by 2.2% to 32.2% by ensembling multiple models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Augmentation for Cross-Domain Named Entity Recognition. (arXiv:2109.01758v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01758">
<div class="article-summary-box-inner">
<span><p>Current work in named entity recognition (NER) shows that data augmentation
techniques can produce more robust models. However, most existing techniques
focus on augmenting in-domain data in low-resource scenarios where annotated
data is quite limited. In contrast, we study cross-domain data augmentation for
the NER task. We investigate the possibility of leveraging data from
high-resource domains by projecting it into the low-resource domains.
Specifically, we propose a novel neural architecture to transform the data
representation from a high-resource to a low-resource domain by learning the
patterns (e.g. style, noise, abbreviations, etc.) in the text that
differentiate them and a shared feature space where both domains are aligned.
We experiment with diverse datasets and show that transforming the data to the
low-resource domain representation achieves significant improvements over only
using data from high-resource domains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Representation Learning for Efficient and Effective Similarity Search and Recommendation. (arXiv:2109.01815v1 [cs.IR])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01815">
<div class="article-summary-box-inner">
<span><p>How data is represented and operationalized is critical for building
computational solutions that are both effective and efficient. A common
approach is to represent data objects as binary vectors, denoted \textit{hash
codes}, which require little storage and enable efficient similarity search
through direct indexing into a hash table or through similarity computations in
an appropriate space. Due to the limited expressibility of hash codes, compared
to real-valued representations, a core open challenge is how to generate hash
codes that well capture semantic content or latent properties using a small
number of bits, while ensuring that the hash codes are distributed in a way
that does not reduce their search efficiency. State of the art methods use
representation learning for generating such hash codes, focusing on neural
autoencoder architectures where semantics are encoded into the hash codes by
learning to reconstruct the original inputs of the hash codes. This thesis
addresses the above challenge and makes a number of contributions to
representation learning that (i) improve effectiveness of hash codes through
more expressive representations and a more effective similarity measure than
the current state of the art, namely the Hamming distance, and (ii) improve
efficiency of hash codes by learning representations that are especially suited
to the choice of search method. The contributions are empirically validated on
several tasks related to similarity search and recommendation.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Frustratingly Simple Pretraining Alternatives to Masked Language Modeling. (arXiv:2109.01819v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01819">
<div class="article-summary-box-inner">
<span><p>Masked language modeling (MLM), a self-supervised pretraining objective, is
widely used in natural language processing for learning text representations.
MLM trains a model to predict a random sample of input tokens that have been
replaced by a [MASK] placeholder in a multi-class setting over the entire
vocabulary. When pretraining, it is common to use alongside MLM other auxiliary
objectives on the token or sequence level to improve downstream performance
(e.g. next sentence prediction). However, no previous work so far has attempted
in examining whether other simpler linguistically intuitive or not objectives
can be used standalone as main pretraining objectives. In this paper, we
explore five simple pretraining objectives based on token-level classification
tasks as replacements of MLM. Empirical results on GLUE and SQuAD show that our
proposed methods achieve comparable or better performance to MLM using a
BERT-BASE architecture. We further validate our methods using smaller models,
showing that pretraining a model with 41% of the BERT-BASE's parameters,
BERT-MEDIUM results in only a 1% drop in GLUE scores with our best objective.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Towards Expressive Communication with Internet Memes: A New Multimodal Conversation Dataset and Benchmark. (arXiv:2109.01839v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01839">
<div class="article-summary-box-inner">
<span><p>As a kind of new expression elements, Internet memes are popular and
extensively used in online chatting scenarios since they manage to make
dialogues vivid, moving, and interesting. However, most current dialogue
researches focus on text-only dialogue tasks. In this paper, we propose a new
task named as \textbf{M}eme incorporated \textbf{O}pen-domain \textbf{D}ialogue
(MOD). Compared to previous dialogue tasks, MOD is much more challenging since
it requires the model to understand the multimodal elements as well as the
emotions behind them. To facilitate the MOD research, we construct a
large-scale open-domain multimodal dialogue dataset incorporating abundant
Internet memes into utterances. The dataset consists of $\sim$45K Chinese
conversations with $\sim$606K utterances. Each conversation contains about $13$
utterances with about $4$ Internet memes on average and each utterance equipped
with an Internet meme is annotated with the corresponding emotion. In addition,
we present a simple and effective method, which utilizes a unified generation
network to solve the MOD task. Experimental results demonstrate that our method
trained on the proposed corpus is able to achieve expressive communication
including texts and memes. The corpus and models have been publicly available
at https://github.com/lizekang/DSTC10-MOD.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Supervised Contrastive Learning for Multimodal Unreliable News Detection in COVID-19 Pandemic. (arXiv:2109.01850v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01850">
<div class="article-summary-box-inner">
<span><p>As the digital news industry becomes the main channel of information
dissemination, the adverse impact of fake news is explosively magnified. The
credibility of a news report should not be considered in isolation. Rather,
previously published news articles on the similar event could be used to assess
the credibility of a news report. Inspired by this, we propose a BERT-based
multimodal unreliable news detection framework, which captures both textual and
visual information from unreliable articles utilising the contrastive learning
strategy. The contrastive learner interacts with the unreliable news classifier
to push similar credible news (or similar unreliable news) closer while moving
news articles with similar content but opposite credibility labels away from
each other in the multimodal embedding space. Experimental results on a
COVID-19 related dataset, ReCOVery, show that our model outperforms a number of
competitive baseline in unreliable news detection.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Pushing Paraphrase Away from Original Sentence: A Multi-Round Paraphrase Generation Approach. (arXiv:2109.01862v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01862">
<div class="article-summary-box-inner">
<span><p>In recent years, neural paraphrase generation based on Seq2Seq has achieved
superior performance, however, the generated paraphrase still has the problem
of lack of diversity. In this paper, we focus on improving the diversity
between the generated paraphrase and the original sentence, i.e., making
generated paraphrase different from the original sentence as much as possible.
We propose BTmPG (Back-Translation guided multi-round Paraphrase Generation),
which leverages multi-round paraphrase generation to improve diversity and
employs back-translation to preserve semantic information. We evaluate BTmPG on
two benchmark datasets. Both automatic and human evaluation show BTmPG can
improve the diversity of paraphrase while preserving the semantics of the
original sentence.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncovering the Limits of Text-based Emotion Detection. (arXiv:2109.01900v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01900">
<div class="article-summary-box-inner">
<span><p>Identifying emotions from text is crucial for a variety of real world tasks.
We consider the two largest now-available corpora for emotion classification:
GoEmotions, with 58k messages labelled by readers, and Vent, with 33M
writer-labelled messages. We design a benchmark and evaluate several feature
spaces and learning algorithms, including two simple yet novel models on top of
BERT that outperform previous strong baselines on GoEmotions. Through an
experiment with human participants, we also analyze the differences between how
writers express emotions and how readers perceive them. Our results suggest
that emotions expressed by writers are harder to identify than emotions that
readers perceive. We share a public web interface for researchers to explore
our models.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Neural Network-Based Linguistic Similarity Measure for Entrainment in Conversations. (arXiv:2109.01924v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01924">
<div class="article-summary-box-inner">
<span><p>Linguistic entrainment is a phenomenon where people tend to mimic each other
in conversation. The core instrument to quantify entrainment is a linguistic
similarity measure between conversational partners. Most of the current
similarity measures are based on bag-of-words approaches that rely on
linguistic markers, ignoring the overall language structure and dialogue
context. To address this issue, we propose to use a neural network model to
perform the similarity measure for entrainment. Our model is context-aware, and
it further leverages a novel component to learn the shared high-level
linguistic features across dialogues. We first investigate the effectiveness of
our novel component. Then we use the model to perform similarity measure in a
corpus-based entrainment analysis. We observe promising results for both
evaluation tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Weakly Supervised Relative Spatial Reasoning for Visual Question Answering. (arXiv:2109.01934v1 [cs.CV])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01934">
<div class="article-summary-box-inner">
<span><p>Vision-and-language (V\&amp;L) reasoning necessitates perception of visual
concepts such as objects and actions, understanding semantics and language
grounding, and reasoning about the interplay between the two modalities. One
crucial aspect of visual reasoning is spatial understanding, which involves
understanding relative locations of objects, i.e.\ implicitly learning the
geometry of the scene. In this work, we evaluate the faithfulness of V\&amp;L
models to such geometric understanding, by formulating the prediction of
pair-wise relative locations of objects as a classification as well as a
regression task. Our findings suggest that state-of-the-art transformer-based
V\&amp;L models lack sufficient abilities to excel at this task. Motivated by this,
we design two objectives as proxies for 3D spatial reasoning (SR) -- object
centroid estimation, and relative position estimation, and train V\&amp;L with weak
supervision from off-the-shelf depth estimators. This leads to considerable
improvements in accuracy for the "GQA" visual question answering challenge (in
fully supervised, few-shot, and O.O.D settings) as well as improvements in
relative spatial reasoning. Code and data will be released
\href{https://github.com/pratyay-banerjee/weak_sup_vqa}{here}.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Self-Supervised Detection of Contextual Synonyms in a Multi-Class Setting: Phenotype Annotation Use Case. (arXiv:2109.01935v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01935">
<div class="article-summary-box-inner">
<span><p>Contextualised word embeddings is a powerful tool to detect contextual
synonyms. However, most of the current state-of-the-art (SOTA) deep learning
concept extraction methods remain supervised and underexploit the potential of
the context. In this paper, we propose a self-supervised pre-training approach
which is able to detect contextual synonyms of concepts being training on the
data created by shallow matching. We apply our methodology in the sparse
multi-class setting (over 15,000 concepts) to extract phenotype information
from electronic health records. We further investigate data augmentation
techniques to address the problem of the class sparsity. Our approach achieves
a new SOTA for the unsupervised phenotype concept annotation on clinical text
on F1 and Recall outperforming the previous SOTA with a gain of up to 4.5 and
4.0 absolute points, respectively. After fine-tuning with as little as 20\% of
the labelled data, we also outperform BioBERT and ClinicalBERT. The extrinsic
evaluation on three ICU benchmarks also shows the benefit of using the
phenotypes annotated by our model as features.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">On the ability of monolingual models to learn language-agnostic representations. (arXiv:2109.01942v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01942">
<div class="article-summary-box-inner">
<span><p>Pretrained multilingual models have become a de facto default approach for
zero-shot cross-lingual transfer. Previous work has shown that these models are
able to achieve cross-lingual representations when pretrained on two or more
languages with shared parameters. In this work, we provide evidence that a
model can achieve language-agnostic representations even when pretrained on a
single language. That is, we find that monolingual models pretrained and
finetuned on different languages achieve competitive performance compared to
the ones that use the same target language. Surprisingly, the models show a
similar performance on a same task regardless of the pretraining language. For
example, models pretrained on distant languages such as German and Portuguese
perform similarly on English tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Joint Learning of Chest X-Ray and Radiology Report by Word Region Alignment. (arXiv:2109.01949v1 [cs.LG])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01949">
<div class="article-summary-box-inner">
<span><p>Self-supervised learning provides an opportunity to explore unlabeled chest
X-rays and their associated free-text reports accumulated in clinical routine
without manual supervision. This paper proposes a Joint Image Text
Representation Learning Network (JoImTeRNet) for pre-training on chest X-ray
images and their radiology reports. The model was pre-trained on both the
global image-sentence level and the local image region-word level for
visual-textual matching. Both are bidirectionally constrained on Cross-Entropy
based and ranking-based Triplet Matching Losses. The region-word matching is
calculated using the attention mechanism without direct supervision about their
mapping. The pre-trained multi-modal representation learning paves the way for
downstream tasks concerning image and/or text encoding. We demonstrate the
representation learning quality by cross-modality retrievals and multi-label
classifications on two datasets: OpenI-IU and MIMIC-CXR
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models. (arXiv:2109.01951v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01951">
<div class="article-summary-box-inner">
<span><p>The task of learning from only a few examples (called a few-shot setting) is
of key importance and relevance to a real-world setting. For question answering
(QA), the current state-of-the-art pre-trained models typically need
fine-tuning on tens of thousands of examples to obtain good results. Their
performance degrades significantly in a few-shot setting (&lt; 100 examples). To
address this, we propose a simple fine-tuning framework that leverages
pre-trained text-to-text models and is directly aligned with their pre-training
framework. Specifically, we construct the input as a concatenation of the
question, a mask token representing the answer span and a context. Given this
input, the model is fine-tuned using the same objective as that of its
pre-training objective. Through experimental studies on various few-shot
configurations, we show that this formulation leads to significant gains on
multiple QA benchmarks (an absolute gain of 34.2 F1 points on average when
there are only 16 training examples). The gains extend further when used with
larger models (Eg:- 72.3 F1 on SQuAD using BART-large with only 32 examples)
and translate well to a multilingual setting . On the multilingual TydiQA
benchmark, our model outperforms the XLM-Roberta-large by an absolute margin of
upto 40 F1 points and an average of 33 F1 points in a few-shot setting (&lt;= 64
training examples). We conduct detailed ablation studies to analyze factors
contributing to these gains.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">SideControl: Controlled Open-domain Dialogue Generation via Additive Side Networks. (arXiv:2109.01958v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01958">
<div class="article-summary-box-inner">
<span><p>Transformer-based pre-trained language models boost the performance of
open-domain dialogue systems. Prior works leverage Transformer-based
pre-trained language models to generate texts with desired attributes in two
general approaches: (1) gradient-based methods: updating all latent
representations of pre-trained models with gradients from attribute models; (2)
weighted-decoding methods: re-ranking beam candidates from pre-trained models
with attribute functions. However, gradient-based methods lead to high
computation cost and can easily get overfitted on small training sets, while
weighted-decoding methods are inherently constrained by the low-variance
high-bias pre-trained model. In this work, we propose a novel approach to
control the generation of Transformer-based pre-trained language models: the
SideControl framework, which leverages a novel control attributes loss to
incorporate useful control signals, and is shown to perform well with very
limited training samples. We evaluate our proposed method on two benchmark
open-domain dialogue datasets, and results show that the SideControl framework
has better controllability, higher generation quality and better
sample-efficiency than existing gradient-based and weighted-decoding baselines.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Counterfactual Evaluation for Explainable AI. (arXiv:2109.01962v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01962">
<div class="article-summary-box-inner">
<span><p>While recent years have witnessed the emergence of various explainable
methods in machine learning, to what degree the explanations really represent
the reasoning process behind the model prediction -- namely, the faithfulness
of explanation -- is still an open problem. One commonly used way to measure
faithfulness is \textit{erasure-based} criteria. Though conceptually simple,
erasure-based criterion could inevitably introduce biases and artifacts. We
propose a new methodology to evaluate the faithfulness of explanations from the
\textit{counterfactual reasoning} perspective: the model should produce
substantially different outputs for the original input and its corresponding
counterfactual edited on a faithful feature. Specially, we introduce two
algorithms to find the proper counterfactuals in both discrete and continuous
scenarios and then use the acquired counterfactuals to measure faithfulness.
Empirical results on several datasets show that compared with existing metrics,
our proposed counterfactual evaluation method can achieve top correlation with
the ground truth under diffe
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Learning Hierarchical Structures with Differentiable Nondeterministic Stacks. (arXiv:2109.01982v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01982">
<div class="article-summary-box-inner">
<span><p>Learning hierarchical structures in sequential data -- from simple
algorithmic patterns to natural language -- in a reliable, generalizable way
remains a challenging problem for neural language models. Past work has shown
that recurrent neural networks (RNNs) struggle to generalize on held-out
algorithmic or syntactic patterns without supervision or some inductive bias.
To remedy this, many papers have explored augmenting RNNs with various
differentiable stacks, by analogy with finite automata and pushdown automata.
In this paper, we present a stack RNN model based on the recently proposed
Nondeterministic Stack RNN (NS-RNN) that achieves lower cross-entropy than all
previous stack RNNs on five context-free language modeling tasks (within 0.05
nats of the information-theoretic lower bound), including a task in which the
NS-RNN previously failed to outperform a deterministic stack RNN baseline. Our
model assigns arbitrary positive weights instead of probabilities to stack
actions, and we provide an analysis of why this improves training. We also
propose a restricted version of the NS-RNN that makes it practical to use for
language modeling on natural language and present results on the Penn Treebank
corpus.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Re-entry Prediction for Online Conversations via Self-Supervised Learning. (arXiv:2109.02020v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02020">
<div class="article-summary-box-inner">
<span><p>In recent years, world business in online discussions and opinion sharing on
social media is booming. Re-entry prediction task is thus proposed to help
people keep track of the discussions which they wish to continue. Nevertheless,
existing works only focus on exploiting chatting history and context
information, and ignore the potential useful learning signals underlying
conversation data, such as conversation thread patterns and repeated engagement
of target users, which help better understand the behavior of target users in
conversations. In this paper, we propose three interesting and well-founded
auxiliary tasks, namely, Spread Pattern, Repeated Target user, and Turn
Authorship, as the self-supervised signals for re-entry prediction. These
auxiliary tasks are trained together with the main task in a multi-task manner.
Experimental results on two datasets newly collected from Twitter and Reddit
show that our method outperforms the previous state-of-the-arts with fewer
parameters and faster convergence. Extensive experiments and analysis show the
effectiveness of our proposed models and also point out some key ideas in
designing self-supervised tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Data Efficient Masked Language Modeling for Vision and Language. (arXiv:2109.02040v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02040">
<div class="article-summary-box-inner">
<span><p>Masked language modeling (MLM) is one of the key sub-tasks in vision-language
pretraining. In the cross-modal setting, tokens in the sentence are masked at
random, and the model predicts the masked tokens given the image and the text.
In this paper, we observe several key disadvantages of MLM in this setting.
First, as captions tend to be short, in a third of the sentences no token is
sampled. Second, the majority of masked tokens are stop-words and punctuation,
leading to under-utilization of the image. We investigate a range of
alternative masking strategies specific to the cross-modal setting that address
these shortcomings, aiming for better fusion of text and image in the learned
representation. When pre-training the LXMERT model, our alternative masking
strategies consistently improve over the original masking strategy on three
downstream tasks, especially in low resource settings. Further, our
pre-training approach substantially outperforms the baseline model on a
prompt-based probing task designed to elicit image objects. These results and
our analysis indicate that our method allows for better utilization of the
training data.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Attention Branch Network with Combined Loss Function for Automatic Speaker Verification Spoof Detection. (arXiv:2109.02051v1 [cs.SD])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02051">
<div class="article-summary-box-inner">
<span><p>Many endeavors have sought to develop countermeasure techniques as
enhancements on Automatic Speaker Verification (ASV) systems, in order to make
them more robust against spoof attacks. As evidenced by the latest ASVspoof
2019 countermeasure challenge, models currently deployed for the task of ASV
are, at their best, devoid of suitable degrees of generalization to unseen
attacks. Upon further investigation of the proposed methods, it appears that a
broader three-tiered view of the proposed systems. comprised of the classifier,
feature extraction phase, and model loss function, may to some extent lessen
the problem. Accordingly, the present study proposes the Efficient Attention
Branch Network (EABN) modular architecture with a combined loss function to
address the generalization problem...
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">End-to-End Self-Debiasing Framework for Robust NLU Training. (arXiv:2109.02071v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02071">
<div class="article-summary-box-inner">
<span><p>Existing Natural Language Understanding (NLU) models have been shown to
incorporate dataset biases leading to strong performance on in-distribution
(ID) test sets but poor performance on out-of-distribution (OOD) ones. We
introduce a simple yet effective debiasing framework whereby the shallow
representations of the main model are used to derive a bias model and both
models are trained simultaneously. We demonstrate on three well studied NLU
tasks that despite its simplicity, our method leads to competitive OOD results.
It significantly outperforms other debiasing approaches on two tasks, while
still delivering high in-distribution performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Knowing False Negatives: An Adversarial Training Method for Distantly Supervised Relation Extraction. (arXiv:2109.02099v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02099">
<div class="article-summary-box-inner">
<span><p>Distantly supervised relation extraction (RE) automatically aligns
unstructured text with relation instances in a knowledge base (KB). Due to the
incompleteness of current KBs, sentences implying certain relations may be
annotated as N/A instances, which causes the so-called false negative (FN)
problem. Current RE methods usually overlook this problem, inducing improper
biases in both training and testing procedures. To address this issue, we
propose a two-stage approach. First, it finds out possible FN samples by
heuristically leveraging the memory mechanism of deep neural networks. Then, it
aligns those unlabeled data with the training data into a unified feature space
by adversarial training to assign pseudo labels and further utilize the
information contained in them. Experiments on two wildly-used benchmark
datasets demonstrate the effectiveness of our approach.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Teaching Autoregressive Language Models Complex Tasks By Demonstration. (arXiv:2109.02102v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02102">
<div class="article-summary-box-inner">
<span><p>This paper demonstrates that by fine-tuning an autoregressive language model
(GPT-Neo) on appropriately structured step-by-step demonstrations, it is
possible to teach it to execute a mathematical task that has previously proved
difficult for Transformers - longhand modulo operations - with a relatively
small number of examples. Specifically, we fine-tune GPT-Neo to solve the
numbers__div_remainder task from the DeepMind Mathematics Dataset; Saxton et
al. (<a href="/abs/1904.01557">arXiv:1904.01557</a>) reported below 40% accuracy on this task with 2 million
training examples. We show that after fine-tuning on 200 appropriately
structured demonstrations of solving long division problems and reporting the
remainders, the smallest available GPT-Neo model achieves over 80% accuracy.
This is achieved by constructing an appropriate dataset for fine-tuning, with
no changes to the learning algorithm. These results suggest that fine-tuning
autoregressive language models on small sets of well-crafted demonstrations may
be a useful paradigm for enabling individuals without training in machine
learning to coax such models to perform some kinds of complex multi-step tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Models for Text Coherence Assessment. (arXiv:2109.02176v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02176">
<div class="article-summary-box-inner">
<span><p>Coherence is an important aspect of text quality and is crucial for ensuring
its readability. It is essential desirable for outputs from text generation
systems like summarization, question answering, machine translation, question
generation, table-to-text, etc. An automated coherence scoring model is also
helpful in essay scoring or providing writing feedback. A large body of
previous work has leveraged entity-based methods, syntactic patterns, discourse
relations, and more recently traditional deep learning architectures for text
coherence assessment. Previous work suffers from drawbacks like the inability
to handle long-range dependencies, out-of-vocabulary words, or model sequence
information. We hypothesize that coherence assessment is a cognitively complex
task that requires deeper models and can benefit from other related tasks.
Accordingly, in this paper, we propose four different Transformer-based
architectures for the task: vanilla Transformer, hierarchical Transformer,
multi-task learning-based model, and a model with fact-based input
representation. Our experiments with popular benchmark datasets across multiple
domains on four different coherence assessment tasks demonstrate that our
models achieve state-of-the-art results outperforming existing models by a good
margin.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Nearest Neighbour Few-Shot Learning for Cross-lingual Classification. (arXiv:2109.02221v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02221">
<div class="article-summary-box-inner">
<span><p>Even though large pre-trained multilingual models (e.g. mBERT, XLM-R) have
led to significant performance gains on a wide range of cross-lingual NLP
tasks, success on many downstream tasks still relies on the availability of
sufficient annotated data. Traditional fine-tuning of pre-trained models using
only a few target samples can cause over-fitting. This can be quite limiting as
most languages in the world are under-resourced. In this work, we investigate
cross-lingual adaptation using a simple nearest neighbor few-shot (&lt;15 samples)
inference technique for classification tasks. We experiment using a total of 16
distinct languages across two NLP tasks- XNLI and PAWS-X. Our approach
consistently improves traditional fine-tuning using only a handful of labeled
samples in target locales. We also demonstrate its generalization capability
across tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Efficient Combinatorial Optimization for Word-level Adversarial Textual Attack. (arXiv:2109.02229v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02229">
<div class="article-summary-box-inner">
<span><p>Over the past few years, various word-level textual attack approaches have
been proposed to reveal the vulnerability of deep neural networks used in
natural language processing. Typically, these approaches involve an important
optimization step to determine which substitute to be used for each word in the
original input. However, current research on this step is still rather limited,
from the perspectives of both problem-understanding and problem-solving. In
this paper, we address these issues by uncovering the theoretical properties of
the problem and proposing an efficient local search algorithm (LS) to solve it.
We establish the first provable approximation guarantee on solving the problem
in general cases. Notably, for adversarial textual attack, it is even better
than the previous bound which only holds in special case. Extensive experiments
involving five NLP tasks, six datasets and eleven NLP models show that LS can
largely reduce the number of queries usually by an order of magnitude to
achieve high attack success rates. Further experiments show that the
adversarial examples crafted by LS usually have higher quality, exhibit better
transferability, and can bring more robustness improvement to victim models by
adversarial training.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">BERT might be Overkill: A Tiny but Effective Biomedical Entity Linker based on Residual Convolutional Neural Networks. (arXiv:2109.02237v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02237">
<div class="article-summary-box-inner">
<span><p>Biomedical entity linking is the task of linking entity mentions in a
biomedical document to referent entities in a knowledge base. Recently, many
BERT-based models have been introduced for the task. While these models have
achieved competitive results on many datasets, they are computationally
expensive and contain about 110M parameters. Little is known about the factors
contributing to their impressive performance and whether the
over-parameterization is needed. In this work, we shed some light on the inner
working mechanisms of these large BERT-based models. Through a set of probing
experiments, we have found that the entity linking performance only changes
slightly when the input word order is shuffled or when the attention scope is
limited to a fixed window size. From these observations, we propose an
efficient convolutional neural network with residual connections for biomedical
entity linking. Because of the sparse connectivity and weight sharing
properties, our model has a small number of parameters and is highly efficient.
On five public datasets, our model achieves comparable or even better linking
accuracy than the state-of-the-art BERT-based models while having about 60
times fewer parameters.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">STaCK: Sentence Ordering with Temporal Commonsense Knowledge. (arXiv:2109.02247v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02247">
<div class="article-summary-box-inner">
<span><p>Sentence order prediction is the task of finding the correct order of
sentences in a randomly ordered document. Correctly ordering the sentences
requires an understanding of coherence with respect to the chronological
sequence of events described in the text. Document-level contextual
understanding and commonsense knowledge centered around these events are often
essential in uncovering this coherence and predicting the exact chronological
order. In this paper, we introduce STaCK -- a framework based on graph neural
networks and temporal commonsense knowledge to model global information and
predict the relative order of sentences. Our graph network accumulates temporal
evidence using knowledge of `past' and `future' and formulates sentence
ordering as a constrained edge classification problem. We report results on
five different datasets, and empirically show that the proposed method is
naturally suitable for order prediction. The implementation of this work is
publicly available at: https://github.com/declare-lab/sentence-ordering.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Sent2Span: Span Detection for PICO Extraction in the Biomedical Text without Span Annotations. (arXiv:2109.02254v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02254">
<div class="article-summary-box-inner">
<span><p>The rapid growth in published clinical trials makes it difficult to maintain
up-to-date systematic reviews, which requires finding all relevant trials. This
leads to policy and practice decisions based on out-of-date, incomplete, and
biased subsets of available clinical evidence. Extracting and then normalising
Population, Intervention, Comparator, and Outcome (PICO) information from
clinical trial articles may be an effective way to automatically assign trials
to systematic reviews and avoid searching and screening - the two most
time-consuming systematic review processes. We propose and test a novel
approach to PICO span detection. The major difference between our proposed
method and previous approaches comes from detecting spans without needing
annotated span data and using only crowdsourced sentence-level annotations.
Experiments on two datasets show that PICO span detection results achieve much
higher results for recall when compared to fully supervised methods with PICO
sentence detection at least as good as human annotations. By removing the
reliance on expert annotations for span detection, this work could be used in
human-machine pipeline for turning low-quality crowdsourced, and sentence-level
PICO annotations into structured information that can be used to quickly assign
trials to relevant systematic reviews.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Uncertainty-Aware Balancing for Multilingual and Multi-Domain Neural Machine Translation Training. (arXiv:2109.02284v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02284">
<div class="article-summary-box-inner">
<span><p>Learning multilingual and multi-domain translation model is challenging as
the heterogeneous and imbalanced data make the model converge inconsistently
over different corpora in real world. One common practice is to adjust the
share of each corpus in the training, so that the learning process is balanced
and low-resource cases can benefit from the high resource ones. However,
automatic balancing methods usually depend on the intra- and inter-dataset
characteristics, which is usually agnostic or requires human priors. In this
work, we propose an approach, MultiUAT, that dynamically adjusts the training
data usage based on the model's uncertainty on a small set of trusted clean
data for multi-corpus machine translation. We experiments with two classes of
uncertainty measures on multilingual (16 languages with 4 settings) and
multi-domain settings (4 for in-domain and 2 for out-of-domain on
English-German translation) and demonstrate our approach MultiUAT substantially
outperforms its baselines, including both static and dynamic strategies. We
analyze the cross-domain transfer and show the deficiency of static and
similarity based methods.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Improving Numerical Reasoning Skills in the Modular Approach for Complex Question Answering on Text. (arXiv:2109.02289v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02289">
<div class="article-summary-box-inner">
<span><p>Numerical reasoning skills are essential for complex question answering (CQA)
over text. It requires opertaions including counting, comparison, addition and
subtraction. A successful approach to CQA on text, Neural Module Networks
(NMNs), follows the programmer-interpreter paradigm and leverages specialised
modules to perform compositional reasoning. However, the NMNs framework does
not consider the relationship between numbers and entities in both questions
and paragraphs. We propose effective techniques to improve NMNs' numerical
reasoning capabilities by making the interpreter question-aware and capturing
the relationship between entities and numbers. On the same subset of the DROP
dataset for CQA on text, experimental results show that our additions
outperform the original NMNs by 3.0 points for the overall F1 score.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Enhancing Visual Dialog Questioner with Entity-based Strategy Learning and Augmented Guesser. (arXiv:2109.02297v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02297">
<div class="article-summary-box-inner">
<span><p>Considering the importance of building a good Visual Dialog (VD) Questioner,
many researchers study the topic under a Q-Bot-A-Bot image-guessing game
setting, where the Questioner needs to raise a series of questions to collect
information of an undisclosed image. Despite progress has been made in
Supervised Learning (SL) and Reinforcement Learning (RL), issues still exist.
Firstly, previous methods do not provide explicit and effective guidance for
Questioner to generate visually related and informative questions. Secondly,
the effect of RL is hampered by an incompetent component, i.e., the Guesser,
who makes image predictions based on the generated dialogs and assigns rewards
accordingly. To enhance VD Questioner: 1) we propose a Related entity enhanced
Questioner (ReeQ) that generates questions under the guidance of related
entities and learns entity-based questioning strategy from human dialogs; 2) we
propose an Augmented Guesser (AugG) that is strong and is optimized for the VD
setting especially. Experimental results on the VisDial v1.0 dataset show that
our approach achieves state-of-theart performance on both image-guessing task
and question diversity. Human study further proves that our model generates
more visually related, informative and coherent questions.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">LightTag: Text Annotation Platform. (arXiv:2109.02320v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02320">
<div class="article-summary-box-inner">
<span><p>Text annotation tools assume that their user's goal is to create a labeled
corpus. However, users view annotation as a necessary evil on the way to
deliver business value through NLP. Thus an annotation tool should optimize for
the throughput of the global NLP process, not only the productivity of
individual annotators. LightTag is a text annotation tool designed and built on
that principle. This paper shares our design rationale, data modeling choices,
and user interface decisions then illustrates how those choices serve the full
NLP lifecycle.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Hocalarim: Mining Turkish Student Reviews. (arXiv:2109.02325v1 [cs.CL])</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.02325">
<div class="article-summary-box-inner">
<span><p>We introduce Hocalarim (MyProfessors), the largest student review dataset
available for the Turkish language. It consists of over 5000 professor reviews
left online by students, with different aspects of education rated on a scale
of 1 to 5 stars. We investigate the properties of the dataset and present its
statistics. We examine the impact of students' institution type on their
ratings and the correlation of students' bias to give positive or negative
feedback.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Putting a Spin on Language: A Quantum Interpretation of Unary Connectives for Linguistic Applications. (arXiv:2004.04128v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04128">
<div class="article-summary-box-inner">
<span><p>Extended versions of the Lambek Calculus currently used in computational
linguistics rely on unary modalities to allow for the controlled application of
structural rules affecting word order and phrase structure. These controlled
structural operations give rise to derivational ambiguities that are missed by
the original Lambek Calculus or its pregroup simplification. Proposals for
compositional interpretation of extended Lambek Calculus in the compact closed
category of FVect and linear maps have been made, but in these proposals the
syntax-semantics mapping ignores the control modalities, effectively
restricting their role to the syntax. Our aim is to turn the modalities into
first-class citizens of the vectorial interpretation. Building on the
directional density matrix semantics, we extend the interpretation of the type
system with an extra spin density matrix space. The interpretation of proofs
then results in ambiguous derivations being tensored with orthogonal spin
states. Our method introduces a way of simultaneously representing co-existing
interpretations of ambiguous utterances, and provides a uniform framework for
the integration of lexical and derivational ambiguity.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Quantum Natural Language Processing on Near-Term Quantum Computers. (arXiv:2005.04147v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.04147">
<div class="article-summary-box-inner">
<span><p>In this work, we describe a full-stack pipeline for natural language
processing on near-term quantum computers, aka QNLP. The language-modelling
framework we employ is that of compositional distributional semantics
(DisCoCat), which extends and complements the compositional structure of
pregroup grammars. Within this model, the grammatical reduction of a sentence
is interpreted as a diagram, encoding a specific interaction of words according
to the grammar. It is this interaction which, together with a specific choice
of word embedding, realises the meaning (or "semantics") of a sentence.
Building on the formal quantum-like nature of such interactions, we present a
method for mapping DisCoCat diagrams to quantum circuits. Our methodology is
compatible both with NISQ devices and with established Quantum Machine Learning
techniques, paving the way to near-term applications of quantum technology to
natural language processing.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Impact and dynamics of hate and counter speech online. (arXiv:2009.08392v3 [cs.SI] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08392">
<div class="article-summary-box-inner">
<span><p>Citizen-generated counter speech is a promising way to fight hate speech and
promote peaceful, non-polarized discourse. However, there is a lack of
large-scale longitudinal studies of its effectiveness for reducing hate speech.
To this end, we perform an exploratory analysis of the effectiveness of counter
speech using several different macro- and micro-level measures to analyze
180,000 political conversations that took place on German Twitter over four
years. We report on the dynamic interactions of hate and counter speech over
time and provide insights into whether, as in `classic' bullying situations,
organized efforts are more effective than independent individuals in steering
online discourse. Taken together, our results build a multifaceted picture of
the dynamics of hate and counter speech online. While we make no causal claims
due to the complexity of discourse dynamics, our findings suggest that
organized hate speech is associated with changes in public discourse and that
counter speech -- especially when organized -- may help curb hateful rhetoric
in online discourse.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic with Natural Language Processing (NLP). (arXiv:2010.16413v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.16413">
<div class="article-summary-box-inner">
<span><p>The COVID-19 pandemic has had a significant impact on society, both because
of the serious health effects of COVID-19 and because of public health measures
implemented to slow its spread. Many of these difficulties are fundamentally
information needs; attempts to address these needs have caused an information
overload for both researchers and the public. Natural language processing
(NLP), the branch of artificial intelligence that interprets human language,
can be applied to address many of the information needs made urgent by the
COVID-19 pandemic. This review surveys approximately 150 NLP studies and more
than 50 systems and datasets addressing the COVID-19 pandemic. We detail work
on four core NLP tasks: information retrieval, named entity recognition,
literature-based discovery, and question answering. We also describe work that
directly addresses aspects of the pandemic through four additional tasks: topic
modeling, sentiment and emotion analysis, caseload forecasting, and
misinformation detection. We conclude by discussing observable trends and
remaining challenges.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference. (arXiv:2011.14203v5 [cs.AR] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14203">
<div class="article-summary-box-inner">
<span><p>Transformer-based language models such as BERT provide significant accuracy
improvement for a multitude of natural language processing (NLP) tasks.
However, their hefty computational and memory demands make them challenging to
deploy to resource-constrained edge platforms with strict latency requirements.
We present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware
energy optimization for multi-task NLP. EdgeBERT employs entropy-based early
exit predication in order to perform dynamic voltage-frequency scaling (DVFS),
at a sentence granularity, for minimal energy consumption while adhering to a
prescribed target latency. Computation and memory footprint overheads are
further alleviated by employing a calibrated combination of adaptive attention
span, selective network pruning, and floating-point quantization. Furthermore,
in order to maximize the synergistic benefits of these algorithms in always-on
and intermediate edge computing settings, we specialize a 12nm scalable
hardware accelerator system, integrating a fast-switching low-dropout voltage
regulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,
high-density embedded non-volatile memories (eNVMs) wherein the sparse
floating-point bit encodings of the shared multi-task parameters are carefully
stored. Altogether, latency-aware multi-task NLP inference acceleration on the
EdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy
compared to the conventional inference without early stopping, the
latency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson
Tegra X2 mobile GPU, respectively.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Transformer Feed-Forward Layers Are Key-Value Memories. (arXiv:2012.14913v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14913">
<div class="article-summary-box-inner">
<span><p>Feed-forward layers constitute two-thirds of a transformer model's
parameters, yet their role in the network remains under-explored. We show that
feed-forward layers in transformer-based language models operate as key-value
memories, where each key correlates with textual patterns in the training
examples, and each value induces a distribution over the output vocabulary. Our
experiments show that the learned patterns are human-interpretable, and that
lower layers tend to capture shallow patterns, while upper layers learn more
semantic ones. The values complement the keys' input patterns by inducing
output distributions that concentrate probability mass on tokens likely to
appear immediately after each pattern, particularly in the upper layers.
Finally, we demonstrate that the output of a feed-forward layer is a
composition of its memories, which is subsequently refined throughout the
model's layers via residual connections to produce the final output
distribution.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Emotion Dynamics in Movie Dialogues. (arXiv:2103.01345v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01345">
<div class="article-summary-box-inner">
<span><p>Emotion dynamics is a framework for measuring how an individual's emotions
change over time. It is a powerful tool for understanding how we behave and
interact with the world. In this paper, we introduce a framework to track
emotion dynamics through one's utterances. Specifically we introduce a number
of utterance emotion dynamics (UED) metrics inspired by work in Psychology. We
use this approach to trace emotional arcs of movie characters. We analyze
thousands of such character arcs to test hypotheses that inform our broader
understanding of stories. Notably, we show that there is a tendency for
characters to use increasingly more negative words and become increasingly
emotionally discordant with each other until about 90 percent of the narrative
length. UED also has applications in behavior studies, social sciences, and
public health.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">The Interplay of Variant, Size, and Task Type in Arabic Pre-trained Language Models. (arXiv:2103.06678v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06678">
<div class="article-summary-box-inner">
<span><p>In this paper, we explore the effects of language variants, data sizes, and
fine-tuning task types in Arabic pre-trained language models. To do so, we
build three pre-trained language models across three variants of Arabic: Modern
Standard Arabic (MSA), dialectal Arabic, and classical Arabic, in addition to a
fourth language model which is pre-trained on a mix of the three. We also
examine the importance of pre-training data size by building additional models
that are pre-trained on a scaled-down set of the MSA variant. We compare our
different models to each other, as well as to eight publicly available models
by fine-tuning them on five NLP tasks spanning 12 datasets. Our results suggest
that the variant proximity of pre-training data to fine-tuning data is more
important than the pre-training data size. We exploit this insight in defining
an optimized system selection model for the studied tasks.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Constructive and Toxic Speech Detection for Open-domain Social Media Comments in Vietnamese. (arXiv:2103.10069v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10069">
<div class="article-summary-box-inner">
<span><p>The rise of social media has led to the increasing of comments on online
forums. However, there still exists invalid comments which are not informative
for users. Moreover, those comments are also quite toxic and harmful to people.
In this paper, we create a dataset for constructive and toxic speech detection,
named UIT-ViCTSD (Vietnamese Constructive and Toxic Speech Detection dataset)
with 10,000 human-annotated comments. For these tasks, we propose a system for
constructive and toxic speech detection with the state-of-the-art transfer
learning model in Vietnamese NLP as PhoBERT. With this system, we obtain
F1-scores of 78.59% and 59.40% for classifying constructive and toxic comments,
respectively. Besides, we implement various baseline models as traditional
Machine Learning and Deep Neural Network-Based models to evaluate the dataset.
With the results, we can solve several tasks on the online discussions and
develop the framework for identifying constructiveness and toxicity of
Vietnamese social media comments automatically.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">What's in your Head? Emergent Behaviour in Multi-Task Transformer Models. (arXiv:2104.06129v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06129">
<div class="article-summary-box-inner">
<span><p>The primary paradigm for multi-task training in natural language processing
is to represent the input with a shared pre-trained language model, and add a
small, thin network (head) per task. Given an input, a target head is the head
that is selected for outputting the final prediction. In this work, we examine
the behaviour of non-target heads, that is, the output of heads when given
input that belongs to a different task than the one they were trained for. We
find that non-target heads exhibit emergent behaviour, which may either explain
the target task, or generalize beyond their original task. For example, in a
numerical reasoning task, a span extraction head extracts from the input the
arguments to a computation that results in a number generated by a target
generative head. In addition, a summarization head that is trained with a
target question answering head, outputs query-based summaries when given a
question and a context from which the answer is to be extracted. This emergent
behaviour suggests that multi-task training leads to non-trivial extrapolation
of skills, which can be harnessed for interpretability and generalization.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Planning with Learned Entity Prompts for Abstractive Summarization. (arXiv:2104.07606v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07606">
<div class="article-summary-box-inner">
<span><p>We introduce a simple but flexible mechanism to learn an intermediate plan to
ground the generation of abstractive summaries. Specifically, we prepend (or
prompt) target summaries with entity chains -- ordered sequences of entities
mentioned in the summary. Transformer-based sequence-to-sequence models are
then trained to generate the entity chain and then continue generating the
summary conditioned on the entity chain and the input. We experimented with
both pretraining and finetuning with this content planning objective. When
evaluated on CNN/DailyMail, XSum, SAMSum and BillSum, we demonstrate
empirically that the grounded generation with the planning objective improves
entity specificity and planning in summaries for all datasets, and achieves
state-of-the-art performance on XSum and SAMSum in terms of Rouge. Moreover, we
demonstrate empirically that planning with entity chains provides a mechanism
to control hallucinations in abstractive summaries. By prompting the decoder
with a modified content plan that drops hallucinated entities, we outperform
state-of-the-art approaches for faithfulness when evaluated automatically and
by humans.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Masked Segmental Language Model for Unsupervised Natural Language Segmentation. (arXiv:2104.07829v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07829">
<div class="article-summary-box-inner">
<span><p>Segmentation remains an important preprocessing step both in languages where
"words" or other important syntactic/semantic units (like morphemes) are not
clearly delineated by white space, as well as when dealing with continuous
speech data, where there is often no meaningful pause between words.
Near-perfect supervised methods have been developed for use in resource-rich
languages such as Chinese, but many of the world's languages are both
morphologically complex, and have no large dataset of "gold" segmentations into
meaningful units. To solve this problem, we propose a new type of Segmental
Language Model (Sun and Deng, 2018; Kawakami et al., 2019; Wang et al., 2021)
for use in both unsupervised and lightly supervised segmentation tasks. We
introduce a Masked Segmental Language Model (MSLM) built on a span-masking
transformer architecture, harnessing the power of a bi-directional masked
modeling context and attention. In a series of experiments, our model
consistently outperforms Recurrent SLMs on Chinese (PKU Corpus) in segmentation
quality, and performs similarly to the Recurrent model on English (PTB). We
conclude by discussing the different challenges posed in segmenting
phonemic-type writing systems.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Matching-oriented Product Quantization For Ad-hoc Retrieval. (arXiv:2104.07858v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07858">
<div class="article-summary-box-inner">
<span><p>Product quantization (PQ) is a widely used technique for ad-hoc retrieval.
Recent studies propose supervised PQ, where the embedding and quantization
models can be jointly trained with supervised learning. However, there is a
lack of appropriate formulation of the joint training objective; thus, the
improvements over previous non-supervised baselines are limited in reality. In
this work, we propose the Matching-oriented Product Quantization (MoPQ), where
a novel objective Multinoulli Contrastive Loss (MCL) is formulated. With the
minimization of MCL, we are able to maximize the matching probability of query
and ground-truth key, which contributes to the optimal retrieval accuracy.
Given that the exact computation of MCL is intractable due to the demand of
vast contrastive samples, we further propose the Differentiable Cross-device
Sampling (DCS), which significantly augments the contrastive samples for
precise approximation of MCL. We conduct extensive experimental studies on four
real-world datasets, whose results verify the effectiveness of MoPQ.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08773">
<div class="article-summary-box-inner">
<span><p>Humans (e.g., crowdworkers) have a remarkable ability in solving different
tasks, by simply reading textual instructions that define them and looking at a
few examples. NLP models built with the conventional paradigm, however, often
struggle with generalization across tasks (e.g., a question-answering system
cannot solve classification tasks). A long-standing challenge in AI is to build
a model that is equipped with the understanding of human-readable instructions
that define the tasks, and can generalize to new tasks. To study this, we
introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their
human-authored instructions and 193k task instances. The instructions are
obtained from crowdsourcing instructions used to collect existing NLP datasets
and mapped to a unified schema. We adopt generative pre-trained language models
to encode task-specific instructions along with input and generate task output.
Our results indicate that models can benefit from instructions to generalize
across tasks. These models, however, are far behind supervised task-specific
models, indicating significant room for more progress in this direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">An automated domain-independent text reading, interpreting and extracting approach for reviewing the scientific literature. (arXiv:2107.14638v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14638">
<div class="article-summary-box-inner">
<span><p>It is presented here a machine learning-based (ML) natural language
processing (NLP) approach capable to automatically recognize and extract
categorical and numerical parameters from a corpus of articles. The approach
(named a.RIX) operates with a concomitant/interchangeable use of ML models such
as neuron networks (NNs), latent semantic analysis (LSA), naive-Bayes
classifiers (NBC), and a pattern recognition model using regular expression
(REGEX). A corpus of 7,873 scientific articles dealing with natural products
(NPs) was used to demonstrate the efficiency of the a.RIX engine. The engine
automatically extracts categorical and numerical parameters such as (i) the
plant species from which active molecules are extracted, (ii) the
microorganisms species for which active molecules can act against, and (iii)
the values of minimum inhibitory concentration (MIC) against these
microorganisms. The parameters are extracted without part-of-speech tagging
(POS) and named entity recognition (NER) approaches (i.e. without the need of
text annotation), and the models training is performed with unsupervised
approaches. In this way, a.RIX can be essentially used on articles from any
scientific field. Finally, it can potentially make obsolete the current article
reviewing process in some areas, especially those in which machine learning
models capture texts structure, text semantics, and latent knowledge.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Opinion Prediction with User Fingerprinting. (arXiv:2108.00270v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.00270">
<div class="article-summary-box-inner">
<span><p>Opinion prediction is an emerging research area with diverse real-world
applications, such as market research and situational awareness. We identify
two lines of approaches to the problem of opinion prediction. One uses
topic-based sentiment analysis with time-series modeling, while the other uses
static embedding of text. The latter approaches seek user-specific solutions by
generating user fingerprints. Such approaches are useful in predicting user's
reactions to unseen content. In this work, we propose a novel dynamic
fingerprinting method that leverages contextual embedding of user's comments
conditioned on relevant user's reading history. We integrate BERT variants with
a recurrent neural network to generate predictions. The results show up to 13\%
improvement in micro F1-score compared to previous approaches. Experimental
results show novel insights that were previously unknown such as better
predictions for an increase in dynamic history length, the impact of the nature
of the article on performance, thereby laying the foundation for further
research.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Mitigating harm in language models with conditional-likelihood filtration. (arXiv:2108.07790v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.07790">
<div class="article-summary-box-inner">
<span><p>Language models trained on large-scale unfiltered datasets curated from the
open web acquire systemic biases, prejudices, and harmful views from their
training data. We present a methodology for programmatically identifying and
removing harmful text from web-scale datasets. A pretrained language model is
used to calculate the log-likelihood of researcher-written trigger phrases
conditioned on a specific document, which is used to identify and filter
documents from the dataset. We demonstrate that models trained on this filtered
dataset exhibit lower propensity to generate harmful text, with a marginal
decrease in performance on standard language modeling benchmarks compared to
unfiltered baselines. We provide a partial explanation for this performance gap
by surfacing examples of hate speech and other undesirable content from
standard language modeling benchmarks. Finally, we discuss the generalization
of this method and how trigger phrases which reflect specific values can be
used by researchers to build language models which are more closely aligned
with their values.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">QUEACO: Borrowing Treasures from Weakly-labeled Behavior Data for Query Attribute Value Extraction. (arXiv:2108.08468v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.08468">
<div class="article-summary-box-inner">
<span><p>We study the problem of query attribute value extraction, which aims to
identify named entities from user queries as diverse surface form attribute
values and afterward transform them into formally canonical forms. Such a
problem consists of two phases: {named entity recognition (NER)} and {attribute
value normalization (AVN)}. However, existing works only focus on the NER phase
but neglect equally important AVN. To bridge this gap, this paper proposes a
unified query attribute value extraction system in e-commerce search named
QUEACO, which involves both two phases. Moreover, by leveraging large-scale
weakly-labeled behavior data, we further improve the extraction performance
with less supervision cost. Specifically, for the NER phase, QUEACO adopts a
novel teacher-student network, where a teacher network that is trained on the
strongly-labeled data generates pseudo-labels to refine the weakly-labeled data
for training a student network. Meanwhile, the teacher network can be
dynamically adapted by the feedback of the student's performance on
strongly-labeled data to maximally denoise the noisy supervisions from the weak
labels. For the AVN phase, we also leverage the weakly-labeled
query-to-attribute behavior data to normalize surface form attribute values
from queries into canonical forms from products. Extensive experiments on a
real-world large-scale E-commerce dataset demonstrate the effectiveness of
QUEACO.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Fastformer: Additive Attention Can Be All You Need. (arXiv:2108.09084v6 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.09084">
<div class="article-summary-box-inner">
<span><p>Transformer is a powerful model for text understanding. However, it is
inefficient due to its quadratic complexity to input sequence length. Although
there are many methods on Transformer acceleration, they are still either
inefficient on long sequences or not effective enough. In this paper, we
propose Fastformer, which is an efficient Transformer model based on additive
attention. In Fastformer, instead of modeling the pair-wise interactions
between tokens, we first use additive attention mechanism to model global
contexts, and then further transform each token representation based on its
interaction with global context representations. In this way, Fastformer can
achieve effective context modeling with linear complexity. Extensive
experiments on five datasets show that Fastformer is much more efficient than
many existing Transformer models and can meanwhile achieve comparable or even
better long text modeling performance.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Relation Extraction from Tables using Artificially Generated Metadata. (arXiv:2108.10750v3 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.10750">
<div class="article-summary-box-inner">
<span><p>Relation Extraction (RE) from tables is the task of identifying relations
between pairs of columns of a table. Generally, RE models for this task require
labelled tables for training. These labelled tables can also be generated
artificially from a Knowledge Graph (KG), which makes the cost to acquire them
much lower in comparison to manual annotations. However, unlike real tables,
these synthetic tables lack associated metadata, such as, column-headers,
captions, etc; this is because synthetic tables are created out of KGs that do
not store such metadata. Meanwhile, previous works have shown that metadata is
important for accurate RE from tables. To address this issue, we propose
methods to artificially create some of this metadata for synthetic tables.
Afterward, we experiment with a BERT-based model, in line with recently
published works, that takes as input a combination of proposed artificial
metadata and table content. Our empirical results show that this leads to an
improvement of 9\%-45\% in F1 score, in absolute terms, over 2 tabular
datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">A Partition Filter Network for Joint Entity and Relation Extraction. (arXiv:2108.12202v5 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.12202">
<div class="article-summary-box-inner">
<span><p>In joint entity and relation extraction, existing work either sequentially
encode task-specific features, leading to an imbalance in inter-task feature
interaction where features extracted later have no direct contact with those
that come first. Or they encode entity features and relation features in a
parallel manner, meaning that feature representation learning for each task is
largely independent of each other except for input sharing. We propose a
partition filter network to model two-way interaction between tasks properly,
where feature encoding is decomposed into two steps: partition and filter. In
our encoder, we leverage two gates: entity and relation gate, to segment
neurons into two task partitions and one shared partition. The shared partition
represents inter-task information valuable to both tasks and is evenly shared
across two tasks to ensure proper two-way interaction. The task partitions
represent intra-task information and are formed through concerted efforts of
both gates, making sure that encoding of task-specific features is dependent
upon each other. Experiment results on six public datasets show that our model
performs significantly better than previous approaches. In addition, contrary
to what previous work claims, our auxiliary experiments suggest that relation
prediction is contributory to named entity prediction in a non-negligible way.
The source code can be found at https://github.com/Coopercoppers/PFN.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">CSDS: A Fine-Grained Chinese Dataset for Customer Service Dialogue Summarization. (arXiv:2108.13139v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13139">
<div class="article-summary-box-inner">
<span><p>Dialogue summarization has drawn much attention recently. Especially in the
customer service domain, agents could use dialogue summaries to help boost
their works by quickly knowing customer's issues and service progress. These
applications require summaries to contain the perspective of a single speaker
and have a clear topic flow structure, while neither are available in existing
datasets. Therefore, in this paper, we introduce a novel Chinese dataset for
Customer Service Dialogue Summarization (CSDS). CSDS improves the abstractive
summaries in two aspects: (1) In addition to the overall summary for the whole
dialogue, role-oriented summaries are also provided to acquire different
speakers' viewpoints. (2) All the summaries sum up each topic separately, thus
containing the topic-level structure of the dialogue. We define tasks in CSDS
as generating the overall summary and different role-oriented summaries for a
given dialogue. Next, we compare various summarization methods on CSDS, and
experiment results show that existing methods are prone to generate redundant
and incoherent summaries. Besides, the performance becomes much worse when
analyzing the performance on role-oriented summaries and topic structures. We
hope that this study could benchmark Chinese dialogue summarization and benefit
further studies.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions. (arXiv:2108.13875v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2108.13875">
<div class="article-summary-box-inner">
<span><p>Scenario-based question answering (SQA) requires retrieving and reading
paragraphs from a large corpus to answer a question which is contextualized by
a long scenario description. Since a scenario contains both keyphrases for
retrieval and much noise, retrieval for SQA is extremely difficult. Moreover,
it can hardly be supervised due to the lack of relevance labels of paragraphs
for SQA. To meet the challenge, in this paper we propose a joint
retriever-reader model called JEEVES where the retriever is implicitly
supervised only using QA labels via a novel word weighting mechanism. JEEVES
significantly outperforms a variety of strong baselines on multiple-choice
questions in three SQA datasets.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">M^2-MedDialog: A Dataset and Benchmarks for Multi-domain Multi-service Medical Dialogues. (arXiv:2109.00430v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00430">
<div class="article-summary-box-inner">
<span><p>Medical dialogue systems (MDSs) aim to assist doctors and patients with a
range of professional medical services, i.e., diagnosis, consultation, and
treatment. However, one-stop MDS is still unexplored because: (1) no dataset
has so large-scale dialogues contains both multiple medical services and
fine-grained medical labels (i.e., intents, slots, values); (2) no model has
addressed a MDS based on multiple-service conversations in a unified framework.
In this work, we first build a Multiple-domain Multiple-service medical
dialogue (M^2-MedDialog)dataset, which contains 1,557 conversations between
doctors and patients, covering 276 types of diseases, 2,468 medical entities,
and 3 specialties of medical services. To the best of our knowledge, it is the
only medical dialogue dataset that includes both multiple medical services and
fine-grained medical labels. Then, we formulate a one-stop MDS as a
sequence-to-sequence generation problem. We unify a MDS with causal language
modeling and conditional causal language modeling, respectively. Specifically,
we employ several pretrained models (i.e., BERT-WWM, BERT-MED, GPT2, and MT5)
and their variants to get benchmarks on M^2-MedDialog dataset. We also propose
pseudo labeling and natural perturbation methods to expand M2-MedDialog dataset
and enhance the state-of-the-art pretrained models. We demonstrate the results
achieved by the benchmarks so far through extensive experiments on
M2-MedDialog. We release the dataset, the code, as well as the evaluation
scripts to facilitate future research in this important research direction.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Imposing Relation Structure in Language-Model Embeddings Using Contrastive Learning. (arXiv:2109.00840v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.00840">
<div class="article-summary-box-inner">
<span><p>Though language model text embeddings have revolutionized NLP research, their
ability to capture high-level semantic information, such as relations between
entities in text, is limited. In this paper, we propose a novel contrastive
learning framework that trains sentence embeddings to encode the relations in a
graph structure. Given a sentence (unstructured text) and its graph, we use
contrastive learning to impose relation-related structure on the token-level
representations of the sentence obtained with a CharacterBERT (El Boukkouri et
al.,2020) model. The resulting relation-aware sentence embeddings achieve
state-of-the-art results on the relation extraction task using only a simple
KNN classifier, thereby demonstrating the success of the proposed method.
Additional visualization by a tSNE analysis shows the effectiveness of the
learned representation space compared to baselines. Furthermore, we show that
we can learn a different space for named entity recognition, again using a
contrastive learning objective, and demonstrate how to successfully combine
both representation spaces in an entity-relation task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation. (arXiv:2109.01048v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01048">
<div class="article-summary-box-inner">
<span><p>Existing technologies expand BERT from different perspectives, e.g. designing
different pre-training tasks, different semantic granularities and different
model architectures. Few models consider expanding BERT from different text
formats. In this paper, we propose a heterogeneous knowledge language model
(HKLM), a unified pre-trained language model (PLM) for all forms of text,
including unstructured text, semi-structured text and well-structured text. To
capture the corresponding relations among these multi-format knowledge, our
approach uses masked language model objective to learn word knowledge, uses
triple classification objective and title matching objective to learn entity
knowledge and topic knowledge respectively. To obtain the aforementioned
multi-format text, we construct a corpus in the tourism domain and conduct
experiments on 5 tourism NLP datasets. The results show that our approach
outperforms the pre-training of plain text using only 1/4 of the data. The
code, datasets, corpus and knowledge graph will be released.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Contextualized Embeddings based Convolutional Neural Networks for Duplicate Question Identification. (arXiv:2109.01560v2 [cs.CL] UPDATED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2109.01560">
<div class="article-summary-box-inner">
<span><p>Question Paraphrase Identification (QPI) is a critical task for large-scale
Question-Answering forums. The purpose of QPI is to determine whether a given
pair of questions are semantically identical or not. Previous approaches for
this task have yielded promising results, but have often relied on complex
recurrence mechanisms that are expensive and time-consuming in nature. In this
paper, we propose a novel architecture combining a Bidirectional Transformer
Encoder with Convolutional Neural Networks for the QPI task. We produce the
predictions from the proposed architecture using two different inference
setups: Siamese and Matched Aggregation. Experimental results demonstrate that
our model achieves state-of-the-art performance on the Quora Question Pairs
dataset. We empirically prove that the addition of convolution layers to the
model architecture improves the results in both inference setups. We also
investigate the impact of partial and complete fine-tuning and analyze the
trade-off between computational power and accuracy in the process. Based on the
obtained results, we conclude that the Matched-Aggregation setup consistently
outperforms the Siamese setup. Our work provides insights into what
architecture combinations and setups are likely to produce better results for
the QPI task.
</p></span>
</div>
</a>
</details>
</article>
<article>
<details class="article-expander">
<summary class="article-expander__title">Handwritten Character Recognition of South Indian Scripts: A Review. (arXiv:1106.0107v1 [cs.CV] CROSS LISTED)</summary>
<a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1106.0107">
<div class="article-summary-box-inner">
<span><p>Handwritten character recognition is always a frontier area of research in
the field of pattern recognition and image processing and there is a large
demand for OCR on hand written documents. Even though, sufficient studies have
performed in foreign scripts like Chinese, Japanese and Arabic characters, only
a very few work can be traced for handwritten character recognition of Indian
scripts especially for the South Indian scripts. This paper provides an
overview of offline handwritten character recognition in South Indian Scripts,
namely Malayalam, Tamil, Kannada and Telungu.
</p></span>
</div>
</a>
</details>
</article>
</section>
</section>
</li>
</ul>
</section>
<footer>
<time id="build-timestamp" datetime="2021-09-07 01:49:01.704766204 UTC">2021-09-07 01:49:01 UTC</time>
<span><a class="footer-link" href="https://github.com/NotCraft/NotFeed"> notfeed 0.2.3</a></span>
</footer>
<script src="index.js"></script>
</body>
</html>